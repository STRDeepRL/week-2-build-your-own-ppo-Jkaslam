{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.25, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.5, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.25, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.5, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.25, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.5, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.40228514348273164, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01303635153229455, "policy_loss": -0.014295487025083275, "vf_loss": 0.0037166654754533586, "vf_explained_var": -0.07566557954996825, "kl": 0.006700659619367806, "entropy": 1.9393296912312508, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "sampler_results": {"episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.7540000000000001, "episode_reward_mean": -0.01343750000000004, "episode_len_mean": 177.5, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"red_0": -1.033, "blue_0": -1.041}, "policy_reward_max": {"red_0": 1.124, "blue_0": 0.9259999999999999}, "policy_reward_mean": {"red_0": -0.20762499999999995, "blue_0": 0.1941875}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.25, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.5, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.25, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.5, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.25, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.5, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028193360849513, "mean_inference_ms": 1.449243311870128, "mean_action_processing_ms": 0.06077462746912702, "mean_env_wait_ms": 0.0858826381607246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021156668663024902, "StateBufferConnector_ms": 0.0013783574104309082, "ViewRequirementAgentConnector_ms": 0.030668824911117554}}, "episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.7540000000000001, "episode_reward_mean": -0.01343750000000004, "episode_len_mean": 177.5, "episodes_this_iter": 16, "policy_reward_min": {"red_0": -1.033, "blue_0": -1.041}, "policy_reward_max": {"red_0": 1.124, "blue_0": 0.9259999999999999}, "policy_reward_mean": {"red_0": -0.20762499999999995, "blue_0": 0.1941875}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22028193360849513, "mean_inference_ms": 1.449243311870128, "mean_action_processing_ms": 0.06077462746912702, "mean_env_wait_ms": 0.0858826381607246, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021156668663024902, "StateBufferConnector_ms": 0.0013783574104309082, "ViewRequirementAgentConnector_ms": 0.030668824911117554}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000, "num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.45887034370392, "num_env_steps_trained_throughput_per_sec": 103.45887034370392, "timesteps_total": 4000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 38662.673, "sample_time_ms": 7326.403, "learn_time_ms": 31318.565, "learn_throughput": 127.72, "synch_weights_time_ms": 17.222}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 4000, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 16, "training_iteration": 1, "trial_id": "d67e4_00000", "date": "2023-09-20_22-09-44", "timestamp": 1695262184, "time_this_iter_s": 38.664963245391846, "time_total_s": 38.664963245391846, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fe320>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 38.664963245391846, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 33.698214285714286, "ram_util_percent": 47.192857142857136}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.12903225806451613, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.5161290322580645, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.12903225806451613, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.5161290322580645, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.12903225806451613, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.5161290322580645, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5166712576290593, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01692663876977652, "policy_loss": -0.019089102900397847, "vf_loss": 0.0033876873104873085, "vf_explained_var": -0.010813174831370512, "kl": 0.011926588996572089, "entropy": 1.9166971736898024, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 1440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "sampler_results": {"episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.7540000000000001, "episode_reward_mean": 0.03890322580645155, "episode_len_mean": 218.41935483870967, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.041}, "policy_reward_max": {"red_0": 1.124, "blue_0": 1.0779999999999998}, "policy_reward_mean": {"red_0": -0.2533548387096774, "blue_0": 0.292258064516129}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.12903225806451613, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.5161290322580645, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.12903225806451613, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.5161290322580645, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.12903225806451613, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.5161290322580645, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2208547614983886, "mean_inference_ms": 1.4525719472428864, "mean_action_processing_ms": 0.06093749290813008, "mean_env_wait_ms": 0.08572680355261625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020515149639498804, "StateBufferConnector_ms": 0.001388211404123614, "ViewRequirementAgentConnector_ms": 0.030762918533817414}}, "episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.7540000000000001, "episode_reward_mean": 0.03890322580645155, "episode_len_mean": 218.41935483870967, "episodes_this_iter": 15, "policy_reward_min": {"red_0": -1.034, "blue_0": -1.041}, "policy_reward_max": {"red_0": 1.124, "blue_0": 1.0779999999999998}, "policy_reward_mean": {"red_0": -0.2533548387096774, "blue_0": 0.292258064516129}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2208547614983886, "mean_inference_ms": 1.4525719472428864, "mean_action_processing_ms": 0.06093749290813008, "mean_env_wait_ms": 0.08572680355261625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020515149639498804, "StateBufferConnector_ms": 0.001388211404123614, "ViewRequirementAgentConnector_ms": 0.030762918533817414}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000, "num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.55394578505654, "num_env_steps_trained_throughput_per_sec": 103.55394578505654, "timesteps_total": 8000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 16000, "timers": {"training_iteration_time_ms": 38644.935, "sample_time_ms": 7332.289, "learn_time_ms": 31294.917, "learn_throughput": 127.816, "synch_weights_time_ms": 17.259}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 8000, "num_agent_steps_sampled": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 31, "training_iteration": 2, "trial_id": "d67e4_00000", "date": "2023-09-20_22-10-22", "timestamp": 1695262222, "time_this_iter_s": 38.62979793548584, "time_total_s": 77.29476118087769, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fde10>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 77.29476118087769, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 34.641818181818174, "ram_util_percent": 47.232727272727246}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.23529411764705882, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.43137254901960786, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.23529411764705882, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.43137254901960786, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.23529411764705882, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.43137254901960786, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.582254243727463, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.022285112511720703, "policy_loss": -0.024550455118696846, "vf_loss": 0.0031301801149690315, "vf_explained_var": 0.18815511769304674, "kl": 0.012968165038737215, "entropy": 1.8933800790458917, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 2400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "sampler_results": {"episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.768, "episode_reward_mean": 0.025411764705882297, "episode_len_mean": 218.31372549019608, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.217, "blue_0": 1.314}, "policy_reward_mean": {"red_0": -0.12541176470588236, "blue_0": 0.1508235294117647}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.23529411764705882, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.43137254901960786, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.23529411764705882, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.43137254901960786, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.23529411764705882, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.43137254901960786, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22153545247810086, "mean_inference_ms": 1.458239255257768, "mean_action_processing_ms": 0.06115342190374543, "mean_env_wait_ms": 0.08592374814866423, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020255761988022748, "StateBufferConnector_ms": 0.0014069033604042203, "ViewRequirementAgentConnector_ms": 0.030858376446892235}}, "episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.768, "episode_reward_mean": 0.025411764705882297, "episode_len_mean": 218.31372549019608, "episodes_this_iter": 20, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.217, "blue_0": 1.314}, "policy_reward_mean": {"red_0": -0.12541176470588236, "blue_0": 0.1508235294117647}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22153545247810086, "mean_inference_ms": 1.458239255257768, "mean_action_processing_ms": 0.06115342190374543, "mean_env_wait_ms": 0.08592374814866423, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020255761988022748, "StateBufferConnector_ms": 0.0014069033604042203, "ViewRequirementAgentConnector_ms": 0.030858376446892235}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000, "num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.98572945052483, "num_env_steps_trained_throughput_per_sec": 102.98572945052483, "timesteps_total": 12000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 24000, "timers": {"training_iteration_time_ms": 38710.063, "sample_time_ms": 7377.423, "learn_time_ms": 31314.841, "learn_throughput": 127.735, "synch_weights_time_ms": 17.317}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 12000, "num_agent_steps_sampled": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 51, "training_iteration": 3, "trial_id": "d67e4_00000", "date": "2023-09-20_22-11-02", "timestamp": 1695262262, "time_this_iter_s": 38.84323501586914, "time_total_s": 116.13799619674683, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fe680>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 116.13799619674683, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 34.17142857142857, "ram_util_percent": 47.36964285714286}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.3055555555555556, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3888888888888889, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3055555555555556, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.3888888888888889, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3055555555555556, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3888888888888889, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7842862197974075, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.024780411593383178, "policy_loss": -0.027570636102124506, "vf_loss": 0.00415069632263112, "vf_explained_var": 0.15567374937236308, "kl": 0.012887009403547367, "entropy": 1.8625253926962615, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 3360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "sampler_results": {"episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.932, "episode_reward_mean": 0.02904166666666662, "episode_len_mean": 208.68055555555554, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.404, "blue_0": 1.314}, "policy_reward_mean": {"red_0": -0.03149999999999999, "blue_0": 0.06054166666666665}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.3055555555555556, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3888888888888889, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3055555555555556, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.3888888888888889, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3055555555555556, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3888888888888889, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22187490548878336, "mean_inference_ms": 1.4613700979542967, "mean_action_processing_ms": 0.06132838374653867, "mean_env_wait_ms": 0.0860537458264308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02000464333428277, "StateBufferConnector_ms": 0.0014223986201816136, "ViewRequirementAgentConnector_ms": 0.03109806113772922}}, "episode_reward_max": 0.9189999999999999, "episode_reward_min": -0.932, "episode_reward_mean": 0.02904166666666662, "episode_len_mean": 208.68055555555554, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.404, "blue_0": 1.314}, "policy_reward_mean": {"red_0": -0.03149999999999999, "blue_0": 0.06054166666666665}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22187490548878336, "mean_inference_ms": 1.4613700979542967, "mean_action_processing_ms": 0.06132838374653867, "mean_env_wait_ms": 0.0860537458264308, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02000464333428277, "StateBufferConnector_ms": 0.0014223986201816136, "ViewRequirementAgentConnector_ms": 0.03109806113772922}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000, "num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.86847473725159, "num_env_steps_trained_throughput_per_sec": 102.86847473725159, "timesteps_total": 16000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 32000, "timers": {"training_iteration_time_ms": 38753.695, "sample_time_ms": 7399.647, "learn_time_ms": 31336.26, "learn_throughput": 127.648, "synch_weights_time_ms": 17.299}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 16000, "num_agent_steps_sampled": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 72, "training_iteration": 4, "trial_id": "d67e4_00000", "date": "2023-09-20_22-11-41", "timestamp": 1695262301, "time_this_iter_s": 38.88800311088562, "time_total_s": 155.02599930763245, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d088ee0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 155.02599930763245, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 34.63272727272727, "ram_util_percent": 47.43818181818183}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.3894736842105263, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3368421052631579, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3894736842105263, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.3368421052631579, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3894736842105263, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3368421052631579, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8283337438789506, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03511224858351246, "policy_loss": -0.0386521352223402, "vf_loss": 0.004116869698555093, "vf_explained_var": 0.2497056022907297, "kl": 0.016312493444574253, "entropy": 1.7810471159716448, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 4320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "sampler_results": {"episode_reward_max": 0.9199999999999999, "episode_reward_min": -0.932, "episode_reward_mean": 0.04547368421052627, "episode_len_mean": 199.34736842105264, "episode_media": {}, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.4060000000000001, "blue_0": 1.314}, "policy_reward_mean": {"red_0": 0.09092631578947369, "blue_0": -0.045452631578947376}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.3894736842105263, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.3368421052631579, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.3894736842105263, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.3368421052631579, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.3894736842105263, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.3368421052631579, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22217112545863765, "mean_inference_ms": 1.464263539060722, "mean_action_processing_ms": 0.061483190569328265, "mean_env_wait_ms": 0.08622220376482695, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01978736174734015, "StateBufferConnector_ms": 0.0014147005583110609, "ViewRequirementAgentConnector_ms": 0.031052012192575557}}, "episode_reward_max": 0.9199999999999999, "episode_reward_min": -0.932, "episode_reward_mean": 0.04547368421052627, "episode_len_mean": 199.34736842105264, "episodes_this_iter": 23, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.4060000000000001, "blue_0": 1.314}, "policy_reward_mean": {"red_0": 0.09092631578947369, "blue_0": -0.045452631578947376}, "hist_stats": {"episode_reward": [0.9119999999999999, -0.22599999999999998, -0.504, -0.363, -0.10000000000000009, 0.31699999999999995, 0.9189999999999999, -0.09999999999999998, -0.019000000000000017, -0.08700000000000006, -0.2390000000000001, -0.17600000000000005, 0.4119999999999999, -0.7540000000000001, -0.31699999999999995, 0.10999999999999988, 0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998], "episode_lengths": [300, 217, 154, 112, 181, 57, 300, 32, 158, 300, 73, 54, 300, 228, 253, 121, 300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233], "policy_red_0_reward": [0.46199999999999997, -1.033, -1.028, -1.011, -1.026, 0.821, 0.45999999999999996, -1.001, -0.524, -0.03800000000000003, 0.7659999999999999, -1.009, 0.45599999999999996, 0.2869999999999999, -1.0279999999999998, 1.124, -0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761], "policy_blue_0_reward": [0.44999999999999996, 0.8069999999999999, 0.524, 0.6479999999999999, 0.9259999999999999, -0.504, 0.45899999999999996, 0.901, 0.505, -0.04900000000000004, -1.005, 0.833, -0.04400000000000003, -1.041, 0.711, -1.014, 0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22217112545863765, "mean_inference_ms": 1.464263539060722, "mean_action_processing_ms": 0.061483190569328265, "mean_env_wait_ms": 0.08622220376482695, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01978736174734015, "StateBufferConnector_ms": 0.0014147005583110609, "ViewRequirementAgentConnector_ms": 0.031052012192575557}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000, "num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.84964705621273, "num_env_steps_trained_throughput_per_sec": 102.84964705621273, "timesteps_total": 20000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 40000, "timers": {"training_iteration_time_ms": 38781.298, "sample_time_ms": 7411.923, "learn_time_ms": 31351.631, "learn_throughput": 127.585, "synch_weights_time_ms": 17.26}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 20000, "num_agent_steps_sampled": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 95, "training_iteration": 5, "trial_id": "d67e4_00000", "date": "2023-09-20_22-12-20", "timestamp": 1695262340, "time_this_iter_s": 38.89572501182556, "time_total_s": 193.921724319458, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d089a20>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 193.921724319458, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 34.71071428571428, "ram_util_percent": 47.42142857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.46, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.28, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.46, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.28, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.46, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.28, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9766839114173005, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.03217730354347926, "policy_loss": -0.0352349519822989, "vf_loss": 0.00333039542571593, "vf_explained_var": 0.38663906877239546, "kl": 0.015282826104795432, "entropy": 1.66411459967494, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 5280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "sampler_results": {"episode_reward_max": 0.9359999999999999, "episode_reward_min": -0.932, "episode_reward_mean": 0.02240999999999995, "episode_len_mean": 198.46, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.04, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.4060000000000001, "blue_0": 1.314}, "policy_reward_mean": {"red_0": 0.19088000000000002, "blue_0": -0.16846999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.46, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.28, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.46, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.28, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.46, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.28, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999], "episode_lengths": [300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117], "policy_red_0_reward": [-0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129], "policy_blue_0_reward": [0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22267046909543914, "mean_inference_ms": 1.4680774920773445, "mean_action_processing_ms": 0.06170108477376702, "mean_env_wait_ms": 0.08640360903511546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01966381072998047, "StateBufferConnector_ms": 0.0014290809631347656, "ViewRequirementAgentConnector_ms": 0.031094908714294434}}, "episode_reward_max": 0.9359999999999999, "episode_reward_min": -0.932, "episode_reward_mean": 0.02240999999999995, "episode_len_mean": 198.46, "episodes_this_iter": 21, "policy_reward_min": {"red_0": -1.04, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.4060000000000001, "blue_0": 1.314}, "policy_reward_mean": {"red_0": 0.19088000000000002, "blue_0": -0.16846999999999998}, "hist_stats": {"episode_reward": [0.4139999999999999, -0.4590000000000001, 0.020999999999999908, 0.9189999999999999, -0.07900000000000006, 0.4039999999999999, 0.4129999999999999, -0.4930000000000001, -0.4700000000000001, -0.46799999999999997, 0.03499999999999992, 0.4179999999999999, 0.4159999999999999, 0.564, -0.21400000000000008, 0.17400000000000015, -0.14400000000000002, -0.09600000000000007, -0.43900000000000006, 0.20399999999999996, -0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999], "episode_lengths": [300, 141, 297, 300, 300, 300, 300, 145, 300, 298, 298, 300, 300, 135, 217, 101, 46, 300, 284, 91, 237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117], "policy_red_0_reward": [-0.04100000000000003, -1.018, -0.544, 0.46299999999999997, -0.05100000000000004, 0.45899999999999996, 0.45699999999999996, -1.03, -1.034, -0.5339999999999999, -0.533, -0.03400000000000002, -0.046000000000000034, -0.514, -0.532, -0.5069999999999999, 0.859, -0.047000000000000035, 0.595, 1.217, 0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129], "policy_blue_0_reward": [0.45499999999999996, 0.5589999999999999, 0.565, 0.45599999999999996, -0.028000000000000018, -0.05500000000000004, -0.04400000000000003, 0.5369999999999999, 0.564, 0.06599999999999995, 0.568, 0.45199999999999996, 0.46199999999999997, 1.0779999999999998, 0.31799999999999995, 0.681, -1.003, -0.04900000000000004, -1.034, -1.013, -1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22267046909543914, "mean_inference_ms": 1.4680774920773445, "mean_action_processing_ms": 0.06170108477376702, "mean_env_wait_ms": 0.08640360903511546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01966381072998047, "StateBufferConnector_ms": 0.0014290809631347656, "ViewRequirementAgentConnector_ms": 0.031094908714294434}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000, "num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.76533880800456, "num_env_steps_trained_throughput_per_sec": 102.76533880800456, "timesteps_total": 24000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 48000, "timers": {"training_iteration_time_ms": 38805.018, "sample_time_ms": 7417.794, "learn_time_ms": 31369.52, "learn_throughput": 127.512, "synch_weights_time_ms": 17.215}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 24000, "num_agent_steps_sampled": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 116, "training_iteration": 6, "trial_id": "d67e4_00000", "date": "2023-09-20_22-12-59", "timestamp": 1695262379, "time_this_iter_s": 38.92770600318909, "time_total_s": 232.8494303226471, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fdfc0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 232.8494303226471, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 34.401785714285715, "ram_util_percent": 47.46249999999999}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.22, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.22, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.22, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.113151096785441, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.021484332356279386, "policy_loss": -0.02431136181827848, "vf_loss": 0.003130154071489718, "vf_explained_var": 0.41064025306453306, "kl": 0.014014799026930973, "entropy": 1.5410072438418865, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 6240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "sampler_results": {"episode_reward_max": 0.9359999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.01783000000000004, "episode_len_mean": 185.39, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"red_0": -1.056, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.43, "blue_0": 1.314}, "policy_reward_mean": {"red_0": 0.30387999999999993, "blue_0": -0.32170999999999994}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.57, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.22, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.57, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.22, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.57, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.22, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999, 0.11099999999999977, -0.721, -0.16100000000000003, 0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999], "episode_lengths": [237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117, 277, 212, 49, 67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80], "policy_red_0_reward": [0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129, 0.6439999999999999, -1.056, 0.849, 1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751], "policy_blue_0_reward": [-1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014, -0.533, 0.33499999999999996, -1.01, -1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.222765870345776, "mean_inference_ms": 1.4704015978280418, "mean_action_processing_ms": 0.061816746895055175, "mean_env_wait_ms": 0.08663062461774965, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019663333892822266, "StateBufferConnector_ms": 0.0014312267303466797, "ViewRequirementAgentConnector_ms": 0.031211018562316895}}, "episode_reward_max": 0.9359999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.01783000000000004, "episode_len_mean": 185.39, "episodes_this_iter": 20, "policy_reward_min": {"red_0": -1.056, "blue_0": -1.054}, "policy_reward_max": {"red_0": 1.43, "blue_0": 1.314}, "policy_reward_mean": {"red_0": 0.30387999999999993, "blue_0": -0.32170999999999994}, "hist_stats": {"episode_reward": [-0.768, -0.44600000000000006, 0.9159999999999999, 0.8049999999999999, 0.4039999999999999, -0.369, 0.42499999999999993, -0.4650000000000002, -0.7120000000000001, -0.4690000000000001, -0.09700000000000009, -0.05400000000000005, 0.397, 0.41899999999999993, 0.4049999999999999, -0.28700000000000003, -0.43000000000000005, -0.125, 0.345, -0.85, 0.401, 0.41899999999999993, 0.798, -0.06600000000000006, 0.42899999999999994, 0.4079999999999999, -0.2579999999999999, 0.262, -0.602, 0.9159999999999999, -0.932, 0.6419999999999999, -0.557, -0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999, 0.11099999999999977, -0.721, -0.16100000000000003, 0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999], "episode_lengths": [237, 287, 300, 59, 300, 114, 300, 292, 222, 295, 180, 171, 184, 300, 300, 237, 134, 193, 202, 260, 31, 300, 62, 20, 300, 300, 233, 74, 187, 300, 283, 110, 168, 53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117, 277, 212, 49, 67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80], "policy_red_0_reward": [0.2669999999999999, -1.039, 0.46499999999999997, -0.509, -0.057000000000000044, -1.015, -0.03400000000000002, 0.5889999999999999, 0.30899999999999994, 0.577, -1.032, -0.518, 0.922, -0.036000000000000025, 0.45199999999999996, -0.5429999999999999, 0.585, 0.399, -0.521, 0.17999999999999994, 1.404, 0.46299999999999997, 1.306, -1.003, -0.03100000000000002, 0.44399999999999995, -0.5209999999999999, -1.008, 0.41500000000000004, 0.45599999999999996, 0.11099999999999988, 1.1600000000000001, -1.023, 0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129, 0.6439999999999999, -1.056, 0.849, 1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751], "policy_blue_0_reward": [-1.035, 0.593, 0.45099999999999996, 1.314, 0.46099999999999997, 0.6459999999999999, 0.45899999999999996, -1.054, -1.021, -1.046, 0.9349999999999999, 0.46399999999999997, -0.525, 0.45499999999999996, -0.047000000000000035, 0.2559999999999999, -1.015, -0.524, 0.866, -1.0299999999999998, -1.003, -0.04400000000000003, -0.508, 0.9369999999999999, 0.45999999999999996, -0.036000000000000025, 0.263, 1.27, -1.017, 0.45999999999999996, -1.043, -0.518, 0.46599999999999986, -1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014, -0.533, 0.33499999999999996, -1.01, -1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.222765870345776, "mean_inference_ms": 1.4704015978280418, "mean_action_processing_ms": 0.061816746895055175, "mean_env_wait_ms": 0.08663062461774965, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019663333892822266, "StateBufferConnector_ms": 0.0014312267303466797, "ViewRequirementAgentConnector_ms": 0.031211018562316895}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000, "num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.90165498899925, "num_env_steps_trained_throughput_per_sec": 102.90165498899925, "timesteps_total": 28000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 56000, "timers": {"training_iteration_time_ms": 38814.594, "sample_time_ms": 7429.693, "learn_time_ms": 31367.217, "learn_throughput": 127.522, "synch_weights_time_ms": 17.195}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 28000, "num_agent_steps_sampled": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 136, "training_iteration": 7, "trial_id": "d67e4_00000", "date": "2023-09-20_22-13-38", "timestamp": 1695262418, "time_this_iter_s": 38.87607789039612, "time_total_s": 271.7255082130432, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a6878700>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 271.7255082130432, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 34.95357142857143, "ram_util_percent": 47.55714285714286}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2667840372771024, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.021311029900728803, "policy_loss": -0.02548836959564748, "vf_loss": 0.0049693946815144345, "vf_explained_var": 0.3837240347638726, "kl": 0.015576930132374163, "entropy": 1.4227437519778807, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 7200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "sampler_results": {"episode_reward_max": 0.9359999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.016700000000000048, "episode_len_mean": 168.66, "episode_media": {}, "episodes_this_iter": 33, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.43, "blue_0": 0.9179999999999999}, "policy_reward_mean": {"red_0": 0.45238999999999996, "blue_0": -0.4690899999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999, 0.11099999999999977, -0.721, -0.16100000000000003, 0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999, -0.16500000000000012, -0.124, -0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013], "episode_lengths": [53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117, 277, 212, 49, 67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80, 300, 38, 116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110], "policy_red_0_reward": [0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129, 0.6439999999999999, -1.056, 0.849, 1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751, -0.11600000000000009, -1.004, 0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161], "policy_blue_0_reward": [-1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014, -0.533, 0.33499999999999996, -1.01, -1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011, -0.04900000000000004, 0.88, -1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22368432497109317, "mean_inference_ms": 1.4752542483671949, "mean_action_processing_ms": 0.06213414132612807, "mean_env_wait_ms": 0.08711816703019647, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02008676528930664, "StateBufferConnector_ms": 0.001448988914489746, "ViewRequirementAgentConnector_ms": 0.03139960765838623}}, "episode_reward_max": 0.9359999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.016700000000000048, "episode_len_mean": 168.66, "episodes_this_iter": 33, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.43, "blue_0": 0.9179999999999999}, "policy_reward_mean": {"red_0": 0.45238999999999996, "blue_0": -0.4690899999999999}, "hist_stats": {"episode_reward": [-0.16700000000000004, 0.4149999999999999, 0.03400000000000003, 0.41899999999999993, -0.4, 0.08699999999999997, 0.01399999999999979, -0.361, 0.40200000000000014, -0.2390000000000001, -0.1280000000000001, 0.353, -0.22099999999999997, -0.20100000000000007, 0.277, 0.4119999999999999, 0.357, 0.09499999999999997, 0.0259999999999998, -0.763, 0.9199999999999999, 0.3460000000000001, 0.9179999999999999, -0.17200000000000004, -0.14, 0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999, 0.11099999999999977, -0.721, -0.16100000000000003, 0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999, -0.16500000000000012, -0.124, -0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013], "episode_lengths": [53, 300, 144, 300, 121, 278, 143, 109, 30, 73, 192, 46, 68, 205, 68, 300, 199, 121, 299, 234, 300, 199, 300, 53, 42, 233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117, 277, 212, 49, 67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80, 300, 38, 116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110], "policy_red_0_reward": [0.838, 0.45899999999999996, 0.558, -0.03200000000000002, 0.618, 0.627, 1.0379999999999998, 0.657, 1.4060000000000001, 0.7709999999999999, 0.4009999999999999, 1.359, 0.788, -0.549, -0.507, -0.036000000000000025, 0.881, 1.112, 0.566, -1.036, 0.45199999999999996, -0.5339999999999999, 0.45999999999999996, 0.836, 0.867, 0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129, 0.6439999999999999, -1.056, 0.849, 1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751, -0.11600000000000009, -1.004, 0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161], "policy_blue_0_reward": [-1.005, -0.04400000000000003, -0.524, 0.45099999999999996, -1.018, -0.54, -1.024, -1.018, -1.0039999999999998, -1.01, -0.529, -1.006, -1.009, 0.348, 0.784, 0.44799999999999995, -0.524, -1.017, -0.54, 0.2729999999999999, 0.46799999999999997, 0.88, 0.45799999999999996, -1.008, -1.007, -0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014, -0.533, 0.33499999999999996, -1.01, -1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011, -0.04900000000000004, 0.88, -1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22368432497109317, "mean_inference_ms": 1.4752542483671949, "mean_action_processing_ms": 0.06213414132612807, "mean_env_wait_ms": 0.08711816703019647, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02008676528930664, "StateBufferConnector_ms": 0.001448988914489746, "ViewRequirementAgentConnector_ms": 0.03139960765838623}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000, "num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.1685325231706, "num_env_steps_trained_throughput_per_sec": 103.1685325231706, "timesteps_total": 32000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 64000, "timers": {"training_iteration_time_ms": 38809.207, "sample_time_ms": 7436.366, "learn_time_ms": 31355.188, "learn_throughput": 127.571, "synch_weights_time_ms": 17.16}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 32000, "num_agent_steps_sampled": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 169, "training_iteration": 8, "trial_id": "d67e4_00000", "date": "2023-09-20_22-14-17", "timestamp": 1695262457, "time_this_iter_s": 38.77560806274414, "time_total_s": 310.50111627578735, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46ffc70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 310.50111627578735, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 35.01636363636363, "ram_util_percent": 47.547272727272734}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.2748469574376942, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.017731561665277694, "policy_loss": -0.020817309231642867, "vf_loss": 0.004145022394466954, "vf_explained_var": 0.4664549975966414, "kl": 0.012010464375064582, "entropy": 1.3888572388639053, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 8160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "sampler_results": {"episode_reward_max": 0.9359999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.039120000000000044, "episode_len_mean": 163.64, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.43, "blue_0": 0.9359999999999999}, "policy_reward_mean": {"red_0": 0.4355799999999999, "blue_0": -0.4747}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.64, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.64, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.64, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999, 0.11099999999999977, -0.721, -0.16100000000000003, 0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999, -0.16500000000000012, -0.124, -0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013, -0.19100000000000014, 0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987], "episode_lengths": [233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117, 277, 212, 49, 67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80, 300, 38, 116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110, 300, 35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153], "policy_red_0_reward": [0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129, 0.6439999999999999, -1.056, 0.849, 1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751, -0.11600000000000009, -1.004, 0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161, -0.1540000000000001, 1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999], "policy_blue_0_reward": [-0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014, -0.533, 0.33499999999999996, -1.01, -1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011, -0.04900000000000004, 0.88, -1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013, -0.037000000000000026, -1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2241354664538323, "mean_inference_ms": 1.4754312496548903, "mean_action_processing_ms": 0.06224726672669901, "mean_env_wait_ms": 0.08735095674196858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020102381706237793, "StateBufferConnector_ms": 0.0014536380767822266, "ViewRequirementAgentConnector_ms": 0.03139376640319824}}, "episode_reward_max": 0.9359999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.039120000000000044, "episode_len_mean": 163.64, "episodes_this_iter": 25, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.43, "blue_0": 0.9359999999999999}, "policy_reward_mean": {"red_0": 0.4355799999999999, "blue_0": -0.4747}, "hist_stats": {"episode_reward": [0.22799999999999998, -0.4960000000000001, -0.1399999999999999, -0.6990000000000002, -0.1080000000000001, -0.08400000000000006, -0.16399999999999992, 0.17199999999999993, 0.4049999999999999, -0.2400000000000001, -0.5249999999999999, -0.32600000000000007, -0.5410000000000001, -0.4780000000000001, -0.245, 0.9359999999999999, 0.038000000000000034, -0.29699999999999993, -0.1380000000000001, 0.30099999999999993, 0.21999999999999975, 0.11499999999999999, 0.11099999999999977, -0.721, -0.16100000000000003, 0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999, -0.16500000000000012, -0.124, -0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013, -0.19100000000000014, 0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987], "episode_lengths": [233, 153, 199, 198, 186, 300, 51, 100, 300, 73, 156, 99, 165, 294, 227, 300, 141, 92, 300, 60, 237, 117, 277, 212, 49, 67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80, 300, 38, 116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110, 300, 35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153], "policy_red_0_reward": [0.761, 0.5269999999999999, -0.5179999999999999, 0.32899999999999985, -1.026, -0.046000000000000034, 0.845, 1.186, 0.44499999999999995, 0.7739999999999999, -1.04, 0.693, 0.4819999999999999, 0.5599999999999999, 0.7899999999999999, 0.46699999999999997, 0.5549999999999999, -1.007, -0.08700000000000006, 1.3119999999999998, 0.7579999999999999, 1.129, 0.6439999999999999, -1.056, 0.849, 1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751, -0.11600000000000009, -1.004, 0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161, -0.1540000000000001, 1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999], "policy_blue_0_reward": [-0.533, -1.023, 0.378, -1.028, 0.9179999999999999, -0.03800000000000003, -1.009, -1.014, -0.04000000000000003, -1.014, 0.515, -1.019, -1.023, -1.038, -1.035, 0.469, -0.5169999999999999, 0.71, -0.05100000000000004, -1.011, -0.538, -1.014, -0.533, 0.33499999999999996, -1.01, -1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011, -0.04900000000000004, 0.88, -1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013, -0.037000000000000026, -1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2241354664538323, "mean_inference_ms": 1.4754312496548903, "mean_action_processing_ms": 0.06224726672669901, "mean_env_wait_ms": 0.08735095674196858, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020102381706237793, "StateBufferConnector_ms": 0.0014536380767822266, "ViewRequirementAgentConnector_ms": 0.03139376640319824}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000, "num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.11860526288163, "num_env_steps_trained_throughput_per_sec": 103.11860526288163, "timesteps_total": 36000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 72000, "timers": {"training_iteration_time_ms": 38807.103, "sample_time_ms": 7433.53, "learn_time_ms": 31355.925, "learn_throughput": 127.568, "synch_weights_time_ms": 17.155}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 36000, "num_agent_steps_sampled": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 194, "training_iteration": 9, "trial_id": "d67e4_00000", "date": "2023-09-20_22-14-56", "timestamp": 1695262496, "time_this_iter_s": 38.79440212249756, "time_total_s": 349.2955183982849, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d088310>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 349.2955183982849, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 33.7375, "ram_util_percent": 47.596428571428575}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4013044636075696, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.018626288578404152, "policy_loss": -0.021571607680258845, "vf_loss": 0.003921563231551772, "vf_explained_var": 0.4417648631458481, "kl": 0.011320812281416525, "entropy": 1.2796248470743496, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 9120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "sampler_results": {"episode_reward_max": 0.9149999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.011330000000000048, "episode_len_mean": 156.78, "episode_media": {}, "episodes_this_iter": 25, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.43, "blue_0": 1.174}, "policy_reward_mean": {"red_0": 0.47637, "blue_0": -0.4877000000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.65, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.15, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.65, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.15, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.65, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.15, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999, -0.16500000000000012, -0.124, -0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013, -0.19100000000000014, 0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987, -0.7670000000000001, 0.24, -0.8370000000000002, -0.18000000000000005, 0.3460000000000001, 0.3679999999999999, 0.1309999999999999, -0.4810000000000002, -0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006], "episode_lengths": [67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80, 300, 38, 116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110, 300, 35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153, 216, 80, 237, 207, 48, 41, 104, 265, 23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119], "policy_red_0_reward": [1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751, -0.11600000000000009, -1.004, 0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161, -0.1540000000000001, 1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999, 0.2679999999999999, 1.254, -1.091, 0.85, 1.351, 1.3719999999999999, -1.043, 0.05899999999999986, 0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577], "policy_blue_0_reward": [-1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011, -0.04900000000000004, 0.88, -1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013, -0.037000000000000026, -1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521, -1.035, -1.014, 0.2539999999999999, -1.03, -1.005, -1.004, 1.174, -0.54, -1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22444310934302678, "mean_inference_ms": 1.474964980853773, "mean_action_processing_ms": 0.06227588411627522, "mean_env_wait_ms": 0.08751476205598543, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02012002468109131, "StateBufferConnector_ms": 0.0014355182647705078, "ViewRequirementAgentConnector_ms": 0.031349778175354004}}, "episode_reward_max": 0.9149999999999999, "episode_reward_min": -1.024, "episode_reward_mean": -0.011330000000000048, "episode_len_mean": 156.78, "episodes_this_iter": 25, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.43, "blue_0": 1.174}, "policy_reward_mean": {"red_0": 0.47637, "blue_0": -0.4877000000000001}, "hist_stats": {"episode_reward": [0.278, 0.42900000000000005, 0.44399999999999995, -0.45899999999999985, 0.33299999999999996, -0.3750000000000001, -0.10500000000000008, -1.024, -0.13100000000000012, -0.17099999999999993, -0.1590000000000001, -0.6330000000000001, -0.1510000000000001, -0.41100000000000014, 0.05300000000000016, 0.20899999999999996, -0.2599999999999999, -0.16500000000000012, -0.124, -0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013, -0.19100000000000014, 0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987, -0.7670000000000001, 0.24, -0.8370000000000002, -0.18000000000000005, 0.3460000000000001, 0.3679999999999999, 0.1309999999999999, -0.4810000000000002, -0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006], "episode_lengths": [67, 22, 159, 144, 51, 261, 300, 298, 188, 52, 300, 195, 300, 266, 136, 89, 80, 300, 38, 116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110, 300, 35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153, 216, 80, 237, 207, 48, 41, 104, 265, 23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119], "policy_red_0_reward": [1.287, 1.43, 0.9649999999999999, -1.011, 1.3399999999999999, 0.6599999999999999, -0.07500000000000005, 0.02099999999999992, 0.8929999999999999, 0.838, -0.1220000000000001, 0.3929999999999999, -0.10200000000000008, 0.6209999999999999, 1.072, -0.513, 0.751, -0.11600000000000009, -1.004, 0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161, -0.1540000000000001, 1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999, 0.2679999999999999, 1.254, -1.091, 0.85, 1.351, 1.3719999999999999, -1.043, 0.05899999999999986, 0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577], "policy_blue_0_reward": [-1.009, -1.001, -0.521, 0.552, -1.007, -1.035, -0.03000000000000002, -1.045, -1.024, -1.009, -0.037000000000000026, -1.026, -0.04900000000000004, -1.032, -1.019, 0.722, -1.011, -0.04900000000000004, 0.88, -1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013, -0.037000000000000026, -1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521, -1.035, -1.014, 0.2539999999999999, -1.03, -1.005, -1.004, 1.174, -0.54, -1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22444310934302678, "mean_inference_ms": 1.474964980853773, "mean_action_processing_ms": 0.06227588411627522, "mean_env_wait_ms": 0.08751476205598543, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02012002468109131, "StateBufferConnector_ms": 0.0014355182647705078, "ViewRequirementAgentConnector_ms": 0.031349778175354004}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000, "num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.15526667260656, "num_env_steps_trained_throughput_per_sec": 103.15526667260656, "timesteps_total": 40000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 80000, "timers": {"training_iteration_time_ms": 38804.041, "sample_time_ms": 7433.409, "learn_time_ms": 31353.027, "learn_throughput": 127.579, "synch_weights_time_ms": 17.112}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 40000, "num_agent_steps_sampled": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 219, "training_iteration": 10, "trial_id": "d67e4_00000", "date": "2023-09-20_22-15-35", "timestamp": 1695262535, "time_this_iter_s": 38.78053092956543, "time_total_s": 388.07604932785034, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a47069e0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 388.07604932785034, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 34.77454545454545, "ram_util_percent": 47.62545454545454}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4644850701714556, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011654733151226537, "policy_loss": -0.013613126912120303, "vf_loss": 0.0029282336262137203, "vf_explained_var": 0.48757424944390854, "kl": 0.008850120424585228, "entropy": 1.2757469009608031, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 10080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "sampler_results": {"episode_reward_max": 0.9149999999999999, "episode_reward_min": -0.8719999999999999, "episode_reward_mean": -0.006310000000000054, "episode_len_mean": 164.03, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.412, "blue_0": 1.174}, "policy_reward_mean": {"red_0": 0.4344999999999999, "blue_0": -0.44081}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.61, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.61, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.61, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013, -0.19100000000000014, 0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987, -0.7670000000000001, 0.24, -0.8370000000000002, -0.18000000000000005, 0.3460000000000001, 0.3679999999999999, 0.1309999999999999, -0.4810000000000002, -0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006, -0.18300000000000013, 0.4139999999999999, -0.30600000000000016, -0.663, 0.23199999999999998, 0.395, -0.05900000000000005, -0.6620000000000001, -0.17000000000000012, -0.04200000000000004, -0.44100000000000017, -0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011], "episode_lengths": [116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110, 300, 35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153, 216, 80, 237, 207, 48, 41, 104, 265, 23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119, 300, 300, 234, 186, 70, 181, 19, 183, 300, 166, 283, 191, 300, 300, 278, 14, 300, 66, 300], "policy_red_0_reward": [0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161, -0.1540000000000001, 1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999, 0.2679999999999999, 1.254, -1.091, 0.85, 1.351, 1.3719999999999999, -1.043, 0.05899999999999986, 0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577, -0.1420000000000001, 0.45199999999999996, 0.7169999999999999, -1.0799999999999998, 0.741, 0.9129999999999999, -1.001, 0.3619999999999999, -0.12000000000000009, 0.976, -0.546, -0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001], "policy_blue_0_reward": [-1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013, -0.037000000000000026, -1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521, -1.035, -1.014, 0.2539999999999999, -1.03, -1.005, -1.004, 1.174, -0.54, -1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021, -0.04100000000000003, -0.03800000000000003, -1.023, 0.4169999999999999, -0.509, -0.518, 0.942, -1.024, -0.05000000000000004, -1.018, 0.10499999999999987, 0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22470774282584943, "mean_inference_ms": 1.4753848168134027, "mean_action_processing_ms": 0.062317381749162404, "mean_env_wait_ms": 0.08763406490367441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02027726173400879, "StateBufferConnector_ms": 0.0014470815658569336, "ViewRequirementAgentConnector_ms": 0.03133213520050049}}, "episode_reward_max": 0.9149999999999999, "episode_reward_min": -0.8719999999999999, "episode_reward_mean": -0.006310000000000054, "episode_len_mean": 164.03, "episodes_this_iter": 19, "policy_reward_min": {"red_0": -1.1179999999999999, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.412, "blue_0": 1.174}, "policy_reward_mean": {"red_0": 0.4344999999999999, "blue_0": -0.44081}, "hist_stats": {"episode_reward": [-0.41100000000000003, -0.356, 0.9149999999999999, 0.383, -0.10599999999999998, 0.09299999999999997, 0.41000000000000014, 0.278, 0.4049999999999999, 0.33099999999999996, 0.18699999999999994, 0.3380000000000001, -0.17200000000000013, -0.22500000000000017, -0.12700000000000009, -0.06300000000000006, 0.3969999999999999, 0.27200000000000024, -0.2450000000000002, -0.17400000000000004, 0.0259999999999998, -0.659, -0.17800000000000013, -0.06900000000000006, 0.23399999999999999, -0.278, 0.6479999999999999, 0.32799999999999985, -0.8719999999999999, -0.15200000000000002, 0.14800000000000013, -0.19100000000000014, 0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987, -0.7670000000000001, 0.24, -0.8370000000000002, -0.18000000000000005, 0.3460000000000001, 0.3679999999999999, 0.1309999999999999, -0.4810000000000002, -0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006, -0.18300000000000013, 0.4139999999999999, -0.30600000000000016, -0.663, 0.23199999999999998, 0.395, -0.05900000000000005, -0.6620000000000001, -0.17000000000000012, -0.04200000000000004, -0.44100000000000017, -0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011], "episode_lengths": [116, 96, 300, 36, 33, 118, 29, 68, 300, 52, 250, 46, 300, 300, 300, 20, 300, 71, 300, 51, 146, 197, 300, 21, 237, 233, 102, 52, 238, 202, 110, 300, 35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153, 216, 80, 237, 207, 48, 41, 104, 265, 23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119, 300, 300, 234, 186, 70, 181, 19, 183, 300, 166, 283, 191, 300, 300, 278, 14, 300, 66, 300], "policy_red_0_reward": [0.604, 0.6589999999999999, 0.45599999999999996, -0.504, 0.898, 0.603, 1.412, 1.29, 0.44499999999999995, 1.337, -0.525, 0.844, -0.1230000000000001, -0.18000000000000013, -0.07900000000000006, 0.939, 0.44099999999999995, 1.28, -0.19400000000000014, 0.829, 1.048, 0.37, -0.1300000000000001, 0.9329999999999999, 0.7659999999999999, 0.755, 1.16, 1.338, -1.1179999999999999, 0.87, 1.161, -0.1540000000000001, 1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999, 0.2679999999999999, 1.254, -1.091, 0.85, 1.351, 1.3719999999999999, -1.043, 0.05899999999999986, 0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577, -0.1420000000000001, 0.45199999999999996, 0.7169999999999999, -1.0799999999999998, 0.741, 0.9129999999999999, -1.001, 0.3619999999999999, -0.12000000000000009, 0.976, -0.546, -0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001], "policy_blue_0_reward": [-1.015, -1.015, 0.45899999999999996, 0.887, -1.004, -0.51, -1.002, -1.012, -0.04000000000000003, -1.006, 0.712, -0.506, -0.04900000000000004, -0.04500000000000003, -0.048000000000000036, -1.002, -0.04400000000000003, -1.0079999999999998, -0.05100000000000004, -1.003, -1.022, -1.029, -0.048000000000000036, -1.002, -0.532, -1.033, -0.512, -1.01, 0.246, -1.022, -1.013, -0.037000000000000026, -1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521, -1.035, -1.014, 0.2539999999999999, -1.03, -1.005, -1.004, 1.174, -0.54, -1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021, -0.04100000000000003, -0.03800000000000003, -1.023, 0.4169999999999999, -0.509, -0.518, 0.942, -1.024, -0.05000000000000004, -1.018, 0.10499999999999987, 0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22470774282584943, "mean_inference_ms": 1.4753848168134027, "mean_action_processing_ms": 0.062317381749162404, "mean_env_wait_ms": 0.08763406490367441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02027726173400879, "StateBufferConnector_ms": 0.0014470815658569336, "ViewRequirementAgentConnector_ms": 0.03133213520050049}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000, "num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.19832762426195, "num_env_steps_trained_throughput_per_sec": 103.19832762426195, "timesteps_total": 44000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 88000, "timers": {"training_iteration_time_ms": 38813.805, "sample_time_ms": 7449.181, "learn_time_ms": 31347.043, "learn_throughput": 127.604, "synch_weights_time_ms": 17.083}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 44000, "num_agent_steps_sampled": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 238, "training_iteration": 11, "trial_id": "d67e4_00000", "date": "2023-09-20_22-16-14", "timestamp": 1695262574, "time_this_iter_s": 38.764307260513306, "time_total_s": 426.84035658836365, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d089240>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 426.84035658836365, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 33.682142857142864, "ram_util_percent": 47.69464285714286}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.63, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.63, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.63, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4791765014951428, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012423770784395553, "policy_loss": -0.015604000511060197, "vf_loss": 0.004685277737492773, "vf_explained_var": 0.4982257309059302, "kl": 0.009892780143362156, "entropy": 1.1409650016576052, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 11040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "sampler_results": {"episode_reward_max": 0.9630000000000001, "episode_reward_min": -0.8370000000000002, "episode_reward_mean": 0.04317999999999994, "episode_len_mean": 155.67, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"red_0": -1.091, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.174}, "policy_reward_mean": {"red_0": 0.47220999999999996, "blue_0": -0.4290300000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.63, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.16, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.63, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.16, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.63, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.16, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987, -0.7670000000000001, 0.24, -0.8370000000000002, -0.18000000000000005, 0.3460000000000001, 0.3679999999999999, 0.1309999999999999, -0.4810000000000002, -0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006, -0.18300000000000013, 0.4139999999999999, -0.30600000000000016, -0.663, 0.23199999999999998, 0.395, -0.05900000000000005, -0.6620000000000001, -0.17000000000000012, -0.04200000000000004, -0.44100000000000017, -0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011, 0.6619999999999999, 0.3889999999999999, -0.08000000000000007, 0.23299999999999998, 0.1429999999999998, -0.16200000000000003, 0.49, 0.44899999999999995, 0.45500000000000007, 0.05700000000000005, -0.04800000000000004, 0.44199999999999995, -0.4790000000000002, -0.17200000000000013, 0.3639999999999999, -0.18000000000000013, 0.40700000000000003, 0.0019999999999997797, -0.16200000000000003, 0.41100000000000003, -0.18000000000000005, -0.1380000000000001, 0.9630000000000001, -0.403, -0.391, 0.8999999999999999, -0.17600000000000005, 0.2829999999999999, 0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998], "episode_lengths": [35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153, 216, 80, 237, 207, 48, 41, 104, 265, 23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119, 300, 300, 234, 186, 70, 181, 19, 183, 300, 166, 283, 191, 300, 300, 278, 14, 300, 66, 300, 105, 300, 171, 84, 106, 48, 162, 300, 15, 133, 15, 300, 292, 300, 42, 300, 28, 143, 51, 28, 54, 300, 12, 107, 113, 30, 211, 66, 300, 72, 66, 134], "policy_red_0_reward": [1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999, 0.2679999999999999, 1.254, -1.091, 0.85, 1.351, 1.3719999999999999, -1.043, 0.05899999999999986, 0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577, -0.1420000000000001, 0.45199999999999996, 0.7169999999999999, -1.0799999999999998, 0.741, 0.9129999999999999, -1.001, 0.3619999999999999, -0.12000000000000009, 0.976, -0.546, -0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001, 1.1760000000000002, 0.43199999999999994, 0.44299999999999995, -0.503, 0.6539999999999999, 0.846, 1.005, 0.493, 0.955, -1.035, 0.953, 0.487, -0.547, -0.1350000000000001, 1.371, -0.1310000000000001, 1.416, 0.5249999999999999, 0.845, 1.415, 0.826, -0.09100000000000007, 1.464, 0.608, 0.623, 1.4060000000000001, 0.857, 1.295, 0.4099999999999999, 0.75, 1.298, 1.091], "policy_blue_0_reward": [-1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521, -1.035, -1.014, 0.2539999999999999, -1.03, -1.005, -1.004, 1.174, -0.54, -1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021, -0.04100000000000003, -0.03800000000000003, -1.023, 0.4169999999999999, -0.509, -0.518, 0.942, -1.024, -0.05000000000000004, -1.018, 0.10499999999999987, 0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003, -0.514, -0.04300000000000003, -0.523, 0.736, -0.511, -1.008, -0.515, -0.04400000000000003, -0.5, 1.092, -1.001, -0.04500000000000003, 0.06799999999999984, -0.037000000000000026, -1.007, -0.04900000000000004, -1.009, -0.523, -1.007, -1.004, -1.006, -0.047000000000000035, -0.501, -1.011, -1.014, -0.506, -1.033, -1.012, -0.03000000000000002, -0.5079999999999999, -0.509, -0.517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22468321780373862, "mean_inference_ms": 1.4741701276689698, "mean_action_processing_ms": 0.06229943542853052, "mean_env_wait_ms": 0.08778992058853945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01994645595550537, "StateBufferConnector_ms": 0.0014238357543945312, "ViewRequirementAgentConnector_ms": 0.0310516357421875}}, "episode_reward_max": 0.9630000000000001, "episode_reward_min": -0.8370000000000002, "episode_reward_mean": 0.04317999999999994, "episode_len_mean": 155.67, "episodes_this_iter": 32, "policy_reward_min": {"red_0": -1.091, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.174}, "policy_reward_mean": {"red_0": 0.47220999999999996, "blue_0": -0.4290300000000001}, "hist_stats": {"episode_reward": [0.387, -0.3380000000000001, -0.714, 0.2689999999999999, -0.061000000000000054, 0.08599999999999997, -0.08099999999999996, 0.35599999999999987, -0.6210000000000001, -0.07999999999999996, 0.43400000000000005, 0.14100000000000001, 0.29700000000000015, -0.697, -0.16200000000000012, -0.17399999999999993, -0.09999999999999998, 0.42799999999999994, 0.3839999999999999, 0.4119999999999999, -0.16800000000000012, -0.14800000000000002, -0.09300000000000008, 0.47499999999999987, -0.7670000000000001, 0.24, -0.8370000000000002, -0.18000000000000005, 0.3460000000000001, 0.3679999999999999, 0.1309999999999999, -0.4810000000000002, -0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006, -0.18300000000000013, 0.4139999999999999, -0.30600000000000016, -0.663, 0.23199999999999998, 0.395, -0.05900000000000005, -0.6620000000000001, -0.17000000000000012, -0.04200000000000004, -0.44100000000000017, -0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011, 0.6619999999999999, 0.3889999999999999, -0.08000000000000007, 0.23299999999999998, 0.1429999999999998, -0.16200000000000003, 0.49, 0.44899999999999995, 0.45500000000000007, 0.05700000000000005, -0.04800000000000004, 0.44199999999999995, -0.4790000000000002, -0.17200000000000013, 0.3639999999999999, -0.18000000000000013, 0.40700000000000003, 0.0019999999999997797, -0.16200000000000003, 0.41100000000000003, -0.18000000000000005, -0.1380000000000001, 0.9630000000000001, -0.403, -0.391, 0.8999999999999999, -0.17600000000000005, 0.2829999999999999, 0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998], "episode_lengths": [35, 254, 203, 69, 175, 125, 25, 45, 176, 26, 20, 101, 62, 200, 300, 205, 31, 172, 300, 178, 300, 46, 174, 153, 216, 80, 237, 207, 48, 41, 104, 265, 23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119, 300, 300, 234, 186, 70, 181, 19, 183, 300, 166, 283, 191, 300, 300, 278, 14, 300, 66, 300, 105, 300, 171, 84, 106, 48, 162, 300, 15, 133, 15, 300, 292, 300, 42, 300, 28, 143, 51, 28, 54, 300, 12, 107, 113, 30, 211, 66, 300, 72, 66, 134], "policy_red_0_reward": [1.395, 0.20199999999999996, -1.074, 1.281, 0.46399999999999997, -0.515, -1.0, 1.362, 0.4069999999999999, 0.922, -0.5019999999999999, 0.655, 1.306, -1.067, -0.1230000000000001, 0.858, 0.906, 0.958, 0.43499999999999994, 0.945, -0.1240000000000001, 0.859, 0.9269999999999999, 0.9959999999999999, 0.2679999999999999, 1.254, -1.091, 0.85, 1.351, 1.3719999999999999, -1.043, 0.05899999999999986, 0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577, -0.1420000000000001, 0.45199999999999996, 0.7169999999999999, -1.0799999999999998, 0.741, 0.9129999999999999, -1.001, 0.3619999999999999, -0.12000000000000009, 0.976, -0.546, -0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001, 1.1760000000000002, 0.43199999999999994, 0.44299999999999995, -0.503, 0.6539999999999999, 0.846, 1.005, 0.493, 0.955, -1.035, 0.953, 0.487, -0.547, -0.1350000000000001, 1.371, -0.1310000000000001, 1.416, 0.5249999999999999, 0.845, 1.415, 0.826, -0.09100000000000007, 1.464, 0.608, 0.623, 1.4060000000000001, 0.857, 1.295, 0.4099999999999999, 0.75, 1.298, 1.091], "policy_blue_0_reward": [-1.008, -0.54, 0.36, -1.012, -0.525, 0.601, 0.919, -1.006, -1.028, -1.002, 0.9359999999999999, -0.514, -1.009, 0.37, -0.03900000000000003, -1.0319999999999998, -1.006, -0.53, -0.05100000000000004, -0.533, -0.04400000000000003, -1.007, -1.02, -0.521, -1.035, -1.014, 0.2539999999999999, -1.03, -1.005, -1.004, 1.174, -0.54, -1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021, -0.04100000000000003, -0.03800000000000003, -1.023, 0.4169999999999999, -0.509, -0.518, 0.942, -1.024, -0.05000000000000004, -1.018, 0.10499999999999987, 0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003, -0.514, -0.04300000000000003, -0.523, 0.736, -0.511, -1.008, -0.515, -0.04400000000000003, -0.5, 1.092, -1.001, -0.04500000000000003, 0.06799999999999984, -0.037000000000000026, -1.007, -0.04900000000000004, -1.009, -0.523, -1.007, -1.004, -1.006, -0.047000000000000035, -0.501, -1.011, -1.014, -0.506, -1.033, -1.012, -0.03000000000000002, -0.5079999999999999, -0.509, -0.517]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22468321780373862, "mean_inference_ms": 1.4741701276689698, "mean_action_processing_ms": 0.06229943542853052, "mean_env_wait_ms": 0.08778992058853945, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01994645595550537, "StateBufferConnector_ms": 0.0014238357543945312, "ViewRequirementAgentConnector_ms": 0.0310516357421875}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000, "num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.19508779253503, "num_env_steps_trained_throughput_per_sec": 103.19508779253503, "timesteps_total": 48000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 96000, "timers": {"training_iteration_time_ms": 38827.237, "sample_time_ms": 7461.61, "learn_time_ms": 31348.043, "learn_throughput": 127.6, "synch_weights_time_ms": 17.081}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 48000, "num_agent_steps_sampled": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 270, "training_iteration": 12, "trial_id": "d67e4_00000", "date": "2023-09-20_22-16-53", "timestamp": 1695262613, "time_this_iter_s": 38.76562809944153, "time_total_s": 465.6059846878052, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a68789d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 465.6059846878052, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 34.527272727272724, "ram_util_percent": 47.70545454545452}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.62, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.62, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.62, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3989639751302698, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.017073761999775647, "policy_loss": -0.0214485973585397, "vf_loss": 0.0054266358455000345, "vf_explained_var": 0.5050931803882122, "kl": 0.014073696976186026, "entropy": 1.153221702327331, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "sampler_results": {"episode_reward_max": 0.9630000000000001, "episode_reward_min": -0.8060000000000002, "episode_reward_mean": 0.10309999999999996, "episode_len_mean": 150.23, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"red_0": -1.0799999999999998, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.092}, "policy_reward_mean": {"red_0": 0.5525899999999999, "blue_0": -0.4494899999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.62, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.13, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.62, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.13, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.62, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.13, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006, -0.18300000000000013, 0.4139999999999999, -0.30600000000000016, -0.663, 0.23199999999999998, 0.395, -0.05900000000000005, -0.6620000000000001, -0.17000000000000012, -0.04200000000000004, -0.44100000000000017, -0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011, 0.6619999999999999, 0.3889999999999999, -0.08000000000000007, 0.23299999999999998, 0.1429999999999998, -0.16200000000000003, 0.49, 0.44899999999999995, 0.45500000000000007, 0.05700000000000005, -0.04800000000000004, 0.44199999999999995, -0.4790000000000002, -0.17200000000000013, 0.3639999999999999, -0.18000000000000013, 0.40700000000000003, 0.0019999999999997797, -0.16200000000000003, 0.41100000000000003, -0.18000000000000005, -0.1380000000000001, 0.9630000000000001, -0.403, -0.391, 0.8999999999999999, -0.17600000000000005, 0.2829999999999999, 0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998, 0.516, -0.18500000000000014, 0.4079999999999999, 0.3820000000000001, 0.256, 0.952, -0.18799999999999994, -0.2320000000000001, 0.42899999999999994, -0.8060000000000002, 0.07199999999999995, 0.8660000000000001, -0.19900000000000015, -0.06800000000000006, 0.43700000000000006, 0.395, -0.17300000000000013, 0.133, -0.05399999999999994, 0.19799999999999995, 0.403, 0.43199999999999994, 0.42300000000000004, 0.4969999999999999, -0.025000000000000022, -0.20600000000000016, 0.42499999999999993, -0.19200000000000006, -0.4790000000000002, 0.3740000000000001, 0.42000000000000015, -0.16700000000000004], "episode_lengths": [23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119, 300, 300, 234, 186, 70, 181, 19, 183, 300, 166, 283, 191, 300, 300, 278, 14, 300, 66, 300, 105, 300, 171, 84, 106, 48, 162, 300, 15, 133, 15, 300, 292, 300, 42, 300, 28, 143, 51, 28, 54, 300, 12, 107, 113, 30, 211, 66, 300, 72, 66, 134, 148, 300, 27, 37, 77, 16, 57, 67, 300, 222, 134, 42, 300, 167, 20, 33, 300, 113, 16, 93, 31, 300, 25, 155, 8, 300, 300, 57, 271, 40, 25, 48], "policy_red_0_reward": [0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577, -0.1420000000000001, 0.45199999999999996, 0.7169999999999999, -1.0799999999999998, 0.741, 0.9129999999999999, -1.001, 0.3619999999999999, -0.12000000000000009, 0.976, -0.546, -0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001, 1.1760000000000002, 0.43199999999999994, 0.44299999999999995, -0.503, 0.6539999999999999, 0.846, 1.005, 0.493, 0.955, -1.035, 0.953, 0.487, -0.547, -0.1350000000000001, 1.371, -0.1310000000000001, 1.416, 0.5249999999999999, 0.845, 1.415, 0.826, -0.09100000000000007, 1.464, 0.608, 0.623, 1.4060000000000001, 0.857, 1.295, 0.4099999999999999, 0.75, 1.298, 1.091, 1.041, -0.1440000000000001, 1.416, 1.3860000000000001, 1.2690000000000001, 1.452, -1.008, 0.7769999999999999, 0.482, 0.22799999999999987, -0.506, 1.3719999999999999, -0.1530000000000001, 0.954, 1.44, 1.4, -0.12800000000000009, -0.506, 0.95, 1.21, 1.4060000000000001, 0.486, 1.424, -0.516, 0.976, -0.16300000000000012, 0.46399999999999997, 0.816, 0.06199999999999986, 1.379, 1.423, 0.842], "policy_blue_0_reward": [-1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021, -0.04100000000000003, -0.03800000000000003, -1.023, 0.4169999999999999, -0.509, -0.518, 0.942, -1.024, -0.05000000000000004, -1.018, 0.10499999999999987, 0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003, -0.514, -0.04300000000000003, -0.523, 0.736, -0.511, -1.008, -0.515, -0.04400000000000003, -0.5, 1.092, -1.001, -0.04500000000000003, 0.06799999999999984, -0.037000000000000026, -1.007, -0.04900000000000004, -1.009, -0.523, -1.007, -1.004, -1.006, -0.047000000000000035, -0.501, -1.011, -1.014, -0.506, -1.033, -1.012, -0.03000000000000002, -0.5079999999999999, -0.509, -0.517, -0.525, -0.04100000000000003, -1.008, -1.004, -1.013, -0.5, 0.82, -1.009, -0.05300000000000004, -1.034, 0.578, -0.5059999999999999, -0.046000000000000034, -1.022, -1.003, -1.005, -0.04500000000000003, 0.639, -1.0039999999999998, -1.012, -1.003, -0.05400000000000004, -1.001, 1.013, -1.001, -0.04300000000000003, -0.03900000000000003, -1.008, -0.541, -1.005, -1.003, -1.009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22475172205917, "mean_inference_ms": 1.4750816883917859, "mean_action_processing_ms": 0.062317637914018585, "mean_env_wait_ms": 0.08795499887024441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020344853401184082, "StateBufferConnector_ms": 0.0014433860778808594, "ViewRequirementAgentConnector_ms": 0.031139373779296875}}, "episode_reward_max": 0.9630000000000001, "episode_reward_min": -0.8060000000000002, "episode_reward_mean": 0.10309999999999996, "episode_len_mean": 150.23, "episodes_this_iter": 32, "policy_reward_min": {"red_0": -1.0799999999999998, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.092}, "policy_reward_mean": {"red_0": 0.5525899999999999, "blue_0": -0.4494899999999999}, "hist_stats": {"episode_reward": [-0.07599999999999996, 0.03100000000000014, 0.3679999999999999, -0.5750000000000002, 0.262, -0.17400000000000013, -0.45300000000000007, 0.2560000000000002, 0.23899999999999988, 0.4019999999999999, -0.11900000000000009, 0.7389999999999999, 0.5609999999999999, -0.278, 0.44799999999999995, -0.06499999999999995, -0.44400000000000006, -0.18300000000000013, 0.4139999999999999, -0.30600000000000016, -0.663, 0.23199999999999998, 0.395, -0.05900000000000005, -0.6620000000000001, -0.17000000000000012, -0.04200000000000004, -0.44100000000000017, -0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011, 0.6619999999999999, 0.3889999999999999, -0.08000000000000007, 0.23299999999999998, 0.1429999999999998, -0.16200000000000003, 0.49, 0.44899999999999995, 0.45500000000000007, 0.05700000000000005, -0.04800000000000004, 0.44199999999999995, -0.4790000000000002, -0.17200000000000013, 0.3639999999999999, -0.18000000000000013, 0.40700000000000003, 0.0019999999999997797, -0.16200000000000003, 0.41100000000000003, -0.18000000000000005, -0.1380000000000001, 0.9630000000000001, -0.403, -0.391, 0.8999999999999999, -0.17600000000000005, 0.2829999999999999, 0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998, 0.516, -0.18500000000000014, 0.4079999999999999, 0.3820000000000001, 0.256, 0.952, -0.18799999999999994, -0.2320000000000001, 0.42899999999999994, -0.8060000000000002, 0.07199999999999995, 0.8660000000000001, -0.19900000000000015, -0.06800000000000006, 0.43700000000000006, 0.395, -0.17300000000000013, 0.133, -0.05399999999999994, 0.19799999999999995, 0.403, 0.43199999999999994, 0.42300000000000004, 0.4969999999999999, -0.025000000000000022, -0.20600000000000016, 0.42499999999999993, -0.19200000000000006, -0.4790000000000002, 0.3740000000000001, 0.42000000000000015, -0.16700000000000004], "episode_lengths": [23, 144, 300, 165, 74, 300, 133, 75, 80, 300, 300, 75, 135, 85, 155, 172, 119, 300, 300, 234, 186, 70, 181, 19, 183, 300, 166, 283, 191, 300, 300, 278, 14, 300, 66, 300, 105, 300, 171, 84, 106, 48, 162, 300, 15, 133, 15, 300, 292, 300, 42, 300, 28, 143, 51, 28, 54, 300, 12, 107, 113, 30, 211, 66, 300, 72, 66, 134, 148, 300, 27, 37, 77, 16, 57, 67, 300, 222, 134, 42, 300, 167, 20, 33, 300, 113, 16, 93, 31, 300, 25, 155, 8, 300, 300, 57, 271, 40, 25, 48], "policy_red_0_reward": [0.926, 1.045, -0.10000000000000007, -1.051, 1.2730000000000001, -0.1290000000000001, -1.039, 1.2690000000000001, 1.25, 0.44399999999999995, -0.08000000000000006, 1.248, 1.0739999999999998, 0.739, 0.9709999999999999, 0.968, 0.577, -0.1420000000000001, 0.45199999999999996, 0.7169999999999999, -1.0799999999999998, 0.741, 0.9129999999999999, -1.001, 0.3619999999999999, -0.12000000000000009, 0.976, -0.546, -0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001, 1.1760000000000002, 0.43199999999999994, 0.44299999999999995, -0.503, 0.6539999999999999, 0.846, 1.005, 0.493, 0.955, -1.035, 0.953, 0.487, -0.547, -0.1350000000000001, 1.371, -0.1310000000000001, 1.416, 0.5249999999999999, 0.845, 1.415, 0.826, -0.09100000000000007, 1.464, 0.608, 0.623, 1.4060000000000001, 0.857, 1.295, 0.4099999999999999, 0.75, 1.298, 1.091, 1.041, -0.1440000000000001, 1.416, 1.3860000000000001, 1.2690000000000001, 1.452, -1.008, 0.7769999999999999, 0.482, 0.22799999999999987, -0.506, 1.3719999999999999, -0.1530000000000001, 0.954, 1.44, 1.4, -0.12800000000000009, -0.506, 0.95, 1.21, 1.4060000000000001, 0.486, 1.424, -0.516, 0.976, -0.16300000000000012, 0.46399999999999997, 0.816, 0.06199999999999986, 1.379, 1.423, 0.842], "policy_blue_0_reward": [-1.002, -1.014, 0.46799999999999997, 0.47599999999999987, -1.011, -0.04500000000000003, 0.586, -1.013, -1.011, -0.04200000000000003, -0.03900000000000003, -0.509, -0.513, -1.017, -0.523, -1.033, -1.021, -0.04100000000000003, -0.03800000000000003, -1.023, 0.4169999999999999, -0.509, -0.518, 0.942, -1.024, -0.05000000000000004, -1.018, 0.10499999999999987, 0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003, -0.514, -0.04300000000000003, -0.523, 0.736, -0.511, -1.008, -0.515, -0.04400000000000003, -0.5, 1.092, -1.001, -0.04500000000000003, 0.06799999999999984, -0.037000000000000026, -1.007, -0.04900000000000004, -1.009, -0.523, -1.007, -1.004, -1.006, -0.047000000000000035, -0.501, -1.011, -1.014, -0.506, -1.033, -1.012, -0.03000000000000002, -0.5079999999999999, -0.509, -0.517, -0.525, -0.04100000000000003, -1.008, -1.004, -1.013, -0.5, 0.82, -1.009, -0.05300000000000004, -1.034, 0.578, -0.5059999999999999, -0.046000000000000034, -1.022, -1.003, -1.005, -0.04500000000000003, 0.639, -1.0039999999999998, -1.012, -1.003, -0.05400000000000004, -1.001, 1.013, -1.001, -0.04300000000000003, -0.03900000000000003, -1.008, -0.541, -1.005, -1.003, -1.009]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22475172205917, "mean_inference_ms": 1.4750816883917859, "mean_action_processing_ms": 0.062317637914018585, "mean_env_wait_ms": 0.08795499887024441, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020344853401184082, "StateBufferConnector_ms": 0.0014433860778808594, "ViewRequirementAgentConnector_ms": 0.031139373779296875}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000, "num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.69122904124677, "num_env_steps_trained_throughput_per_sec": 102.69122904124677, "timesteps_total": 52000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 104000, "timers": {"training_iteration_time_ms": 38838.376, "sample_time_ms": 7459.171, "learn_time_ms": 31361.691, "learn_throughput": 127.544, "synch_weights_time_ms": 17.012}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 52000, "num_agent_steps_sampled": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 302, "training_iteration": 13, "trial_id": "d67e4_00000", "date": "2023-09-20_22-17-33", "timestamp": 1695262653, "time_this_iter_s": 38.95586395263672, "time_total_s": 504.5618486404419, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d08a8c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 504.5618486404419, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 36.357142857142854, "ram_util_percent": 47.71607142857142}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5469236708556613, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.023559379839207396, "policy_loss": -0.027233043825496375, "vf_loss": 0.003577433567049108, "vf_explained_var": 0.6136516212796171, "kl": 0.01563698430856997, "entropy": 1.2424498971551656, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 12960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "sampler_results": {"episode_reward_max": 1.495, "episode_reward_min": -0.8060000000000002, "episode_reward_mean": 0.16763999999999996, "episode_len_mean": 134.34, "episode_media": {}, "episodes_this_iter": 28, "policy_reward_min": {"red_0": -1.035, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.092}, "policy_reward_mean": {"red_0": 0.7167600000000001, "blue_0": -0.54912}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.69, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.69, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.69, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011, 0.6619999999999999, 0.3889999999999999, -0.08000000000000007, 0.23299999999999998, 0.1429999999999998, -0.16200000000000003, 0.49, 0.44899999999999995, 0.45500000000000007, 0.05700000000000005, -0.04800000000000004, 0.44199999999999995, -0.4790000000000002, -0.17200000000000013, 0.3639999999999999, -0.18000000000000013, 0.40700000000000003, 0.0019999999999997797, -0.16200000000000003, 0.41100000000000003, -0.18000000000000005, -0.1380000000000001, 0.9630000000000001, -0.403, -0.391, 0.8999999999999999, -0.17600000000000005, 0.2829999999999999, 0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998, 0.516, -0.18500000000000014, 0.4079999999999999, 0.3820000000000001, 0.256, 0.952, -0.18799999999999994, -0.2320000000000001, 0.42899999999999994, -0.8060000000000002, 0.07199999999999995, 0.8660000000000001, -0.19900000000000015, -0.06800000000000006, 0.43700000000000006, 0.395, -0.17300000000000013, 0.133, -0.05399999999999994, 0.19799999999999995, 0.403, 0.43199999999999994, 0.42300000000000004, 0.4969999999999999, -0.025000000000000022, -0.20600000000000016, 0.42499999999999993, -0.19200000000000006, -0.4790000000000002, 0.3740000000000001, 0.42000000000000015, -0.16700000000000004, -0.28, -0.31700000000000006, 0.3939999999999999, 0.42300000000000004, 0.794, 0.3639999999999999, -0.7170000000000001, 0.41800000000000015, 1.495, 0.3599999999999999, -0.21100000000000016, -0.0040000000000000036, 0.4159999999999999, -0.125, -0.6480000000000001, -0.29800000000000004, 0.41999999999999993, 0.9260000000000002, 0.831, 0.4079999999999999, 0.359, -0.3830000000000001, 0.615, 0.16699999999999982, -0.17999999999999994, 0.31300000000000017, 0.3719999999999999, 0.17900000000000005], "episode_lengths": [191, 300, 300, 278, 14, 300, 66, 300, 105, 300, 171, 84, 106, 48, 162, 300, 15, 133, 15, 300, 292, 300, 42, 300, 28, 143, 51, 28, 54, 300, 12, 107, 113, 30, 211, 66, 300, 72, 66, 134, 148, 300, 27, 37, 77, 16, 57, 67, 300, 222, 134, 42, 300, 167, 20, 33, 300, 113, 16, 93, 31, 300, 25, 155, 8, 300, 300, 57, 271, 40, 25, 48, 84, 96, 300, 25, 65, 43, 197, 25, 150, 45, 300, 154, 300, 39, 173, 80, 25, 23, 53, 300, 44, 266, 124, 104, 55, 58, 41, 99], "policy_red_0_reward": [-0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001, 1.1760000000000002, 0.43199999999999994, 0.44299999999999995, -0.503, 0.6539999999999999, 0.846, 1.005, 0.493, 0.955, -1.035, 0.953, 0.487, -0.547, -0.1350000000000001, 1.371, -0.1310000000000001, 1.416, 0.5249999999999999, 0.845, 1.415, 0.826, -0.09100000000000007, 1.464, 0.608, 0.623, 1.4060000000000001, 0.857, 1.295, 0.4099999999999999, 0.75, 1.298, 1.091, 1.041, -0.1440000000000001, 1.416, 1.3860000000000001, 1.2690000000000001, 1.452, -1.008, 0.7769999999999999, 0.482, 0.22799999999999987, -0.506, 1.3719999999999999, -0.1530000000000001, 0.954, 1.44, 1.4, -0.12800000000000009, -0.506, 0.95, 1.21, 1.4060000000000001, 0.486, 1.424, -0.516, 0.976, -0.16300000000000012, 0.46399999999999997, 0.816, 0.06199999999999986, 1.379, 1.423, 0.842, 0.737, 0.696, 0.44099999999999995, 1.425, 1.298, 1.37, 0.31599999999999995, 1.423, 1.022, 1.3639999999999999, -0.16400000000000012, 1.0230000000000001, 0.45699999999999996, 0.881, 0.3799999999999999, 0.715, 1.424, 1.4300000000000002, 1.3399999999999999, 0.46199999999999997, 1.361, 0.6449999999999999, 1.127, 1.178, 0.831, 1.322, 1.377, 1.193], "policy_blue_0_reward": [0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003, -0.514, -0.04300000000000003, -0.523, 0.736, -0.511, -1.008, -0.515, -0.04400000000000003, -0.5, 1.092, -1.001, -0.04500000000000003, 0.06799999999999984, -0.037000000000000026, -1.007, -0.04900000000000004, -1.009, -0.523, -1.007, -1.004, -1.006, -0.047000000000000035, -0.501, -1.011, -1.014, -0.506, -1.033, -1.012, -0.03000000000000002, -0.5079999999999999, -0.509, -0.517, -0.525, -0.04100000000000003, -1.008, -1.004, -1.013, -0.5, 0.82, -1.009, -0.05300000000000004, -1.034, 0.578, -0.5059999999999999, -0.046000000000000034, -1.022, -1.003, -1.005, -0.04500000000000003, 0.639, -1.0039999999999998, -1.012, -1.003, -0.05400000000000004, -1.001, 1.013, -1.001, -0.04300000000000003, -0.03900000000000003, -1.008, -0.541, -1.005, -1.003, -1.009, -1.017, -1.013, -0.047000000000000035, -1.002, -0.5039999999999999, -1.006, -1.033, -1.005, 0.473, -1.004, -0.047000000000000035, -1.027, -0.04100000000000003, -1.006, -1.028, -1.013, -1.004, -0.504, -0.509, -0.05400000000000004, -1.002, -1.028, -0.512, -1.011, -1.011, -1.009, -1.005, -1.0139999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22487751248356105, "mean_inference_ms": 1.4750858610459778, "mean_action_processing_ms": 0.0623351851940244, "mean_env_wait_ms": 0.08805320680226383, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020400047302246094, "StateBufferConnector_ms": 0.0014569759368896484, "ViewRequirementAgentConnector_ms": 0.031209111213684082}}, "episode_reward_max": 1.495, "episode_reward_min": -0.8060000000000002, "episode_reward_mean": 0.16763999999999996, "episode_len_mean": 134.34, "episodes_this_iter": 28, "policy_reward_min": {"red_0": -1.035, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.464, "blue_0": 1.092}, "policy_reward_mean": {"red_0": 0.7167600000000001, "blue_0": -0.54912}, "hist_stats": {"episode_reward": [-0.1250000000000001, -0.08100000000000006, -0.17900000000000013, -0.43900000000000006, -0.04300000000000004, 0.3049999999999998, 0.2869999999999999, -0.16000000000000011, 0.6619999999999999, 0.3889999999999999, -0.08000000000000007, 0.23299999999999998, 0.1429999999999998, -0.16200000000000003, 0.49, 0.44899999999999995, 0.45500000000000007, 0.05700000000000005, -0.04800000000000004, 0.44199999999999995, -0.4790000000000002, -0.17200000000000013, 0.3639999999999999, -0.18000000000000013, 0.40700000000000003, 0.0019999999999997797, -0.16200000000000003, 0.41100000000000003, -0.18000000000000005, -0.1380000000000001, 0.9630000000000001, -0.403, -0.391, 0.8999999999999999, -0.17600000000000005, 0.2829999999999999, 0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998, 0.516, -0.18500000000000014, 0.4079999999999999, 0.3820000000000001, 0.256, 0.952, -0.18799999999999994, -0.2320000000000001, 0.42899999999999994, -0.8060000000000002, 0.07199999999999995, 0.8660000000000001, -0.19900000000000015, -0.06800000000000006, 0.43700000000000006, 0.395, -0.17300000000000013, 0.133, -0.05399999999999994, 0.19799999999999995, 0.403, 0.43199999999999994, 0.42300000000000004, 0.4969999999999999, -0.025000000000000022, -0.20600000000000016, 0.42499999999999993, -0.19200000000000006, -0.4790000000000002, 0.3740000000000001, 0.42000000000000015, -0.16700000000000004, -0.28, -0.31700000000000006, 0.3939999999999999, 0.42300000000000004, 0.794, 0.3639999999999999, -0.7170000000000001, 0.41800000000000015, 1.495, 0.3599999999999999, -0.21100000000000016, -0.0040000000000000036, 0.4159999999999999, -0.125, -0.6480000000000001, -0.29800000000000004, 0.41999999999999993, 0.9260000000000002, 0.831, 0.4079999999999999, 0.359, -0.3830000000000001, 0.615, 0.16699999999999982, -0.17999999999999994, 0.31300000000000017, 0.3719999999999999, 0.17900000000000005], "episode_lengths": [191, 300, 300, 278, 14, 300, 66, 300, 105, 300, 171, 84, 106, 48, 162, 300, 15, 133, 15, 300, 292, 300, 42, 300, 28, 143, 51, 28, 54, 300, 12, 107, 113, 30, 211, 66, 300, 72, 66, 134, 148, 300, 27, 37, 77, 16, 57, 67, 300, 222, 134, 42, 300, 167, 20, 33, 300, 113, 16, 93, 31, 300, 25, 155, 8, 300, 300, 57, 271, 40, 25, 48, 84, 96, 300, 25, 65, 43, 197, 25, 150, 45, 300, 154, 300, 39, 173, 80, 25, 23, 53, 300, 44, 266, 124, 104, 55, 58, 41, 99], "policy_red_0_reward": [-0.527, -0.047000000000000035, -0.1310000000000001, 0.601, 0.958, -0.1570000000000001, 1.2930000000000001, -0.1210000000000001, 1.1760000000000002, 0.43199999999999994, 0.44299999999999995, -0.503, 0.6539999999999999, 0.846, 1.005, 0.493, 0.955, -1.035, 0.953, 0.487, -0.547, -0.1350000000000001, 1.371, -0.1310000000000001, 1.416, 0.5249999999999999, 0.845, 1.415, 0.826, -0.09100000000000007, 1.464, 0.608, 0.623, 1.4060000000000001, 0.857, 1.295, 0.4099999999999999, 0.75, 1.298, 1.091, 1.041, -0.1440000000000001, 1.416, 1.3860000000000001, 1.2690000000000001, 1.452, -1.008, 0.7769999999999999, 0.482, 0.22799999999999987, -0.506, 1.3719999999999999, -0.1530000000000001, 0.954, 1.44, 1.4, -0.12800000000000009, -0.506, 0.95, 1.21, 1.4060000000000001, 0.486, 1.424, -0.516, 0.976, -0.16300000000000012, 0.46399999999999997, 0.816, 0.06199999999999986, 1.379, 1.423, 0.842, 0.737, 0.696, 0.44099999999999995, 1.425, 1.298, 1.37, 0.31599999999999995, 1.423, 1.022, 1.3639999999999999, -0.16400000000000012, 1.0230000000000001, 0.45699999999999996, 0.881, 0.3799999999999999, 0.715, 1.424, 1.4300000000000002, 1.3399999999999999, 0.46199999999999997, 1.361, 0.6449999999999999, 1.127, 1.178, 0.831, 1.322, 1.377, 1.193], "policy_blue_0_reward": [0.4019999999999999, -0.03400000000000002, -0.048000000000000036, -1.04, -1.001, 0.46199999999999997, -1.006, -0.03900000000000003, -0.514, -0.04300000000000003, -0.523, 0.736, -0.511, -1.008, -0.515, -0.04400000000000003, -0.5, 1.092, -1.001, -0.04500000000000003, 0.06799999999999984, -0.037000000000000026, -1.007, -0.04900000000000004, -1.009, -0.523, -1.007, -1.004, -1.006, -0.047000000000000035, -0.501, -1.011, -1.014, -0.506, -1.033, -1.012, -0.03000000000000002, -0.5079999999999999, -0.509, -0.517, -0.525, -0.04100000000000003, -1.008, -1.004, -1.013, -0.5, 0.82, -1.009, -0.05300000000000004, -1.034, 0.578, -0.5059999999999999, -0.046000000000000034, -1.022, -1.003, -1.005, -0.04500000000000003, 0.639, -1.0039999999999998, -1.012, -1.003, -0.05400000000000004, -1.001, 1.013, -1.001, -0.04300000000000003, -0.03900000000000003, -1.008, -0.541, -1.005, -1.003, -1.009, -1.017, -1.013, -0.047000000000000035, -1.002, -0.5039999999999999, -1.006, -1.033, -1.005, 0.473, -1.004, -0.047000000000000035, -1.027, -0.04100000000000003, -1.006, -1.028, -1.013, -1.004, -0.504, -0.509, -0.05400000000000004, -1.002, -1.028, -0.512, -1.011, -1.011, -1.009, -1.005, -1.0139999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22487751248356105, "mean_inference_ms": 1.4750858610459778, "mean_action_processing_ms": 0.0623351851940244, "mean_env_wait_ms": 0.08805320680226383, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.020400047302246094, "StateBufferConnector_ms": 0.0014569759368896484, "ViewRequirementAgentConnector_ms": 0.031209111213684082}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000, "num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.19915856215854, "num_env_steps_trained_throughput_per_sec": 103.19915856215854, "timesteps_total": 56000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 112000, "timers": {"training_iteration_time_ms": 38825.916, "sample_time_ms": 7458.12, "learn_time_ms": 31350.331, "learn_throughput": 127.59, "synch_weights_time_ms": 16.964}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 56000, "num_agent_steps_sampled": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 330, "training_iteration": 14, "trial_id": "d67e4_00000", "date": "2023-09-20_22-18-12", "timestamp": 1695262692, "time_this_iter_s": 38.76410984992981, "time_total_s": 543.3259584903717, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4707640>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 543.3259584903717, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 35.129090909090905, "ram_util_percent": 47.76363636363634}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.71, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.71, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.11, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.71, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4074895151269933, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0119454926008378, "policy_loss": -0.016124463504820597, "vf_loss": 0.00606423341144667, "vf_explained_var": 0.4910701518257459, "kl": 0.011968270491314208, "entropy": 1.2468000226964553, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 13920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "sampler_results": {"episode_reward_max": 1.495, "episode_reward_min": -0.8060000000000002, "episode_reward_mean": 0.11325999999999993, "episode_len_mean": 120.34, "episode_media": {}, "episodes_this_iter": 36, "policy_reward_min": {"red_0": -1.0919999999999999, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.452, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.6905599999999998, "blue_0": -0.5772999999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.71, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.71, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.11, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.71, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998, 0.516, -0.18500000000000014, 0.4079999999999999, 0.3820000000000001, 0.256, 0.952, -0.18799999999999994, -0.2320000000000001, 0.42899999999999994, -0.8060000000000002, 0.07199999999999995, 0.8660000000000001, -0.19900000000000015, -0.06800000000000006, 0.43700000000000006, 0.395, -0.17300000000000013, 0.133, -0.05399999999999994, 0.19799999999999995, 0.403, 0.43199999999999994, 0.42300000000000004, 0.4969999999999999, -0.025000000000000022, -0.20600000000000016, 0.42499999999999993, -0.19200000000000006, -0.4790000000000002, 0.3740000000000001, 0.42000000000000015, -0.16700000000000004, -0.28, -0.31700000000000006, 0.3939999999999999, 0.42300000000000004, 0.794, 0.3639999999999999, -0.7170000000000001, 0.41800000000000015, 1.495, 0.3599999999999999, -0.21100000000000016, -0.0040000000000000036, 0.4159999999999999, -0.125, -0.6480000000000001, -0.29800000000000004, 0.41999999999999993, 0.9260000000000002, 0.831, 0.4079999999999999, 0.359, -0.3830000000000001, 0.615, 0.16699999999999982, -0.17999999999999994, 0.31300000000000017, 0.3719999999999999, 0.17900000000000005, -0.16700000000000012, 0.43499999999999994, -0.07999999999999996, -0.04800000000000004, -0.277, 0.391, -0.2350000000000001, -0.486, -0.1550000000000001, -0.16500000000000012, -0.061000000000000054, 0.019999999999999907, -0.07000000000000006, -0.15900000000000003, -0.06800000000000006, -0.30399999999999994, 0.006999999999999895, -0.06800000000000006, 0.30400000000000005, -0.07300000000000006, 0.42999999999999994, -0.126, -0.030000000000000027, 0.42399999999999993, 0.20199999999999996, -0.6010000000000001, -0.031000000000000028, -0.08999999999999997, -0.7440000000000002, 0.30900000000000016, 0.361, 0.3420000000000001, -0.3900000000000001, -0.1510000000000001, -0.1530000000000001, -0.28700000000000003], "episode_lengths": [300, 72, 66, 134, 148, 300, 27, 37, 77, 16, 57, 67, 300, 222, 134, 42, 300, 167, 20, 33, 300, 113, 16, 93, 31, 300, 25, 155, 8, 300, 300, 57, 271, 40, 25, 48, 84, 96, 300, 25, 65, 43, 197, 25, 150, 45, 300, 154, 300, 39, 173, 80, 25, 23, 53, 300, 44, 266, 124, 104, 55, 58, 41, 99, 300, 21, 23, 15, 243, 35, 231, 127, 300, 300, 19, 147, 22, 49, 21, 81, 300, 170, 62, 22, 22, 37, 10, 24, 92, 170, 10, 29, 201, 58, 43, 49, 251, 300, 300, 81], "policy_red_0_reward": [0.4099999999999999, 0.75, 1.298, 1.091, 1.041, -0.1440000000000001, 1.416, 1.3860000000000001, 1.2690000000000001, 1.452, -1.008, 0.7769999999999999, 0.482, 0.22799999999999987, -0.506, 1.3719999999999999, -0.1530000000000001, 0.954, 1.44, 1.4, -0.12800000000000009, -0.506, 0.95, 1.21, 1.4060000000000001, 0.486, 1.424, -0.516, 0.976, -0.16300000000000012, 0.46399999999999997, 0.816, 0.06199999999999986, 1.379, 1.423, 0.842, 0.737, 0.696, 0.44099999999999995, 1.425, 1.298, 1.37, 0.31599999999999995, 1.423, 1.022, 1.3639999999999999, -0.16400000000000012, 1.0230000000000001, 0.45699999999999996, 0.881, 0.3799999999999999, 0.715, 1.424, 1.4300000000000002, 1.3399999999999999, 0.46199999999999997, 1.361, 0.6449999999999999, 1.127, 1.178, 0.831, 1.322, 1.377, 1.193, -0.12600000000000008, -1.0, 0.924, 0.955, 0.7599999999999999, 1.392, -0.518, -1.0919999999999999, -0.10600000000000008, -0.12500000000000008, 0.942, -0.517, 0.9319999999999999, 0.846, 0.9349999999999999, 0.708, 0.5519999999999999, 0.954, 1.312, 0.9309999999999999, 1.434, 0.883, 0.97, 1.428, 1.208, 0.42599999999999993, 0.97, 0.913, 0.2909999999999998, -0.5119999999999999, -0.502, 1.349, 0.6429999999999999, -0.11000000000000008, -0.11400000000000009, -1.034], "policy_blue_0_reward": [-0.03000000000000002, -0.5079999999999999, -0.509, -0.517, -0.525, -0.04100000000000003, -1.008, -1.004, -1.013, -0.5, 0.82, -1.009, -0.05300000000000004, -1.034, 0.578, -0.5059999999999999, -0.046000000000000034, -1.022, -1.003, -1.005, -0.04500000000000003, 0.639, -1.0039999999999998, -1.012, -1.003, -0.05400000000000004, -1.001, 1.013, -1.001, -0.04300000000000003, -0.03900000000000003, -1.008, -0.541, -1.005, -1.003, -1.009, -1.017, -1.013, -0.047000000000000035, -1.002, -0.5039999999999999, -1.006, -1.033, -1.005, 0.473, -1.004, -0.047000000000000035, -1.027, -0.04100000000000003, -1.006, -1.028, -1.013, -1.004, -0.504, -0.509, -0.05400000000000004, -1.002, -1.028, -0.512, -1.011, -1.011, -1.009, -1.005, -1.0139999999999998, -0.04100000000000003, 1.435, -1.004, -1.003, -1.037, -1.001, 0.2829999999999999, 0.606, -0.04900000000000004, -0.04000000000000003, -1.003, 0.5369999999999999, -1.002, -1.005, -1.003, -1.0119999999999998, -0.545, -1.022, -1.008, -1.004, -1.004, -1.009, -1.0, -1.004, -1.006, -1.027, -1.001, -1.003, -1.035, 0.8210000000000001, 0.863, -1.007, -1.033, -0.04100000000000003, -0.03900000000000003, 0.747]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22520985708062105, "mean_inference_ms": 1.475849888471833, "mean_action_processing_ms": 0.06242869474984946, "mean_env_wait_ms": 0.08820525335212259, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02063441276550293, "StateBufferConnector_ms": 0.0014660358428955078, "ViewRequirementAgentConnector_ms": 0.03132045269012451}}, "episode_reward_max": 1.495, "episode_reward_min": -0.8060000000000002, "episode_reward_mean": 0.11325999999999993, "episode_len_mean": 120.34, "episodes_this_iter": 36, "policy_reward_min": {"red_0": -1.0919999999999999, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.452, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.6905599999999998, "blue_0": -0.5772999999999999}, "hist_stats": {"episode_reward": [0.3799999999999999, 0.242, 0.7890000000000001, 0.5739999999999998, 0.516, -0.18500000000000014, 0.4079999999999999, 0.3820000000000001, 0.256, 0.952, -0.18799999999999994, -0.2320000000000001, 0.42899999999999994, -0.8060000000000002, 0.07199999999999995, 0.8660000000000001, -0.19900000000000015, -0.06800000000000006, 0.43700000000000006, 0.395, -0.17300000000000013, 0.133, -0.05399999999999994, 0.19799999999999995, 0.403, 0.43199999999999994, 0.42300000000000004, 0.4969999999999999, -0.025000000000000022, -0.20600000000000016, 0.42499999999999993, -0.19200000000000006, -0.4790000000000002, 0.3740000000000001, 0.42000000000000015, -0.16700000000000004, -0.28, -0.31700000000000006, 0.3939999999999999, 0.42300000000000004, 0.794, 0.3639999999999999, -0.7170000000000001, 0.41800000000000015, 1.495, 0.3599999999999999, -0.21100000000000016, -0.0040000000000000036, 0.4159999999999999, -0.125, -0.6480000000000001, -0.29800000000000004, 0.41999999999999993, 0.9260000000000002, 0.831, 0.4079999999999999, 0.359, -0.3830000000000001, 0.615, 0.16699999999999982, -0.17999999999999994, 0.31300000000000017, 0.3719999999999999, 0.17900000000000005, -0.16700000000000012, 0.43499999999999994, -0.07999999999999996, -0.04800000000000004, -0.277, 0.391, -0.2350000000000001, -0.486, -0.1550000000000001, -0.16500000000000012, -0.061000000000000054, 0.019999999999999907, -0.07000000000000006, -0.15900000000000003, -0.06800000000000006, -0.30399999999999994, 0.006999999999999895, -0.06800000000000006, 0.30400000000000005, -0.07300000000000006, 0.42999999999999994, -0.126, -0.030000000000000027, 0.42399999999999993, 0.20199999999999996, -0.6010000000000001, -0.031000000000000028, -0.08999999999999997, -0.7440000000000002, 0.30900000000000016, 0.361, 0.3420000000000001, -0.3900000000000001, -0.1510000000000001, -0.1530000000000001, -0.28700000000000003], "episode_lengths": [300, 72, 66, 134, 148, 300, 27, 37, 77, 16, 57, 67, 300, 222, 134, 42, 300, 167, 20, 33, 300, 113, 16, 93, 31, 300, 25, 155, 8, 300, 300, 57, 271, 40, 25, 48, 84, 96, 300, 25, 65, 43, 197, 25, 150, 45, 300, 154, 300, 39, 173, 80, 25, 23, 53, 300, 44, 266, 124, 104, 55, 58, 41, 99, 300, 21, 23, 15, 243, 35, 231, 127, 300, 300, 19, 147, 22, 49, 21, 81, 300, 170, 62, 22, 22, 37, 10, 24, 92, 170, 10, 29, 201, 58, 43, 49, 251, 300, 300, 81], "policy_red_0_reward": [0.4099999999999999, 0.75, 1.298, 1.091, 1.041, -0.1440000000000001, 1.416, 1.3860000000000001, 1.2690000000000001, 1.452, -1.008, 0.7769999999999999, 0.482, 0.22799999999999987, -0.506, 1.3719999999999999, -0.1530000000000001, 0.954, 1.44, 1.4, -0.12800000000000009, -0.506, 0.95, 1.21, 1.4060000000000001, 0.486, 1.424, -0.516, 0.976, -0.16300000000000012, 0.46399999999999997, 0.816, 0.06199999999999986, 1.379, 1.423, 0.842, 0.737, 0.696, 0.44099999999999995, 1.425, 1.298, 1.37, 0.31599999999999995, 1.423, 1.022, 1.3639999999999999, -0.16400000000000012, 1.0230000000000001, 0.45699999999999996, 0.881, 0.3799999999999999, 0.715, 1.424, 1.4300000000000002, 1.3399999999999999, 0.46199999999999997, 1.361, 0.6449999999999999, 1.127, 1.178, 0.831, 1.322, 1.377, 1.193, -0.12600000000000008, -1.0, 0.924, 0.955, 0.7599999999999999, 1.392, -0.518, -1.0919999999999999, -0.10600000000000008, -0.12500000000000008, 0.942, -0.517, 0.9319999999999999, 0.846, 0.9349999999999999, 0.708, 0.5519999999999999, 0.954, 1.312, 0.9309999999999999, 1.434, 0.883, 0.97, 1.428, 1.208, 0.42599999999999993, 0.97, 0.913, 0.2909999999999998, -0.5119999999999999, -0.502, 1.349, 0.6429999999999999, -0.11000000000000008, -0.11400000000000009, -1.034], "policy_blue_0_reward": [-0.03000000000000002, -0.5079999999999999, -0.509, -0.517, -0.525, -0.04100000000000003, -1.008, -1.004, -1.013, -0.5, 0.82, -1.009, -0.05300000000000004, -1.034, 0.578, -0.5059999999999999, -0.046000000000000034, -1.022, -1.003, -1.005, -0.04500000000000003, 0.639, -1.0039999999999998, -1.012, -1.003, -0.05400000000000004, -1.001, 1.013, -1.001, -0.04300000000000003, -0.03900000000000003, -1.008, -0.541, -1.005, -1.003, -1.009, -1.017, -1.013, -0.047000000000000035, -1.002, -0.5039999999999999, -1.006, -1.033, -1.005, 0.473, -1.004, -0.047000000000000035, -1.027, -0.04100000000000003, -1.006, -1.028, -1.013, -1.004, -0.504, -0.509, -0.05400000000000004, -1.002, -1.028, -0.512, -1.011, -1.011, -1.009, -1.005, -1.0139999999999998, -0.04100000000000003, 1.435, -1.004, -1.003, -1.037, -1.001, 0.2829999999999999, 0.606, -0.04900000000000004, -0.04000000000000003, -1.003, 0.5369999999999999, -1.002, -1.005, -1.003, -1.0119999999999998, -0.545, -1.022, -1.008, -1.004, -1.004, -1.009, -1.0, -1.004, -1.006, -1.027, -1.001, -1.003, -1.035, 0.8210000000000001, 0.863, -1.007, -1.033, -0.04100000000000003, -0.03900000000000003, 0.747]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22520985708062105, "mean_inference_ms": 1.475849888471833, "mean_action_processing_ms": 0.06242869474984946, "mean_env_wait_ms": 0.08820525335212259, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02063441276550293, "StateBufferConnector_ms": 0.0014660358428955078, "ViewRequirementAgentConnector_ms": 0.03132045269012451}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000, "num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.7681494579664, "num_env_steps_trained_throughput_per_sec": 102.7681494579664, "timesteps_total": 60000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 120000, "timers": {"training_iteration_time_ms": 38829.0, "sample_time_ms": 7463.703, "learn_time_ms": 31347.846, "learn_throughput": 127.6, "synch_weights_time_ms": 16.94}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 60000, "num_agent_steps_sampled": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 366, "training_iteration": 15, "trial_id": "d67e4_00000", "date": "2023-09-20_22-18-51", "timestamp": 1695262731, "time_this_iter_s": 38.92696213722229, "time_total_s": 582.252920627594, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a6879630>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 582.252920627594, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 35.30714285714286, "ram_util_percent": 47.88392857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.78, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.78, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.11, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.78, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6350994039326907, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.019290161457198942, "policy_loss": -0.025080059037039366, "vf_loss": 0.0075080299910041505, "vf_explained_var": 0.5156850007052223, "kl": 0.016144138892424092, "entropy": 1.1929449843863646, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 14880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "sampler_results": {"episode_reward_max": 0.96, "episode_reward_min": -0.7440000000000002, "episode_reward_mean": 0.10661999999999994, "episode_len_mean": 102.18, "episode_media": {}, "episodes_this_iter": 47, "policy_reward_min": {"red_0": -1.0919999999999999, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.7519800000000001, "blue_0": -0.6453599999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.78, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.11, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.78, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.11, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.78, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.11, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.0040000000000000036, 0.4159999999999999, -0.125, -0.6480000000000001, -0.29800000000000004, 0.41999999999999993, 0.9260000000000002, 0.831, 0.4079999999999999, 0.359, -0.3830000000000001, 0.615, 0.16699999999999982, -0.17999999999999994, 0.31300000000000017, 0.3719999999999999, 0.17900000000000005, -0.16700000000000012, 0.43499999999999994, -0.07999999999999996, -0.04800000000000004, -0.277, 0.391, -0.2350000000000001, -0.486, -0.1550000000000001, -0.16500000000000012, -0.061000000000000054, 0.019999999999999907, -0.07000000000000006, -0.15900000000000003, -0.06800000000000006, -0.30399999999999994, 0.006999999999999895, -0.06800000000000006, 0.30400000000000005, -0.07300000000000006, 0.42999999999999994, -0.126, -0.030000000000000027, 0.42399999999999993, 0.20199999999999996, -0.6010000000000001, -0.031000000000000028, -0.08999999999999997, -0.7440000000000002, 0.30900000000000016, 0.361, 0.3420000000000001, -0.3900000000000001, -0.1510000000000001, -0.1530000000000001, -0.28700000000000003, 0.33599999999999985, -0.16800000000000004, 0.4119999999999999, 0.3879999999999999, 0.827, 0.377, -0.10799999999999987, 0.81, 0.41500000000000004, -0.41400000000000015, 0.4750000000000001, -0.31700000000000006, 0.40100000000000025, -0.43600000000000005, 0.30099999999999993, 0.19099999999999984, 0.42100000000000004, -0.030999999999999917, 0.7010000000000001, -0.271, 0.42900000000000005, 0.43100000000000005, -0.277, -0.1500000000000001, 0.3520000000000001, -0.19800000000000015, 0.43599999999999994, -0.027000000000000024, 0.96, 0.32299999999999995, -0.09500000000000008, 0.29400000000000004, -0.44299999999999995, 0.1519999999999999, -0.025000000000000022, -0.31200000000000006, -0.07199999999999995, -0.06900000000000006, 0.133, 0.44499999999999984, 0.704, -0.07299999999999995, 0.30800000000000005, 0.44699999999999995, 0.1419999999999999, 0.5579999999999998, 0.405], "episode_lengths": [154, 300, 39, 173, 80, 25, 23, 53, 300, 44, 266, 124, 104, 55, 58, 41, 99, 300, 21, 23, 15, 243, 35, 231, 127, 300, 300, 19, 147, 22, 49, 21, 81, 300, 170, 62, 22, 22, 37, 10, 24, 92, 170, 10, 29, 201, 58, 43, 49, 251, 300, 300, 81, 51, 49, 300, 300, 53, 38, 34, 56, 27, 114, 8, 219, 29, 120, 63, 91, 26, 10, 90, 76, 23, 23, 81, 300, 46, 300, 20, 9, 12, 56, 162, 65, 126, 104, 163, 233, 23, 22, 108, 17, 94, 23, 60, 17, 109, 135, 30], "policy_red_0_reward": [1.0230000000000001, 0.45699999999999996, 0.881, 0.3799999999999999, 0.715, 1.424, 1.4300000000000002, 1.3399999999999999, 0.46199999999999997, 1.361, 0.6449999999999999, 1.127, 1.178, 0.831, 1.322, 1.377, 1.193, -0.12600000000000008, -1.0, 0.924, 0.955, 0.7599999999999999, 1.392, -0.518, -1.0919999999999999, -0.10600000000000008, -0.12500000000000008, 0.942, -0.517, 0.9319999999999999, 0.846, 0.9349999999999999, 0.708, 0.5519999999999999, 0.954, 1.312, 0.9309999999999999, 1.434, 0.883, 0.97, 1.428, 1.208, 0.42599999999999993, 0.97, 0.913, 0.2909999999999998, -0.5119999999999999, -0.502, 1.349, 0.6429999999999999, -0.11000000000000008, -0.11400000000000009, -1.034, 1.342, 0.838, 0.45099999999999996, 0.43299999999999994, 1.338, 1.383, 0.897, 1.317, 1.419, 0.6039999999999999, 1.476, 0.7219999999999999, 1.407, 0.5769999999999998, 1.3079999999999998, 1.205, 1.4220000000000002, 0.97, 1.2149999999999999, 0.743, 0.931, 1.431, -1.021, -0.10300000000000008, 1.359, -0.1460000000000001, 1.439, 0.973, 1.464, 1.327, 0.42899999999999994, 1.303, -1.049, 1.174, 1.001, 0.21899999999999997, 0.93, 0.9329999999999999, 1.15, 1.4489999999999998, -0.508, 0.931, 1.318, -0.5, 1.158, 1.083, 1.408], "policy_blue_0_reward": [-1.027, -0.04100000000000003, -1.006, -1.028, -1.013, -1.004, -0.504, -0.509, -0.05400000000000004, -1.002, -1.028, -0.512, -1.011, -1.011, -1.009, -1.005, -1.0139999999999998, -0.04100000000000003, 1.435, -1.004, -1.003, -1.037, -1.001, 0.2829999999999999, 0.606, -0.04900000000000004, -0.04000000000000003, -1.003, 0.5369999999999999, -1.002, -1.005, -1.003, -1.0119999999999998, -0.545, -1.022, -1.008, -1.004, -1.004, -1.009, -1.0, -1.004, -1.006, -1.027, -1.001, -1.003, -1.035, 0.8210000000000001, 0.863, -1.007, -1.033, -0.04100000000000003, -0.03900000000000003, 0.747, -1.006, -1.006, -0.03900000000000003, -0.04500000000000003, -0.511, -1.006, -1.005, -0.507, -1.004, -1.018, -1.001, -1.039, -1.0059999999999998, -1.013, -1.007, -1.014, -1.001, -1.001, -0.514, -1.014, -0.502, -1.0, 0.744, -0.047000000000000035, -1.007, -0.05200000000000004, -1.003, -1.0, -0.504, -1.004, -0.524, -1.009, 0.606, -1.022, -1.026, -0.531, -1.002, -1.002, -1.017, -1.004, 1.212, -1.004, -1.0099999999999998, 0.947, -1.016, -0.525, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2255666910550595, "mean_inference_ms": 1.4754157067494509, "mean_action_processing_ms": 0.062440870541756885, "mean_env_wait_ms": 0.08827451987150407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02106451988220215, "StateBufferConnector_ms": 0.0014911890029907227, "ViewRequirementAgentConnector_ms": 0.03168666362762451}}, "episode_reward_max": 0.96, "episode_reward_min": -0.7440000000000002, "episode_reward_mean": 0.10661999999999994, "episode_len_mean": 102.18, "episodes_this_iter": 47, "policy_reward_min": {"red_0": -1.0919999999999999, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.435}, "policy_reward_mean": {"red_0": 0.7519800000000001, "blue_0": -0.6453599999999998}, "hist_stats": {"episode_reward": [-0.0040000000000000036, 0.4159999999999999, -0.125, -0.6480000000000001, -0.29800000000000004, 0.41999999999999993, 0.9260000000000002, 0.831, 0.4079999999999999, 0.359, -0.3830000000000001, 0.615, 0.16699999999999982, -0.17999999999999994, 0.31300000000000017, 0.3719999999999999, 0.17900000000000005, -0.16700000000000012, 0.43499999999999994, -0.07999999999999996, -0.04800000000000004, -0.277, 0.391, -0.2350000000000001, -0.486, -0.1550000000000001, -0.16500000000000012, -0.061000000000000054, 0.019999999999999907, -0.07000000000000006, -0.15900000000000003, -0.06800000000000006, -0.30399999999999994, 0.006999999999999895, -0.06800000000000006, 0.30400000000000005, -0.07300000000000006, 0.42999999999999994, -0.126, -0.030000000000000027, 0.42399999999999993, 0.20199999999999996, -0.6010000000000001, -0.031000000000000028, -0.08999999999999997, -0.7440000000000002, 0.30900000000000016, 0.361, 0.3420000000000001, -0.3900000000000001, -0.1510000000000001, -0.1530000000000001, -0.28700000000000003, 0.33599999999999985, -0.16800000000000004, 0.4119999999999999, 0.3879999999999999, 0.827, 0.377, -0.10799999999999987, 0.81, 0.41500000000000004, -0.41400000000000015, 0.4750000000000001, -0.31700000000000006, 0.40100000000000025, -0.43600000000000005, 0.30099999999999993, 0.19099999999999984, 0.42100000000000004, -0.030999999999999917, 0.7010000000000001, -0.271, 0.42900000000000005, 0.43100000000000005, -0.277, -0.1500000000000001, 0.3520000000000001, -0.19800000000000015, 0.43599999999999994, -0.027000000000000024, 0.96, 0.32299999999999995, -0.09500000000000008, 0.29400000000000004, -0.44299999999999995, 0.1519999999999999, -0.025000000000000022, -0.31200000000000006, -0.07199999999999995, -0.06900000000000006, 0.133, 0.44499999999999984, 0.704, -0.07299999999999995, 0.30800000000000005, 0.44699999999999995, 0.1419999999999999, 0.5579999999999998, 0.405], "episode_lengths": [154, 300, 39, 173, 80, 25, 23, 53, 300, 44, 266, 124, 104, 55, 58, 41, 99, 300, 21, 23, 15, 243, 35, 231, 127, 300, 300, 19, 147, 22, 49, 21, 81, 300, 170, 62, 22, 22, 37, 10, 24, 92, 170, 10, 29, 201, 58, 43, 49, 251, 300, 300, 81, 51, 49, 300, 300, 53, 38, 34, 56, 27, 114, 8, 219, 29, 120, 63, 91, 26, 10, 90, 76, 23, 23, 81, 300, 46, 300, 20, 9, 12, 56, 162, 65, 126, 104, 163, 233, 23, 22, 108, 17, 94, 23, 60, 17, 109, 135, 30], "policy_red_0_reward": [1.0230000000000001, 0.45699999999999996, 0.881, 0.3799999999999999, 0.715, 1.424, 1.4300000000000002, 1.3399999999999999, 0.46199999999999997, 1.361, 0.6449999999999999, 1.127, 1.178, 0.831, 1.322, 1.377, 1.193, -0.12600000000000008, -1.0, 0.924, 0.955, 0.7599999999999999, 1.392, -0.518, -1.0919999999999999, -0.10600000000000008, -0.12500000000000008, 0.942, -0.517, 0.9319999999999999, 0.846, 0.9349999999999999, 0.708, 0.5519999999999999, 0.954, 1.312, 0.9309999999999999, 1.434, 0.883, 0.97, 1.428, 1.208, 0.42599999999999993, 0.97, 0.913, 0.2909999999999998, -0.5119999999999999, -0.502, 1.349, 0.6429999999999999, -0.11000000000000008, -0.11400000000000009, -1.034, 1.342, 0.838, 0.45099999999999996, 0.43299999999999994, 1.338, 1.383, 0.897, 1.317, 1.419, 0.6039999999999999, 1.476, 0.7219999999999999, 1.407, 0.5769999999999998, 1.3079999999999998, 1.205, 1.4220000000000002, 0.97, 1.2149999999999999, 0.743, 0.931, 1.431, -1.021, -0.10300000000000008, 1.359, -0.1460000000000001, 1.439, 0.973, 1.464, 1.327, 0.42899999999999994, 1.303, -1.049, 1.174, 1.001, 0.21899999999999997, 0.93, 0.9329999999999999, 1.15, 1.4489999999999998, -0.508, 0.931, 1.318, -0.5, 1.158, 1.083, 1.408], "policy_blue_0_reward": [-1.027, -0.04100000000000003, -1.006, -1.028, -1.013, -1.004, -0.504, -0.509, -0.05400000000000004, -1.002, -1.028, -0.512, -1.011, -1.011, -1.009, -1.005, -1.0139999999999998, -0.04100000000000003, 1.435, -1.004, -1.003, -1.037, -1.001, 0.2829999999999999, 0.606, -0.04900000000000004, -0.04000000000000003, -1.003, 0.5369999999999999, -1.002, -1.005, -1.003, -1.0119999999999998, -0.545, -1.022, -1.008, -1.004, -1.004, -1.009, -1.0, -1.004, -1.006, -1.027, -1.001, -1.003, -1.035, 0.8210000000000001, 0.863, -1.007, -1.033, -0.04100000000000003, -0.03900000000000003, 0.747, -1.006, -1.006, -0.03900000000000003, -0.04500000000000003, -0.511, -1.006, -1.005, -0.507, -1.004, -1.018, -1.001, -1.039, -1.0059999999999998, -1.013, -1.007, -1.014, -1.001, -1.001, -0.514, -1.014, -0.502, -1.0, 0.744, -0.047000000000000035, -1.007, -0.05200000000000004, -1.003, -1.0, -0.504, -1.004, -0.524, -1.009, 0.606, -1.022, -1.026, -0.531, -1.002, -1.002, -1.017, -1.004, 1.212, -1.004, -1.0099999999999998, 0.947, -1.016, -0.525, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2255666910550595, "mean_inference_ms": 1.4754157067494509, "mean_action_processing_ms": 0.062440870541756885, "mean_env_wait_ms": 0.08827451987150407, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02106451988220215, "StateBufferConnector_ms": 0.0014911890029907227, "ViewRequirementAgentConnector_ms": 0.03168666362762451}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000, "num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.86175788254137, "num_env_steps_trained_throughput_per_sec": 102.86175788254137, "timesteps_total": 64000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 128000, "timers": {"training_iteration_time_ms": 38825.351, "sample_time_ms": 7465.675, "learn_time_ms": 31342.25, "learn_throughput": 127.623, "synch_weights_time_ms": 16.917}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 64000, "num_agent_steps_sampled": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 413, "training_iteration": 16, "trial_id": "d67e4_00000", "date": "2023-09-20_22-19-30", "timestamp": 1695262770, "time_this_iter_s": 38.891557931900024, "time_total_s": 621.144478559494, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d0888b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 621.144478559494, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 33.84464285714286, "ram_util_percent": 47.90535714285714}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.78, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.78, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.12, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.78, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5307111154310404, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.02344946402530089, "policy_loss": -0.028689691853166246, "vf_loss": 0.006747547726869622, "vf_explained_var": 0.5650922585278749, "kl": 0.015389315885507434, "entropy": 1.211408910776178, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 15840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "sampler_results": {"episode_reward_max": 0.96, "episode_reward_min": -0.9430000000000001, "episode_reward_mean": 0.15282999999999997, "episode_len_mean": 98.37, "episode_media": {}, "episodes_this_iter": 37, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.7672000000000001, "blue_0": -0.61437}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.78, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.12, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.78, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.12, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.78, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.12, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.42999999999999994, -0.126, -0.030000000000000027, 0.42399999999999993, 0.20199999999999996, -0.6010000000000001, -0.031000000000000028, -0.08999999999999997, -0.7440000000000002, 0.30900000000000016, 0.361, 0.3420000000000001, -0.3900000000000001, -0.1510000000000001, -0.1530000000000001, -0.28700000000000003, 0.33599999999999985, -0.16800000000000004, 0.4119999999999999, 0.3879999999999999, 0.827, 0.377, -0.10799999999999987, 0.81, 0.41500000000000004, -0.41400000000000015, 0.4750000000000001, -0.31700000000000006, 0.40100000000000025, -0.43600000000000005, 0.30099999999999993, 0.19099999999999984, 0.42100000000000004, -0.030999999999999917, 0.7010000000000001, -0.271, 0.42900000000000005, 0.43100000000000005, -0.277, -0.1500000000000001, 0.3520000000000001, -0.19800000000000015, 0.43599999999999994, -0.027000000000000024, 0.96, 0.32299999999999995, -0.09500000000000008, 0.29400000000000004, -0.44299999999999995, 0.1519999999999999, -0.025000000000000022, -0.31200000000000006, -0.07199999999999995, -0.06900000000000006, 0.133, 0.44499999999999984, 0.704, -0.07299999999999995, 0.30800000000000005, 0.44699999999999995, 0.1419999999999999, 0.5579999999999998, 0.405, 0.254, -0.031000000000000028, 0.401, -0.30600000000000005, 0.46599999999999997, 0.8500000000000001, -0.10800000000000008, 0.264, -0.27400000000000013, 0.42599999999999993, 0.22299999999999998, 0.32099999999999995, 0.3819999999999999, 0.41500000000000004, -0.05500000000000005, 0.653, 0.9029999999999999, 0.4209999999999998, 0.841, 0.45199999999999996, 0.21399999999999997, -0.038000000000000034, 0.43099999999999994, 0.43000000000000005, 0.44700000000000006, 0.238, -0.487, -0.029000000000000026, -0.5399999999999999, 0.847, -0.3630000000000001, -0.6560000000000001, -0.10099999999999998, 0.45500000000000007, 0.29300000000000015, -0.9430000000000001, 0.03400000000000003], "episode_lengths": [22, 37, 10, 24, 92, 170, 10, 29, 201, 58, 43, 49, 251, 300, 300, 81, 51, 49, 300, 300, 53, 38, 34, 56, 27, 114, 8, 219, 29, 120, 63, 91, 26, 10, 90, 76, 23, 23, 81, 300, 46, 300, 20, 9, 12, 56, 162, 65, 126, 104, 163, 233, 23, 22, 108, 17, 94, 23, 60, 17, 109, 135, 30, 231, 10, 32, 94, 10, 48, 300, 72, 228, 24, 86, 54, 300, 26, 17, 109, 300, 24, 51, 14, 91, 12, 300, 23, 16, 81, 293, 9, 152, 46, 262, 192, 29, 14, 64, 287, 144], "policy_red_0_reward": [1.434, 0.883, 0.97, 1.428, 1.208, 0.42599999999999993, 0.97, 0.913, 0.2909999999999998, -0.5119999999999999, -0.502, 1.349, 0.6429999999999999, -0.11000000000000008, -0.11400000000000009, -1.034, 1.342, 0.838, 0.45099999999999996, 0.43299999999999994, 1.338, 1.383, 0.897, 1.317, 1.419, 0.6039999999999999, 1.476, 0.7219999999999999, 1.407, 0.5769999999999998, 1.3079999999999998, 1.205, 1.4220000000000002, 0.97, 1.2149999999999999, 0.743, 0.931, 1.431, -1.021, -0.10300000000000008, 1.359, -0.1460000000000001, 1.439, 0.973, 1.464, 1.327, 0.42899999999999994, 1.303, -1.049, 1.174, 1.001, 0.21899999999999997, 0.93, 0.9329999999999999, 1.15, 1.4489999999999998, -0.508, 0.931, 1.318, -0.5, 1.158, 1.083, 1.408, 0.7799999999999999, 0.97, -1.002, 0.702, 1.47, 1.3559999999999999, -0.06300000000000004, 0.773, 0.7589999999999999, 1.426, -0.504, 1.3279999999999998, 0.42599999999999993, 1.419, 0.949, 1.17, 0.45099999999999996, 1.427, -0.501, 1.4569999999999999, 1.222, 0.964, 0.48, -0.5, 1.4489999999999998, 1.252, 0.5419999999999999, 0.973, -1.059, 1.358, 0.6689999999999999, 0.3739999999999999, 0.903, 1.458, 1.302, 0.09499999999999997, 1.052], "policy_blue_0_reward": [-1.004, -1.009, -1.0, -1.004, -1.006, -1.027, -1.001, -1.003, -1.035, 0.8210000000000001, 0.863, -1.007, -1.033, -0.04100000000000003, -0.03900000000000003, 0.747, -1.006, -1.006, -0.03900000000000003, -0.04500000000000003, -0.511, -1.006, -1.005, -0.507, -1.004, -1.018, -1.001, -1.039, -1.0059999999999998, -1.013, -1.007, -1.014, -1.001, -1.001, -0.514, -1.014, -0.502, -1.0, 0.744, -0.047000000000000035, -1.007, -0.05200000000000004, -1.003, -1.0, -0.504, -1.004, -0.524, -1.009, 0.606, -1.022, -1.026, -0.531, -1.002, -1.002, -1.017, -1.004, 1.212, -1.004, -1.0099999999999998, 0.947, -1.016, -0.525, -1.003, -0.526, -1.001, 1.403, -1.008, -1.004, -0.506, -0.04500000000000003, -0.509, -1.033, -1.0, 0.727, -1.007, -0.04400000000000003, -1.004, -1.004, -0.517, 0.45199999999999996, -1.006, 1.342, -1.005, -1.0079999999999998, -1.002, -0.04900000000000004, 0.93, -1.002, -1.014, -1.029, -1.002, 0.5189999999999999, -0.511, -1.032, -1.03, -1.004, -1.003, -1.009, -1.038, -1.018]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22576010593827667, "mean_inference_ms": 1.4754026158906353, "mean_action_processing_ms": 0.06242202160272972, "mean_env_wait_ms": 0.08828323881167455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021729350090026855, "StateBufferConnector_ms": 0.0015066862106323242, "ViewRequirementAgentConnector_ms": 0.03206944465637207}}, "episode_reward_max": 0.96, "episode_reward_min": -0.9430000000000001, "episode_reward_mean": 0.15282999999999997, "episode_len_mean": 98.37, "episodes_this_iter": 37, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.7672000000000001, "blue_0": -0.61437}, "hist_stats": {"episode_reward": [0.42999999999999994, -0.126, -0.030000000000000027, 0.42399999999999993, 0.20199999999999996, -0.6010000000000001, -0.031000000000000028, -0.08999999999999997, -0.7440000000000002, 0.30900000000000016, 0.361, 0.3420000000000001, -0.3900000000000001, -0.1510000000000001, -0.1530000000000001, -0.28700000000000003, 0.33599999999999985, -0.16800000000000004, 0.4119999999999999, 0.3879999999999999, 0.827, 0.377, -0.10799999999999987, 0.81, 0.41500000000000004, -0.41400000000000015, 0.4750000000000001, -0.31700000000000006, 0.40100000000000025, -0.43600000000000005, 0.30099999999999993, 0.19099999999999984, 0.42100000000000004, -0.030999999999999917, 0.7010000000000001, -0.271, 0.42900000000000005, 0.43100000000000005, -0.277, -0.1500000000000001, 0.3520000000000001, -0.19800000000000015, 0.43599999999999994, -0.027000000000000024, 0.96, 0.32299999999999995, -0.09500000000000008, 0.29400000000000004, -0.44299999999999995, 0.1519999999999999, -0.025000000000000022, -0.31200000000000006, -0.07199999999999995, -0.06900000000000006, 0.133, 0.44499999999999984, 0.704, -0.07299999999999995, 0.30800000000000005, 0.44699999999999995, 0.1419999999999999, 0.5579999999999998, 0.405, 0.254, -0.031000000000000028, 0.401, -0.30600000000000005, 0.46599999999999997, 0.8500000000000001, -0.10800000000000008, 0.264, -0.27400000000000013, 0.42599999999999993, 0.22299999999999998, 0.32099999999999995, 0.3819999999999999, 0.41500000000000004, -0.05500000000000005, 0.653, 0.9029999999999999, 0.4209999999999998, 0.841, 0.45199999999999996, 0.21399999999999997, -0.038000000000000034, 0.43099999999999994, 0.43000000000000005, 0.44700000000000006, 0.238, -0.487, -0.029000000000000026, -0.5399999999999999, 0.847, -0.3630000000000001, -0.6560000000000001, -0.10099999999999998, 0.45500000000000007, 0.29300000000000015, -0.9430000000000001, 0.03400000000000003], "episode_lengths": [22, 37, 10, 24, 92, 170, 10, 29, 201, 58, 43, 49, 251, 300, 300, 81, 51, 49, 300, 300, 53, 38, 34, 56, 27, 114, 8, 219, 29, 120, 63, 91, 26, 10, 90, 76, 23, 23, 81, 300, 46, 300, 20, 9, 12, 56, 162, 65, 126, 104, 163, 233, 23, 22, 108, 17, 94, 23, 60, 17, 109, 135, 30, 231, 10, 32, 94, 10, 48, 300, 72, 228, 24, 86, 54, 300, 26, 17, 109, 300, 24, 51, 14, 91, 12, 300, 23, 16, 81, 293, 9, 152, 46, 262, 192, 29, 14, 64, 287, 144], "policy_red_0_reward": [1.434, 0.883, 0.97, 1.428, 1.208, 0.42599999999999993, 0.97, 0.913, 0.2909999999999998, -0.5119999999999999, -0.502, 1.349, 0.6429999999999999, -0.11000000000000008, -0.11400000000000009, -1.034, 1.342, 0.838, 0.45099999999999996, 0.43299999999999994, 1.338, 1.383, 0.897, 1.317, 1.419, 0.6039999999999999, 1.476, 0.7219999999999999, 1.407, 0.5769999999999998, 1.3079999999999998, 1.205, 1.4220000000000002, 0.97, 1.2149999999999999, 0.743, 0.931, 1.431, -1.021, -0.10300000000000008, 1.359, -0.1460000000000001, 1.439, 0.973, 1.464, 1.327, 0.42899999999999994, 1.303, -1.049, 1.174, 1.001, 0.21899999999999997, 0.93, 0.9329999999999999, 1.15, 1.4489999999999998, -0.508, 0.931, 1.318, -0.5, 1.158, 1.083, 1.408, 0.7799999999999999, 0.97, -1.002, 0.702, 1.47, 1.3559999999999999, -0.06300000000000004, 0.773, 0.7589999999999999, 1.426, -0.504, 1.3279999999999998, 0.42599999999999993, 1.419, 0.949, 1.17, 0.45099999999999996, 1.427, -0.501, 1.4569999999999999, 1.222, 0.964, 0.48, -0.5, 1.4489999999999998, 1.252, 0.5419999999999999, 0.973, -1.059, 1.358, 0.6689999999999999, 0.3739999999999999, 0.903, 1.458, 1.302, 0.09499999999999997, 1.052], "policy_blue_0_reward": [-1.004, -1.009, -1.0, -1.004, -1.006, -1.027, -1.001, -1.003, -1.035, 0.8210000000000001, 0.863, -1.007, -1.033, -0.04100000000000003, -0.03900000000000003, 0.747, -1.006, -1.006, -0.03900000000000003, -0.04500000000000003, -0.511, -1.006, -1.005, -0.507, -1.004, -1.018, -1.001, -1.039, -1.0059999999999998, -1.013, -1.007, -1.014, -1.001, -1.001, -0.514, -1.014, -0.502, -1.0, 0.744, -0.047000000000000035, -1.007, -0.05200000000000004, -1.003, -1.0, -0.504, -1.004, -0.524, -1.009, 0.606, -1.022, -1.026, -0.531, -1.002, -1.002, -1.017, -1.004, 1.212, -1.004, -1.0099999999999998, 0.947, -1.016, -0.525, -1.003, -0.526, -1.001, 1.403, -1.008, -1.004, -0.506, -0.04500000000000003, -0.509, -1.033, -1.0, 0.727, -1.007, -0.04400000000000003, -1.004, -1.004, -0.517, 0.45199999999999996, -1.006, 1.342, -1.005, -1.0079999999999998, -1.002, -0.04900000000000004, 0.93, -1.002, -1.014, -1.029, -1.002, 0.5189999999999999, -0.511, -1.032, -1.03, -1.004, -1.003, -1.009, -1.038, -1.018]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22576010593827667, "mean_inference_ms": 1.4754026158906353, "mean_action_processing_ms": 0.06242202160272972, "mean_env_wait_ms": 0.08828323881167455, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021729350090026855, "StateBufferConnector_ms": 0.0015066862106323242, "ViewRequirementAgentConnector_ms": 0.03206944465637207}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000, "num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.87897812424463, "num_env_steps_trained_throughput_per_sec": 102.87897812424463, "timesteps_total": 68000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 136000, "timers": {"training_iteration_time_ms": 38826.208, "sample_time_ms": 7461.172, "learn_time_ms": 31347.633, "learn_throughput": 127.601, "synch_weights_time_ms": 16.897}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 68000, "num_agent_steps_sampled": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 450, "training_iteration": 17, "trial_id": "d67e4_00000", "date": "2023-09-20_22-20-09", "timestamp": 1695262809, "time_this_iter_s": 38.88477683067322, "time_total_s": 660.0292553901672, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706710>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 660.0292553901672, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 32.78181818181818, "ram_util_percent": 47.920000000000016}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.87, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.87, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.87, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8454240197936693, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.022942850877977133, "policy_loss": -0.029239953413101222, "vf_loss": 0.007162134062188367, "vf_explained_var": 0.607321445333461, "kl": 0.01884480155344352, "entropy": 1.0529250527421634, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 16800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "sampler_results": {"episode_reward_max": 0.9590000000000001, "episode_reward_min": -0.9430000000000001, "episode_reward_mean": 0.17734000000000003, "episode_len_mean": 85.54, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.05}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.9031, "blue_0": -0.7257599999999997}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.87, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.87, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.08, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.87, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44699999999999995, 0.1419999999999999, 0.5579999999999998, 0.405, 0.254, -0.031000000000000028, 0.401, -0.30600000000000005, 0.46599999999999997, 0.8500000000000001, -0.10800000000000008, 0.264, -0.27400000000000013, 0.42599999999999993, 0.22299999999999998, 0.32099999999999995, 0.3819999999999999, 0.41500000000000004, -0.05500000000000005, 0.653, 0.9029999999999999, 0.4209999999999998, 0.841, 0.45199999999999996, 0.21399999999999997, -0.038000000000000034, 0.43099999999999994, 0.43000000000000005, 0.44700000000000006, 0.238, -0.487, -0.029000000000000026, -0.5399999999999999, 0.847, -0.3630000000000001, -0.6560000000000001, -0.10099999999999998, 0.45500000000000007, 0.29300000000000015, -0.9430000000000001, 0.03400000000000003, -0.32900000000000007, 0.42400000000000015, -0.32000000000000006, -0.03200000000000003, 0.41400000000000015, -0.4580000000000002, 0.43100000000000005, 0.786, 0.31899999999999995, -0.08000000000000006, 0.32299999999999995, 0.20900000000000007, -0.14200000000000002, -0.03500000000000003, 0.3599999999999999, 0.26000000000000023, 0.389, -0.08999999999999997, -0.13, 0.22799999999999998, -0.16800000000000004, -0.06500000000000006, 0.405, -0.05699999999999994, 0.7610000000000001, -0.04500000000000004, -0.04800000000000004, -0.15500000000000003, 0.3719999999999999, -0.20600000000000007, 0.24, -0.03700000000000003, -0.026000000000000023, 0.9590000000000001, 0.42300000000000004, 0.385, -0.237, -0.030000000000000027, 0.2809999999999999, 0.07600000000000007, 0.29000000000000004, -0.04499999999999993, 0.41400000000000015, 0.20399999999999996, 0.3900000000000001, -0.02300000000000002, -0.4620000000000001, 0.3500000000000001, 0.4079999999999999, 0.3759999999999999, -0.09399999999999997, 0.45999999999999996, 0.2889999999999999, -0.10400000000000009, -0.052000000000000046, 0.18999999999999995, 0.08300000000000018, 0.567, 0.8559999999999999], "episode_lengths": [17, 109, 135, 30, 231, 10, 32, 94, 10, 48, 300, 72, 228, 24, 86, 54, 300, 26, 17, 109, 300, 24, 51, 14, 91, 12, 300, 23, 16, 81, 293, 9, 152, 46, 262, 192, 29, 14, 64, 287, 144, 238, 23, 233, 10, 25, 292, 22, 67, 55, 300, 55, 87, 42, 11, 43, 74, 34, 27, 39, 242, 49, 21, 27, 17, 73, 14, 15, 195, 41, 218, 80, 12, 8, 13, 24, 37, 72, 10, 60, 133, 66, 14, 26, 84, 34, 7, 127, 47, 29, 39, 30, 13, 65, 192, 16, 86, 129, 134, 42], "policy_red_0_reward": [-0.5, 1.158, 1.083, 1.408, 0.7799999999999999, 0.97, -1.002, 0.702, 1.47, 1.3559999999999999, -0.06300000000000004, 0.773, 0.7589999999999999, 1.426, -0.504, 1.3279999999999998, 0.42599999999999993, 1.419, 0.949, 1.17, 0.45099999999999996, 1.427, -0.501, 1.4569999999999999, 1.222, 0.964, 0.48, -0.5, 1.4489999999999998, 1.252, 0.5419999999999999, 0.973, -1.059, 1.358, 0.6689999999999999, 0.3739999999999999, 0.903, 1.458, 1.302, 0.09499999999999997, 1.052, 0.708, 1.4300000000000002, 0.713, 0.97, 1.4220000000000002, 0.5919999999999999, 1.4329999999999998, 1.2959999999999998, 1.331, -0.04000000000000003, 1.331, 1.2229999999999999, 0.863, 0.966, 1.365, 1.271, 1.396, 0.913, 0.879, 0.759, 0.842, 0.9369999999999999, 0.91, 0.949, 1.274, 0.956, 0.954, 0.8689999999999999, 0.874, 0.821, 1.248, 0.963, 0.976, 1.4609999999999999, 1.427, 1.388, 0.769, 0.97, 0.7879999999999999, 1.095, 1.295, 0.957, 1.419, 1.218, 1.395, -1.0, 0.568, 1.3559999999999999, 1.412, 1.381, 0.909, 1.4609999999999999, 1.299, 0.9159999999999999, 0.948, -0.542, 1.1, 1.084, 1.366], "policy_blue_0_reward": [0.947, -1.016, -0.525, -1.003, -0.526, -1.001, 1.403, -1.008, -1.004, -0.506, -0.04500000000000003, -0.509, -1.033, -1.0, 0.727, -1.007, -0.04400000000000003, -1.004, -1.004, -0.517, 0.45199999999999996, -1.006, 1.342, -1.005, -1.0079999999999998, -1.002, -0.04900000000000004, 0.93, -1.002, -1.014, -1.029, -1.002, 0.5189999999999999, -0.511, -1.032, -1.03, -1.004, -1.003, -1.009, -1.038, -1.018, -1.037, -1.0059999999999998, -1.033, -1.002, -1.008, -1.05, -1.0019999999999998, -0.51, -1.012, -0.04000000000000003, -1.0079999999999998, -1.0139999999999998, -1.005, -1.001, -1.005, -1.011, -1.007, -1.003, -1.009, -0.531, -1.01, -1.002, -0.505, -1.0059999999999998, -0.5129999999999999, -1.001, -1.002, -1.0239999999999998, -0.502, -1.027, -1.008, -1.0, -1.002, -0.502, -1.0039999999999998, -1.003, -1.006, -1.0, -0.507, -1.019, -1.005, -1.0019999999999998, -1.005, -1.014, -1.005, 0.977, -1.03, -1.006, -1.004, -1.005, -1.003, -1.001, -1.01, -1.02, -1.0, 0.732, -1.017, -0.517, -0.51]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22647506754338406, "mean_inference_ms": 1.4747272203894977, "mean_action_processing_ms": 0.06252297502468956, "mean_env_wait_ms": 0.08843415467970069, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021697640419006348, "StateBufferConnector_ms": 0.0014799833297729492, "ViewRequirementAgentConnector_ms": 0.0321047306060791}}, "episode_reward_max": 0.9590000000000001, "episode_reward_min": -0.9430000000000001, "episode_reward_mean": 0.17734000000000003, "episode_len_mean": 85.54, "episodes_this_iter": 59, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.05}, "policy_reward_max": {"red_0": 1.47, "blue_0": 1.403}, "policy_reward_mean": {"red_0": 0.9031, "blue_0": -0.7257599999999997}, "hist_stats": {"episode_reward": [0.44699999999999995, 0.1419999999999999, 0.5579999999999998, 0.405, 0.254, -0.031000000000000028, 0.401, -0.30600000000000005, 0.46599999999999997, 0.8500000000000001, -0.10800000000000008, 0.264, -0.27400000000000013, 0.42599999999999993, 0.22299999999999998, 0.32099999999999995, 0.3819999999999999, 0.41500000000000004, -0.05500000000000005, 0.653, 0.9029999999999999, 0.4209999999999998, 0.841, 0.45199999999999996, 0.21399999999999997, -0.038000000000000034, 0.43099999999999994, 0.43000000000000005, 0.44700000000000006, 0.238, -0.487, -0.029000000000000026, -0.5399999999999999, 0.847, -0.3630000000000001, -0.6560000000000001, -0.10099999999999998, 0.45500000000000007, 0.29300000000000015, -0.9430000000000001, 0.03400000000000003, -0.32900000000000007, 0.42400000000000015, -0.32000000000000006, -0.03200000000000003, 0.41400000000000015, -0.4580000000000002, 0.43100000000000005, 0.786, 0.31899999999999995, -0.08000000000000006, 0.32299999999999995, 0.20900000000000007, -0.14200000000000002, -0.03500000000000003, 0.3599999999999999, 0.26000000000000023, 0.389, -0.08999999999999997, -0.13, 0.22799999999999998, -0.16800000000000004, -0.06500000000000006, 0.405, -0.05699999999999994, 0.7610000000000001, -0.04500000000000004, -0.04800000000000004, -0.15500000000000003, 0.3719999999999999, -0.20600000000000007, 0.24, -0.03700000000000003, -0.026000000000000023, 0.9590000000000001, 0.42300000000000004, 0.385, -0.237, -0.030000000000000027, 0.2809999999999999, 0.07600000000000007, 0.29000000000000004, -0.04499999999999993, 0.41400000000000015, 0.20399999999999996, 0.3900000000000001, -0.02300000000000002, -0.4620000000000001, 0.3500000000000001, 0.4079999999999999, 0.3759999999999999, -0.09399999999999997, 0.45999999999999996, 0.2889999999999999, -0.10400000000000009, -0.052000000000000046, 0.18999999999999995, 0.08300000000000018, 0.567, 0.8559999999999999], "episode_lengths": [17, 109, 135, 30, 231, 10, 32, 94, 10, 48, 300, 72, 228, 24, 86, 54, 300, 26, 17, 109, 300, 24, 51, 14, 91, 12, 300, 23, 16, 81, 293, 9, 152, 46, 262, 192, 29, 14, 64, 287, 144, 238, 23, 233, 10, 25, 292, 22, 67, 55, 300, 55, 87, 42, 11, 43, 74, 34, 27, 39, 242, 49, 21, 27, 17, 73, 14, 15, 195, 41, 218, 80, 12, 8, 13, 24, 37, 72, 10, 60, 133, 66, 14, 26, 84, 34, 7, 127, 47, 29, 39, 30, 13, 65, 192, 16, 86, 129, 134, 42], "policy_red_0_reward": [-0.5, 1.158, 1.083, 1.408, 0.7799999999999999, 0.97, -1.002, 0.702, 1.47, 1.3559999999999999, -0.06300000000000004, 0.773, 0.7589999999999999, 1.426, -0.504, 1.3279999999999998, 0.42599999999999993, 1.419, 0.949, 1.17, 0.45099999999999996, 1.427, -0.501, 1.4569999999999999, 1.222, 0.964, 0.48, -0.5, 1.4489999999999998, 1.252, 0.5419999999999999, 0.973, -1.059, 1.358, 0.6689999999999999, 0.3739999999999999, 0.903, 1.458, 1.302, 0.09499999999999997, 1.052, 0.708, 1.4300000000000002, 0.713, 0.97, 1.4220000000000002, 0.5919999999999999, 1.4329999999999998, 1.2959999999999998, 1.331, -0.04000000000000003, 1.331, 1.2229999999999999, 0.863, 0.966, 1.365, 1.271, 1.396, 0.913, 0.879, 0.759, 0.842, 0.9369999999999999, 0.91, 0.949, 1.274, 0.956, 0.954, 0.8689999999999999, 0.874, 0.821, 1.248, 0.963, 0.976, 1.4609999999999999, 1.427, 1.388, 0.769, 0.97, 0.7879999999999999, 1.095, 1.295, 0.957, 1.419, 1.218, 1.395, -1.0, 0.568, 1.3559999999999999, 1.412, 1.381, 0.909, 1.4609999999999999, 1.299, 0.9159999999999999, 0.948, -0.542, 1.1, 1.084, 1.366], "policy_blue_0_reward": [0.947, -1.016, -0.525, -1.003, -0.526, -1.001, 1.403, -1.008, -1.004, -0.506, -0.04500000000000003, -0.509, -1.033, -1.0, 0.727, -1.007, -0.04400000000000003, -1.004, -1.004, -0.517, 0.45199999999999996, -1.006, 1.342, -1.005, -1.0079999999999998, -1.002, -0.04900000000000004, 0.93, -1.002, -1.014, -1.029, -1.002, 0.5189999999999999, -0.511, -1.032, -1.03, -1.004, -1.003, -1.009, -1.038, -1.018, -1.037, -1.0059999999999998, -1.033, -1.002, -1.008, -1.05, -1.0019999999999998, -0.51, -1.012, -0.04000000000000003, -1.0079999999999998, -1.0139999999999998, -1.005, -1.001, -1.005, -1.011, -1.007, -1.003, -1.009, -0.531, -1.01, -1.002, -0.505, -1.0059999999999998, -0.5129999999999999, -1.001, -1.002, -1.0239999999999998, -0.502, -1.027, -1.008, -1.0, -1.002, -0.502, -1.0039999999999998, -1.003, -1.006, -1.0, -0.507, -1.019, -1.005, -1.0019999999999998, -1.005, -1.014, -1.005, 0.977, -1.03, -1.006, -1.004, -1.005, -1.003, -1.001, -1.01, -1.02, -1.0, 0.732, -1.017, -0.517, -0.51]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22647506754338406, "mean_inference_ms": 1.4747272203894977, "mean_action_processing_ms": 0.06252297502468956, "mean_env_wait_ms": 0.08843415467970069, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021697640419006348, "StateBufferConnector_ms": 0.0014799833297729492, "ViewRequirementAgentConnector_ms": 0.0321047306060791}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000, "num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.03245855887911, "num_env_steps_trained_throughput_per_sec": 103.03245855887911, "timesteps_total": 72000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 144000, "timers": {"training_iteration_time_ms": 38831.329, "sample_time_ms": 7460.968, "learn_time_ms": 31352.951, "learn_throughput": 127.58, "synch_weights_time_ms": 16.907}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 72000, "num_agent_steps_sampled": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 509, "training_iteration": 18, "trial_id": "d67e4_00000", "date": "2023-09-20_22-20-48", "timestamp": 1695262848, "time_this_iter_s": 38.82715320587158, "time_total_s": 698.8564085960388, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d088820>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 698.8564085960388, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 34.58392857142857, "ram_util_percent": 48.026785714285715}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.93, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.93, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.06, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.93, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7157669341812531, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.020017445146125586, "policy_loss": -0.026858405413319512, "vf_loss": 0.008566791169384184, "vf_explained_var": 0.6213500798990329, "kl": 0.018493589633832623, "entropy": 1.1411530072490375, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 17760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "sampler_results": {"episode_reward_max": 0.9590000000000001, "episode_reward_min": -0.8670000000000001, "episode_reward_mean": 0.16036999999999998, "episode_len_mean": 61.56, "episode_media": {}, "episodes_this_iter": 62, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.044}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.977}, "policy_reward_mean": {"red_0": 0.99102, "blue_0": -0.8306499999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.0, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 0, "red_0/eliminated_opponents_done_mean": 0.93, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.93, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.06, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.93, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.06500000000000006, 0.405, -0.05699999999999994, 0.7610000000000001, -0.04500000000000004, -0.04800000000000004, -0.15500000000000003, 0.3719999999999999, -0.20600000000000007, 0.24, -0.03700000000000003, -0.026000000000000023, 0.9590000000000001, 0.42300000000000004, 0.385, -0.237, -0.030000000000000027, 0.2809999999999999, 0.07600000000000007, 0.29000000000000004, -0.04499999999999993, 0.41400000000000015, 0.20399999999999996, 0.3900000000000001, -0.02300000000000002, -0.4620000000000001, 0.3500000000000001, 0.4079999999999999, 0.3759999999999999, -0.09399999999999997, 0.45999999999999996, 0.2889999999999999, -0.10400000000000009, -0.052000000000000046, 0.18999999999999995, 0.08300000000000018, 0.567, 0.8559999999999999, 0.2759999999999998, 0.33699999999999997, -0.02400000000000002, 0.44399999999999995, 0.43900000000000006, 0.30100000000000016, -0.028000000000000025, -0.05700000000000005, -0.027000000000000024, 0.4710000000000001, -0.040000000000000036, -0.4570000000000001, 0.95, -0.401, 0.46099999999999985, 0.3719999999999999, 0.4289999999999998, 0.14400000000000013, 0.30100000000000016, 0.496, 0.3860000000000001, -0.06200000000000005, -0.040999999999999925, -0.20100000000000007, 0.20699999999999985, -0.8670000000000001, -0.4650000000000001, 0.42399999999999993, -0.06899999999999995, 0.03699999999999992, 0.42200000000000015, 0.369, 0.44199999999999995, 0.45799999999999996, 0.3719999999999999, 0.40600000000000014, -0.06700000000000006, 0.357, 0.355, 0.774, 0.40200000000000014, -0.026000000000000023, -0.09499999999999986, 0.44999999999999996, -0.031000000000000028, 0.32099999999999995, 0.403, -0.062000000000000055, 0.47, -0.040000000000000036, -0.10699999999999998, 0.2959999999999998, -0.028000000000000025, -0.038000000000000034, -0.21399999999999997, -0.748, 0.3799999999999999, -0.4760000000000001, -0.06600000000000006, 0.30499999999999994, 0.28400000000000003, -0.05999999999999994], "episode_lengths": [21, 27, 17, 73, 14, 15, 195, 41, 218, 80, 12, 8, 13, 24, 37, 72, 10, 60, 133, 66, 14, 26, 84, 34, 7, 127, 47, 29, 39, 30, 13, 65, 192, 16, 86, 129, 134, 42, 69, 45, 8, 17, 19, 62, 9, 18, 9, 9, 13, 299, 16, 122, 12, 40, 22, 109, 61, 142, 36, 300, 13, 218, 91, 222, 285, 23, 23, 141, 25, 40, 18, 12, 39, 30, 21, 44, 45, 69, 30, 8, 28, 16, 10, 54, 30, 18, 10, 13, 31, 63, 9, 12, 59, 221, 38, 293, 19, 61, 68, 19], "policy_red_0_reward": [0.9369999999999999, 0.91, 0.949, 1.274, 0.956, 0.954, 0.8689999999999999, 0.874, 0.821, 1.248, 0.963, 0.976, 1.4609999999999999, 1.427, 1.388, 0.769, 0.97, 0.7879999999999999, 1.095, 1.295, 0.957, 1.419, 1.218, 1.395, -1.0, 0.568, 1.3559999999999999, 1.412, 1.381, 0.909, 1.4609999999999999, 1.299, 0.9159999999999999, 0.948, -0.542, 1.1, 1.084, 1.366, 1.2879999999999998, 0.845, 0.976, 1.447, 1.443, 1.312, 0.973, 0.946, 0.973, 1.4729999999999999, 0.961, 0.587, 1.451, 0.612, 1.464, 1.376, 1.434, 1.159, 1.315, 1.0230000000000001, 1.3900000000000001, -0.025000000000000015, 0.961, 0.821, 1.216, 0.16799999999999984, 0.574, 1.429, 0.931, 1.056, 1.424, 1.379, 1.446, 1.464, 1.381, 1.408, 0.9369999999999999, 0.864, 1.363, 1.283, 1.408, 0.976, 0.912, 1.452, 0.97, 1.327, 1.409, 0.94, -0.5, 0.961, 0.898, 1.31, 0.973, 0.962, -1.025, -1.059, 1.384, 0.5619999999999999, 0.9369999999999999, 1.314, 1.2930000000000001, -1.001], "policy_blue_0_reward": [-1.002, -0.505, -1.0059999999999998, -0.5129999999999999, -1.001, -1.002, -1.0239999999999998, -0.502, -1.027, -1.008, -1.0, -1.002, -0.502, -1.0039999999999998, -1.003, -1.006, -1.0, -0.507, -1.019, -1.005, -1.0019999999999998, -1.005, -1.014, -1.005, 0.977, -1.03, -1.006, -1.004, -1.005, -1.003, -1.001, -1.01, -1.02, -1.0, 0.732, -1.017, -0.517, -0.51, -1.012, -0.508, -1.0, -1.003, -1.004, -1.011, -1.001, -1.003, -1.0, -1.002, -1.001, -1.044, -0.501, -1.013, -1.003, -1.004, -1.005, -1.015, -1.0139999999999998, -0.527, -1.0039999999999998, -0.037000000000000026, -1.0019999999999998, -1.022, -1.009, -1.035, -1.039, -1.005, -1.0, -1.019, -1.002, -1.01, -1.004, -1.006, -1.009, -1.002, -1.004, -0.507, -1.008, -0.509, -1.006, -1.002, -1.007, -1.002, -1.001, -1.006, -1.006, -1.002, 0.97, -1.001, -1.005, -1.014, -1.001, -1.0, 0.8109999999999999, 0.31099999999999994, -1.004, -1.038, -1.003, -1.009, -1.009, 0.941]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22723243982634575, "mean_inference_ms": 1.475028170743684, "mean_action_processing_ms": 0.06262008463079344, "mean_env_wait_ms": 0.08859435037085156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02158677577972412, "StateBufferConnector_ms": 0.0015079975128173828, "ViewRequirementAgentConnector_ms": 0.03211259841918945}}, "episode_reward_max": 0.9590000000000001, "episode_reward_min": -0.8670000000000001, "episode_reward_mean": 0.16036999999999998, "episode_len_mean": 61.56, "episodes_this_iter": 62, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.044}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.977}, "policy_reward_mean": {"red_0": 0.99102, "blue_0": -0.8306499999999999}, "hist_stats": {"episode_reward": [-0.06500000000000006, 0.405, -0.05699999999999994, 0.7610000000000001, -0.04500000000000004, -0.04800000000000004, -0.15500000000000003, 0.3719999999999999, -0.20600000000000007, 0.24, -0.03700000000000003, -0.026000000000000023, 0.9590000000000001, 0.42300000000000004, 0.385, -0.237, -0.030000000000000027, 0.2809999999999999, 0.07600000000000007, 0.29000000000000004, -0.04499999999999993, 0.41400000000000015, 0.20399999999999996, 0.3900000000000001, -0.02300000000000002, -0.4620000000000001, 0.3500000000000001, 0.4079999999999999, 0.3759999999999999, -0.09399999999999997, 0.45999999999999996, 0.2889999999999999, -0.10400000000000009, -0.052000000000000046, 0.18999999999999995, 0.08300000000000018, 0.567, 0.8559999999999999, 0.2759999999999998, 0.33699999999999997, -0.02400000000000002, 0.44399999999999995, 0.43900000000000006, 0.30100000000000016, -0.028000000000000025, -0.05700000000000005, -0.027000000000000024, 0.4710000000000001, -0.040000000000000036, -0.4570000000000001, 0.95, -0.401, 0.46099999999999985, 0.3719999999999999, 0.4289999999999998, 0.14400000000000013, 0.30100000000000016, 0.496, 0.3860000000000001, -0.06200000000000005, -0.040999999999999925, -0.20100000000000007, 0.20699999999999985, -0.8670000000000001, -0.4650000000000001, 0.42399999999999993, -0.06899999999999995, 0.03699999999999992, 0.42200000000000015, 0.369, 0.44199999999999995, 0.45799999999999996, 0.3719999999999999, 0.40600000000000014, -0.06700000000000006, 0.357, 0.355, 0.774, 0.40200000000000014, -0.026000000000000023, -0.09499999999999986, 0.44999999999999996, -0.031000000000000028, 0.32099999999999995, 0.403, -0.062000000000000055, 0.47, -0.040000000000000036, -0.10699999999999998, 0.2959999999999998, -0.028000000000000025, -0.038000000000000034, -0.21399999999999997, -0.748, 0.3799999999999999, -0.4760000000000001, -0.06600000000000006, 0.30499999999999994, 0.28400000000000003, -0.05999999999999994], "episode_lengths": [21, 27, 17, 73, 14, 15, 195, 41, 218, 80, 12, 8, 13, 24, 37, 72, 10, 60, 133, 66, 14, 26, 84, 34, 7, 127, 47, 29, 39, 30, 13, 65, 192, 16, 86, 129, 134, 42, 69, 45, 8, 17, 19, 62, 9, 18, 9, 9, 13, 299, 16, 122, 12, 40, 22, 109, 61, 142, 36, 300, 13, 218, 91, 222, 285, 23, 23, 141, 25, 40, 18, 12, 39, 30, 21, 44, 45, 69, 30, 8, 28, 16, 10, 54, 30, 18, 10, 13, 31, 63, 9, 12, 59, 221, 38, 293, 19, 61, 68, 19], "policy_red_0_reward": [0.9369999999999999, 0.91, 0.949, 1.274, 0.956, 0.954, 0.8689999999999999, 0.874, 0.821, 1.248, 0.963, 0.976, 1.4609999999999999, 1.427, 1.388, 0.769, 0.97, 0.7879999999999999, 1.095, 1.295, 0.957, 1.419, 1.218, 1.395, -1.0, 0.568, 1.3559999999999999, 1.412, 1.381, 0.909, 1.4609999999999999, 1.299, 0.9159999999999999, 0.948, -0.542, 1.1, 1.084, 1.366, 1.2879999999999998, 0.845, 0.976, 1.447, 1.443, 1.312, 0.973, 0.946, 0.973, 1.4729999999999999, 0.961, 0.587, 1.451, 0.612, 1.464, 1.376, 1.434, 1.159, 1.315, 1.0230000000000001, 1.3900000000000001, -0.025000000000000015, 0.961, 0.821, 1.216, 0.16799999999999984, 0.574, 1.429, 0.931, 1.056, 1.424, 1.379, 1.446, 1.464, 1.381, 1.408, 0.9369999999999999, 0.864, 1.363, 1.283, 1.408, 0.976, 0.912, 1.452, 0.97, 1.327, 1.409, 0.94, -0.5, 0.961, 0.898, 1.31, 0.973, 0.962, -1.025, -1.059, 1.384, 0.5619999999999999, 0.9369999999999999, 1.314, 1.2930000000000001, -1.001], "policy_blue_0_reward": [-1.002, -0.505, -1.0059999999999998, -0.5129999999999999, -1.001, -1.002, -1.0239999999999998, -0.502, -1.027, -1.008, -1.0, -1.002, -0.502, -1.0039999999999998, -1.003, -1.006, -1.0, -0.507, -1.019, -1.005, -1.0019999999999998, -1.005, -1.014, -1.005, 0.977, -1.03, -1.006, -1.004, -1.005, -1.003, -1.001, -1.01, -1.02, -1.0, 0.732, -1.017, -0.517, -0.51, -1.012, -0.508, -1.0, -1.003, -1.004, -1.011, -1.001, -1.003, -1.0, -1.002, -1.001, -1.044, -0.501, -1.013, -1.003, -1.004, -1.005, -1.015, -1.0139999999999998, -0.527, -1.0039999999999998, -0.037000000000000026, -1.0019999999999998, -1.022, -1.009, -1.035, -1.039, -1.005, -1.0, -1.019, -1.002, -1.01, -1.004, -1.006, -1.009, -1.002, -1.004, -0.507, -1.008, -0.509, -1.006, -1.002, -1.007, -1.002, -1.001, -1.006, -1.006, -1.002, 0.97, -1.001, -1.005, -1.014, -1.001, -1.0, 0.8109999999999999, 0.31099999999999994, -1.004, -1.038, -1.003, -1.009, -1.009, 0.941]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22723243982634575, "mean_inference_ms": 1.475028170743684, "mean_action_processing_ms": 0.06262008463079344, "mean_env_wait_ms": 0.08859435037085156, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02158677577972412, "StateBufferConnector_ms": 0.0015079975128173828, "ViewRequirementAgentConnector_ms": 0.03211259841918945}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000, "num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.78122902835355, "num_env_steps_trained_throughput_per_sec": 102.78122902835355, "timesteps_total": 76000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 152000, "timers": {"training_iteration_time_ms": 38844.061, "sample_time_ms": 7468.51, "learn_time_ms": 31358.198, "learn_throughput": 127.558, "synch_weights_time_ms": 16.852}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 76000, "num_agent_steps_sampled": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 571, "training_iteration": 19, "trial_id": "d67e4_00000", "date": "2023-09-20_22-21-28", "timestamp": 1695262888, "time_this_iter_s": 38.92209506034851, "time_total_s": 737.7785036563873, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fe8c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 737.7785036563873, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 33.70181818181818, "ram_util_percent": 48.03818181818182}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.87, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.87, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.87, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9374665380145113, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.019791509955151318, "policy_loss": -0.02875442532094894, "vf_loss": 0.009773899494636378, "vf_explained_var": 0.5688898804287116, "kl": 0.02556003156320609, "entropy": 1.0360403275117278, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 18720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "sampler_results": {"episode_reward_max": 1.355, "episode_reward_min": -1.0050000000000001, "episode_reward_mean": 0.14358999999999997, "episode_len_mean": 56.48, "episode_media": {}, "episodes_this_iter": 81, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.4300000000000002}, "policy_reward_mean": {"red_0": 0.8942000000000001, "blue_0": -0.7506099999999999}, "custom_metrics": {"red_0/door_open_done_mean": 0.02, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.87, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.1, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.87, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.1, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.87, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.1, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44999999999999996, -0.031000000000000028, 0.32099999999999995, 0.403, -0.062000000000000055, 0.47, -0.040000000000000036, -0.10699999999999998, 0.2959999999999998, -0.028000000000000025, -0.038000000000000034, -0.21399999999999997, -0.748, 0.3799999999999999, -0.4760000000000001, -0.06600000000000006, 0.30499999999999994, 0.28400000000000003, -0.05999999999999994, -0.20300000000000007, -0.041000000000000036, -0.05300000000000005, -1.0050000000000001, 0.05799999999999983, -0.28900000000000003, -0.040000000000000036, 0.44700000000000006, -0.10399999999999998, 0.42799999999999994, -0.02499999999999991, 0.27300000000000013, 0.42100000000000004, 0.34399999999999986, 0.635, 0.31800000000000006, 0.42600000000000016, 0.841, 0.41300000000000026, 0.42300000000000004, 0.7829999999999999, -0.04300000000000004, 0.46499999999999986, 1.355, 0.3719999999999999, 0.33299999999999996, -0.04800000000000004, -0.11199999999999999, -0.030000000000000027, 0.2250000000000001, -0.40700000000000014, 0.3679999999999999, -0.06300000000000006, -0.08299999999999996, 0.353, -0.03200000000000003, 0.23399999999999999, -0.29300000000000004, -0.2539999999999999, -0.5130000000000001, 0.357, 0.907, -0.15200000000000002, -0.04300000000000004, 0.46199999999999997, 0.4650000000000001, 0.32499999999999996, -0.08099999999999996, 1.3399999999999999, 0.643, -0.43600000000000005, 0.4590000000000001, 0.2709999999999999, -0.11500000000000009, -0.4610000000000001, 0.42999999999999994, -0.17100000000000004, -0.14100000000000001, 0.46499999999999986, -0.1409999999999999, -0.040000000000000036, 0.16999999999999993, -0.02199999999999991, -0.236, 0.3639999999999999, -0.06500000000000006, 0.4159999999999999, 0.357, -0.029000000000000026, 0.31800000000000006, 0.41400000000000015, -0.029999999999999916, -0.05500000000000005, -0.03300000000000003, 0.44999999999999996, -0.031000000000000028, 0.39300000000000024, 0.389, -0.03399999999999992, -0.03700000000000003, 0.401], "episode_lengths": [16, 10, 54, 30, 18, 10, 13, 31, 63, 9, 12, 59, 221, 38, 293, 19, 61, 68, 19, 218, 13, 17, 296, 140, 82, 13, 17, 33, 24, 8, 71, 24, 49, 115, 57, 23, 49, 27, 23, 66, 14, 11, 45, 39, 54, 15, 34, 9, 86, 112, 41, 20, 26, 47, 10, 82, 91, 76, 287, 45, 29, 48, 14, 12, 11, 56, 26, 50, 109, 296, 13, 70, 300, 140, 22, 54, 44, 11, 190, 13, 103, 7, 71, 42, 21, 27, 44, 9, 51, 27, 9, 18, 10, 16, 9, 33, 35, 11, 12, 32], "policy_red_0_reward": [1.452, 0.97, 1.327, 1.409, 0.94, -0.5, 0.961, 0.898, 1.31, 0.973, 0.962, -1.025, -1.059, 1.384, 0.5619999999999999, 0.9369999999999999, 1.314, 1.2930000000000001, -1.001, 0.826, 0.961, 0.949, 0.034999999999999934, 1.073, 0.718, 0.961, 1.448, 0.9, -0.5, -1.0, 1.28, 1.427, 1.353, 1.1520000000000001, 1.3239999999999998, 0.928, 1.351, 1.419, -1.007, 1.298, 0.958, 1.467, 1.362, 1.379, 1.338, 0.954, 0.893, 0.973, 1.237, 0.6129999999999999, 1.373, 0.938, 0.922, 1.359, 0.97, 1.2469999999999999, 0.721, 0.759, 0.5259999999999999, -0.502, 1.411, 0.851, 0.958, -0.5, 1.467, 1.33, 0.92, 1.349, 1.154, 0.603, 1.46, 1.28, -0.07100000000000005, 0.5529999999999999, 1.434, 0.836, 0.867, 1.467, 0.892, 0.961, 1.183, 0.979, 0.771, 1.373, 0.9369999999999999, 1.4180000000000001, 1.3639999999999999, 0.973, 0.827, 1.417, -1.0, 0.946, 0.97, 1.451, 0.973, 1.399, 1.393, 0.967, 0.964, 1.403], "policy_blue_0_reward": [-1.002, -1.001, -1.006, -1.006, -1.002, 0.97, -1.001, -1.005, -1.014, -1.001, -1.0, 0.8109999999999999, 0.31099999999999994, -1.004, -1.038, -1.003, -1.009, -1.009, 0.941, -1.029, -1.002, -1.002, -1.04, -1.015, -1.007, -1.001, -1.001, -1.004, 0.9279999999999999, 0.975, -1.007, -1.0059999999999998, -1.009, -0.517, -1.006, -0.5019999999999999, -0.51, -1.0059999999999998, 1.4300000000000002, -0.515, -1.001, -1.002, -0.007, -1.007, -1.005, -1.002, -1.005, -1.003, -1.0119999999999998, -1.02, -1.005, -1.001, -1.005, -1.006, -1.002, -1.013, -1.014, -1.013, -1.039, 0.859, -0.504, -1.003, -1.001, 0.962, -1.0019999999999998, -1.005, -1.001, -0.009000000000000001, -0.511, -1.039, -1.001, -1.009, -0.04400000000000003, -1.014, -1.004, -1.007, -1.008, -1.002, -1.033, -1.001, -1.013, -1.001, -1.007, -1.009, -1.002, -1.002, -1.007, -1.002, -0.509, -1.003, 0.97, -1.001, -1.003, -1.001, -1.004, -1.0059999999999998, -1.004, -1.001, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22776878788359134, "mean_inference_ms": 1.4738919088492635, "mean_action_processing_ms": 0.0625764988991178, "mean_env_wait_ms": 0.088565727241406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021704554557800293, "StateBufferConnector_ms": 0.0015186071395874023, "ViewRequirementAgentConnector_ms": 0.032204508781433105}}, "episode_reward_max": 1.355, "episode_reward_min": -1.0050000000000001, "episode_reward_mean": 0.14358999999999997, "episode_len_mean": 56.48, "episodes_this_iter": 81, "policy_reward_min": {"red_0": -1.059, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.467, "blue_0": 1.4300000000000002}, "policy_reward_mean": {"red_0": 0.8942000000000001, "blue_0": -0.7506099999999999}, "hist_stats": {"episode_reward": [0.44999999999999996, -0.031000000000000028, 0.32099999999999995, 0.403, -0.062000000000000055, 0.47, -0.040000000000000036, -0.10699999999999998, 0.2959999999999998, -0.028000000000000025, -0.038000000000000034, -0.21399999999999997, -0.748, 0.3799999999999999, -0.4760000000000001, -0.06600000000000006, 0.30499999999999994, 0.28400000000000003, -0.05999999999999994, -0.20300000000000007, -0.041000000000000036, -0.05300000000000005, -1.0050000000000001, 0.05799999999999983, -0.28900000000000003, -0.040000000000000036, 0.44700000000000006, -0.10399999999999998, 0.42799999999999994, -0.02499999999999991, 0.27300000000000013, 0.42100000000000004, 0.34399999999999986, 0.635, 0.31800000000000006, 0.42600000000000016, 0.841, 0.41300000000000026, 0.42300000000000004, 0.7829999999999999, -0.04300000000000004, 0.46499999999999986, 1.355, 0.3719999999999999, 0.33299999999999996, -0.04800000000000004, -0.11199999999999999, -0.030000000000000027, 0.2250000000000001, -0.40700000000000014, 0.3679999999999999, -0.06300000000000006, -0.08299999999999996, 0.353, -0.03200000000000003, 0.23399999999999999, -0.29300000000000004, -0.2539999999999999, -0.5130000000000001, 0.357, 0.907, -0.15200000000000002, -0.04300000000000004, 0.46199999999999997, 0.4650000000000001, 0.32499999999999996, -0.08099999999999996, 1.3399999999999999, 0.643, -0.43600000000000005, 0.4590000000000001, 0.2709999999999999, -0.11500000000000009, -0.4610000000000001, 0.42999999999999994, -0.17100000000000004, -0.14100000000000001, 0.46499999999999986, -0.1409999999999999, -0.040000000000000036, 0.16999999999999993, -0.02199999999999991, -0.236, 0.3639999999999999, -0.06500000000000006, 0.4159999999999999, 0.357, -0.029000000000000026, 0.31800000000000006, 0.41400000000000015, -0.029999999999999916, -0.05500000000000005, -0.03300000000000003, 0.44999999999999996, -0.031000000000000028, 0.39300000000000024, 0.389, -0.03399999999999992, -0.03700000000000003, 0.401], "episode_lengths": [16, 10, 54, 30, 18, 10, 13, 31, 63, 9, 12, 59, 221, 38, 293, 19, 61, 68, 19, 218, 13, 17, 296, 140, 82, 13, 17, 33, 24, 8, 71, 24, 49, 115, 57, 23, 49, 27, 23, 66, 14, 11, 45, 39, 54, 15, 34, 9, 86, 112, 41, 20, 26, 47, 10, 82, 91, 76, 287, 45, 29, 48, 14, 12, 11, 56, 26, 50, 109, 296, 13, 70, 300, 140, 22, 54, 44, 11, 190, 13, 103, 7, 71, 42, 21, 27, 44, 9, 51, 27, 9, 18, 10, 16, 9, 33, 35, 11, 12, 32], "policy_red_0_reward": [1.452, 0.97, 1.327, 1.409, 0.94, -0.5, 0.961, 0.898, 1.31, 0.973, 0.962, -1.025, -1.059, 1.384, 0.5619999999999999, 0.9369999999999999, 1.314, 1.2930000000000001, -1.001, 0.826, 0.961, 0.949, 0.034999999999999934, 1.073, 0.718, 0.961, 1.448, 0.9, -0.5, -1.0, 1.28, 1.427, 1.353, 1.1520000000000001, 1.3239999999999998, 0.928, 1.351, 1.419, -1.007, 1.298, 0.958, 1.467, 1.362, 1.379, 1.338, 0.954, 0.893, 0.973, 1.237, 0.6129999999999999, 1.373, 0.938, 0.922, 1.359, 0.97, 1.2469999999999999, 0.721, 0.759, 0.5259999999999999, -0.502, 1.411, 0.851, 0.958, -0.5, 1.467, 1.33, 0.92, 1.349, 1.154, 0.603, 1.46, 1.28, -0.07100000000000005, 0.5529999999999999, 1.434, 0.836, 0.867, 1.467, 0.892, 0.961, 1.183, 0.979, 0.771, 1.373, 0.9369999999999999, 1.4180000000000001, 1.3639999999999999, 0.973, 0.827, 1.417, -1.0, 0.946, 0.97, 1.451, 0.973, 1.399, 1.393, 0.967, 0.964, 1.403], "policy_blue_0_reward": [-1.002, -1.001, -1.006, -1.006, -1.002, 0.97, -1.001, -1.005, -1.014, -1.001, -1.0, 0.8109999999999999, 0.31099999999999994, -1.004, -1.038, -1.003, -1.009, -1.009, 0.941, -1.029, -1.002, -1.002, -1.04, -1.015, -1.007, -1.001, -1.001, -1.004, 0.9279999999999999, 0.975, -1.007, -1.0059999999999998, -1.009, -0.517, -1.006, -0.5019999999999999, -0.51, -1.0059999999999998, 1.4300000000000002, -0.515, -1.001, -1.002, -0.007, -1.007, -1.005, -1.002, -1.005, -1.003, -1.0119999999999998, -1.02, -1.005, -1.001, -1.005, -1.006, -1.002, -1.013, -1.014, -1.013, -1.039, 0.859, -0.504, -1.003, -1.001, 0.962, -1.0019999999999998, -1.005, -1.001, -0.009000000000000001, -0.511, -1.039, -1.001, -1.009, -0.04400000000000003, -1.014, -1.004, -1.007, -1.008, -1.002, -1.033, -1.001, -1.013, -1.001, -1.007, -1.009, -1.002, -1.002, -1.007, -1.002, -0.509, -1.003, 0.97, -1.001, -1.003, -1.001, -1.004, -1.0059999999999998, -1.004, -1.001, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22776878788359134, "mean_inference_ms": 1.4738919088492635, "mean_action_processing_ms": 0.0625764988991178, "mean_env_wait_ms": 0.088565727241406, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021704554557800293, "StateBufferConnector_ms": 0.0015186071395874023, "ViewRequirementAgentConnector_ms": 0.032204508781433105}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000, "num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.9249733915973, "num_env_steps_trained_throughput_per_sec": 103.9249733915973, "timesteps_total": 80000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 160000, "timers": {"training_iteration_time_ms": 38815.342, "sample_time_ms": 7476.491, "learn_time_ms": 31321.469, "learn_throughput": 127.708, "synch_weights_time_ms": 16.875}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 80000, "num_agent_steps_sampled": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 652, "training_iteration": 20, "trial_id": "d67e4_00000", "date": "2023-09-20_22-22-06", "timestamp": 1695262926, "time_this_iter_s": 38.49403214454651, "time_total_s": 776.2725358009338, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687b1c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 776.2725358009338, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 37.77090909090909, "ram_util_percent": 48.01818181818182}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6555072631686927, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01837525604860275, "policy_loss": -0.025844831166129248, "vf_loss": 0.008953755922266281, "vf_explained_var": 0.6487949760009845, "kl": 0.013156182948923406, "entropy": 0.9541573270534476, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 19680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "sampler_results": {"episode_reward_max": 1.7999999999999998, "episode_reward_min": -0.927, "episode_reward_mean": 0.25519, "episode_len_mean": 39.77, "episode_media": {}, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.0419999999999998}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.346}, "policy_reward_mean": {"red_0": 1.05977, "blue_0": -0.80458}, "custom_metrics": {"red_0/door_open_done_mean": 0.05, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.31800000000000006, 0.41400000000000015, -0.029999999999999916, -0.05500000000000005, -0.03300000000000003, 0.44999999999999996, -0.031000000000000028, 0.39300000000000024, 0.389, -0.03399999999999992, -0.03700000000000003, 0.401, 0.27700000000000014, -0.05800000000000005, -0.02300000000000002, -0.02400000000000002, -0.08999999999999986, 0.43100000000000005, 0.46599999999999997, 0.40700000000000003, -0.029000000000000026, 0.46899999999999986, 0.3460000000000001, 0.8300000000000001, 0.40600000000000014, 0.35199999999999987, -0.05700000000000005, 1.7999999999999998, 0.20900000000000007, 0.45099999999999996, -0.08399999999999996, -0.07899999999999985, 0.40600000000000014, 0.45199999999999996, -0.04400000000000004, 0.3460000000000001, 0.47299999999999986, 0.8840000000000001, 0.361, 0.45699999999999985, -0.06800000000000006, -0.21200000000000008, 1.388, 1.42, 0.669, 0.9550000000000001, 0.403, 0.42600000000000016, 0.845, 0.4079999999999999, -0.03399999999999992, 0.31999999999999995, -0.025000000000000022, 1.411, 0.365, 0.7879999999999999, -0.03300000000000003, -0.03200000000000003, -0.03400000000000003, 0.41400000000000015, -0.19799999999999995, 0.43699999999999983, -0.031000000000000028, 0.42700000000000005, 0.6819999999999999, 0.34399999999999986, -0.027000000000000024, -0.08299999999999996, -0.03500000000000003, 0.3999999999999999, -0.1369999999999999, 0.472, -0.06700000000000006, 0.41400000000000015, -0.06300000000000006, -0.07200000000000006, 0.32899999999999996, -0.10399999999999998, 0.3400000000000001, 0.4630000000000001, -0.08199999999999996, 0.4610000000000001, -0.20800000000000007, -0.07700000000000007, -0.04500000000000004, 0.43999999999999995, -0.03300000000000003, -0.927, 0.3780000000000001, 0.363, -0.030000000000000027, -0.06300000000000006, 0.256, -0.06800000000000006, -0.02400000000000002, -0.03700000000000003, 0.3420000000000001, -0.031000000000000028, 0.15900000000000025, 0.3999999999999999], "episode_lengths": [51, 27, 9, 18, 10, 16, 9, 33, 35, 11, 12, 32, 71, 19, 7, 8, 27, 22, 11, 30, 9, 10, 48, 54, 30, 44, 18, 61, 93, 300, 27, 23, 30, 15, 14, 50, 9, 36, 44, 13, 22, 225, 188, 26, 103, 15, 30, 23, 48, 29, 11, 55, 8, 29, 42, 65, 11, 10, 11, 26, 60, 20, 10, 22, 97, 49, 9, 26, 11, 32, 43, 9, 21, 27, 20, 22, 54, 31, 48, 12, 25, 12, 65, 24, 14, 19, 10, 241, 38, 44, 10, 178, 75, 21, 8, 11, 48, 10, 107, 31], "policy_red_0_reward": [0.827, 1.417, -1.0, 0.946, 0.97, 1.451, 0.973, 1.399, 1.393, 0.967, 0.964, 1.403, 1.284, 0.943, 0.979, 0.976, -1.002, 1.4329999999999998, 1.467, 1.408, 0.973, 1.47, 1.3559999999999999, 1.3359999999999999, 1.409, 1.3599999999999999, 0.946, 1.309, 1.2149999999999999, 0.0, 0.917, 0.927, 1.409, 1.454, 0.958, 1.349, 1.4729999999999999, 1.388, 1.367, 1.4609999999999999, 0.9339999999999999, 0.31299999999999994, 0.9209999999999999, 1.4220000000000002, 1.179, 1.455, 1.408, 1.431, -0.501, 1.412, 0.967, -1.007, 0.976, 1.413, 1.373, 0.29699999999999993, 0.967, 0.97, 0.967, 1.4180000000000001, 0.8099999999999999, 1.439, 0.97, 1.432, 1.195, 1.3519999999999999, 0.973, 0.922, 0.966, 1.4020000000000001, 0.869, 1.4729999999999999, 0.9359999999999999, 1.417, 0.938, 0.9299999999999999, 1.334, 0.901, 1.345, 1.464, 0.923, 1.464, 0.7979999999999999, 0.9269999999999999, 0.957, 1.442, 0.97, 0.11499999999999991, 1.384, 1.366, 0.97, 0.958, 1.267, 0.9359999999999999, 0.976, 0.967, 1.349, 0.97, 1.175, 1.405], "policy_blue_0_reward": [-0.509, -1.003, 0.97, -1.001, -1.003, -1.001, -1.004, -1.0059999999999998, -1.004, -1.001, -1.001, -1.002, -1.007, -1.001, -1.002, -1.0, 0.912, -1.002, -1.001, -1.001, -1.002, -1.001, -1.01, -0.506, -1.003, -1.008, -1.003, 0.491, -1.006, 0.45099999999999996, -1.001, -1.0059999999999998, -1.003, -1.002, -1.002, -1.003, -1.0, -0.5039999999999999, -1.006, -1.004, -1.002, -0.525, 0.46699999999999997, -0.002, -0.51, -0.5, -1.005, -1.005, 1.346, -1.004, -1.001, 1.327, -1.001, -0.002, -1.008, 0.491, -1.0, -1.002, -1.001, -1.004, -1.0079999999999998, -1.002, -1.001, -1.005, -0.513, -1.008, -1.0, -1.005, -1.001, -1.002, -1.0059999999999998, -1.001, -1.003, -1.003, -1.001, -1.002, -1.005, -1.005, -1.005, -1.001, -1.005, -1.003, -1.006, -1.004, -1.002, -1.002, -1.003, -1.0419999999999998, -1.006, -1.003, -1.0, -1.021, -1.011, -1.004, -1.0, -1.004, -1.007, -1.001, -1.0159999999999998, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22901314565969297, "mean_inference_ms": 1.4740360631689355, "mean_action_processing_ms": 0.06276702714339094, "mean_env_wait_ms": 0.08878569383758378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021546244621276855, "StateBufferConnector_ms": 0.001566767692565918, "ViewRequirementAgentConnector_ms": 0.03242850303649902}}, "episode_reward_max": 1.7999999999999998, "episode_reward_min": -0.927, "episode_reward_mean": 0.25519, "episode_len_mean": 39.77, "episodes_this_iter": 88, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.0419999999999998}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.346}, "policy_reward_mean": {"red_0": 1.05977, "blue_0": -0.80458}, "hist_stats": {"episode_reward": [0.31800000000000006, 0.41400000000000015, -0.029999999999999916, -0.05500000000000005, -0.03300000000000003, 0.44999999999999996, -0.031000000000000028, 0.39300000000000024, 0.389, -0.03399999999999992, -0.03700000000000003, 0.401, 0.27700000000000014, -0.05800000000000005, -0.02300000000000002, -0.02400000000000002, -0.08999999999999986, 0.43100000000000005, 0.46599999999999997, 0.40700000000000003, -0.029000000000000026, 0.46899999999999986, 0.3460000000000001, 0.8300000000000001, 0.40600000000000014, 0.35199999999999987, -0.05700000000000005, 1.7999999999999998, 0.20900000000000007, 0.45099999999999996, -0.08399999999999996, -0.07899999999999985, 0.40600000000000014, 0.45199999999999996, -0.04400000000000004, 0.3460000000000001, 0.47299999999999986, 0.8840000000000001, 0.361, 0.45699999999999985, -0.06800000000000006, -0.21200000000000008, 1.388, 1.42, 0.669, 0.9550000000000001, 0.403, 0.42600000000000016, 0.845, 0.4079999999999999, -0.03399999999999992, 0.31999999999999995, -0.025000000000000022, 1.411, 0.365, 0.7879999999999999, -0.03300000000000003, -0.03200000000000003, -0.03400000000000003, 0.41400000000000015, -0.19799999999999995, 0.43699999999999983, -0.031000000000000028, 0.42700000000000005, 0.6819999999999999, 0.34399999999999986, -0.027000000000000024, -0.08299999999999996, -0.03500000000000003, 0.3999999999999999, -0.1369999999999999, 0.472, -0.06700000000000006, 0.41400000000000015, -0.06300000000000006, -0.07200000000000006, 0.32899999999999996, -0.10399999999999998, 0.3400000000000001, 0.4630000000000001, -0.08199999999999996, 0.4610000000000001, -0.20800000000000007, -0.07700000000000007, -0.04500000000000004, 0.43999999999999995, -0.03300000000000003, -0.927, 0.3780000000000001, 0.363, -0.030000000000000027, -0.06300000000000006, 0.256, -0.06800000000000006, -0.02400000000000002, -0.03700000000000003, 0.3420000000000001, -0.031000000000000028, 0.15900000000000025, 0.3999999999999999], "episode_lengths": [51, 27, 9, 18, 10, 16, 9, 33, 35, 11, 12, 32, 71, 19, 7, 8, 27, 22, 11, 30, 9, 10, 48, 54, 30, 44, 18, 61, 93, 300, 27, 23, 30, 15, 14, 50, 9, 36, 44, 13, 22, 225, 188, 26, 103, 15, 30, 23, 48, 29, 11, 55, 8, 29, 42, 65, 11, 10, 11, 26, 60, 20, 10, 22, 97, 49, 9, 26, 11, 32, 43, 9, 21, 27, 20, 22, 54, 31, 48, 12, 25, 12, 65, 24, 14, 19, 10, 241, 38, 44, 10, 178, 75, 21, 8, 11, 48, 10, 107, 31], "policy_red_0_reward": [0.827, 1.417, -1.0, 0.946, 0.97, 1.451, 0.973, 1.399, 1.393, 0.967, 0.964, 1.403, 1.284, 0.943, 0.979, 0.976, -1.002, 1.4329999999999998, 1.467, 1.408, 0.973, 1.47, 1.3559999999999999, 1.3359999999999999, 1.409, 1.3599999999999999, 0.946, 1.309, 1.2149999999999999, 0.0, 0.917, 0.927, 1.409, 1.454, 0.958, 1.349, 1.4729999999999999, 1.388, 1.367, 1.4609999999999999, 0.9339999999999999, 0.31299999999999994, 0.9209999999999999, 1.4220000000000002, 1.179, 1.455, 1.408, 1.431, -0.501, 1.412, 0.967, -1.007, 0.976, 1.413, 1.373, 0.29699999999999993, 0.967, 0.97, 0.967, 1.4180000000000001, 0.8099999999999999, 1.439, 0.97, 1.432, 1.195, 1.3519999999999999, 0.973, 0.922, 0.966, 1.4020000000000001, 0.869, 1.4729999999999999, 0.9359999999999999, 1.417, 0.938, 0.9299999999999999, 1.334, 0.901, 1.345, 1.464, 0.923, 1.464, 0.7979999999999999, 0.9269999999999999, 0.957, 1.442, 0.97, 0.11499999999999991, 1.384, 1.366, 0.97, 0.958, 1.267, 0.9359999999999999, 0.976, 0.967, 1.349, 0.97, 1.175, 1.405], "policy_blue_0_reward": [-0.509, -1.003, 0.97, -1.001, -1.003, -1.001, -1.004, -1.0059999999999998, -1.004, -1.001, -1.001, -1.002, -1.007, -1.001, -1.002, -1.0, 0.912, -1.002, -1.001, -1.001, -1.002, -1.001, -1.01, -0.506, -1.003, -1.008, -1.003, 0.491, -1.006, 0.45099999999999996, -1.001, -1.0059999999999998, -1.003, -1.002, -1.002, -1.003, -1.0, -0.5039999999999999, -1.006, -1.004, -1.002, -0.525, 0.46699999999999997, -0.002, -0.51, -0.5, -1.005, -1.005, 1.346, -1.004, -1.001, 1.327, -1.001, -0.002, -1.008, 0.491, -1.0, -1.002, -1.001, -1.004, -1.0079999999999998, -1.002, -1.001, -1.005, -0.513, -1.008, -1.0, -1.005, -1.001, -1.002, -1.0059999999999998, -1.001, -1.003, -1.003, -1.001, -1.002, -1.005, -1.005, -1.005, -1.001, -1.005, -1.003, -1.006, -1.004, -1.002, -1.002, -1.003, -1.0419999999999998, -1.006, -1.003, -1.0, -1.021, -1.011, -1.004, -1.0, -1.004, -1.007, -1.001, -1.0159999999999998, -1.005]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.22901314565969297, "mean_inference_ms": 1.4740360631689355, "mean_action_processing_ms": 0.06276702714339094, "mean_env_wait_ms": 0.08878569383758378, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021546244621276855, "StateBufferConnector_ms": 0.001566767692565918, "ViewRequirementAgentConnector_ms": 0.03242850303649902}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000, "num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.92214961966562, "num_env_steps_trained_throughput_per_sec": 102.92214961966562, "timesteps_total": 84000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 168000, "timers": {"training_iteration_time_ms": 38825.743, "sample_time_ms": 7478.143, "learn_time_ms": 31330.256, "learn_throughput": 127.672, "synch_weights_time_ms": 16.841}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 84000, "num_agent_steps_sampled": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 740, "training_iteration": 21, "trial_id": "d67e4_00000", "date": "2023-09-20_22-22-46", "timestamp": 1695262966, "time_this_iter_s": 38.869032859802246, "time_total_s": 815.1415686607361, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687a8c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 815.1415686607361, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 34.721428571428575, "ram_util_percent": 48.00535714285714}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.04, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.91, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.91, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.91, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7372590965901813, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.017698798054334476, "policy_loss": -0.02404185580914297, "vf_loss": 0.006609612176422767, "vf_explained_var": 0.7098399740333359, "kl": 0.013072291302721313, "entropy": 0.8834358728180329, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 20640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "sampler_results": {"episode_reward_max": 1.444, "episode_reward_min": -0.927, "episode_reward_mean": 0.22019999999999995, "episode_len_mean": 51.32, "episode_media": {}, "episodes_this_iter": 77, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.0419999999999998}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.705}, "policy_reward_mean": {"red_0": 1.05843, "blue_0": -0.8382299999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.04, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.91, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.91, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.91, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.10399999999999998, 0.3400000000000001, 0.4630000000000001, -0.08199999999999996, 0.4610000000000001, -0.20800000000000007, -0.07700000000000007, -0.04500000000000004, 0.43999999999999995, -0.03300000000000003, -0.927, 0.3780000000000001, 0.363, -0.030000000000000027, -0.06300000000000006, 0.256, -0.06800000000000006, -0.02400000000000002, -0.03700000000000003, 0.3420000000000001, -0.031000000000000028, 0.15900000000000025, 0.3999999999999999, 0.42300000000000004, 0.264, 0.403, 0.385, -0.028000000000000025, -0.02100000000000002, 0.17300000000000004, -0.052000000000000046, -0.06500000000000006, -0.027000000000000024, 0.42999999999999994, 0.45599999999999996, -0.030000000000000027, 0.1459999999999999, 0.42600000000000016, -0.10099999999999998, 0.46399999999999997, -0.31600000000000006, 0.9100000000000001, 0.43399999999999994, 0.42500000000000004, -0.30099999999999993, 0.6950000000000001, 0.22599999999999998, 0.1459999999999999, -0.027000000000000024, 0.4710000000000001, 0.3660000000000001, 0.33999999999999986, -0.07399999999999995, -0.33000000000000007, 0.379, 0.2789999999999999, -0.04400000000000004, -0.051999999999999935, 0.766, 0.07699999999999996, 0.31499999999999995, 1.419, 0.03500000000000014, 0.29100000000000015, 0.44499999999999984, -0.16999999999999993, 0.901, 0.727, -0.027000000000000024, 0.3380000000000001, 0.45599999999999996, -0.08299999999999996, -0.028000000000000025, -0.122, -0.031000000000000028, -0.030000000000000027, 0.782, 0.397, -0.030000000000000027, 0.32200000000000006, 0.45599999999999996, 0.45899999999999996, -0.131, -0.052999999999999936, 0.42999999999999994, 0.45699999999999996, 0.11099999999999988, 0.43599999999999994, -0.04500000000000004, 0.3690000000000002, 0.3250000000000002, -0.06800000000000006, 0.45999999999999996, -0.03500000000000003, 1.401, -0.030000000000000027, 0.40600000000000014, -0.10499999999999998, 1.444, 0.33699999999999997], "episode_lengths": [31, 48, 12, 25, 12, 65, 24, 14, 19, 10, 241, 38, 44, 10, 178, 75, 21, 8, 11, 48, 10, 107, 31, 25, 74, 30, 35, 9, 7, 103, 17, 20, 9, 300, 14, 10, 108, 23, 32, 11, 99, 29, 21, 23, 94, 97, 85, 107, 9, 9, 42, 47, 23, 94, 38, 69, 14, 17, 74, 117, 58, 26, 142, 64, 18, 53, 31, 245, 9, 48, 14, 26, 9, 32, 10, 10, 70, 32, 10, 54, 14, 300, 40, 17, 22, 300, 120, 20, 15, 41, 54, 20, 13, 11, 29, 10, 30, 34, 18, 46], "policy_red_0_reward": [0.901, 1.345, 1.464, 0.923, 1.464, 0.7979999999999999, 0.9269999999999999, 0.957, 1.442, 0.97, 0.11499999999999991, 1.384, 1.366, 0.97, 0.958, 1.267, 0.9359999999999999, 0.976, 0.967, 1.349, 0.97, 1.175, 1.405, 1.424, 1.272, 1.409, 0.889, 0.973, 0.979, 0.683, 0.949, 0.939, 0.973, 0.471, 1.458, 0.97, 1.161, 1.4300000000000002, 0.899, 1.466, 0.7, 1.412, 1.4369999999999998, 1.4300000000000002, -1.006, 1.207, 1.2389999999999999, 1.158, 0.973, 1.4729999999999999, 1.371, 0.84, 0.929, 0.6809999999999999, 1.384, 1.2919999999999998, 0.958, 0.949, 1.275, 1.0939999999999999, 1.323, 1.421, 1.058, 1.3050000000000002, 0.945, 0.835, 1.405, 0.756, 0.973, 1.342, 1.458, 0.921, 0.973, 0.886, 0.97, 0.97, 1.29, 1.404, 0.97, 1.331, 1.458, -0.003, 0.876, 0.949, 1.4329999999999998, -0.006, -0.509, 1.438, 0.955, 0.875, 1.334, 0.9359999999999999, 1.4609999999999999, 0.967, 1.409, 0.97, 1.409, 0.897, 1.446, 0.842], "policy_blue_0_reward": [-1.005, -1.005, -1.001, -1.005, -1.003, -1.006, -1.004, -1.002, -1.002, -1.003, -1.0419999999999998, -1.006, -1.003, -1.0, -1.021, -1.011, -1.004, -1.0, -1.004, -1.007, -1.001, -1.0159999999999998, -1.005, -1.001, -1.008, -1.006, -0.504, -1.001, -1.0, -0.51, -1.001, -1.004, -1.0, -0.04100000000000003, -1.002, -1.0, -1.015, -1.0039999999999998, -1.0, -1.002, -1.016, -0.502, -1.003, -1.005, 0.705, -0.512, -1.013, -1.012, -1.0, -1.002, -1.005, -0.5, -1.003, -1.011, -1.005, -1.013, -1.002, -1.001, -0.509, -1.017, -1.008, -0.002, -1.023, -1.0139999999999998, -0.5, -1.005, -0.504, -0.02900000000000002, -1.0, -1.004, -1.0019999999999998, -1.004, -1.001, -1.008, -1.001, -1.0, -0.508, -1.007, -1.0, -1.009, -1.002, 0.46199999999999997, -1.007, -1.0019999999999998, -1.003, 0.46299999999999997, 0.6199999999999999, -1.002, -1.0, -0.5059999999999999, -1.009, -1.004, -1.001, -1.002, -0.008, -1.0, -1.003, -1.002, -0.002, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2293982103601669, "mean_inference_ms": 1.4751714808726535, "mean_action_processing_ms": 0.06272459205913207, "mean_env_wait_ms": 0.08874298801578773, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02138340473175049, "StateBufferConnector_ms": 0.0015285015106201172, "ViewRequirementAgentConnector_ms": 0.032317161560058594}}, "episode_reward_max": 1.444, "episode_reward_min": -0.927, "episode_reward_mean": 0.22019999999999995, "episode_len_mean": 51.32, "episodes_this_iter": 77, "policy_reward_min": {"red_0": -1.006, "blue_0": -1.0419999999999998}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.705}, "policy_reward_mean": {"red_0": 1.05843, "blue_0": -0.8382299999999998}, "hist_stats": {"episode_reward": [-0.10399999999999998, 0.3400000000000001, 0.4630000000000001, -0.08199999999999996, 0.4610000000000001, -0.20800000000000007, -0.07700000000000007, -0.04500000000000004, 0.43999999999999995, -0.03300000000000003, -0.927, 0.3780000000000001, 0.363, -0.030000000000000027, -0.06300000000000006, 0.256, -0.06800000000000006, -0.02400000000000002, -0.03700000000000003, 0.3420000000000001, -0.031000000000000028, 0.15900000000000025, 0.3999999999999999, 0.42300000000000004, 0.264, 0.403, 0.385, -0.028000000000000025, -0.02100000000000002, 0.17300000000000004, -0.052000000000000046, -0.06500000000000006, -0.027000000000000024, 0.42999999999999994, 0.45599999999999996, -0.030000000000000027, 0.1459999999999999, 0.42600000000000016, -0.10099999999999998, 0.46399999999999997, -0.31600000000000006, 0.9100000000000001, 0.43399999999999994, 0.42500000000000004, -0.30099999999999993, 0.6950000000000001, 0.22599999999999998, 0.1459999999999999, -0.027000000000000024, 0.4710000000000001, 0.3660000000000001, 0.33999999999999986, -0.07399999999999995, -0.33000000000000007, 0.379, 0.2789999999999999, -0.04400000000000004, -0.051999999999999935, 0.766, 0.07699999999999996, 0.31499999999999995, 1.419, 0.03500000000000014, 0.29100000000000015, 0.44499999999999984, -0.16999999999999993, 0.901, 0.727, -0.027000000000000024, 0.3380000000000001, 0.45599999999999996, -0.08299999999999996, -0.028000000000000025, -0.122, -0.031000000000000028, -0.030000000000000027, 0.782, 0.397, -0.030000000000000027, 0.32200000000000006, 0.45599999999999996, 0.45899999999999996, -0.131, -0.052999999999999936, 0.42999999999999994, 0.45699999999999996, 0.11099999999999988, 0.43599999999999994, -0.04500000000000004, 0.3690000000000002, 0.3250000000000002, -0.06800000000000006, 0.45999999999999996, -0.03500000000000003, 1.401, -0.030000000000000027, 0.40600000000000014, -0.10499999999999998, 1.444, 0.33699999999999997], "episode_lengths": [31, 48, 12, 25, 12, 65, 24, 14, 19, 10, 241, 38, 44, 10, 178, 75, 21, 8, 11, 48, 10, 107, 31, 25, 74, 30, 35, 9, 7, 103, 17, 20, 9, 300, 14, 10, 108, 23, 32, 11, 99, 29, 21, 23, 94, 97, 85, 107, 9, 9, 42, 47, 23, 94, 38, 69, 14, 17, 74, 117, 58, 26, 142, 64, 18, 53, 31, 245, 9, 48, 14, 26, 9, 32, 10, 10, 70, 32, 10, 54, 14, 300, 40, 17, 22, 300, 120, 20, 15, 41, 54, 20, 13, 11, 29, 10, 30, 34, 18, 46], "policy_red_0_reward": [0.901, 1.345, 1.464, 0.923, 1.464, 0.7979999999999999, 0.9269999999999999, 0.957, 1.442, 0.97, 0.11499999999999991, 1.384, 1.366, 0.97, 0.958, 1.267, 0.9359999999999999, 0.976, 0.967, 1.349, 0.97, 1.175, 1.405, 1.424, 1.272, 1.409, 0.889, 0.973, 0.979, 0.683, 0.949, 0.939, 0.973, 0.471, 1.458, 0.97, 1.161, 1.4300000000000002, 0.899, 1.466, 0.7, 1.412, 1.4369999999999998, 1.4300000000000002, -1.006, 1.207, 1.2389999999999999, 1.158, 0.973, 1.4729999999999999, 1.371, 0.84, 0.929, 0.6809999999999999, 1.384, 1.2919999999999998, 0.958, 0.949, 1.275, 1.0939999999999999, 1.323, 1.421, 1.058, 1.3050000000000002, 0.945, 0.835, 1.405, 0.756, 0.973, 1.342, 1.458, 0.921, 0.973, 0.886, 0.97, 0.97, 1.29, 1.404, 0.97, 1.331, 1.458, -0.003, 0.876, 0.949, 1.4329999999999998, -0.006, -0.509, 1.438, 0.955, 0.875, 1.334, 0.9359999999999999, 1.4609999999999999, 0.967, 1.409, 0.97, 1.409, 0.897, 1.446, 0.842], "policy_blue_0_reward": [-1.005, -1.005, -1.001, -1.005, -1.003, -1.006, -1.004, -1.002, -1.002, -1.003, -1.0419999999999998, -1.006, -1.003, -1.0, -1.021, -1.011, -1.004, -1.0, -1.004, -1.007, -1.001, -1.0159999999999998, -1.005, -1.001, -1.008, -1.006, -0.504, -1.001, -1.0, -0.51, -1.001, -1.004, -1.0, -0.04100000000000003, -1.002, -1.0, -1.015, -1.0039999999999998, -1.0, -1.002, -1.016, -0.502, -1.003, -1.005, 0.705, -0.512, -1.013, -1.012, -1.0, -1.002, -1.005, -0.5, -1.003, -1.011, -1.005, -1.013, -1.002, -1.001, -0.509, -1.017, -1.008, -0.002, -1.023, -1.0139999999999998, -0.5, -1.005, -0.504, -0.02900000000000002, -1.0, -1.004, -1.0019999999999998, -1.004, -1.001, -1.008, -1.001, -1.0, -0.508, -1.007, -1.0, -1.009, -1.002, 0.46199999999999997, -1.007, -1.0019999999999998, -1.003, 0.46299999999999997, 0.6199999999999999, -1.002, -1.0, -0.5059999999999999, -1.009, -1.004, -1.001, -1.002, -0.008, -1.0, -1.003, -1.002, -0.002, -0.505]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2293982103601669, "mean_inference_ms": 1.4751714808726535, "mean_action_processing_ms": 0.06272459205913207, "mean_env_wait_ms": 0.08874298801578773, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02138340473175049, "StateBufferConnector_ms": 0.0015285015106201172, "ViewRequirementAgentConnector_ms": 0.032317161560058594}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000, "num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.77328582222519, "num_env_steps_trained_throughput_per_sec": 102.77328582222519, "timesteps_total": 88000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 176000, "timers": {"training_iteration_time_ms": 38841.651, "sample_time_ms": 7479.662, "learn_time_ms": 31344.66, "learn_throughput": 127.613, "synch_weights_time_ms": 16.826}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 88000, "num_agent_steps_sampled": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 817, "training_iteration": 22, "trial_id": "d67e4_00000", "date": "2023-09-20_22-23-25", "timestamp": 1695263005, "time_this_iter_s": 38.92550206184387, "time_total_s": 854.06707072258, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a6879120>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 854.06707072258, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 34.449090909090906, "ram_util_percent": 48.085454545454525}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.09558823529411764, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8602941176470589, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.029411764705882353, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8602941176470589, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.029411764705882353, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8602941176470589, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.029411764705882353, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7461554761976004, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.012735957457819799, "policy_loss": -0.020801111587934427, "vf_loss": 0.010244923144879674, "vf_explained_var": 0.6721407054613034, "kl": 0.012267612640107473, "entropy": 0.7375911382337411, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 21600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "sampler_results": {"episode_reward_max": 1.9500000000000002, "episode_reward_min": -0.252, "episode_reward_mean": 0.32133823529411765, "episode_len_mean": 30.11764705882353, "episode_media": {}, "episodes_this_iter": 136, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.033}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.471}, "policy_reward_mean": {"red_0": 1.125375, "blue_0": -0.8040367647058823}, "custom_metrics": {"red_0/door_open_done_mean": 0.09558823529411764, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8602941176470589, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.029411764705882353, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8602941176470589, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.029411764705882353, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8602941176470589, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.029411764705882353, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.05799999999999983, -0.039000000000000035, -0.041000000000000036, 0.44399999999999995, -0.03799999999999992, 0.46199999999999997, -0.029000000000000026, -0.17800000000000005, 0.45300000000000007, -0.252, 0.4590000000000001, 0.44700000000000006, 0.3800000000000001, 0.4630000000000001, 0.46599999999999997, 0.472, 0.42200000000000015, 1.439, -0.028000000000000025, -0.03700000000000003, 0.4590000000000001, 0.387, 0.46499999999999986, -0.03700000000000003, -0.03500000000000003, -0.028000000000000025, -0.03499999999999992, 1.431, 0.46899999999999986, -0.03400000000000003, -0.07799999999999996, 0.47, -0.02100000000000002, 0.2699999999999999, 0.45799999999999996, -0.03700000000000003, -0.040999999999999925, 0.42200000000000015, -0.05400000000000005, -0.03599999999999992, 1.436, 0.4750000000000001, 0.44999999999999996, 1.409, -0.05900000000000005, -0.04300000000000004, 0.44700000000000006, 0.46599999999999997, -0.03300000000000003, 0.43999999999999995, 0.33299999999999996, -0.02199999999999991, 0.4710000000000001, -0.07199999999999995, 0.41800000000000015, -0.03199999999999992, 1.016, -0.03300000000000003, -0.02400000000000002, -0.046000000000000034, 0.43399999999999994, 0.3810000000000002, 0.46599999999999997, 0.43999999999999995, 0.45399999999999996, 1.413, -0.03199999999999992, 0.45799999999999996, 0.31899999999999995, 0.4590000000000001, -0.04300000000000004, 0.42799999999999994, -0.05700000000000005, -0.03300000000000003, -0.14700000000000013, -0.025000000000000022, 0.45299999999999985, 0.45399999999999996, 0.46499999999999986, 0.46899999999999986, 0.39400000000000013, 0.45699999999999985, 0.42399999999999993, 1.393, -0.02200000000000002, 0.45299999999999985, -0.08299999999999996, -0.03700000000000003, 0.7609999999999999, 1.443, 0.782, 0.26900000000000013, -0.09399999999999997, -0.030000000000000027, 0.45299999999999985, -0.04300000000000004, 1.3679999999999999, 0.45999999999999996, 1.312, -0.029999999999999916, 0.46899999999999986, 0.45299999999999985, -0.038999999999999924, 1.153, 0.471, -0.06499999999999995, -0.02200000000000002, -0.05400000000000005, -0.030000000000000027, -0.03400000000000003, -0.031000000000000028, 0.4670000000000001, -0.21600000000000008, -0.031000000000000028, 0.4670000000000001, 0.4590000000000001, -0.027000000000000024, 0.4660000000000002, -0.030000000000000027, -0.04699999999999993, -0.029000000000000026, 0.389, 1.9500000000000002, 0.5609999999999999, -0.02100000000000002, 0.45799999999999996, 0.44399999999999995, -0.03300000000000003, 0.4650000000000001, -0.039000000000000035, 0.45699999999999985, 1.267, -0.03400000000000003, 0.44700000000000006, -0.028000000000000025, 0.5680000000000001], "episode_lengths": [134, 12, 13, 17, 12, 12, 9, 54, 15, 72, 13, 16, 39, 12, 11, 9, 25, 20, 8, 12, 12, 37, 11, 12, 11, 9, 11, 22, 10, 10, 25, 10, 7, 73, 14, 12, 13, 25, 18, 11, 20, 8, 300, 28, 19, 14, 17, 11, 10, 19, 51, 7, 9, 23, 26, 10, 153, 11, 8, 300, 20, 37, 10, 19, 15, 27, 10, 13, 57, 13, 14, 23, 19, 11, 188, 8, 14, 15, 11, 10, 33, 14, 24, 32, 7, 15, 26, 12, 67, 18, 68, 74, 29, 9, 15, 14, 43, 13, 59, 9, 9, 15, 12, 107, 9, 20, 7, 17, 10, 11, 10, 11, 227, 10, 11, 13, 8, 11, 10, 14, 9, 35, 16, 138, 7, 13, 17, 11, 11, 13, 14, 70, 11, 17, 9, 136], "policy_red_0_reward": [1.08, 0.964, 0.961, 1.4489999999999998, 0.964, 1.464, -1.0, 0.828, 1.455, 0.754, 1.4609999999999999, 1.452, 1.3820000000000001, 1.464, 1.467, 1.4729999999999999, 1.424, 1.44, 0.976, 0.964, 1.463, 1.389, 1.467, 0.964, 0.967, 0.973, 0.967, 1.4329999999999998, 1.47, 0.97, 0.925, 1.47, 0.979, -0.5, 0.958, 0.964, 0.961, 1.425, 0.946, 0.967, 1.439, 1.476, -0.001, 1.415, 0.943, 0.957, 1.4489999999999998, 1.467, 0.97, 1.442, 1.339, -1.0, 1.4729999999999999, 0.929, 1.421, 0.969, 1.0339999999999998, 0.967, 0.976, -0.004, 1.438, 1.389, 1.47, 1.443, 1.455, 1.416, 0.97, 1.4609999999999999, 1.327, 1.4609999999999999, 0.958, 1.431, 0.943, 0.967, 0.8799999999999999, 0.976, 1.4569999999999999, 1.455, 1.467, 1.47, 1.401, 1.458, 1.428, 1.3980000000000001, 0.979, 1.454, 0.92, 0.964, 1.267, 1.446, 1.295, 1.275, 0.91, 0.973, 1.455, 0.958, 1.3679999999999999, 1.4609999999999999, 1.321, 0.973, 1.4729999999999999, 1.454, 0.964, 1.167, -1.0, 0.939, 0.979, 0.949, 0.97, 0.967, 0.97, 0.967, 0.817, 0.97, 1.467, 1.4609999999999999, 0.976, 1.467, 0.97, 0.957, 0.973, 1.395, 1.452, 1.0779999999999998, 0.979, 1.46, 1.4489999999999998, 0.967, 1.467, 0.961, 1.458, 1.2730000000000001, 0.967, 1.448, 0.973, 1.088], "policy_blue_0_reward": [-1.022, -1.003, -1.002, -1.005, -1.0019999999999998, -1.002, 0.971, -1.006, -1.0019999999999998, -1.006, -1.002, -1.005, -1.0019999999999998, -1.001, -1.001, -1.001, -1.002, -0.001, -1.004, -1.001, -1.0039999999999998, -1.002, -1.002, -1.001, -1.002, -1.001, -1.0019999999999998, -0.002, -1.001, -1.004, -1.003, -1.0, -1.0, 0.7699999999999999, -0.5, -1.001, -1.0019999999999998, -1.003, -1.0, -1.003, -0.003, -1.001, 0.45099999999999996, -0.006, -1.002, -1.0, -1.002, -1.001, -1.003, -1.002, -1.006, 0.978, -1.0019999999999998, -1.001, -1.003, -1.001, -0.01800000000000001, -1.0, -1.0, -0.04200000000000003, -1.004, -1.0079999999999998, -1.004, -1.003, -1.001, -0.003, -1.0019999999999998, -1.003, -1.008, -1.002, -1.001, -1.003, -1.0, -1.0, -1.027, -1.001, -1.004, -1.001, -1.002, -1.001, -1.007, -1.001, -1.004, -0.005, -1.001, -1.001, -1.003, -1.001, -0.506, -0.003, -0.5129999999999999, -1.006, -1.004, -1.003, -1.002, -1.001, 0.0, -1.001, -0.009000000000000001, -1.003, -1.004, -1.001, -1.003, -0.014000000000000005, 1.471, -1.0039999999999998, -1.001, -1.003, -1.0, -1.001, -1.001, -0.5, -1.033, -1.001, -1.0, -1.002, -1.003, -1.001, -1.0, -1.0039999999999998, -1.002, -1.006, 0.498, -0.5169999999999999, -1.0, -1.002, -1.005, -1.0, -1.0019999999999998, -1.0, -1.001, -0.006, -1.001, -1.001, -1.001, -0.52]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303244701517364, "mean_inference_ms": 1.4753489300301976, "mean_action_processing_ms": 0.06279053927478473, "mean_env_wait_ms": 0.08884322223577851, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019263344652512494, "StateBufferConnector_ms": 0.0015532269197351793, "ViewRequirementAgentConnector_ms": 0.03162745167227352}}, "episode_reward_max": 1.9500000000000002, "episode_reward_min": -0.252, "episode_reward_mean": 0.32133823529411765, "episode_len_mean": 30.11764705882353, "episodes_this_iter": 136, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.033}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.471}, "policy_reward_mean": {"red_0": 1.125375, "blue_0": -0.8040367647058823}, "hist_stats": {"episode_reward": [0.05799999999999983, -0.039000000000000035, -0.041000000000000036, 0.44399999999999995, -0.03799999999999992, 0.46199999999999997, -0.029000000000000026, -0.17800000000000005, 0.45300000000000007, -0.252, 0.4590000000000001, 0.44700000000000006, 0.3800000000000001, 0.4630000000000001, 0.46599999999999997, 0.472, 0.42200000000000015, 1.439, -0.028000000000000025, -0.03700000000000003, 0.4590000000000001, 0.387, 0.46499999999999986, -0.03700000000000003, -0.03500000000000003, -0.028000000000000025, -0.03499999999999992, 1.431, 0.46899999999999986, -0.03400000000000003, -0.07799999999999996, 0.47, -0.02100000000000002, 0.2699999999999999, 0.45799999999999996, -0.03700000000000003, -0.040999999999999925, 0.42200000000000015, -0.05400000000000005, -0.03599999999999992, 1.436, 0.4750000000000001, 0.44999999999999996, 1.409, -0.05900000000000005, -0.04300000000000004, 0.44700000000000006, 0.46599999999999997, -0.03300000000000003, 0.43999999999999995, 0.33299999999999996, -0.02199999999999991, 0.4710000000000001, -0.07199999999999995, 0.41800000000000015, -0.03199999999999992, 1.016, -0.03300000000000003, -0.02400000000000002, -0.046000000000000034, 0.43399999999999994, 0.3810000000000002, 0.46599999999999997, 0.43999999999999995, 0.45399999999999996, 1.413, -0.03199999999999992, 0.45799999999999996, 0.31899999999999995, 0.4590000000000001, -0.04300000000000004, 0.42799999999999994, -0.05700000000000005, -0.03300000000000003, -0.14700000000000013, -0.025000000000000022, 0.45299999999999985, 0.45399999999999996, 0.46499999999999986, 0.46899999999999986, 0.39400000000000013, 0.45699999999999985, 0.42399999999999993, 1.393, -0.02200000000000002, 0.45299999999999985, -0.08299999999999996, -0.03700000000000003, 0.7609999999999999, 1.443, 0.782, 0.26900000000000013, -0.09399999999999997, -0.030000000000000027, 0.45299999999999985, -0.04300000000000004, 1.3679999999999999, 0.45999999999999996, 1.312, -0.029999999999999916, 0.46899999999999986, 0.45299999999999985, -0.038999999999999924, 1.153, 0.471, -0.06499999999999995, -0.02200000000000002, -0.05400000000000005, -0.030000000000000027, -0.03400000000000003, -0.031000000000000028, 0.4670000000000001, -0.21600000000000008, -0.031000000000000028, 0.4670000000000001, 0.4590000000000001, -0.027000000000000024, 0.4660000000000002, -0.030000000000000027, -0.04699999999999993, -0.029000000000000026, 0.389, 1.9500000000000002, 0.5609999999999999, -0.02100000000000002, 0.45799999999999996, 0.44399999999999995, -0.03300000000000003, 0.4650000000000001, -0.039000000000000035, 0.45699999999999985, 1.267, -0.03400000000000003, 0.44700000000000006, -0.028000000000000025, 0.5680000000000001], "episode_lengths": [134, 12, 13, 17, 12, 12, 9, 54, 15, 72, 13, 16, 39, 12, 11, 9, 25, 20, 8, 12, 12, 37, 11, 12, 11, 9, 11, 22, 10, 10, 25, 10, 7, 73, 14, 12, 13, 25, 18, 11, 20, 8, 300, 28, 19, 14, 17, 11, 10, 19, 51, 7, 9, 23, 26, 10, 153, 11, 8, 300, 20, 37, 10, 19, 15, 27, 10, 13, 57, 13, 14, 23, 19, 11, 188, 8, 14, 15, 11, 10, 33, 14, 24, 32, 7, 15, 26, 12, 67, 18, 68, 74, 29, 9, 15, 14, 43, 13, 59, 9, 9, 15, 12, 107, 9, 20, 7, 17, 10, 11, 10, 11, 227, 10, 11, 13, 8, 11, 10, 14, 9, 35, 16, 138, 7, 13, 17, 11, 11, 13, 14, 70, 11, 17, 9, 136], "policy_red_0_reward": [1.08, 0.964, 0.961, 1.4489999999999998, 0.964, 1.464, -1.0, 0.828, 1.455, 0.754, 1.4609999999999999, 1.452, 1.3820000000000001, 1.464, 1.467, 1.4729999999999999, 1.424, 1.44, 0.976, 0.964, 1.463, 1.389, 1.467, 0.964, 0.967, 0.973, 0.967, 1.4329999999999998, 1.47, 0.97, 0.925, 1.47, 0.979, -0.5, 0.958, 0.964, 0.961, 1.425, 0.946, 0.967, 1.439, 1.476, -0.001, 1.415, 0.943, 0.957, 1.4489999999999998, 1.467, 0.97, 1.442, 1.339, -1.0, 1.4729999999999999, 0.929, 1.421, 0.969, 1.0339999999999998, 0.967, 0.976, -0.004, 1.438, 1.389, 1.47, 1.443, 1.455, 1.416, 0.97, 1.4609999999999999, 1.327, 1.4609999999999999, 0.958, 1.431, 0.943, 0.967, 0.8799999999999999, 0.976, 1.4569999999999999, 1.455, 1.467, 1.47, 1.401, 1.458, 1.428, 1.3980000000000001, 0.979, 1.454, 0.92, 0.964, 1.267, 1.446, 1.295, 1.275, 0.91, 0.973, 1.455, 0.958, 1.3679999999999999, 1.4609999999999999, 1.321, 0.973, 1.4729999999999999, 1.454, 0.964, 1.167, -1.0, 0.939, 0.979, 0.949, 0.97, 0.967, 0.97, 0.967, 0.817, 0.97, 1.467, 1.4609999999999999, 0.976, 1.467, 0.97, 0.957, 0.973, 1.395, 1.452, 1.0779999999999998, 0.979, 1.46, 1.4489999999999998, 0.967, 1.467, 0.961, 1.458, 1.2730000000000001, 0.967, 1.448, 0.973, 1.088], "policy_blue_0_reward": [-1.022, -1.003, -1.002, -1.005, -1.0019999999999998, -1.002, 0.971, -1.006, -1.0019999999999998, -1.006, -1.002, -1.005, -1.0019999999999998, -1.001, -1.001, -1.001, -1.002, -0.001, -1.004, -1.001, -1.0039999999999998, -1.002, -1.002, -1.001, -1.002, -1.001, -1.0019999999999998, -0.002, -1.001, -1.004, -1.003, -1.0, -1.0, 0.7699999999999999, -0.5, -1.001, -1.0019999999999998, -1.003, -1.0, -1.003, -0.003, -1.001, 0.45099999999999996, -0.006, -1.002, -1.0, -1.002, -1.001, -1.003, -1.002, -1.006, 0.978, -1.0019999999999998, -1.001, -1.003, -1.001, -0.01800000000000001, -1.0, -1.0, -0.04200000000000003, -1.004, -1.0079999999999998, -1.004, -1.003, -1.001, -0.003, -1.0019999999999998, -1.003, -1.008, -1.002, -1.001, -1.003, -1.0, -1.0, -1.027, -1.001, -1.004, -1.001, -1.002, -1.001, -1.007, -1.001, -1.004, -0.005, -1.001, -1.001, -1.003, -1.001, -0.506, -0.003, -0.5129999999999999, -1.006, -1.004, -1.003, -1.002, -1.001, 0.0, -1.001, -0.009000000000000001, -1.003, -1.004, -1.001, -1.003, -0.014000000000000005, 1.471, -1.0039999999999998, -1.001, -1.003, -1.0, -1.001, -1.001, -0.5, -1.033, -1.001, -1.0, -1.002, -1.003, -1.001, -1.0, -1.0039999999999998, -1.002, -1.006, 0.498, -0.5169999999999999, -1.0, -1.002, -1.005, -1.0, -1.0019999999999998, -1.0, -1.001, -0.006, -1.001, -1.001, -1.001, -0.52]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2303244701517364, "mean_inference_ms": 1.4753489300301976, "mean_action_processing_ms": 0.06279053927478473, "mean_env_wait_ms": 0.08884322223577851, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019263344652512494, "StateBufferConnector_ms": 0.0015532269197351793, "ViewRequirementAgentConnector_ms": 0.03162745167227352}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000, "num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.83409684179696, "num_env_steps_trained_throughput_per_sec": 102.83409684179696, "timesteps_total": 92000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 184000, "timers": {"training_iteration_time_ms": 38836.24, "sample_time_ms": 7489.612, "learn_time_ms": 31329.295, "learn_throughput": 127.676, "synch_weights_time_ms": 16.827}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 92000, "num_agent_steps_sampled": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 953, "training_iteration": 23, "trial_id": "d67e4_00000", "date": "2023-09-20_22-24-04", "timestamp": 1695263044, "time_this_iter_s": 38.90355324745178, "time_total_s": 892.9706239700317, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fe170>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 892.9706239700317, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 33.5, "ram_util_percent": 48.126785714285724}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06428571428571428, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8357142857142857, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08571428571428572, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8357142857142857, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.08571428571428572, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8357142857142857, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08571428571428572, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.625012708455324, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.015331866681663087, "policy_loss": -0.025371964280930116, "vf_loss": 0.012807950589679725, "vf_explained_var": 0.615869384072721, "kl": 0.0149493749517326, "entropy": 0.848690560584267, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 22560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "sampler_results": {"episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.21199999999999997, "episode_reward_mean": 0.29764285714285715, "episode_len_mean": 27.9, "episode_media": {}, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 1.0125142857142857, "blue_0": -0.7148714285714285}, "custom_metrics": {"red_0/door_open_done_mean": 0.06428571428571428, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8357142857142857, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.08571428571428572, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8357142857142857, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.08571428571428572, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8357142857142857, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.08571428571428572, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.27300000000000013, -0.031000000000000028, -0.05699999999999994, -0.030000000000000027, 1.075, 1.371, -0.06000000000000005, 0.42600000000000016, 0.43800000000000017, 0.41500000000000004, 1.4100000000000001, 0.4630000000000001, 0.4620000000000002, -0.03700000000000003, -0.21199999999999997, 0.45999999999999996, -0.03600000000000003, 0.3600000000000001, 0.41100000000000003, 0.09699999999999998, -0.029000000000000026, -0.05400000000000005, -0.02200000000000002, 1.383, -0.038000000000000034, 0.3730000000000002, 0.927, -0.05699999999999994, -0.018000000000000016, -0.029000000000000026, 0.40600000000000014, -0.029999999999999916, -0.08399999999999996, 0.958, 0.45399999999999996, 0.643, -0.025000000000000022, 0.45500000000000007, 0.46899999999999986, -0.030000000000000027, -0.029999999999999916, -0.03300000000000003, -0.038999999999999924, 0.46099999999999985, 0.4580000000000002, -0.03700000000000003, 0.45699999999999996, -0.03399999999999992, -0.133, 0.44999999999999996, 0.43100000000000005, -0.02200000000000002, 0.397, 0.349, -0.20800000000000016, 0.46099999999999985, 0.43900000000000006, 1.46, 0.397, 0.44700000000000006, 0.44699999999999995, -0.07499999999999996, -0.03200000000000003, -0.050000000000000044, 1.425, 0.475, -0.051000000000000045, 0.44199999999999995, 0.236, -0.02499999999999991, -0.03200000000000003, -0.03200000000000003, 0.45899999999999996, -0.049000000000000044, 0.42799999999999994, 0.44099999999999984, -0.029000000000000026, 0.1379999999999999, 0.4670000000000001, -0.02199999999999991, -0.028000000000000025, -0.05400000000000005, 0.46499999999999986, -0.02100000000000002, 0.46199999999999997, 0.47299999999999986, -0.031000000000000028, 0.4670000000000001, -0.030000000000000027, -0.03700000000000003, -0.06600000000000006, -0.029000000000000026, 0.45100000000000007, -0.030999999999999917, 0.21799999999999997, 0.8759999999999999, -0.04500000000000004, -0.05400000000000005, -0.027000000000000024, -0.031000000000000028, 0.45100000000000007, 1.4609999999999999, -0.031000000000000028, 0.47, 0.403, 0.45500000000000007, -0.06500000000000006, 0.42399999999999993, 0.357, 0.403, -0.049000000000000044, -0.10199999999999998, 0.43199999999999994, 0.7649999999999999, 0.43500000000000005, 0.46599999999999997, 0.9630000000000001, 0.2909999999999999, 0.9649999999999999, 0.3879999999999999, -0.06800000000000006, -0.049000000000000044, 0.4590000000000001, 0.45399999999999996, 0.40700000000000003, 0.46599999999999997, 0.3740000000000001, 0.46599999999999997, -0.02499999999999991, 0.45199999999999996, -0.03200000000000003, -0.03299999999999992, -0.05300000000000005, -0.02400000000000002, -0.03300000000000003, 1.448, 1.2999999999999998, -0.03500000000000003, 0.399, 0.905], "episode_lengths": [71, 10, 17, 10, 133, 42, 20, 23, 19, 27, 29, 12, 12, 12, 60, 13, 12, 44, 28, 126, 9, 175, 7, 37, 12, 39, 22, 18, 6, 9, 30, 9, 26, 13, 15, 109, 8, 14, 10, 10, 9, 10, 12, 12, 13, 12, 14, 10, 39, 16, 22, 7, 31, 46, 300, 13, 18, 13, 31, 17, 300, 23, 10, 16, 23, 8, 16, 19, 82, 8, 10, 10, 13, 16, 23, 19, 9, 114, 11, 7, 9, 17, 11, 7, 12, 9, 10, 11, 10, 12, 21, 9, 15, 10, 88, 38, 14, 17, 9, 10, 16, 13, 10, 9, 31, 14, 21, 25, 44, 30, 16, 27, 21, 73, 20, 11, 12, 65, 11, 36, 22, 15, 13, 14, 29, 10, 40, 11, 8, 15, 10, 10, 16, 8, 10, 16, 63, 11, 30, 31], "policy_red_0_reward": [1.283, 0.97, 0.949, 0.97, 1.0979999999999999, 1.374, 0.94, 1.4300000000000002, 1.442, 1.417, 1.412, 1.464, 1.464, 0.964, 0.7969999999999999, 1.4609999999999999, 0.964, 1.366, 1.415, 1.116, 0.973, 0.968, 0.979, 1.388, 0.964, 1.3820000000000001, 1.432, 0.946, 0.982, 0.973, 1.409, 0.973, 0.922, -0.501, 1.455, 1.158, 0.975, 1.458, 0.97, 0.97, -1.0, 0.97, 0.964, 1.464, 1.46, 0.964, -0.5, 0.969, 0.873, -0.5, 1.4329999999999998, 0.979, 1.403, 1.3599999999999999, -0.17000000000000012, 1.4609999999999999, 0.94, 1.4609999999999999, -0.502, 1.4489999999999998, -0.006, 0.926, 0.97, 0.952, 1.431, -0.5, 0.951, -0.5, 1.25, -1.0, 0.97, 0.97, -0.5, 0.952, 1.4300000000000002, 1.443, 0.973, 1.153, 0.967, -1.0, 0.973, 0.949, 1.467, 0.979, 1.464, 1.4729999999999999, 0.97, 1.467, 0.97, 0.964, 0.9369999999999999, 0.973, 1.454, 0.97, 1.229, 1.379, 0.958, 0.948, 0.973, 0.97, 1.452, 1.4609999999999999, 0.97, 1.4729999999999999, -0.5, 1.458, 0.9369999999999999, 1.425, 1.365, 1.408, 0.952, 0.903, 1.432, 1.278, 1.439, 1.467, 1.464, 1.2999999999999998, 1.467, 1.391, 0.9329999999999999, 0.952, 1.46, 1.458, 1.411, 1.47, 1.379, 1.467, -1.0, 1.454, 0.97, 0.97, 0.95, 0.976, 0.97, 1.452, 1.3079999999999998, 0.967, 1.408, 1.4060000000000001], "policy_blue_0_reward": [-1.01, -1.001, -1.0059999999999998, -1.0, -0.023000000000000013, -0.003, -1.0, -1.004, -1.0039999999999998, -1.002, -0.002, -1.001, -1.0019999999999998, -1.001, -1.009, -1.001, -1.0, -1.0059999999999998, -1.004, -1.019, -1.002, -1.022, -1.001, -0.005, -1.002, -1.009, -0.505, -1.003, -1.0, -1.002, -1.003, -1.003, -1.006, 1.459, -1.001, -0.515, -1.0, -1.003, -0.501, -1.0, 0.97, -1.003, -1.003, -1.003, -1.0019999999999998, -1.001, 0.957, -1.003, -1.006, 0.95, -1.002, -1.001, -1.006, -1.011, -0.03800000000000003, -1.0, -0.501, -0.001, 0.899, -1.002, 0.45299999999999996, -1.001, -1.002, -1.002, -0.006, 0.975, -1.002, 0.942, -1.014, 0.975, -1.002, -1.002, 0.959, -1.001, -1.002, -1.002, -1.002, -1.015, -0.5, 0.978, -1.001, -1.003, -1.002, -1.0, -1.002, -1.0, -1.001, -1.0, -1.0, -1.001, -1.003, -1.002, -1.003, -1.001, -1.011, -0.503, -1.003, -1.002, -1.0, -1.001, -1.001, 0.0, -1.001, -1.003, 0.903, -1.003, -1.002, -1.001, -1.008, -1.005, -1.001, -1.005, -1.0, -0.513, -1.004, -1.001, -0.501, -1.009, -0.502, -1.003, -1.001, -1.001, -1.001, -1.004, -1.004, -1.004, -1.005, -1.001, 0.975, -1.002, -1.002, -1.003, -1.003, -1.0, -1.003, -0.004, -0.008, -1.002, -1.009, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23108107962042085, "mean_inference_ms": 1.4747352257193793, "mean_action_processing_ms": 0.06273925221932862, "mean_env_wait_ms": 0.08880451601191261, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01957169600895473, "StateBufferConnector_ms": 0.001553382192339216, "ViewRequirementAgentConnector_ms": 0.03169187477656773}}, "episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.21199999999999997, "episode_reward_mean": 0.29764285714285715, "episode_len_mean": 27.9, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.459}, "policy_reward_mean": {"red_0": 1.0125142857142857, "blue_0": -0.7148714285714285}, "hist_stats": {"episode_reward": [0.27300000000000013, -0.031000000000000028, -0.05699999999999994, -0.030000000000000027, 1.075, 1.371, -0.06000000000000005, 0.42600000000000016, 0.43800000000000017, 0.41500000000000004, 1.4100000000000001, 0.4630000000000001, 0.4620000000000002, -0.03700000000000003, -0.21199999999999997, 0.45999999999999996, -0.03600000000000003, 0.3600000000000001, 0.41100000000000003, 0.09699999999999998, -0.029000000000000026, -0.05400000000000005, -0.02200000000000002, 1.383, -0.038000000000000034, 0.3730000000000002, 0.927, -0.05699999999999994, -0.018000000000000016, -0.029000000000000026, 0.40600000000000014, -0.029999999999999916, -0.08399999999999996, 0.958, 0.45399999999999996, 0.643, -0.025000000000000022, 0.45500000000000007, 0.46899999999999986, -0.030000000000000027, -0.029999999999999916, -0.03300000000000003, -0.038999999999999924, 0.46099999999999985, 0.4580000000000002, -0.03700000000000003, 0.45699999999999996, -0.03399999999999992, -0.133, 0.44999999999999996, 0.43100000000000005, -0.02200000000000002, 0.397, 0.349, -0.20800000000000016, 0.46099999999999985, 0.43900000000000006, 1.46, 0.397, 0.44700000000000006, 0.44699999999999995, -0.07499999999999996, -0.03200000000000003, -0.050000000000000044, 1.425, 0.475, -0.051000000000000045, 0.44199999999999995, 0.236, -0.02499999999999991, -0.03200000000000003, -0.03200000000000003, 0.45899999999999996, -0.049000000000000044, 0.42799999999999994, 0.44099999999999984, -0.029000000000000026, 0.1379999999999999, 0.4670000000000001, -0.02199999999999991, -0.028000000000000025, -0.05400000000000005, 0.46499999999999986, -0.02100000000000002, 0.46199999999999997, 0.47299999999999986, -0.031000000000000028, 0.4670000000000001, -0.030000000000000027, -0.03700000000000003, -0.06600000000000006, -0.029000000000000026, 0.45100000000000007, -0.030999999999999917, 0.21799999999999997, 0.8759999999999999, -0.04500000000000004, -0.05400000000000005, -0.027000000000000024, -0.031000000000000028, 0.45100000000000007, 1.4609999999999999, -0.031000000000000028, 0.47, 0.403, 0.45500000000000007, -0.06500000000000006, 0.42399999999999993, 0.357, 0.403, -0.049000000000000044, -0.10199999999999998, 0.43199999999999994, 0.7649999999999999, 0.43500000000000005, 0.46599999999999997, 0.9630000000000001, 0.2909999999999999, 0.9649999999999999, 0.3879999999999999, -0.06800000000000006, -0.049000000000000044, 0.4590000000000001, 0.45399999999999996, 0.40700000000000003, 0.46599999999999997, 0.3740000000000001, 0.46599999999999997, -0.02499999999999991, 0.45199999999999996, -0.03200000000000003, -0.03299999999999992, -0.05300000000000005, -0.02400000000000002, -0.03300000000000003, 1.448, 1.2999999999999998, -0.03500000000000003, 0.399, 0.905], "episode_lengths": [71, 10, 17, 10, 133, 42, 20, 23, 19, 27, 29, 12, 12, 12, 60, 13, 12, 44, 28, 126, 9, 175, 7, 37, 12, 39, 22, 18, 6, 9, 30, 9, 26, 13, 15, 109, 8, 14, 10, 10, 9, 10, 12, 12, 13, 12, 14, 10, 39, 16, 22, 7, 31, 46, 300, 13, 18, 13, 31, 17, 300, 23, 10, 16, 23, 8, 16, 19, 82, 8, 10, 10, 13, 16, 23, 19, 9, 114, 11, 7, 9, 17, 11, 7, 12, 9, 10, 11, 10, 12, 21, 9, 15, 10, 88, 38, 14, 17, 9, 10, 16, 13, 10, 9, 31, 14, 21, 25, 44, 30, 16, 27, 21, 73, 20, 11, 12, 65, 11, 36, 22, 15, 13, 14, 29, 10, 40, 11, 8, 15, 10, 10, 16, 8, 10, 16, 63, 11, 30, 31], "policy_red_0_reward": [1.283, 0.97, 0.949, 0.97, 1.0979999999999999, 1.374, 0.94, 1.4300000000000002, 1.442, 1.417, 1.412, 1.464, 1.464, 0.964, 0.7969999999999999, 1.4609999999999999, 0.964, 1.366, 1.415, 1.116, 0.973, 0.968, 0.979, 1.388, 0.964, 1.3820000000000001, 1.432, 0.946, 0.982, 0.973, 1.409, 0.973, 0.922, -0.501, 1.455, 1.158, 0.975, 1.458, 0.97, 0.97, -1.0, 0.97, 0.964, 1.464, 1.46, 0.964, -0.5, 0.969, 0.873, -0.5, 1.4329999999999998, 0.979, 1.403, 1.3599999999999999, -0.17000000000000012, 1.4609999999999999, 0.94, 1.4609999999999999, -0.502, 1.4489999999999998, -0.006, 0.926, 0.97, 0.952, 1.431, -0.5, 0.951, -0.5, 1.25, -1.0, 0.97, 0.97, -0.5, 0.952, 1.4300000000000002, 1.443, 0.973, 1.153, 0.967, -1.0, 0.973, 0.949, 1.467, 0.979, 1.464, 1.4729999999999999, 0.97, 1.467, 0.97, 0.964, 0.9369999999999999, 0.973, 1.454, 0.97, 1.229, 1.379, 0.958, 0.948, 0.973, 0.97, 1.452, 1.4609999999999999, 0.97, 1.4729999999999999, -0.5, 1.458, 0.9369999999999999, 1.425, 1.365, 1.408, 0.952, 0.903, 1.432, 1.278, 1.439, 1.467, 1.464, 1.2999999999999998, 1.467, 1.391, 0.9329999999999999, 0.952, 1.46, 1.458, 1.411, 1.47, 1.379, 1.467, -1.0, 1.454, 0.97, 0.97, 0.95, 0.976, 0.97, 1.452, 1.3079999999999998, 0.967, 1.408, 1.4060000000000001], "policy_blue_0_reward": [-1.01, -1.001, -1.0059999999999998, -1.0, -0.023000000000000013, -0.003, -1.0, -1.004, -1.0039999999999998, -1.002, -0.002, -1.001, -1.0019999999999998, -1.001, -1.009, -1.001, -1.0, -1.0059999999999998, -1.004, -1.019, -1.002, -1.022, -1.001, -0.005, -1.002, -1.009, -0.505, -1.003, -1.0, -1.002, -1.003, -1.003, -1.006, 1.459, -1.001, -0.515, -1.0, -1.003, -0.501, -1.0, 0.97, -1.003, -1.003, -1.003, -1.0019999999999998, -1.001, 0.957, -1.003, -1.006, 0.95, -1.002, -1.001, -1.006, -1.011, -0.03800000000000003, -1.0, -0.501, -0.001, 0.899, -1.002, 0.45299999999999996, -1.001, -1.002, -1.002, -0.006, 0.975, -1.002, 0.942, -1.014, 0.975, -1.002, -1.002, 0.959, -1.001, -1.002, -1.002, -1.002, -1.015, -0.5, 0.978, -1.001, -1.003, -1.002, -1.0, -1.002, -1.0, -1.001, -1.0, -1.0, -1.001, -1.003, -1.002, -1.003, -1.001, -1.011, -0.503, -1.003, -1.002, -1.0, -1.001, -1.001, 0.0, -1.001, -1.003, 0.903, -1.003, -1.002, -1.001, -1.008, -1.005, -1.001, -1.005, -1.0, -0.513, -1.004, -1.001, -0.501, -1.009, -0.502, -1.003, -1.001, -1.001, -1.001, -1.004, -1.004, -1.004, -1.005, -1.001, 0.975, -1.002, -1.002, -1.003, -1.003, -1.0, -1.003, -0.004, -0.008, -1.002, -1.009, -0.501]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23108107962042085, "mean_inference_ms": 1.4747352257193793, "mean_action_processing_ms": 0.06273925221932862, "mean_env_wait_ms": 0.08880451601191261, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01957169600895473, "StateBufferConnector_ms": 0.001553382192339216, "ViewRequirementAgentConnector_ms": 0.03169187477656773}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000, "num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.05353578535716, "num_env_steps_trained_throughput_per_sec": 103.05353578535716, "timesteps_total": 96000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 192000, "timers": {"training_iteration_time_ms": 38841.717, "sample_time_ms": 7496.465, "learn_time_ms": 31327.939, "learn_throughput": 127.682, "synch_weights_time_ms": 16.809}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 96000, "num_agent_steps_sampled": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 1093, "training_iteration": 24, "trial_id": "d67e4_00000", "date": "2023-09-20_22-24-43", "timestamp": 1695263083, "time_this_iter_s": 38.82076621055603, "time_total_s": 931.7913901805878, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687bc70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 931.7913901805878, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 34.63999999999999, "ram_util_percent": 48.11090909090908}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0759493670886076, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8924050632911392, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0189873417721519, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8924050632911392, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0189873417721519, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8924050632911392, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0189873417721519, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7539355903243026, "cur_kl_coeff": 0.29999999999999993, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01866140552131886, "policy_loss": -0.029113853677214745, "vf_loss": 0.009962990454368992, "vf_explained_var": 0.7227403823907177, "kl": 0.020684614814767126, "entropy": 0.7344314785053333, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 23520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "sampler_results": {"episode_reward_max": 1.9329999999999998, "episode_reward_min": -0.7270000000000001, "episode_reward_mean": 0.3102025316455696, "episode_len_mean": 26.449367088607595, "episode_media": {}, "episodes_this_iter": 158, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.979}, "policy_reward_mean": {"red_0": 1.1529050632911393, "blue_0": -0.8427025316455695}, "custom_metrics": {"red_0/door_open_done_mean": 0.0759493670886076, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8924050632911392, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0189873417721519, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8924050632911392, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0189873417721519, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8924050632911392, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0189873417721519, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.027000000000000024, 0.45199999999999996, 0.45100000000000007, 0.8839999999999999, -0.027999999999999914, -0.03700000000000003, 0.46499999999999986, 0.47299999999999986, -0.03600000000000003, 0.4750000000000001, 0.472, 1.9329999999999998, -0.03500000000000003, -0.07099999999999995, -0.038000000000000034, 0.4590000000000001, 0.46799999999999997, -0.04700000000000004, 0.4670000000000001, -0.027000000000000024, 0.4630000000000001, -0.031000000000000028, 0.30000000000000004, 0.46799999999999997, -0.02100000000000002, 0.45099999999999996, 0.44999999999999996, -0.03300000000000003, 0.45399999999999996, 0.4590000000000001, 0.31999999999999984, -0.028000000000000025, 0.45299999999999985, -0.028000000000000025, -0.04500000000000004, -0.05899999999999994, -0.041999999999999926, 0.46199999999999997, -0.02100000000000002, 1.452, 0.44499999999999984, 0.46899999999999986, 0.46799999999999997, 0.45299999999999985, 0.43799999999999994, 0.45799999999999996, 0.45199999999999996, -0.027000000000000024, 0.46099999999999985, 0.397, 0.46499999999999986, 0.42200000000000015, 0.2829999999999999, 0.44899999999999984, 0.4630000000000001, -0.027000000000000024, -0.031000000000000028, -0.031000000000000028, 0.403, -0.03400000000000003, 0.4750000000000001, 0.2849999999999999, 0.46199999999999997, 0.46099999999999985, 0.4690000000000001, 0.45699999999999985, -0.04700000000000004, -0.04200000000000004, 0.4289999999999998, -0.10899999999999999, -0.06900000000000006, -0.07600000000000007, 0.45999999999999996, 0.43399999999999994, -0.03400000000000003, 0.43699999999999983, -0.08299999999999996, 0.34399999999999986, 0.9790000000000001, -0.03399999999999992, -0.09199999999999997, -0.04400000000000004, 0.44899999999999984, 0.44700000000000006, 0.46599999999999997, 0.46899999999999986, -0.02499999999999991, -0.122, -0.062000000000000055, -0.03200000000000003, -0.030000000000000027, 0.476, 0.46799999999999997, 0.3919999999999999, 0.847, -0.03300000000000003, 0.44399999999999995, 0.45799999999999996, 0.3860000000000001, 1.403, -0.05500000000000005, -0.04200000000000003, 0.46499999999999986, -0.029000000000000026, -0.264, 1.448, 0.349, -0.02100000000000002, 0.46199999999999997, 0.351, 0.47299999999999986, -0.028000000000000025, -0.05600000000000005, -0.03300000000000003, -0.09399999999999997, -0.07099999999999995, -0.08399999999999985, 0.44199999999999995, 0.28200000000000003, 0.774, -0.02100000000000002, 0.46399999999999997, -0.41400000000000003, -0.03300000000000003, 0.45999999999999996, 1.3239999999999998, 1.0779999999999998, -0.05700000000000005, -0.05600000000000005, -0.02100000000000002, 0.43100000000000005, 0.41800000000000015, -0.06499999999999995, 1.33, -0.03500000000000003, -0.030999999999999917, 1.4249999999999998, 0.45399999999999996, -0.03400000000000003, -0.03300000000000003, 1.44, 0.9649999999999999, 0.4460000000000002, -0.7270000000000001, 0.4159999999999999, 0.944, -0.03700000000000003, 1.456, -0.09399999999999986, 0.353, -0.03500000000000003, 0.40600000000000014, 0.45799999999999996, 0.45599999999999996, -0.04600000000000004, 1.447, -0.028000000000000025, 0.42300000000000004], "episode_lengths": [9, 15, 16, 37, 9, 12, 11, 9, 12, 8, 9, 21, 11, 22, 12, 13, 10, 14, 11, 9, 11, 10, 62, 10, 7, 300, 16, 11, 14, 13, 56, 9, 15, 9, 15, 18, 13, 12, 7, 15, 17, 10, 10, 15, 20, 13, 15, 9, 13, 32, 11, 25, 69, 16, 12, 8, 10, 10, 30, 11, 8, 67, 12, 13, 10, 14, 15, 13, 22, 34, 22, 22, 12, 22, 11, 20, 27, 45, 7, 11, 29, 14, 16, 17, 11, 10, 8, 38, 20, 10, 10, 8, 10, 33, 47, 11, 18, 13, 36, 30, 18, 300, 11, 9, 84, 17, 47, 7, 12, 47, 9, 9, 17, 11, 27, 23, 27, 19, 68, 226, 7, 12, 129, 11, 13, 55, 130, 18, 17, 7, 22, 26, 20, 53, 11, 9, 24, 15, 11, 11, 20, 11, 17, 219, 26, 18, 12, 14, 29, 46, 11, 30, 14, 13, 14, 17, 9, 25], "policy_red_0_reward": [0.973, 1.454, 1.452, 1.388, 0.973, 0.964, 1.467, 1.4729999999999999, 0.964, 0.976, 1.4729999999999999, 1.4369999999999998, 0.967, 0.9329999999999999, 0.964, 1.4609999999999999, 1.47, 0.957, 1.467, 0.973, 1.467, 0.97, 1.31, 1.47, 0.979, 0.499, 1.452, 0.967, 1.458, 1.4609999999999999, 1.3279999999999998, 0.973, 1.455, 0.973, 0.955, 0.942, 0.961, 1.464, 0.979, 1.455, 1.4489999999999998, 1.47, 1.47, 1.455, 1.44, 1.46, 1.454, 0.973, 1.4609999999999999, 1.403, 1.467, 1.424, 1.293, 1.452, 1.464, 0.976, 0.97, 0.97, 1.409, 0.967, 1.476, 1.295, 1.464, 1.4609999999999999, 1.47, 1.458, 0.955, 0.961, 1.4329999999999998, 0.896, 0.9329999999999999, 0.9279999999999999, 1.464, 1.434, 0.967, 1.439, 0.918, 0.847, 1.479, 0.967, 0.913, 0.958, 1.452, 1.4489999999999998, 1.467, 1.47, -1.0, 0.885, 0.94, 0.97, 0.97, 1.476, 0.97, 1.4, 1.3559999999999999, 0.967, 1.4449999999999998, 1.4609999999999999, 1.392, 1.408, 0.946, -0.001, 1.4649999999999999, 0.973, 0.747, 1.4489999999999998, 1.3559999999999999, -1.0, 1.464, 1.355, 1.4729999999999999, 0.973, 0.948, 0.967, 0.907, 0.931, 0.919, 0.942, 1.291, 0.799, -1.0, 1.464, 0.613, 0.967, 1.4609999999999999, 1.334, 1.103, 0.946, 0.949, 0.979, 1.434, 1.4220000000000002, 0.939, 1.337, 0.967, 0.973, 1.428, 1.454, 0.967, 0.967, 1.44, 1.467, 1.4489999999999998, 0.31299999999999994, 1.4220000000000002, 1.446, 0.964, 1.458, 0.909, 1.359, 0.967, 0.909, 1.458, 1.4609999999999999, 0.958, 1.4489999999999998, 0.973, 1.424], "policy_blue_0_reward": [-1.0, -1.002, -1.001, -0.504, -1.001, -1.001, -1.002, -1.0, -1.0, -0.5009999999999999, -1.001, 0.496, -1.002, -1.0039999999999998, -1.002, -1.002, -1.002, -1.004, -1.0, -1.0, -1.0039999999999998, -1.001, -1.01, -1.0019999999999998, -1.0, -0.048000000000000036, -1.002, -1.0, -1.004, -1.002, -1.008, -1.001, -1.002, -1.001, -1.0, -1.001, -1.003, -1.002, -1.0, -0.003, -1.004, -1.001, -1.002, -1.002, -1.002, -1.002, -1.002, -1.0, -1.0, -1.006, -1.002, -1.002, -1.01, -1.003, -1.001, -1.003, -1.001, -1.001, -1.006, -1.001, -1.001, -1.01, -1.002, -1.0, -1.001, -1.001, -1.002, -1.003, -1.004, -1.005, -1.002, -1.004, -1.004, -1.0, -1.001, -1.002, -1.001, -0.503, -0.5, -1.001, -1.005, -1.002, -1.003, -1.002, -1.001, -1.001, 0.975, -1.007, -1.002, -1.002, -1.0, -1.0, -0.502, -1.008, -0.509, -1.0, -1.001, -1.003, -1.006, -0.005, -1.001, -0.04100000000000003, -1.0, -1.002, -1.011, -0.001, -1.007, 0.979, -1.002, -1.004, -1.0, -1.001, -1.004, -1.0, -1.001, -1.002, -1.003, -0.5, -1.009, -0.025000000000000015, 0.979, -1.0, -1.027, -1.0, -1.001, -0.010000000000000002, -0.025000000000000015, -1.003, -1.005, -1.0, -1.003, -1.004, -1.0039999999999998, -0.007, -1.002, -1.0039999999999998, -0.003, -1.0, -1.001, -1.0, 0.0, -0.502, -1.003, -1.04, -1.006, -0.5019999999999999, -1.001, -0.002, -1.003, -1.006, -1.002, -0.503, -1.0, -1.005, -1.004, -0.002, -1.001, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23199477815222053, "mean_inference_ms": 1.4752286340521867, "mean_action_processing_ms": 0.06289331227917308, "mean_env_wait_ms": 0.08893845752543314, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019347516796256924, "StateBufferConnector_ms": 0.0015679039532625224, "ViewRequirementAgentConnector_ms": 0.031550775600385064}}, "episode_reward_max": 1.9329999999999998, "episode_reward_min": -0.7270000000000001, "episode_reward_mean": 0.3102025316455696, "episode_len_mean": 26.449367088607595, "episodes_this_iter": 158, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.04}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.979}, "policy_reward_mean": {"red_0": 1.1529050632911393, "blue_0": -0.8427025316455695}, "hist_stats": {"episode_reward": [-0.027000000000000024, 0.45199999999999996, 0.45100000000000007, 0.8839999999999999, -0.027999999999999914, -0.03700000000000003, 0.46499999999999986, 0.47299999999999986, -0.03600000000000003, 0.4750000000000001, 0.472, 1.9329999999999998, -0.03500000000000003, -0.07099999999999995, -0.038000000000000034, 0.4590000000000001, 0.46799999999999997, -0.04700000000000004, 0.4670000000000001, -0.027000000000000024, 0.4630000000000001, -0.031000000000000028, 0.30000000000000004, 0.46799999999999997, -0.02100000000000002, 0.45099999999999996, 0.44999999999999996, -0.03300000000000003, 0.45399999999999996, 0.4590000000000001, 0.31999999999999984, -0.028000000000000025, 0.45299999999999985, -0.028000000000000025, -0.04500000000000004, -0.05899999999999994, -0.041999999999999926, 0.46199999999999997, -0.02100000000000002, 1.452, 0.44499999999999984, 0.46899999999999986, 0.46799999999999997, 0.45299999999999985, 0.43799999999999994, 0.45799999999999996, 0.45199999999999996, -0.027000000000000024, 0.46099999999999985, 0.397, 0.46499999999999986, 0.42200000000000015, 0.2829999999999999, 0.44899999999999984, 0.4630000000000001, -0.027000000000000024, -0.031000000000000028, -0.031000000000000028, 0.403, -0.03400000000000003, 0.4750000000000001, 0.2849999999999999, 0.46199999999999997, 0.46099999999999985, 0.4690000000000001, 0.45699999999999985, -0.04700000000000004, -0.04200000000000004, 0.4289999999999998, -0.10899999999999999, -0.06900000000000006, -0.07600000000000007, 0.45999999999999996, 0.43399999999999994, -0.03400000000000003, 0.43699999999999983, -0.08299999999999996, 0.34399999999999986, 0.9790000000000001, -0.03399999999999992, -0.09199999999999997, -0.04400000000000004, 0.44899999999999984, 0.44700000000000006, 0.46599999999999997, 0.46899999999999986, -0.02499999999999991, -0.122, -0.062000000000000055, -0.03200000000000003, -0.030000000000000027, 0.476, 0.46799999999999997, 0.3919999999999999, 0.847, -0.03300000000000003, 0.44399999999999995, 0.45799999999999996, 0.3860000000000001, 1.403, -0.05500000000000005, -0.04200000000000003, 0.46499999999999986, -0.029000000000000026, -0.264, 1.448, 0.349, -0.02100000000000002, 0.46199999999999997, 0.351, 0.47299999999999986, -0.028000000000000025, -0.05600000000000005, -0.03300000000000003, -0.09399999999999997, -0.07099999999999995, -0.08399999999999985, 0.44199999999999995, 0.28200000000000003, 0.774, -0.02100000000000002, 0.46399999999999997, -0.41400000000000003, -0.03300000000000003, 0.45999999999999996, 1.3239999999999998, 1.0779999999999998, -0.05700000000000005, -0.05600000000000005, -0.02100000000000002, 0.43100000000000005, 0.41800000000000015, -0.06499999999999995, 1.33, -0.03500000000000003, -0.030999999999999917, 1.4249999999999998, 0.45399999999999996, -0.03400000000000003, -0.03300000000000003, 1.44, 0.9649999999999999, 0.4460000000000002, -0.7270000000000001, 0.4159999999999999, 0.944, -0.03700000000000003, 1.456, -0.09399999999999986, 0.353, -0.03500000000000003, 0.40600000000000014, 0.45799999999999996, 0.45599999999999996, -0.04600000000000004, 1.447, -0.028000000000000025, 0.42300000000000004], "episode_lengths": [9, 15, 16, 37, 9, 12, 11, 9, 12, 8, 9, 21, 11, 22, 12, 13, 10, 14, 11, 9, 11, 10, 62, 10, 7, 300, 16, 11, 14, 13, 56, 9, 15, 9, 15, 18, 13, 12, 7, 15, 17, 10, 10, 15, 20, 13, 15, 9, 13, 32, 11, 25, 69, 16, 12, 8, 10, 10, 30, 11, 8, 67, 12, 13, 10, 14, 15, 13, 22, 34, 22, 22, 12, 22, 11, 20, 27, 45, 7, 11, 29, 14, 16, 17, 11, 10, 8, 38, 20, 10, 10, 8, 10, 33, 47, 11, 18, 13, 36, 30, 18, 300, 11, 9, 84, 17, 47, 7, 12, 47, 9, 9, 17, 11, 27, 23, 27, 19, 68, 226, 7, 12, 129, 11, 13, 55, 130, 18, 17, 7, 22, 26, 20, 53, 11, 9, 24, 15, 11, 11, 20, 11, 17, 219, 26, 18, 12, 14, 29, 46, 11, 30, 14, 13, 14, 17, 9, 25], "policy_red_0_reward": [0.973, 1.454, 1.452, 1.388, 0.973, 0.964, 1.467, 1.4729999999999999, 0.964, 0.976, 1.4729999999999999, 1.4369999999999998, 0.967, 0.9329999999999999, 0.964, 1.4609999999999999, 1.47, 0.957, 1.467, 0.973, 1.467, 0.97, 1.31, 1.47, 0.979, 0.499, 1.452, 0.967, 1.458, 1.4609999999999999, 1.3279999999999998, 0.973, 1.455, 0.973, 0.955, 0.942, 0.961, 1.464, 0.979, 1.455, 1.4489999999999998, 1.47, 1.47, 1.455, 1.44, 1.46, 1.454, 0.973, 1.4609999999999999, 1.403, 1.467, 1.424, 1.293, 1.452, 1.464, 0.976, 0.97, 0.97, 1.409, 0.967, 1.476, 1.295, 1.464, 1.4609999999999999, 1.47, 1.458, 0.955, 0.961, 1.4329999999999998, 0.896, 0.9329999999999999, 0.9279999999999999, 1.464, 1.434, 0.967, 1.439, 0.918, 0.847, 1.479, 0.967, 0.913, 0.958, 1.452, 1.4489999999999998, 1.467, 1.47, -1.0, 0.885, 0.94, 0.97, 0.97, 1.476, 0.97, 1.4, 1.3559999999999999, 0.967, 1.4449999999999998, 1.4609999999999999, 1.392, 1.408, 0.946, -0.001, 1.4649999999999999, 0.973, 0.747, 1.4489999999999998, 1.3559999999999999, -1.0, 1.464, 1.355, 1.4729999999999999, 0.973, 0.948, 0.967, 0.907, 0.931, 0.919, 0.942, 1.291, 0.799, -1.0, 1.464, 0.613, 0.967, 1.4609999999999999, 1.334, 1.103, 0.946, 0.949, 0.979, 1.434, 1.4220000000000002, 0.939, 1.337, 0.967, 0.973, 1.428, 1.454, 0.967, 0.967, 1.44, 1.467, 1.4489999999999998, 0.31299999999999994, 1.4220000000000002, 1.446, 0.964, 1.458, 0.909, 1.359, 0.967, 0.909, 1.458, 1.4609999999999999, 0.958, 1.4489999999999998, 0.973, 1.424], "policy_blue_0_reward": [-1.0, -1.002, -1.001, -0.504, -1.001, -1.001, -1.002, -1.0, -1.0, -0.5009999999999999, -1.001, 0.496, -1.002, -1.0039999999999998, -1.002, -1.002, -1.002, -1.004, -1.0, -1.0, -1.0039999999999998, -1.001, -1.01, -1.0019999999999998, -1.0, -0.048000000000000036, -1.002, -1.0, -1.004, -1.002, -1.008, -1.001, -1.002, -1.001, -1.0, -1.001, -1.003, -1.002, -1.0, -0.003, -1.004, -1.001, -1.002, -1.002, -1.002, -1.002, -1.002, -1.0, -1.0, -1.006, -1.002, -1.002, -1.01, -1.003, -1.001, -1.003, -1.001, -1.001, -1.006, -1.001, -1.001, -1.01, -1.002, -1.0, -1.001, -1.001, -1.002, -1.003, -1.004, -1.005, -1.002, -1.004, -1.004, -1.0, -1.001, -1.002, -1.001, -0.503, -0.5, -1.001, -1.005, -1.002, -1.003, -1.002, -1.001, -1.001, 0.975, -1.007, -1.002, -1.002, -1.0, -1.0, -0.502, -1.008, -0.509, -1.0, -1.001, -1.003, -1.006, -0.005, -1.001, -0.04100000000000003, -1.0, -1.002, -1.011, -0.001, -1.007, 0.979, -1.002, -1.004, -1.0, -1.001, -1.004, -1.0, -1.001, -1.002, -1.003, -0.5, -1.009, -0.025000000000000015, 0.979, -1.0, -1.027, -1.0, -1.001, -0.010000000000000002, -0.025000000000000015, -1.003, -1.005, -1.0, -1.003, -1.004, -1.0039999999999998, -0.007, -1.002, -1.0039999999999998, -0.003, -1.0, -1.001, -1.0, 0.0, -0.502, -1.003, -1.04, -1.006, -0.5019999999999999, -1.001, -0.002, -1.003, -1.006, -1.002, -0.503, -1.0, -1.005, -1.004, -0.002, -1.001, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23199477815222053, "mean_inference_ms": 1.4752286340521867, "mean_action_processing_ms": 0.06289331227917308, "mean_env_wait_ms": 0.08893845752543314, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019347516796256924, "StateBufferConnector_ms": 0.0015679039532625224, "ViewRequirementAgentConnector_ms": 0.031550775600385064}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000, "num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.73132230893539, "num_env_steps_trained_throughput_per_sec": 102.73132230893539, "timesteps_total": 100000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 200000, "timers": {"training_iteration_time_ms": 38843.112, "sample_time_ms": 7500.306, "learn_time_ms": 31325.485, "learn_throughput": 127.692, "synch_weights_time_ms": 16.824}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 100000, "num_agent_steps_sampled": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 1251, "training_iteration": 25, "trial_id": "d67e4_00000", "date": "2023-09-20_22-25-22", "timestamp": 1695263122, "time_this_iter_s": 38.94326090812683, "time_total_s": 970.7346510887146, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46ff520>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 970.7346510887146, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 33.982142857142854, "ram_util_percent": 48.17321428571428}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06790123456790123, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9012345679012346, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.024691358024691357, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9012345679012346, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.024691358024691357, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9012345679012346, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.024691358024691357, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7446537969633937, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01543420633097412, "policy_loss": -0.02598961570984102, "vf_loss": 0.010538285297419256, "vf_explained_var": 0.6894145452106992, "kl": 0.013262377071668356, "entropy": 0.6818033673179646, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 24480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "sampler_results": {"episode_reward_max": 1.889, "episode_reward_min": -0.18900000000000006, "episode_reward_mean": 0.31605555555555553, "episode_len_mean": 23.74074074074074, "episode_media": {}, "episodes_this_iter": 162, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.035}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.978}, "policy_reward_mean": {"red_0": 1.169148148148148, "blue_0": -0.8530925925925927}, "custom_metrics": {"red_0/door_open_done_mean": 0.06790123456790123, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9012345679012346, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.024691358024691357, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9012345679012346, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.024691358024691357, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9012345679012346, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.024691358024691357, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.359, 0.30500000000000016, 0.45599999999999996, 0.363, 0.46799999999999997, 0.46599999999999997, 0.45799999999999996, 0.41300000000000026, -0.04500000000000004, -0.040000000000000036, -0.10499999999999998, -0.029000000000000026, 0.44799999999999995, -0.028000000000000025, -0.03400000000000003, 0.45799999999999996, -0.03400000000000003, -0.027000000000000024, 0.46599999999999997, 0.45999999999999996, -0.041000000000000036, 0.44199999999999995, 0.41100000000000003, 0.46899999999999986, 0.46199999999999997, -0.05800000000000005, -0.040000000000000036, 0.40000000000000013, 0.2469999999999999, -0.02299999999999991, -0.03600000000000003, 0.43999999999999995, 0.4610000000000001, 1.3439999999999999, -0.03300000000000003, -0.06000000000000005, -0.04300000000000004, -0.03300000000000003, -0.03300000000000003, -0.028000000000000025, -0.03400000000000003, -0.15999999999999992, -0.025000000000000022, -0.07599999999999996, -0.028000000000000025, 0.8919999999999999, 0.45399999999999996, 0.45300000000000007, 0.44599999999999995, -0.030000000000000027, -0.027999999999999914, -0.11499999999999999, 0.46899999999999986, 0.4650000000000001, 1.436, 1.409, 0.4249999999999998, 0.4660000000000002, 1.4180000000000001, -0.02199999999999991, 0.46199999999999997, 0.4670000000000001, 0.41100000000000003, 0.44799999999999995, 0.40600000000000014, 0.399, -0.03200000000000003, 0.4630000000000001, -0.03199999999999992, 0.45699999999999985, 0.46499999999999986, -0.05500000000000005, -0.04800000000000004, -0.03500000000000003, -0.1090000000000001, -0.02400000000000002, 1.889, 0.9299999999999999, 0.44799999999999995, 0.41800000000000015, 0.44799999999999995, -0.031000000000000028, -0.04800000000000004, 0.43500000000000005, 0.46299999999999997, -0.03400000000000003, 1.431, -0.038000000000000034, 0.46499999999999986, 0.4590000000000001, -0.029999999999999916, 0.40600000000000014, -0.04800000000000004, 0.45699999999999985, 0.45500000000000007, -0.029999999999999916, 0.47, 0.43900000000000006, 0.46599999999999997, -0.02100000000000002, 0.43399999999999994, 0.45199999999999996, -0.03500000000000003, 0.45299999999999985, 0.45799999999999996, 0.44499999999999984, 0.39300000000000024, 0.30600000000000005, 0.46399999999999997, -0.02200000000000002, -0.04800000000000004, 0.44799999999999995, 0.3919999999999999, 1.1949999999999998, 1.446, -0.028000000000000025, 0.44799999999999995, 0.44799999999999995, -0.030000000000000027, 0.46399999999999997, -0.02200000000000002, 1.3679999999999999, 0.3999999999999999, -0.18900000000000006, 0.45299999999999985, -0.03600000000000003, -0.03700000000000003, -0.05899999999999994, 0.28600000000000003, 0.41800000000000015, 0.3460000000000001, 0.45500000000000007, -0.03499999999999992, 0.41700000000000004, 0.367, -0.051000000000000045, 0.472, 0.46599999999999997, 0.41800000000000015, 0.7429999999999999, 0.44099999999999984, 0.45799999999999996, 1.454, 0.4630000000000001, -0.04500000000000004, -0.04399999999999993, -0.09699999999999998, 0.41000000000000014, 0.42999999999999994, 0.45799999999999996, -0.02400000000000002, -0.03200000000000003, -0.039999999999999925, -0.04400000000000004, -0.16100000000000003, 0.46499999999999986, 1.438, 0.45299999999999985, -0.040000000000000036, 0.381, -0.126, 0.4570000000000001], "episode_lengths": [44, 62, 14, 43, 10, 11, 13, 27, 14, 13, 33, 9, 16, 9, 11, 300, 11, 9, 11, 13, 13, 18, 29, 10, 12, 19, 13, 32, 78, 7, 11, 19, 11, 51, 11, 19, 13, 10, 10, 9, 11, 51, 8, 23, 9, 33, 15, 14, 17, 10, 8, 37, 10, 11, 21, 29, 24, 11, 27, 7, 12, 11, 29, 16, 29, 31, 10, 12, 10, 14, 11, 18, 15, 11, 188, 8, 35, 22, 17, 25, 16, 10, 15, 21, 12, 11, 22, 12, 11, 13, 9, 30, 15, 14, 14, 9, 10, 19, 11, 7, 21, 15, 11, 15, 13, 17, 33, 59, 11, 7, 15, 16, 34, 96, 17, 9, 17, 16, 10, 12, 7, 42, 32, 61, 15, 11, 12, 19, 227, 26, 48, 14, 11, 25, 41, 16, 9, 11, 26, 83, 17, 13, 15, 12, 14, 14, 31, 29, 22, 13, 8, 10, 13, 13, 49, 11, 20, 15, 12, 34, 39, 13], "policy_red_0_reward": [1.366, 1.3130000000000002, 1.458, 1.369, 1.47, 1.467, 1.46, 1.419, 0.958, 0.961, 0.898, 0.972, 1.451, 0.973, 0.967, 0.0, 0.967, 0.973, 1.467, 1.4609999999999999, 0.96, 1.446, 1.413, 1.47, 1.464, 0.943, 0.961, 1.404, 1.26, 0.979, 0.967, 1.443, 1.467, 1.347, 0.967, 0.943, 0.961, 0.97, 0.97, 0.973, 0.967, 0.847, 0.976, 0.929, 0.973, 1.4, 1.455, 1.458, 0.948, 0.97, 0.975, 0.889, 1.47, 1.467, 1.4369999999999998, 1.412, 1.427, 1.467, 1.419, -1.0, 1.464, 1.467, 1.412, 1.452, 1.413, 1.407, 0.97, 1.464, 0.97, 1.458, 1.467, 0.945, 0.955, 0.967, 0.9259999999999999, 0.976, 1.3940000000000001, 1.4329999999999998, 1.4489999999999998, 1.424, 1.452, 0.97, 0.955, 1.4369999999999998, -0.5, 0.967, 1.434, 0.964, 1.467, 1.4609999999999999, 0.973, 0.91, 0.955, 1.458, 1.458, 0.972, 1.47, 1.443, -0.5, 0.979, 1.4369999999999998, 1.454, 0.967, 1.4529999999999998, 1.4609999999999999, 0.949, 1.4, 1.323, 1.467, 0.979, 0.954, 1.452, 1.3980000000000001, 1.21, 1.4489999999999998, 0.973, 1.4489999999999998, 1.452, 0.97, 1.464, 0.979, 1.374, 1.404, 0.817, 1.454, 0.967, 0.964, 0.943, 0.817, 1.421, 1.3519999999999999, 1.458, 0.966, 1.424, 1.373, 0.952, 1.4729999999999999, 1.467, 1.4220000000000002, 1.251, 1.448, 1.4609999999999999, 1.455, 1.464, 0.957, 0.958, 0.907, 1.413, 1.4329999999999998, 1.4609999999999999, 0.976, 0.97, -1.0, 0.961, 0.846, 1.467, 1.439, 1.454, 0.96, 1.389, 0.881, 1.4609999999999999], "policy_blue_0_reward": [-1.007, -1.008, -1.002, -1.006, -1.002, -1.001, -1.002, -1.0059999999999998, -1.003, -1.001, -1.003, -1.001, -1.003, -1.001, -1.001, 0.45799999999999996, -1.001, -1.0, -1.001, -1.001, -1.001, -1.004, -1.002, -1.001, -1.002, -1.001, -1.001, -1.0039999999999998, -1.013, -1.0019999999999998, -1.003, -1.003, -1.0059999999999998, -0.003, -1.0, -1.003, -1.004, -1.003, -1.003, -1.001, -1.001, -1.007, -1.001, -1.005, -1.001, -0.508, -1.001, -1.005, -0.502, -1.0, -1.003, -1.004, -1.001, -1.0019999999999998, -0.001, -0.003, -1.002, -1.001, -0.001, 0.978, -1.002, -1.0, -1.001, -1.004, -1.007, -1.008, -1.002, -1.001, -1.0019999999999998, -1.001, -1.002, -1.0, -1.003, -1.002, -1.035, -1.0, 0.495, -0.503, -1.001, -1.0059999999999998, -1.004, -1.001, -1.003, -1.002, 0.963, -1.001, -0.003, -1.002, -1.002, -1.002, -1.003, -0.504, -1.003, -1.001, -1.003, -1.0019999999999998, -1.0, -1.004, 0.966, -1.0, -1.003, -1.002, -1.002, -1.0, -1.003, -0.504, -1.007, -1.017, -1.003, -1.001, -1.002, -1.004, -1.006, -0.015000000000000006, -0.003, -1.001, -1.001, -1.0039999999999998, -1.0, -1.0, -1.001, -0.006, -1.004, -1.006, -1.001, -1.003, -1.001, -1.0019999999999998, -0.531, -1.003, -1.006, -1.003, -1.001, -1.007, -1.0059999999999998, -1.003, -1.001, -1.001, -1.004, -0.508, -1.007, -1.003, -0.001, -1.001, -1.002, -1.0019999999999998, -1.004, -1.003, -1.003, -1.003, -1.0, -1.002, 0.96, -1.005, -1.007, -1.002, -0.001, -1.001, -1.0, -1.008, -1.007, -1.0039999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2324616638157676, "mean_inference_ms": 1.474418541948498, "mean_action_processing_ms": 0.06275284534694739, "mean_env_wait_ms": 0.08880297376895695, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01946584677990572, "StateBufferConnector_ms": 0.0015377998352050781, "ViewRequirementAgentConnector_ms": 0.031545647868403685}}, "episode_reward_max": 1.889, "episode_reward_min": -0.18900000000000006, "episode_reward_mean": 0.31605555555555553, "episode_len_mean": 23.74074074074074, "episodes_this_iter": 162, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.035}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.978}, "policy_reward_mean": {"red_0": 1.169148148148148, "blue_0": -0.8530925925925927}, "hist_stats": {"episode_reward": [0.359, 0.30500000000000016, 0.45599999999999996, 0.363, 0.46799999999999997, 0.46599999999999997, 0.45799999999999996, 0.41300000000000026, -0.04500000000000004, -0.040000000000000036, -0.10499999999999998, -0.029000000000000026, 0.44799999999999995, -0.028000000000000025, -0.03400000000000003, 0.45799999999999996, -0.03400000000000003, -0.027000000000000024, 0.46599999999999997, 0.45999999999999996, -0.041000000000000036, 0.44199999999999995, 0.41100000000000003, 0.46899999999999986, 0.46199999999999997, -0.05800000000000005, -0.040000000000000036, 0.40000000000000013, 0.2469999999999999, -0.02299999999999991, -0.03600000000000003, 0.43999999999999995, 0.4610000000000001, 1.3439999999999999, -0.03300000000000003, -0.06000000000000005, -0.04300000000000004, -0.03300000000000003, -0.03300000000000003, -0.028000000000000025, -0.03400000000000003, -0.15999999999999992, -0.025000000000000022, -0.07599999999999996, -0.028000000000000025, 0.8919999999999999, 0.45399999999999996, 0.45300000000000007, 0.44599999999999995, -0.030000000000000027, -0.027999999999999914, -0.11499999999999999, 0.46899999999999986, 0.4650000000000001, 1.436, 1.409, 0.4249999999999998, 0.4660000000000002, 1.4180000000000001, -0.02199999999999991, 0.46199999999999997, 0.4670000000000001, 0.41100000000000003, 0.44799999999999995, 0.40600000000000014, 0.399, -0.03200000000000003, 0.4630000000000001, -0.03199999999999992, 0.45699999999999985, 0.46499999999999986, -0.05500000000000005, -0.04800000000000004, -0.03500000000000003, -0.1090000000000001, -0.02400000000000002, 1.889, 0.9299999999999999, 0.44799999999999995, 0.41800000000000015, 0.44799999999999995, -0.031000000000000028, -0.04800000000000004, 0.43500000000000005, 0.46299999999999997, -0.03400000000000003, 1.431, -0.038000000000000034, 0.46499999999999986, 0.4590000000000001, -0.029999999999999916, 0.40600000000000014, -0.04800000000000004, 0.45699999999999985, 0.45500000000000007, -0.029999999999999916, 0.47, 0.43900000000000006, 0.46599999999999997, -0.02100000000000002, 0.43399999999999994, 0.45199999999999996, -0.03500000000000003, 0.45299999999999985, 0.45799999999999996, 0.44499999999999984, 0.39300000000000024, 0.30600000000000005, 0.46399999999999997, -0.02200000000000002, -0.04800000000000004, 0.44799999999999995, 0.3919999999999999, 1.1949999999999998, 1.446, -0.028000000000000025, 0.44799999999999995, 0.44799999999999995, -0.030000000000000027, 0.46399999999999997, -0.02200000000000002, 1.3679999999999999, 0.3999999999999999, -0.18900000000000006, 0.45299999999999985, -0.03600000000000003, -0.03700000000000003, -0.05899999999999994, 0.28600000000000003, 0.41800000000000015, 0.3460000000000001, 0.45500000000000007, -0.03499999999999992, 0.41700000000000004, 0.367, -0.051000000000000045, 0.472, 0.46599999999999997, 0.41800000000000015, 0.7429999999999999, 0.44099999999999984, 0.45799999999999996, 1.454, 0.4630000000000001, -0.04500000000000004, -0.04399999999999993, -0.09699999999999998, 0.41000000000000014, 0.42999999999999994, 0.45799999999999996, -0.02400000000000002, -0.03200000000000003, -0.039999999999999925, -0.04400000000000004, -0.16100000000000003, 0.46499999999999986, 1.438, 0.45299999999999985, -0.040000000000000036, 0.381, -0.126, 0.4570000000000001], "episode_lengths": [44, 62, 14, 43, 10, 11, 13, 27, 14, 13, 33, 9, 16, 9, 11, 300, 11, 9, 11, 13, 13, 18, 29, 10, 12, 19, 13, 32, 78, 7, 11, 19, 11, 51, 11, 19, 13, 10, 10, 9, 11, 51, 8, 23, 9, 33, 15, 14, 17, 10, 8, 37, 10, 11, 21, 29, 24, 11, 27, 7, 12, 11, 29, 16, 29, 31, 10, 12, 10, 14, 11, 18, 15, 11, 188, 8, 35, 22, 17, 25, 16, 10, 15, 21, 12, 11, 22, 12, 11, 13, 9, 30, 15, 14, 14, 9, 10, 19, 11, 7, 21, 15, 11, 15, 13, 17, 33, 59, 11, 7, 15, 16, 34, 96, 17, 9, 17, 16, 10, 12, 7, 42, 32, 61, 15, 11, 12, 19, 227, 26, 48, 14, 11, 25, 41, 16, 9, 11, 26, 83, 17, 13, 15, 12, 14, 14, 31, 29, 22, 13, 8, 10, 13, 13, 49, 11, 20, 15, 12, 34, 39, 13], "policy_red_0_reward": [1.366, 1.3130000000000002, 1.458, 1.369, 1.47, 1.467, 1.46, 1.419, 0.958, 0.961, 0.898, 0.972, 1.451, 0.973, 0.967, 0.0, 0.967, 0.973, 1.467, 1.4609999999999999, 0.96, 1.446, 1.413, 1.47, 1.464, 0.943, 0.961, 1.404, 1.26, 0.979, 0.967, 1.443, 1.467, 1.347, 0.967, 0.943, 0.961, 0.97, 0.97, 0.973, 0.967, 0.847, 0.976, 0.929, 0.973, 1.4, 1.455, 1.458, 0.948, 0.97, 0.975, 0.889, 1.47, 1.467, 1.4369999999999998, 1.412, 1.427, 1.467, 1.419, -1.0, 1.464, 1.467, 1.412, 1.452, 1.413, 1.407, 0.97, 1.464, 0.97, 1.458, 1.467, 0.945, 0.955, 0.967, 0.9259999999999999, 0.976, 1.3940000000000001, 1.4329999999999998, 1.4489999999999998, 1.424, 1.452, 0.97, 0.955, 1.4369999999999998, -0.5, 0.967, 1.434, 0.964, 1.467, 1.4609999999999999, 0.973, 0.91, 0.955, 1.458, 1.458, 0.972, 1.47, 1.443, -0.5, 0.979, 1.4369999999999998, 1.454, 0.967, 1.4529999999999998, 1.4609999999999999, 0.949, 1.4, 1.323, 1.467, 0.979, 0.954, 1.452, 1.3980000000000001, 1.21, 1.4489999999999998, 0.973, 1.4489999999999998, 1.452, 0.97, 1.464, 0.979, 1.374, 1.404, 0.817, 1.454, 0.967, 0.964, 0.943, 0.817, 1.421, 1.3519999999999999, 1.458, 0.966, 1.424, 1.373, 0.952, 1.4729999999999999, 1.467, 1.4220000000000002, 1.251, 1.448, 1.4609999999999999, 1.455, 1.464, 0.957, 0.958, 0.907, 1.413, 1.4329999999999998, 1.4609999999999999, 0.976, 0.97, -1.0, 0.961, 0.846, 1.467, 1.439, 1.454, 0.96, 1.389, 0.881, 1.4609999999999999], "policy_blue_0_reward": [-1.007, -1.008, -1.002, -1.006, -1.002, -1.001, -1.002, -1.0059999999999998, -1.003, -1.001, -1.003, -1.001, -1.003, -1.001, -1.001, 0.45799999999999996, -1.001, -1.0, -1.001, -1.001, -1.001, -1.004, -1.002, -1.001, -1.002, -1.001, -1.001, -1.0039999999999998, -1.013, -1.0019999999999998, -1.003, -1.003, -1.0059999999999998, -0.003, -1.0, -1.003, -1.004, -1.003, -1.003, -1.001, -1.001, -1.007, -1.001, -1.005, -1.001, -0.508, -1.001, -1.005, -0.502, -1.0, -1.003, -1.004, -1.001, -1.0019999999999998, -0.001, -0.003, -1.002, -1.001, -0.001, 0.978, -1.002, -1.0, -1.001, -1.004, -1.007, -1.008, -1.002, -1.001, -1.0019999999999998, -1.001, -1.002, -1.0, -1.003, -1.002, -1.035, -1.0, 0.495, -0.503, -1.001, -1.0059999999999998, -1.004, -1.001, -1.003, -1.002, 0.963, -1.001, -0.003, -1.002, -1.002, -1.002, -1.003, -0.504, -1.003, -1.001, -1.003, -1.0019999999999998, -1.0, -1.004, 0.966, -1.0, -1.003, -1.002, -1.002, -1.0, -1.003, -0.504, -1.007, -1.017, -1.003, -1.001, -1.002, -1.004, -1.006, -0.015000000000000006, -0.003, -1.001, -1.001, -1.0039999999999998, -1.0, -1.0, -1.001, -0.006, -1.004, -1.006, -1.001, -1.003, -1.001, -1.0019999999999998, -0.531, -1.003, -1.006, -1.003, -1.001, -1.007, -1.0059999999999998, -1.003, -1.001, -1.001, -1.004, -0.508, -1.007, -1.003, -0.001, -1.001, -1.002, -1.0019999999999998, -1.004, -1.003, -1.003, -1.003, -1.0, -1.002, 0.96, -1.005, -1.007, -1.002, -0.001, -1.001, -1.0, -1.008, -1.007, -1.0039999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2324616638157676, "mean_inference_ms": 1.474418541948498, "mean_action_processing_ms": 0.06275284534694739, "mean_env_wait_ms": 0.08880297376895695, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01946584677990572, "StateBufferConnector_ms": 0.0015377998352050781, "ViewRequirementAgentConnector_ms": 0.031545647868403685}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000, "num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.88413819168991, "num_env_steps_trained_throughput_per_sec": 102.88413819168991, "timesteps_total": 104000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 208000, "timers": {"training_iteration_time_ms": 38842.266, "sample_time_ms": 7510.43, "learn_time_ms": 31314.483, "learn_throughput": 127.736, "synch_weights_time_ms": 16.855}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 104000, "num_agent_steps_sampled": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 1413, "training_iteration": 26, "trial_id": "d67e4_00000", "date": "2023-09-20_22-26-01", "timestamp": 1695263161, "time_this_iter_s": 38.88543081283569, "time_total_s": 1009.6200819015503, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fe440>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1009.6200819015503, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 33.93571428571428, "ram_util_percent": 48.253571428571426}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.047619047619047616, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9095238095238095, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0380952380952381, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9095238095238095, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0380952380952381, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9095238095238095, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0380952380952381, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8740051637093227, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0092219451534523, "policy_loss": -0.018850442724700163, "vf_loss": 0.012685089839699988, "vf_explained_var": 0.6555403169865409, "kl": 0.008647760098141196, "entropy": 0.6055391839084526, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 25440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "sampler_results": {"episode_reward_max": 1.957, "episode_reward_min": -0.6469999999999999, "episode_reward_mean": 0.304352380952381, "episode_len_mean": 20.957142857142856, "episode_media": {}, "episodes_this_iter": 210, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.44}, "policy_reward_mean": {"red_0": 1.1421809523809525, "blue_0": -0.8378285714285713}, "custom_metrics": {"red_0/door_open_done_mean": 0.047619047619047616, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9095238095238095, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0380952380952381, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9095238095238095, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0380952380952381, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9095238095238095, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0380952380952381, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.377, 0.4570000000000001, -0.040000000000000036, -0.1349999999999999, -0.038000000000000034, 0.44900000000000007, 0.4630000000000001, 0.46599999999999997, -0.04800000000000004, 0.45999999999999996, 0.45999999999999996, 0.43999999999999995, 0.43599999999999994, -0.041000000000000036, 0.09499999999999997, 0.45699999999999985, -0.03600000000000003, 0.4670000000000001, 1.957, 0.08999999999999986, -0.02200000000000002, -0.027000000000000024, -0.03600000000000003, -0.031000000000000028, -0.03400000000000003, 0.43599999999999994, 0.389, 0.45699999999999985, 0.43999999999999995, -0.03600000000000003, 0.29200000000000004, 0.4590000000000001, -0.02499999999999991, 0.956, 0.45799999999999996, -0.030000000000000027, 0.46899999999999986, -0.031000000000000028, 1.446, 0.46799999999999997, 0.40700000000000003, 0.44399999999999995, -0.030000000000000027, -0.027000000000000024, 1.435, 0.45999999999999996, 0.7640000000000002, -0.03600000000000003, -0.03300000000000003, 0.47299999999999986, 0.45999999999999996, 0.405, 0.4630000000000001, -0.027000000000000024, -0.027999999999999914, 0.45599999999999996, -0.03700000000000003, -0.030000000000000027, 0.475, -0.031000000000000028, -0.11399999999999999, 0.44799999999999995, -0.05900000000000005, 0.4630000000000001, -0.031000000000000028, 0.958, 0.45699999999999985, 0.45799999999999996, 0.46599999999999997, -0.029999999999999916, 0.46599999999999997, 0.43299999999999983, 0.46499999999999986, -0.027000000000000024, -0.038000000000000034, 0.46099999999999985, 0.4670000000000001, 0.472, -0.027999999999999914, -0.6469999999999999, 1.8980000000000001, 1.384, -0.06999999999999995, 0.44499999999999984, 0.39800000000000013, 0.42700000000000005, -0.029000000000000026, -0.03499999999999992, -0.03300000000000003, -0.06500000000000006, -0.05500000000000005, 0.42200000000000015, 0.4650000000000001, -0.040000000000000036, -0.038000000000000034, 0.474, -0.02400000000000002, -0.029000000000000026, 0.3719999999999999, 0.4670000000000001, 0.46599999999999997, -0.027000000000000024, 0.9430000000000001, -0.030000000000000027, -0.027000000000000024, 0.3679999999999999, -0.030000000000000027, 0.47, 0.45399999999999996, -0.05799999999999994, -0.04800000000000004, -0.028000000000000025, -0.10399999999999998, 1.435, 0.3780000000000001, 0.32400000000000007, 0.46599999999999997, 0.44799999999999995, 0.4249999999999998, -0.03200000000000003, -0.04300000000000004, 0.381, -0.09999999999999987, 0.47299999999999986, -0.05700000000000005, -0.03200000000000003, 0.4590000000000001, -0.027999999999999914, 0.46499999999999986, 0.45299999999999985, 0.472, -0.041000000000000036, -0.04800000000000004, -0.028000000000000025, 1.358, 0.4690000000000001, -0.02499999999999991, -0.04300000000000004, 0.46599999999999997, 0.42999999999999994, -0.09099999999999997, 0.42599999999999993, 0.4849999999999999, -0.05800000000000005, 1.365, 0.47299999999999986, -0.02200000000000002, 0.4590000000000001, -0.121, 0.44900000000000007, 0.365, 0.45399999999999996, -0.031000000000000028, 0.45100000000000007, 0.45399999999999996, -0.02499999999999991, 0.4670000000000001, 0.45299999999999985, 0.45500000000000007, -0.03300000000000003, 0.935, -0.030000000000000027, 0.45999999999999996, -0.04300000000000004, -0.04200000000000004, 0.46399999999999997, 0.44300000000000006, 0.9609999999999999, 0.47299999999999986, 0.43999999999999995, 0.40200000000000014, 0.46899999999999986, -0.03200000000000003, 0.45799999999999996, 0.44199999999999995, 0.43500000000000005, 0.46099999999999985, -0.03300000000000003, -0.031000000000000028, 1.4140000000000001, 0.45599999999999996, -0.03700000000000003, -0.03400000000000003, 0.44399999999999995, 0.4730000000000001, 0.43400000000000016, -0.031000000000000028, 0.42100000000000004, 0.44799999999999995, 0.46499999999999986, -0.02400000000000002, -0.04500000000000004, 0.43800000000000017, 0.4590000000000001, 0.43599999999999994, 0.46499999999999986, 0.43000000000000016, -0.031000000000000028, 0.363, -0.14800000000000002, 0.43799999999999994, 0.43199999999999994, -0.02100000000000002, 0.46499999999999986, -0.03500000000000003, -0.051000000000000045, 0.43800000000000017, 0.45500000000000007, 1.435, 0.46399999999999997], "episode_lengths": [109, 13, 13, 42, 12, 16, 11, 11, 15, 13, 13, 19, 19, 13, 125, 14, 12, 11, 14, 132, 7, 9, 11, 10, 11, 21, 31, 14, 19, 12, 65, 13, 8, 14, 14, 10, 10, 9, 17, 10, 29, 17, 9, 9, 21, 13, 71, 12, 11, 9, 13, 30, 11, 9, 9, 14, 12, 10, 8, 10, 36, 17, 19, 12, 10, 300, 14, 12, 11, 9, 11, 21, 11, 8, 12, 12, 10, 9, 9, 203, 32, 36, 23, 18, 32, 23, 9, 11, 10, 21, 17, 25, 11, 13, 12, 8, 8, 9, 39, 11, 11, 9, 18, 9, 9, 39, 10, 10, 14, 19, 15, 9, 33, 20, 40, 52, 11, 16, 24, 10, 14, 39, 31, 9, 18, 10, 13, 9, 11, 15, 9, 13, 15, 9, 45, 9, 8, 14, 11, 22, 27, 24, 163, 17, 42, 9, 7, 13, 38, 16, 43, 15, 10, 16, 14, 8, 10, 15, 14, 10, 21, 10, 13, 14, 13, 11, 18, 13, 9, 19, 31, 10, 10, 13, 17, 20, 13, 10, 10, 27, 14, 12, 11, 18, 8, 20, 10, 25, 16, 11, 8, 13, 20, 13, 20, 11, 22, 10, 43, 46, 19, 22, 7, 11, 11, 16, 19, 14, 21, 12], "policy_red_0_reward": [0.638, 1.4609999999999999, 0.961, 0.874, 0.964, 1.452, 1.467, 1.467, 0.953, 1.4609999999999999, 1.4609999999999999, 1.443, 1.443, 0.96, 1.1099999999999999, 1.458, 0.964, 1.467, 1.458, 1.101, 0.979, 0.973, 0.967, 0.97, 0.967, 1.4369999999999998, 1.3940000000000001, 1.458, -1.0, 0.964, 1.301, 1.4609999999999999, 0.976, 1.458, 1.458, 0.97, 1.47, 0.973, 1.4489999999999998, 1.47, 1.412, 1.4489999999999998, 0.973, 0.973, 1.4369999999999998, 1.4609999999999999, 1.275, 0.964, 0.967, 1.4729999999999999, 1.46, 1.409, 1.467, 0.973, -1.0, 1.458, 0.964, 0.97, -0.5, 0.97, -1.001, 1.4489999999999998, 0.943, 1.464, 0.97, 0.497, 1.458, 1.464, 1.467, 0.973, 0.967, 1.436, 1.467, 0.976, 0.964, 1.464, 1.47, 0.973, 0.973, 0.38, 1.404, 1.3900000000000001, 0.93, 1.446, 1.404, 1.431, 0.973, 0.967, 0.97, 0.9369999999999999, 0.949, 1.425, 1.467, 0.961, 0.964, -0.5, 0.976, 0.973, 1.3820000000000001, 1.467, 1.467, 0.973, 1.446, 0.973, 0.973, 1.3820000000000001, 0.97, 1.47, 1.458, 0.943, 0.955, 0.973, 0.9, 1.44, 1.379, 1.335, -0.5, 1.451, 1.428, 0.969, 0.958, 1.3820000000000001, 0.906, 1.4729999999999999, 0.944, 0.97, 1.4609999999999999, 0.973, 1.467, 1.455, 0.972, 0.96, 0.953, 0.973, 1.365, 1.4729999999999999, 0.976, 0.958, 1.467, 1.4329999999999998, 0.914, 1.428, 1.008, 0.948, 1.373, 1.4729999999999999, 0.979, 1.4609999999999999, 0.886, 1.452, 1.37, 1.455, 0.97, 1.452, 1.4569999999999999, -1.0, 1.47, 1.455, 1.458, 0.969, 1.4369999999999998, 0.97, 1.4609999999999999, 0.958, 0.961, 1.467, 1.443, 1.4609999999999999, 1.4729999999999999, 1.443, 1.407, 1.47, 0.97, 1.4609999999999999, 1.4489999999999998, 1.44, 1.4609999999999999, 0.97, 0.97, 1.417, 1.458, 0.964, 0.967, 1.4449999999999998, 1.476, 0.938, 0.97, 1.425, 0.951, 1.467, -1.0, 0.96, 1.439, 1.4609999999999999, 1.439, 1.467, 1.4329999999999998, 0.97, 1.37, 0.862, 1.443, 0.9329999999999999, 0.979, 1.467, 0.966, 0.952, 1.443, 1.458, 1.4369999999999998, 1.464], "policy_blue_0_reward": [-1.015, -1.0039999999999998, -1.001, -1.009, -1.002, -1.003, -1.004, -1.001, -1.001, -1.001, -1.001, -1.003, -1.007, -1.001, -1.015, -1.001, -1.0, -1.0, 0.499, -1.011, -1.001, -1.0, -1.003, -1.001, -1.001, -1.001, -1.005, -1.001, 1.44, -1.0, -1.009, -1.002, -1.001, -0.502, -1.0, -1.0, -1.001, -1.004, -0.003, -1.0019999999999998, -1.005, -1.005, -1.003, -1.0, -0.002, -1.001, -0.5109999999999999, -1.0, -1.0, -1.0, -1.0, -1.004, -1.0039999999999998, -1.0, 0.972, -1.002, -1.001, -1.0, 0.975, -1.001, 0.887, -1.001, -1.002, -1.001, -1.001, 0.46099999999999997, -1.001, -1.006, -1.001, -1.003, -0.501, -1.003, -1.002, -1.003, -1.002, -1.003, -1.003, -0.501, -1.001, -1.027, 0.494, -0.006, -1.0, -1.001, -1.006, -1.004, -1.002, -1.0019999999999998, -1.003, -1.002, -1.004, -1.003, -1.0019999999999998, -1.001, -1.002, 0.974, -1.0, -1.002, -1.01, -1.0, -1.001, -1.0, -0.503, -1.003, -1.0, -1.014, -1.0, -1.0, -1.004, -1.001, -1.003, -1.001, -1.004, -0.005, -1.001, -1.011, 0.966, -1.003, -1.003, -1.001, -1.001, -1.001, -1.0059999999999998, -1.0, -1.001, -1.002, -1.002, -1.001, -1.002, -1.002, -0.5, -1.001, -1.001, -1.001, -0.007, -1.0039999999999998, -1.001, -1.001, -1.001, -1.003, -1.005, -1.002, -0.523, -1.006, -0.008, -1.0, -1.001, -1.0019999999999998, -1.007, -1.003, -1.005, -1.001, -1.001, -1.001, -1.003, 0.975, -1.003, -1.002, -1.003, -1.002, -0.5019999999999999, -1.0, -1.001, -1.001, -1.003, -1.003, -1.0, -0.5, -1.0, -1.003, -1.005, -1.001, -1.002, -1.003, -1.007, -1.005, -1.0, -1.003, -1.001, -0.003, -1.002, -1.001, -1.001, -1.001, -1.003, -0.5039999999999999, -1.001, -1.004, -0.503, -1.002, 0.976, -1.005, -1.001, -1.002, -1.003, -1.002, -1.003, -1.001, -1.007, -1.01, -1.005, -0.501, -1.0, -1.002, -1.001, -1.003, -1.005, -1.003, -0.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23339506628750673, "mean_inference_ms": 1.4753725204117283, "mean_action_processing_ms": 0.06277421418858264, "mean_env_wait_ms": 0.08883820345049204, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01941448166256859, "StateBufferConnector_ms": 0.0015714622679210844, "ViewRequirementAgentConnector_ms": 0.03154164268856957}}, "episode_reward_max": 1.957, "episode_reward_min": -0.6469999999999999, "episode_reward_mean": 0.304352380952381, "episode_len_mean": 20.957142857142856, "episodes_this_iter": 210, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.44}, "policy_reward_mean": {"red_0": 1.1421809523809525, "blue_0": -0.8378285714285713}, "hist_stats": {"episode_reward": [-0.377, 0.4570000000000001, -0.040000000000000036, -0.1349999999999999, -0.038000000000000034, 0.44900000000000007, 0.4630000000000001, 0.46599999999999997, -0.04800000000000004, 0.45999999999999996, 0.45999999999999996, 0.43999999999999995, 0.43599999999999994, -0.041000000000000036, 0.09499999999999997, 0.45699999999999985, -0.03600000000000003, 0.4670000000000001, 1.957, 0.08999999999999986, -0.02200000000000002, -0.027000000000000024, -0.03600000000000003, -0.031000000000000028, -0.03400000000000003, 0.43599999999999994, 0.389, 0.45699999999999985, 0.43999999999999995, -0.03600000000000003, 0.29200000000000004, 0.4590000000000001, -0.02499999999999991, 0.956, 0.45799999999999996, -0.030000000000000027, 0.46899999999999986, -0.031000000000000028, 1.446, 0.46799999999999997, 0.40700000000000003, 0.44399999999999995, -0.030000000000000027, -0.027000000000000024, 1.435, 0.45999999999999996, 0.7640000000000002, -0.03600000000000003, -0.03300000000000003, 0.47299999999999986, 0.45999999999999996, 0.405, 0.4630000000000001, -0.027000000000000024, -0.027999999999999914, 0.45599999999999996, -0.03700000000000003, -0.030000000000000027, 0.475, -0.031000000000000028, -0.11399999999999999, 0.44799999999999995, -0.05900000000000005, 0.4630000000000001, -0.031000000000000028, 0.958, 0.45699999999999985, 0.45799999999999996, 0.46599999999999997, -0.029999999999999916, 0.46599999999999997, 0.43299999999999983, 0.46499999999999986, -0.027000000000000024, -0.038000000000000034, 0.46099999999999985, 0.4670000000000001, 0.472, -0.027999999999999914, -0.6469999999999999, 1.8980000000000001, 1.384, -0.06999999999999995, 0.44499999999999984, 0.39800000000000013, 0.42700000000000005, -0.029000000000000026, -0.03499999999999992, -0.03300000000000003, -0.06500000000000006, -0.05500000000000005, 0.42200000000000015, 0.4650000000000001, -0.040000000000000036, -0.038000000000000034, 0.474, -0.02400000000000002, -0.029000000000000026, 0.3719999999999999, 0.4670000000000001, 0.46599999999999997, -0.027000000000000024, 0.9430000000000001, -0.030000000000000027, -0.027000000000000024, 0.3679999999999999, -0.030000000000000027, 0.47, 0.45399999999999996, -0.05799999999999994, -0.04800000000000004, -0.028000000000000025, -0.10399999999999998, 1.435, 0.3780000000000001, 0.32400000000000007, 0.46599999999999997, 0.44799999999999995, 0.4249999999999998, -0.03200000000000003, -0.04300000000000004, 0.381, -0.09999999999999987, 0.47299999999999986, -0.05700000000000005, -0.03200000000000003, 0.4590000000000001, -0.027999999999999914, 0.46499999999999986, 0.45299999999999985, 0.472, -0.041000000000000036, -0.04800000000000004, -0.028000000000000025, 1.358, 0.4690000000000001, -0.02499999999999991, -0.04300000000000004, 0.46599999999999997, 0.42999999999999994, -0.09099999999999997, 0.42599999999999993, 0.4849999999999999, -0.05800000000000005, 1.365, 0.47299999999999986, -0.02200000000000002, 0.4590000000000001, -0.121, 0.44900000000000007, 0.365, 0.45399999999999996, -0.031000000000000028, 0.45100000000000007, 0.45399999999999996, -0.02499999999999991, 0.4670000000000001, 0.45299999999999985, 0.45500000000000007, -0.03300000000000003, 0.935, -0.030000000000000027, 0.45999999999999996, -0.04300000000000004, -0.04200000000000004, 0.46399999999999997, 0.44300000000000006, 0.9609999999999999, 0.47299999999999986, 0.43999999999999995, 0.40200000000000014, 0.46899999999999986, -0.03200000000000003, 0.45799999999999996, 0.44199999999999995, 0.43500000000000005, 0.46099999999999985, -0.03300000000000003, -0.031000000000000028, 1.4140000000000001, 0.45599999999999996, -0.03700000000000003, -0.03400000000000003, 0.44399999999999995, 0.4730000000000001, 0.43400000000000016, -0.031000000000000028, 0.42100000000000004, 0.44799999999999995, 0.46499999999999986, -0.02400000000000002, -0.04500000000000004, 0.43800000000000017, 0.4590000000000001, 0.43599999999999994, 0.46499999999999986, 0.43000000000000016, -0.031000000000000028, 0.363, -0.14800000000000002, 0.43799999999999994, 0.43199999999999994, -0.02100000000000002, 0.46499999999999986, -0.03500000000000003, -0.051000000000000045, 0.43800000000000017, 0.45500000000000007, 1.435, 0.46399999999999997], "episode_lengths": [109, 13, 13, 42, 12, 16, 11, 11, 15, 13, 13, 19, 19, 13, 125, 14, 12, 11, 14, 132, 7, 9, 11, 10, 11, 21, 31, 14, 19, 12, 65, 13, 8, 14, 14, 10, 10, 9, 17, 10, 29, 17, 9, 9, 21, 13, 71, 12, 11, 9, 13, 30, 11, 9, 9, 14, 12, 10, 8, 10, 36, 17, 19, 12, 10, 300, 14, 12, 11, 9, 11, 21, 11, 8, 12, 12, 10, 9, 9, 203, 32, 36, 23, 18, 32, 23, 9, 11, 10, 21, 17, 25, 11, 13, 12, 8, 8, 9, 39, 11, 11, 9, 18, 9, 9, 39, 10, 10, 14, 19, 15, 9, 33, 20, 40, 52, 11, 16, 24, 10, 14, 39, 31, 9, 18, 10, 13, 9, 11, 15, 9, 13, 15, 9, 45, 9, 8, 14, 11, 22, 27, 24, 163, 17, 42, 9, 7, 13, 38, 16, 43, 15, 10, 16, 14, 8, 10, 15, 14, 10, 21, 10, 13, 14, 13, 11, 18, 13, 9, 19, 31, 10, 10, 13, 17, 20, 13, 10, 10, 27, 14, 12, 11, 18, 8, 20, 10, 25, 16, 11, 8, 13, 20, 13, 20, 11, 22, 10, 43, 46, 19, 22, 7, 11, 11, 16, 19, 14, 21, 12], "policy_red_0_reward": [0.638, 1.4609999999999999, 0.961, 0.874, 0.964, 1.452, 1.467, 1.467, 0.953, 1.4609999999999999, 1.4609999999999999, 1.443, 1.443, 0.96, 1.1099999999999999, 1.458, 0.964, 1.467, 1.458, 1.101, 0.979, 0.973, 0.967, 0.97, 0.967, 1.4369999999999998, 1.3940000000000001, 1.458, -1.0, 0.964, 1.301, 1.4609999999999999, 0.976, 1.458, 1.458, 0.97, 1.47, 0.973, 1.4489999999999998, 1.47, 1.412, 1.4489999999999998, 0.973, 0.973, 1.4369999999999998, 1.4609999999999999, 1.275, 0.964, 0.967, 1.4729999999999999, 1.46, 1.409, 1.467, 0.973, -1.0, 1.458, 0.964, 0.97, -0.5, 0.97, -1.001, 1.4489999999999998, 0.943, 1.464, 0.97, 0.497, 1.458, 1.464, 1.467, 0.973, 0.967, 1.436, 1.467, 0.976, 0.964, 1.464, 1.47, 0.973, 0.973, 0.38, 1.404, 1.3900000000000001, 0.93, 1.446, 1.404, 1.431, 0.973, 0.967, 0.97, 0.9369999999999999, 0.949, 1.425, 1.467, 0.961, 0.964, -0.5, 0.976, 0.973, 1.3820000000000001, 1.467, 1.467, 0.973, 1.446, 0.973, 0.973, 1.3820000000000001, 0.97, 1.47, 1.458, 0.943, 0.955, 0.973, 0.9, 1.44, 1.379, 1.335, -0.5, 1.451, 1.428, 0.969, 0.958, 1.3820000000000001, 0.906, 1.4729999999999999, 0.944, 0.97, 1.4609999999999999, 0.973, 1.467, 1.455, 0.972, 0.96, 0.953, 0.973, 1.365, 1.4729999999999999, 0.976, 0.958, 1.467, 1.4329999999999998, 0.914, 1.428, 1.008, 0.948, 1.373, 1.4729999999999999, 0.979, 1.4609999999999999, 0.886, 1.452, 1.37, 1.455, 0.97, 1.452, 1.4569999999999999, -1.0, 1.47, 1.455, 1.458, 0.969, 1.4369999999999998, 0.97, 1.4609999999999999, 0.958, 0.961, 1.467, 1.443, 1.4609999999999999, 1.4729999999999999, 1.443, 1.407, 1.47, 0.97, 1.4609999999999999, 1.4489999999999998, 1.44, 1.4609999999999999, 0.97, 0.97, 1.417, 1.458, 0.964, 0.967, 1.4449999999999998, 1.476, 0.938, 0.97, 1.425, 0.951, 1.467, -1.0, 0.96, 1.439, 1.4609999999999999, 1.439, 1.467, 1.4329999999999998, 0.97, 1.37, 0.862, 1.443, 0.9329999999999999, 0.979, 1.467, 0.966, 0.952, 1.443, 1.458, 1.4369999999999998, 1.464], "policy_blue_0_reward": [-1.015, -1.0039999999999998, -1.001, -1.009, -1.002, -1.003, -1.004, -1.001, -1.001, -1.001, -1.001, -1.003, -1.007, -1.001, -1.015, -1.001, -1.0, -1.0, 0.499, -1.011, -1.001, -1.0, -1.003, -1.001, -1.001, -1.001, -1.005, -1.001, 1.44, -1.0, -1.009, -1.002, -1.001, -0.502, -1.0, -1.0, -1.001, -1.004, -0.003, -1.0019999999999998, -1.005, -1.005, -1.003, -1.0, -0.002, -1.001, -0.5109999999999999, -1.0, -1.0, -1.0, -1.0, -1.004, -1.0039999999999998, -1.0, 0.972, -1.002, -1.001, -1.0, 0.975, -1.001, 0.887, -1.001, -1.002, -1.001, -1.001, 0.46099999999999997, -1.001, -1.006, -1.001, -1.003, -0.501, -1.003, -1.002, -1.003, -1.002, -1.003, -1.003, -0.501, -1.001, -1.027, 0.494, -0.006, -1.0, -1.001, -1.006, -1.004, -1.002, -1.0019999999999998, -1.003, -1.002, -1.004, -1.003, -1.0019999999999998, -1.001, -1.002, 0.974, -1.0, -1.002, -1.01, -1.0, -1.001, -1.0, -0.503, -1.003, -1.0, -1.014, -1.0, -1.0, -1.004, -1.001, -1.003, -1.001, -1.004, -0.005, -1.001, -1.011, 0.966, -1.003, -1.003, -1.001, -1.001, -1.001, -1.0059999999999998, -1.0, -1.001, -1.002, -1.002, -1.001, -1.002, -1.002, -0.5, -1.001, -1.001, -1.001, -0.007, -1.0039999999999998, -1.001, -1.001, -1.001, -1.003, -1.005, -1.002, -0.523, -1.006, -0.008, -1.0, -1.001, -1.0019999999999998, -1.007, -1.003, -1.005, -1.001, -1.001, -1.001, -1.003, 0.975, -1.003, -1.002, -1.003, -1.002, -0.5019999999999999, -1.0, -1.001, -1.001, -1.003, -1.003, -1.0, -0.5, -1.0, -1.003, -1.005, -1.001, -1.002, -1.003, -1.007, -1.005, -1.0, -1.003, -1.001, -0.003, -1.002, -1.001, -1.001, -1.001, -1.003, -0.5039999999999999, -1.001, -1.004, -0.503, -1.002, 0.976, -1.005, -1.001, -1.002, -1.003, -1.002, -1.003, -1.001, -1.007, -1.01, -1.005, -0.501, -1.0, -1.002, -1.001, -1.003, -1.005, -1.003, -0.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23339506628750673, "mean_inference_ms": 1.4753725204117283, "mean_action_processing_ms": 0.06277421418858264, "mean_env_wait_ms": 0.08883820345049204, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01941448166256859, "StateBufferConnector_ms": 0.0015714622679210844, "ViewRequirementAgentConnector_ms": 0.03154164268856957}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000, "num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.80223003885747, "num_env_steps_trained_throughput_per_sec": 102.80223003885747, "timesteps_total": 108000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 216000, "timers": {"training_iteration_time_ms": 38845.169, "sample_time_ms": 7525.981, "learn_time_ms": 31301.824, "learn_throughput": 127.788, "synch_weights_time_ms": 16.859}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 108000, "num_agent_steps_sampled": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 1623, "training_iteration": 27, "trial_id": "d67e4_00000", "date": "2023-09-20_22-26-41", "timestamp": 1695263201, "time_this_iter_s": 38.91797208786011, "time_total_s": 1048.5380539894104, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d08a170>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1048.5380539894104, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 35.29821428571428, "ram_util_percent": 48.22678571428571}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05042016806722689, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8907563025210085, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.058823529411764705, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8907563025210085, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.058823529411764705, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8907563025210085, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.058823529411764705, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8189117391904195, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0038601432508585274, "policy_loss": -0.014617137054544097, "vf_loss": 0.015108786889080269, "vf_explained_var": 0.5942631186296542, "kl": 0.008249633356534173, "entropy": 0.509734669389824, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 26400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "sampler_results": {"episode_reward_max": 1.4569999999999999, "episode_reward_min": -0.16700000000000004, "episode_reward_mean": 0.3010210084033613, "episode_len_mean": 16.42436974789916, "episode_media": {}, "episodes_this_iter": 238, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.444}, "policy_reward_mean": {"red_0": 1.1198193277310926, "blue_0": -0.818798319327731}, "custom_metrics": {"red_0/door_open_done_mean": 0.05042016806722689, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8907563025210085, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.058823529411764705, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8907563025210085, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.058823529411764705, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8907563025210085, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.058823529411764705, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46599999999999997, 0.45500000000000007, 0.44799999999999995, 0.43799999999999994, -0.03700000000000003, 0.46399999999999997, -0.038000000000000034, -0.09399999999999986, 0.4670000000000001, -0.07700000000000007, -0.027999999999999914, 1.412, 0.4630000000000001, 0.9670000000000001, -0.06900000000000006, 0.46199999999999997, 0.45799999999999996, 0.43699999999999983, 0.381, 0.3999999999999999, -0.04600000000000004, 0.46799999999999997, -0.07400000000000007, 0.45699999999999985, -0.038000000000000034, 0.4670000000000001, 0.45099999999999996, 0.45699999999999985, -0.04999999999999993, 0.46599999999999997, -0.025000000000000022, 0.46399999999999997, -0.03300000000000003, 0.4630000000000001, -0.09999999999999998, 0.46199999999999997, 0.44999999999999996, -0.030000000000000027, -0.030000000000000027, -0.030000000000000027, 0.46799999999999997, -0.04899999999999993, 1.428, 0.46499999999999986, -0.10799999999999998, -0.041999999999999926, 0.46499999999999986, 0.43799999999999994, -0.03199999999999992, 0.472, 0.47, 0.46599999999999997, -0.126, -0.04299999999999993, -0.031000000000000028, -0.02499999999999991, 1.45, 0.97, 0.47, 0.476, 0.476, 0.32200000000000006, 0.45599999999999996, -0.027000000000000024, 0.41500000000000004, 0.45100000000000007, 0.45100000000000007, 0.4590000000000001, 0.4590000000000001, 0.3639999999999999, 0.46599999999999997, -0.052000000000000046, 0.3639999999999999, -0.03500000000000003, 0.46899999999999986, 0.4660000000000002, -0.08100000000000007, 0.872, -0.028000000000000025, -0.03200000000000003, -0.038999999999999924, 0.2749999999999999, 0.45999999999999996, -0.039000000000000035, -0.031000000000000028, -0.04700000000000004, 0.46499999999999986, 0.47, -0.027000000000000024, 0.4630000000000001, 0.46599999999999997, 0.46599999999999997, -0.03400000000000003, 1.452, -0.04300000000000004, 0.45199999999999996, 0.4750000000000001, 0.472, -0.031000000000000028, -0.025000000000000022, -0.038000000000000034, 1.399, -0.039000000000000035, -0.02400000000000002, 0.474, 0.46899999999999986, 0.45500000000000007, 0.4710000000000001, -0.07899999999999996, 0.31100000000000017, -0.03600000000000003, -0.05300000000000005, 0.44799999999999995, 0.4590000000000001, -0.03500000000000003, -0.025000000000000022, 0.39400000000000013, -0.03300000000000003, 0.4630000000000001, -0.06300000000000006, -0.05800000000000005, 1.423, -0.038999999999999924, 0.472, -0.031000000000000028, -0.025000000000000022, 0.9209999999999998, -0.031000000000000028, -0.05400000000000005, -0.03499999999999992, 1.339, 0.45399999999999996, 0.45999999999999996, -0.03300000000000003, 0.43199999999999994, 1.436, -0.03500000000000003, 0.46399999999999997, -0.03300000000000003, 0.4670000000000001, 0.43799999999999994, 0.45599999999999996, -0.029000000000000026, 0.44199999999999995, -0.06700000000000006, 0.45299999999999985, 0.46799999999999997, 0.44099999999999984, -0.029000000000000026, 0.44899999999999984, -0.039000000000000035, -0.09099999999999997, -0.028000000000000025, 0.47, 0.41300000000000003, 0.47699999999999987, -0.038999999999999924, 0.4630000000000001, -0.027000000000000024, -0.08799999999999986, 0.43599999999999994, 0.45199999999999996, -0.031000000000000028, 0.476, -0.028000000000000025, -0.025000000000000022, 0.4570000000000001, 0.44300000000000006, 0.3879999999999999, 0.41700000000000004, 1.4569999999999999, -0.07000000000000006, -0.04699999999999993, 0.46899999999999986, 0.46899999999999986, -0.03400000000000003, -0.029000000000000026, -0.028000000000000025, -0.03600000000000003, 0.44700000000000006, -0.02200000000000002, 0.964, 0.3620000000000001, 0.46499999999999986, 0.4630000000000001, 0.45999999999999996, 0.4289999999999998, -0.05600000000000005, 0.45199999999999996, -0.04799999999999993, 0.4670000000000001, -0.030000000000000027, 0.46899999999999986, 1.454, -0.03799999999999992, 0.44199999999999995, 0.46199999999999997, -0.029000000000000026, 0.42599999999999993, -0.16700000000000004, 0.4750000000000001, 0.393, -0.052000000000000046, 0.46499999999999986, -0.027000000000000024, 0.44799999999999995, 1.452, 0.45799999999999996, -0.039000000000000035, 0.47299999999999986, -0.031000000000000028, 0.45999999999999996, -0.027000000000000024, 0.46399999999999997, 0.44200000000000017, -0.039000000000000035, -0.026000000000000023, 0.42700000000000005, 0.4590000000000001, -0.03600000000000003, -0.041000000000000036, 0.46499999999999986, 0.46899999999999986, -0.031000000000000028, 1.33, -0.038000000000000034, -0.138, 0.944, -0.03600000000000003, -0.040000000000000036, 0.46199999999999997, 0.46199999999999997, -0.029999999999999916, 0.46599999999999997, -0.031000000000000028, 0.4630000000000001, 0.4660000000000002, -0.03199999999999992], "episode_lengths": [11, 14, 17, 20, 12, 11, 12, 27, 11, 22, 9, 28, 12, 11, 20, 12, 13, 20, 39, 31, 14, 10, 24, 14, 12, 11, 16, 14, 14, 11, 8, 11, 10, 12, 32, 12, 16, 10, 10, 10, 10, 16, 22, 11, 31, 13, 11, 20, 10, 9, 10, 11, 41, 14, 10, 8, 15, 10, 10, 8, 8, 55, 14, 9, 27, 16, 16, 13, 13, 42, 11, 16, 43, 11, 9, 11, 185, 40, 9, 10, 12, 71, 12, 12, 10, 15, 11, 10, 9, 12, 11, 11, 11, 15, 14, 16, 8, 9, 10, 8, 11, 33, 13, 8, 8, 10, 14, 9, 24, 58, 11, 17, 17, 13, 11, 8, 33, 10, 12, 19, 18, 24, 12, 9, 10, 8, 24, 10, 17, 11, 51, 14, 13, 11, 22, 21, 11, 12, 11, 11, 20, 14, 9, 19, 21, 15, 10, 19, 9, 16, 12, 28, 9, 10, 28, 7, 11, 12, 9, 27, 21, 15, 10, 7, 9, 8, 13, 18, 35, 26, 14, 22, 14, 10, 10, 11, 9, 9, 11, 17, 7, 11, 44, 11, 12, 13, 22, 18, 15, 15, 10, 10, 10, 15, 12, 18, 12, 9, 24, 53, 8, 34, 16, 11, 9, 17, 15, 13, 12, 9, 10, 13, 9, 11, 18, 12, 8, 23, 13, 12, 13, 11, 10, 10, 55, 12, 44, 18, 12, 13, 12, 12, 9, 11, 10, 11, 11, 10], "policy_red_0_reward": [1.467, 1.458, 1.4489999999999998, 1.44, 0.964, 1.467, 0.964, 0.912, 1.467, 0.9269999999999999, -1.0, 1.416, 1.464, 1.467, 0.9319999999999999, 1.464, 1.4609999999999999, 1.438, 1.383, 1.405, 0.958, 1.47, 0.9269999999999999, 1.458, 0.964, 1.467, -0.5, 1.458, 0.953, 1.467, 0.976, 1.467, 0.969, 1.464, 0.904, 1.464, 1.452, 0.97, 0.97, 0.97, 1.47, -1.0, 1.434, 1.467, 0.894, 0.961, 1.467, 1.44, 0.97, 1.4729999999999999, 1.47, 1.467, 0.877, 0.958, 0.97, 0.976, 1.455, 1.47, 1.47, 1.476, 1.476, 1.334, 1.458, 0.973, 1.4180000000000001, 1.452, 1.452, 1.4609999999999999, 1.4609999999999999, 1.369, 1.467, 0.952, 1.369, 0.967, 1.4729999999999999, 1.467, -1.007, -0.502, 0.973, 0.97, 0.964, 1.286, 1.464, 0.964, 0.97, 0.955, 1.467, 1.47, -1.0, 1.464, 1.467, 1.467, 0.967, 1.455, 0.958, 1.452, 1.476, 1.4729999999999999, 0.97, 0.976, 0.966, 1.401, 0.961, 0.976, 1.476, 1.47, 1.4569999999999999, 1.4729999999999999, 0.9269999999999999, 0.8180000000000001, 0.967, 0.949, 1.4489999999999998, 1.4609999999999999, 0.967, 0.976, 1.401, 0.97, 1.464, 0.941, 0.945, 1.428, 0.964, 1.4729999999999999, 0.97, 0.976, 1.424, 0.97, 0.949, 0.967, 1.347, 1.4569999999999999, 1.4609999999999999, 0.967, -0.5, 1.4369999999999998, 0.967, 1.464, 0.967, 1.467, 1.44, 1.458, 0.973, 1.443, 0.9359999999999999, 1.455, 1.47, 1.443, 0.973, 1.452, 0.963, 0.916, 0.973, 1.47, 1.415, 0.979, 0.967, 1.464, 0.973, -1.004, 1.4369999999999998, 0.955, 0.97, -0.5, 0.973, 0.976, 1.4609999999999999, 1.446, 1.395, 1.4220000000000002, 1.458, 0.9339999999999999, 0.957, 1.47, 1.47, 0.967, 0.973, 0.973, 0.966, 1.4489999999999998, 0.979, 1.467, 1.3679999999999999, 1.467, 1.464, 1.4609999999999999, 1.434, 0.946, 1.455, 0.955, 1.47, 0.97, 1.47, 1.455, 0.963, 1.4449999999999998, -0.5, 0.973, 1.427, -1.0, 1.476, 1.397, 0.952, 1.467, 0.973, 1.4489999999999998, 1.455, 1.4609999999999999, 0.964, 1.4729999999999999, 0.97, 1.4609999999999999, 0.973, 1.467, 1.446, 0.963, 0.976, -0.501, 1.4609999999999999, 0.964, 0.96, 1.467, 1.47, 0.97, 1.333, -1.0, 0.868, -0.5, 0.964, 0.96, 1.464, 1.464, 0.973, 1.467, 0.97, 1.467, 1.467, 0.97], "policy_blue_0_reward": [-1.001, -1.003, -1.001, -1.002, -1.001, -1.003, -1.002, -1.0059999999999998, -1.0, -1.004, 0.972, -0.004, -1.001, -0.5, -1.001, -1.002, -1.003, -1.001, -1.002, -1.005, -1.004, -1.002, -1.001, -1.001, -1.002, -1.0, 0.951, -1.001, -1.003, -1.001, -1.001, -1.003, -1.002, -1.001, -1.004, -1.002, -1.002, -1.0, -1.0, -1.0, -1.002, 0.951, -0.006, -1.002, -1.002, -1.003, -1.002, -1.002, -1.0019999999999998, -1.001, -1.0, -1.001, -1.003, -1.001, -1.001, -1.001, -0.005, -0.5, -1.0, -1.0, -1.0, -1.012, -1.0019999999999998, -1.0, -1.003, -1.001, -1.001, -1.002, -1.002, -1.005, -1.001, -1.004, -1.005, -1.002, -1.004, -1.001, 0.9259999999999999, 1.374, -1.001, -1.002, -1.003, -1.011, -1.0039999999999998, -1.003, -1.001, -1.002, -1.002, -1.0, 0.973, -1.001, -1.001, -1.001, -1.001, -0.003, -1.001, -1.0, -1.001, -1.001, -1.001, -1.001, -1.004, -0.002, -1.0, -1.0, -1.002, -1.001, -1.002, -1.0019999999999998, -1.0059999999999998, -0.5069999999999999, -1.003, -1.002, -1.001, -1.002, -1.002, -1.001, -1.007, -1.003, -1.001, -1.004, -1.003, -0.005, -1.003, -1.001, -1.001, -1.001, -0.503, -1.001, -1.003, -1.0019999999999998, -0.008, -1.003, -1.001, -1.0, 0.9319999999999999, -0.001, -1.002, -1.0, -1.0, -1.0, -1.002, -1.002, -1.002, -1.001, -1.003, -1.002, -1.0019999999999998, -1.002, -1.002, -1.003, -1.002, -1.007, -1.001, -1.0, -1.002, -0.502, -1.0059999999999998, -1.001, -1.0, 0.916, -1.001, -0.5029999999999999, -1.001, 0.976, -1.001, -1.001, -1.0039999999999998, -1.003, -1.007, -1.005, -0.001, -1.004, -1.0039999999999998, -1.001, -1.001, -1.001, -1.002, -1.001, -1.002, -1.002, -1.001, -0.503, -1.006, -1.002, -1.001, -1.001, -1.005, -1.002, -1.003, -1.003, -1.003, -1.0, -1.001, -0.001, -1.001, -1.003, 0.962, -1.002, -1.001, 0.833, -1.001, -1.004, -1.004, -1.002, -1.0, -1.001, -0.003, -1.003, -1.003, -1.0, -1.001, -1.001, -1.0, -1.003, -1.0039999999999998, -1.002, -1.002, 0.928, -1.002, -1.0, -1.001, -1.002, -1.001, -1.001, -0.003, 0.962, -1.006, 1.444, -1.0, -1.0, -1.002, -1.002, -1.003, -1.001, -1.001, -1.004, -1.001, -1.0019999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23461395576719282, "mean_inference_ms": 1.4755053821880386, "mean_action_processing_ms": 0.06278441463669303, "mean_env_wait_ms": 0.08888659459515072, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01936319495449547, "StateBufferConnector_ms": 0.0015515740178212397, "ViewRequirementAgentConnector_ms": 0.03151633158451369}}, "episode_reward_max": 1.4569999999999999, "episode_reward_min": -0.16700000000000004, "episode_reward_mean": 0.3010210084033613, "episode_len_mean": 16.42436974789916, "episodes_this_iter": 238, "policy_reward_min": {"red_0": -1.007, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.444}, "policy_reward_mean": {"red_0": 1.1198193277310926, "blue_0": -0.818798319327731}, "hist_stats": {"episode_reward": [0.46599999999999997, 0.45500000000000007, 0.44799999999999995, 0.43799999999999994, -0.03700000000000003, 0.46399999999999997, -0.038000000000000034, -0.09399999999999986, 0.4670000000000001, -0.07700000000000007, -0.027999999999999914, 1.412, 0.4630000000000001, 0.9670000000000001, -0.06900000000000006, 0.46199999999999997, 0.45799999999999996, 0.43699999999999983, 0.381, 0.3999999999999999, -0.04600000000000004, 0.46799999999999997, -0.07400000000000007, 0.45699999999999985, -0.038000000000000034, 0.4670000000000001, 0.45099999999999996, 0.45699999999999985, -0.04999999999999993, 0.46599999999999997, -0.025000000000000022, 0.46399999999999997, -0.03300000000000003, 0.4630000000000001, -0.09999999999999998, 0.46199999999999997, 0.44999999999999996, -0.030000000000000027, -0.030000000000000027, -0.030000000000000027, 0.46799999999999997, -0.04899999999999993, 1.428, 0.46499999999999986, -0.10799999999999998, -0.041999999999999926, 0.46499999999999986, 0.43799999999999994, -0.03199999999999992, 0.472, 0.47, 0.46599999999999997, -0.126, -0.04299999999999993, -0.031000000000000028, -0.02499999999999991, 1.45, 0.97, 0.47, 0.476, 0.476, 0.32200000000000006, 0.45599999999999996, -0.027000000000000024, 0.41500000000000004, 0.45100000000000007, 0.45100000000000007, 0.4590000000000001, 0.4590000000000001, 0.3639999999999999, 0.46599999999999997, -0.052000000000000046, 0.3639999999999999, -0.03500000000000003, 0.46899999999999986, 0.4660000000000002, -0.08100000000000007, 0.872, -0.028000000000000025, -0.03200000000000003, -0.038999999999999924, 0.2749999999999999, 0.45999999999999996, -0.039000000000000035, -0.031000000000000028, -0.04700000000000004, 0.46499999999999986, 0.47, -0.027000000000000024, 0.4630000000000001, 0.46599999999999997, 0.46599999999999997, -0.03400000000000003, 1.452, -0.04300000000000004, 0.45199999999999996, 0.4750000000000001, 0.472, -0.031000000000000028, -0.025000000000000022, -0.038000000000000034, 1.399, -0.039000000000000035, -0.02400000000000002, 0.474, 0.46899999999999986, 0.45500000000000007, 0.4710000000000001, -0.07899999999999996, 0.31100000000000017, -0.03600000000000003, -0.05300000000000005, 0.44799999999999995, 0.4590000000000001, -0.03500000000000003, -0.025000000000000022, 0.39400000000000013, -0.03300000000000003, 0.4630000000000001, -0.06300000000000006, -0.05800000000000005, 1.423, -0.038999999999999924, 0.472, -0.031000000000000028, -0.025000000000000022, 0.9209999999999998, -0.031000000000000028, -0.05400000000000005, -0.03499999999999992, 1.339, 0.45399999999999996, 0.45999999999999996, -0.03300000000000003, 0.43199999999999994, 1.436, -0.03500000000000003, 0.46399999999999997, -0.03300000000000003, 0.4670000000000001, 0.43799999999999994, 0.45599999999999996, -0.029000000000000026, 0.44199999999999995, -0.06700000000000006, 0.45299999999999985, 0.46799999999999997, 0.44099999999999984, -0.029000000000000026, 0.44899999999999984, -0.039000000000000035, -0.09099999999999997, -0.028000000000000025, 0.47, 0.41300000000000003, 0.47699999999999987, -0.038999999999999924, 0.4630000000000001, -0.027000000000000024, -0.08799999999999986, 0.43599999999999994, 0.45199999999999996, -0.031000000000000028, 0.476, -0.028000000000000025, -0.025000000000000022, 0.4570000000000001, 0.44300000000000006, 0.3879999999999999, 0.41700000000000004, 1.4569999999999999, -0.07000000000000006, -0.04699999999999993, 0.46899999999999986, 0.46899999999999986, -0.03400000000000003, -0.029000000000000026, -0.028000000000000025, -0.03600000000000003, 0.44700000000000006, -0.02200000000000002, 0.964, 0.3620000000000001, 0.46499999999999986, 0.4630000000000001, 0.45999999999999996, 0.4289999999999998, -0.05600000000000005, 0.45199999999999996, -0.04799999999999993, 0.4670000000000001, -0.030000000000000027, 0.46899999999999986, 1.454, -0.03799999999999992, 0.44199999999999995, 0.46199999999999997, -0.029000000000000026, 0.42599999999999993, -0.16700000000000004, 0.4750000000000001, 0.393, -0.052000000000000046, 0.46499999999999986, -0.027000000000000024, 0.44799999999999995, 1.452, 0.45799999999999996, -0.039000000000000035, 0.47299999999999986, -0.031000000000000028, 0.45999999999999996, -0.027000000000000024, 0.46399999999999997, 0.44200000000000017, -0.039000000000000035, -0.026000000000000023, 0.42700000000000005, 0.4590000000000001, -0.03600000000000003, -0.041000000000000036, 0.46499999999999986, 0.46899999999999986, -0.031000000000000028, 1.33, -0.038000000000000034, -0.138, 0.944, -0.03600000000000003, -0.040000000000000036, 0.46199999999999997, 0.46199999999999997, -0.029999999999999916, 0.46599999999999997, -0.031000000000000028, 0.4630000000000001, 0.4660000000000002, -0.03199999999999992], "episode_lengths": [11, 14, 17, 20, 12, 11, 12, 27, 11, 22, 9, 28, 12, 11, 20, 12, 13, 20, 39, 31, 14, 10, 24, 14, 12, 11, 16, 14, 14, 11, 8, 11, 10, 12, 32, 12, 16, 10, 10, 10, 10, 16, 22, 11, 31, 13, 11, 20, 10, 9, 10, 11, 41, 14, 10, 8, 15, 10, 10, 8, 8, 55, 14, 9, 27, 16, 16, 13, 13, 42, 11, 16, 43, 11, 9, 11, 185, 40, 9, 10, 12, 71, 12, 12, 10, 15, 11, 10, 9, 12, 11, 11, 11, 15, 14, 16, 8, 9, 10, 8, 11, 33, 13, 8, 8, 10, 14, 9, 24, 58, 11, 17, 17, 13, 11, 8, 33, 10, 12, 19, 18, 24, 12, 9, 10, 8, 24, 10, 17, 11, 51, 14, 13, 11, 22, 21, 11, 12, 11, 11, 20, 14, 9, 19, 21, 15, 10, 19, 9, 16, 12, 28, 9, 10, 28, 7, 11, 12, 9, 27, 21, 15, 10, 7, 9, 8, 13, 18, 35, 26, 14, 22, 14, 10, 10, 11, 9, 9, 11, 17, 7, 11, 44, 11, 12, 13, 22, 18, 15, 15, 10, 10, 10, 15, 12, 18, 12, 9, 24, 53, 8, 34, 16, 11, 9, 17, 15, 13, 12, 9, 10, 13, 9, 11, 18, 12, 8, 23, 13, 12, 13, 11, 10, 10, 55, 12, 44, 18, 12, 13, 12, 12, 9, 11, 10, 11, 11, 10], "policy_red_0_reward": [1.467, 1.458, 1.4489999999999998, 1.44, 0.964, 1.467, 0.964, 0.912, 1.467, 0.9269999999999999, -1.0, 1.416, 1.464, 1.467, 0.9319999999999999, 1.464, 1.4609999999999999, 1.438, 1.383, 1.405, 0.958, 1.47, 0.9269999999999999, 1.458, 0.964, 1.467, -0.5, 1.458, 0.953, 1.467, 0.976, 1.467, 0.969, 1.464, 0.904, 1.464, 1.452, 0.97, 0.97, 0.97, 1.47, -1.0, 1.434, 1.467, 0.894, 0.961, 1.467, 1.44, 0.97, 1.4729999999999999, 1.47, 1.467, 0.877, 0.958, 0.97, 0.976, 1.455, 1.47, 1.47, 1.476, 1.476, 1.334, 1.458, 0.973, 1.4180000000000001, 1.452, 1.452, 1.4609999999999999, 1.4609999999999999, 1.369, 1.467, 0.952, 1.369, 0.967, 1.4729999999999999, 1.467, -1.007, -0.502, 0.973, 0.97, 0.964, 1.286, 1.464, 0.964, 0.97, 0.955, 1.467, 1.47, -1.0, 1.464, 1.467, 1.467, 0.967, 1.455, 0.958, 1.452, 1.476, 1.4729999999999999, 0.97, 0.976, 0.966, 1.401, 0.961, 0.976, 1.476, 1.47, 1.4569999999999999, 1.4729999999999999, 0.9269999999999999, 0.8180000000000001, 0.967, 0.949, 1.4489999999999998, 1.4609999999999999, 0.967, 0.976, 1.401, 0.97, 1.464, 0.941, 0.945, 1.428, 0.964, 1.4729999999999999, 0.97, 0.976, 1.424, 0.97, 0.949, 0.967, 1.347, 1.4569999999999999, 1.4609999999999999, 0.967, -0.5, 1.4369999999999998, 0.967, 1.464, 0.967, 1.467, 1.44, 1.458, 0.973, 1.443, 0.9359999999999999, 1.455, 1.47, 1.443, 0.973, 1.452, 0.963, 0.916, 0.973, 1.47, 1.415, 0.979, 0.967, 1.464, 0.973, -1.004, 1.4369999999999998, 0.955, 0.97, -0.5, 0.973, 0.976, 1.4609999999999999, 1.446, 1.395, 1.4220000000000002, 1.458, 0.9339999999999999, 0.957, 1.47, 1.47, 0.967, 0.973, 0.973, 0.966, 1.4489999999999998, 0.979, 1.467, 1.3679999999999999, 1.467, 1.464, 1.4609999999999999, 1.434, 0.946, 1.455, 0.955, 1.47, 0.97, 1.47, 1.455, 0.963, 1.4449999999999998, -0.5, 0.973, 1.427, -1.0, 1.476, 1.397, 0.952, 1.467, 0.973, 1.4489999999999998, 1.455, 1.4609999999999999, 0.964, 1.4729999999999999, 0.97, 1.4609999999999999, 0.973, 1.467, 1.446, 0.963, 0.976, -0.501, 1.4609999999999999, 0.964, 0.96, 1.467, 1.47, 0.97, 1.333, -1.0, 0.868, -0.5, 0.964, 0.96, 1.464, 1.464, 0.973, 1.467, 0.97, 1.467, 1.467, 0.97], "policy_blue_0_reward": [-1.001, -1.003, -1.001, -1.002, -1.001, -1.003, -1.002, -1.0059999999999998, -1.0, -1.004, 0.972, -0.004, -1.001, -0.5, -1.001, -1.002, -1.003, -1.001, -1.002, -1.005, -1.004, -1.002, -1.001, -1.001, -1.002, -1.0, 0.951, -1.001, -1.003, -1.001, -1.001, -1.003, -1.002, -1.001, -1.004, -1.002, -1.002, -1.0, -1.0, -1.0, -1.002, 0.951, -0.006, -1.002, -1.002, -1.003, -1.002, -1.002, -1.0019999999999998, -1.001, -1.0, -1.001, -1.003, -1.001, -1.001, -1.001, -0.005, -0.5, -1.0, -1.0, -1.0, -1.012, -1.0019999999999998, -1.0, -1.003, -1.001, -1.001, -1.002, -1.002, -1.005, -1.001, -1.004, -1.005, -1.002, -1.004, -1.001, 0.9259999999999999, 1.374, -1.001, -1.002, -1.003, -1.011, -1.0039999999999998, -1.003, -1.001, -1.002, -1.002, -1.0, 0.973, -1.001, -1.001, -1.001, -1.001, -0.003, -1.001, -1.0, -1.001, -1.001, -1.001, -1.001, -1.004, -0.002, -1.0, -1.0, -1.002, -1.001, -1.002, -1.0019999999999998, -1.0059999999999998, -0.5069999999999999, -1.003, -1.002, -1.001, -1.002, -1.002, -1.001, -1.007, -1.003, -1.001, -1.004, -1.003, -0.005, -1.003, -1.001, -1.001, -1.001, -0.503, -1.001, -1.003, -1.0019999999999998, -0.008, -1.003, -1.001, -1.0, 0.9319999999999999, -0.001, -1.002, -1.0, -1.0, -1.0, -1.002, -1.002, -1.002, -1.001, -1.003, -1.002, -1.0019999999999998, -1.002, -1.002, -1.003, -1.002, -1.007, -1.001, -1.0, -1.002, -0.502, -1.0059999999999998, -1.001, -1.0, 0.916, -1.001, -0.5029999999999999, -1.001, 0.976, -1.001, -1.001, -1.0039999999999998, -1.003, -1.007, -1.005, -0.001, -1.004, -1.0039999999999998, -1.001, -1.001, -1.001, -1.002, -1.001, -1.002, -1.002, -1.001, -0.503, -1.006, -1.002, -1.001, -1.001, -1.005, -1.002, -1.003, -1.003, -1.003, -1.0, -1.001, -0.001, -1.001, -1.003, 0.962, -1.002, -1.001, 0.833, -1.001, -1.004, -1.004, -1.002, -1.0, -1.001, -0.003, -1.003, -1.003, -1.0, -1.001, -1.001, -1.0, -1.003, -1.0039999999999998, -1.002, -1.002, 0.928, -1.002, -1.0, -1.001, -1.002, -1.001, -1.001, -0.003, 0.962, -1.006, 1.444, -1.0, -1.0, -1.002, -1.002, -1.003, -1.001, -1.001, -1.004, -1.001, -1.0019999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23461395576719282, "mean_inference_ms": 1.4755053821880386, "mean_action_processing_ms": 0.06278441463669303, "mean_env_wait_ms": 0.08888659459515072, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01936319495449547, "StateBufferConnector_ms": 0.0015515740178212397, "ViewRequirementAgentConnector_ms": 0.03151633158451369}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000, "num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.82475019015776, "num_env_steps_trained_throughput_per_sec": 102.82475019015776, "timesteps_total": 112000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 224000, "timers": {"training_iteration_time_ms": 38853.011, "sample_time_ms": 7540.098, "learn_time_ms": 31295.568, "learn_throughput": 127.814, "synch_weights_time_ms": 16.842}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 112000, "num_agent_steps_sampled": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 1861, "training_iteration": 28, "trial_id": "d67e4_00000", "date": "2023-09-20_22-27-20", "timestamp": 1695263240, "time_this_iter_s": 38.910398960113525, "time_total_s": 1087.448452949524, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4707370>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1087.448452949524, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 34.33818181818182, "ram_util_percent": 48.278181818181835}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9090909090909091, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04090909090909091, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9090909090909091, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04090909090909091, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9090909090909091, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04090909090909091, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7225994620472194, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008907910809042126, "policy_loss": -0.018024971798877232, "vf_loss": 0.012209874527373661, "vf_explained_var": 0.6088305612405142, "kl": 0.00782414226904824, "entropy": 0.5087402912477652, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 27360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "sampler_results": {"episode_reward_max": 1.944, "episode_reward_min": -0.35, "episode_reward_mean": 0.3095636363636364, "episode_len_mean": 18.40909090909091, "episode_media": {}, "episodes_this_iter": 220, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.439}, "policy_reward_mean": {"red_0": 1.1415500000000003, "blue_0": -0.8319863636363636}, "custom_metrics": {"red_0/door_open_done_mean": 0.05, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9090909090909091, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04090909090909091, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9090909090909091, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04090909090909091, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9090909090909091, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04090909090909091, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.031000000000000028, 0.9630000000000001, -0.03700000000000003, -0.02100000000000002, 0.46199999999999997, 0.4630000000000001, -0.03700000000000003, 0.42999999999999994, 0.44799999999999995, 0.46399999999999997, 0.44399999999999995, 0.4630000000000001, 0.46499999999999986, -0.029999999999999916, 0.4670000000000001, -0.025000000000000022, 0.44300000000000006, -0.03399999999999992, -0.031000000000000028, -0.03399999999999992, -0.03699999999999992, 0.46899999999999986, 0.44899999999999984, -0.03700000000000003, -0.08399999999999996, -0.04300000000000004, -0.039000000000000035, 0.45500000000000007, -0.02400000000000002, -0.040000000000000036, 0.45699999999999985, 1.389, -0.09999999999999998, -0.03400000000000003, 0.45999999999999996, -0.03500000000000003, 0.373, 0.31699999999999995, -0.03399999999999992, -0.03700000000000003, -0.027000000000000024, 0.46199999999999997, -0.03500000000000003, -0.10899999999999999, -0.03200000000000003, -0.041000000000000036, 1.33, 0.4610000000000001, 0.4670000000000001, 0.46799999999999997, 0.42600000000000016, -0.03600000000000003, -0.04500000000000004, -0.04700000000000004, 1.4569999999999999, 0.46499999999999986, -0.03600000000000003, 0.44799999999999995, 0.41700000000000026, 0.4710000000000001, -0.03699999999999992, 0.46899999999999986, 0.45100000000000007, 0.4630000000000001, 0.46499999999999986, 0.45999999999999996, 0.45299999999999985, 0.46899999999999986, 1.4409999999999998, -0.027000000000000024, 0.4630000000000001, 0.42999999999999994, 0.46199999999999997, 0.45699999999999985, -0.03300000000000003, -0.031000000000000028, 0.46199999999999997, 0.45399999999999996, 0.42899999999999994, -0.04200000000000004, -0.026000000000000023, 0.44700000000000006, 1.443, -0.029000000000000026, 0.45699999999999985, 0.4630000000000001, -0.040000000000000036, -0.031000000000000028, 0.44500000000000006, 0.4630000000000001, -0.08099999999999996, 0.44399999999999995, 0.46099999999999985, 0.46799999999999997, 0.476, -0.038000000000000034, 0.4540000000000002, 0.42999999999999994, 0.46099999999999985, 0.45999999999999996, 0.46599999999999997, 0.472, 0.46099999999999985, 0.4540000000000002, -0.030000000000000027, -0.03300000000000003, 0.47299999999999986, 0.46399999999999997, 0.387, 0.4670000000000001, 0.3879999999999999, 0.4660000000000002, 0.45500000000000007, -0.028000000000000025, 0.44500000000000006, 0.4289999999999998, -0.031000000000000028, 0.45299999999999985, -0.04700000000000004, 1.4409999999999998, 1.4290000000000003, 0.4610000000000001, -0.030000000000000027, -0.30800000000000005, 0.366, 0.34099999999999997, -0.02400000000000002, -0.123, -0.02400000000000002, 0.43899999999999995, 0.44999999999999996, -0.02300000000000002, 0.3959999999999999, 0.43199999999999994, -0.031000000000000028, 0.46599999999999997, 0.44799999999999995, -0.038000000000000034, 0.44899999999999984, 0.46499999999999986, -0.041999999999999926, 0.46899999999999986, -0.06400000000000006, -0.262, -0.04800000000000004, -0.025000000000000022, 0.44399999999999995, 0.45899999999999996, 0.4630000000000001, 0.387, 0.47, -0.06800000000000006, 0.387, 0.46799999999999997, 0.4750000000000001, -0.10099999999999998, 0.42300000000000004, -0.03499999999999992, 0.06000000000000005, -0.041000000000000036, 0.29600000000000026, 0.9449999999999998, -0.04600000000000004, 0.41700000000000004, -0.03300000000000003, 0.4670000000000001, 0.45699999999999985, 0.46599999999999997, -0.031000000000000028, 1.395, 0.46899999999999986, 0.45799999999999996, 0.476, -0.04999999999999993, 0.469, 0.42700000000000005, 0.4670000000000001, 0.45999999999999996, 0.4670000000000001, -0.041000000000000036, -0.35, 0.44399999999999995, 1.944, -0.03600000000000003, 0.4590000000000001, 0.43199999999999994, 1.4529999999999998, -0.04500000000000004, -0.026000000000000023, -0.03700000000000003, -0.027000000000000024, -0.08299999999999996, -0.030000000000000027, -0.03400000000000003, 0.46799999999999997, 0.41300000000000003, 0.883, 0.45599999999999996, 0.43299999999999983, -0.05300000000000005, 0.4590000000000001, 0.391, -0.026000000000000023, -0.02100000000000002, -0.03600000000000003, 0.44799999999999995, 0.18500000000000005, 0.44999999999999996, 1.4329999999999998, 0.43699999999999983, 0.47, 0.472, -0.05800000000000005, -0.030999999999999917, 0.4540000000000002, 0.472, 0.397, -0.02200000000000002, -0.03500000000000003, 0.44799999999999995], "episode_lengths": [10, 12, 12, 7, 12, 12, 11, 22, 16, 12, 18, 12, 11, 9, 10, 8, 18, 11, 10, 10, 12, 10, 16, 12, 27, 14, 13, 14, 8, 13, 13, 34, 31, 11, 13, 10, 39, 56, 11, 12, 9, 12, 11, 32, 10, 13, 53, 12, 10, 10, 23, 12, 14, 15, 14, 11, 11, 17, 27, 9, 12, 10, 15, 12, 11, 13, 15, 10, 19, 8, 12, 22, 12, 13, 10, 10, 12, 14, 22, 13, 8, 17, 18, 9, 14, 12, 12, 10, 17, 12, 26, 17, 12, 10, 8, 12, 14, 22, 13, 12, 10, 9, 12, 14, 10, 10, 9, 11, 35, 10, 36, 11, 14, 9, 17, 22, 10, 15, 15, 18, 23, 11, 10, 87, 44, 50, 8, 34, 8, 20, 15, 7, 33, 22, 10, 11, 16, 12, 16, 11, 13, 10, 21, 241, 15, 8, 18, 13, 12, 31, 10, 22, 35, 10, 8, 31, 24, 11, 141, 13, 64, 18, 14, 24, 11, 11, 14, 11, 10, 33, 10, 14, 8, 15, 10, 23, 11, 13, 10, 13, 111, 17, 18, 11, 13, 22, 15, 15, 8, 12, 8, 27, 10, 11, 10, 26, 37, 14, 21, 17, 13, 34, 8, 7, 11, 16, 97, 16, 21, 20, 10, 9, 18, 10, 14, 9, 33, 7, 11, 17], "policy_red_0_reward": [0.97, 1.464, 0.964, 0.979, 1.464, 1.464, 0.966, 1.434, 1.452, 1.464, 1.446, 1.464, 1.467, 0.972, 1.47, 0.976, 1.446, 0.967, 0.97, 0.969, -1.0, 1.47, 1.452, 0.963, 0.918, 0.958, 0.961, 1.458, -1.0, 0.961, 1.46, 1.396, 0.903, 0.967, 1.4609999999999999, 0.97, 1.379, 0.829, 0.967, 0.964, 0.973, 1.464, 0.967, 0.903, 0.97, 0.961, 1.3359999999999999, 1.464, 1.47, 1.47, 1.431, 0.964, 0.958, 0.954, 1.458, 1.467, 0.967, 1.4489999999999998, 0.918, 1.4729999999999999, -1.0, 1.47, 1.455, 1.464, 1.467, -0.5, 1.455, 1.47, 1.443, 0.976, 1.464, 1.434, 1.463, 1.4609999999999999, 0.97, 0.97, 1.464, 1.458, -0.501, 0.961, 0.976, 1.4489999999999998, 1.4449999999999998, 0.973, 1.458, 1.464, 0.964, 0.97, 1.4489999999999998, 1.464, 0.921, 1.4489999999999998, 1.464, 1.47, 1.476, 0.963, 1.458, 1.434, 1.4609999999999999, 0.964, 1.47, 1.4729999999999999, 1.464, 1.458, 0.97, 0.97, 1.4729999999999999, 1.467, 1.393, 0.97, 1.392, 1.467, 1.4569999999999999, 0.973, 1.4489999999999998, 1.434, 0.97, 1.455, 0.955, 1.446, 1.431, 0.964, 0.97, 0.705, -0.5, 0.843, 0.976, 0.883, 0.976, -1.0, 1.455, 0.979, 1.401, 1.434, 0.97, 1.467, 1.452, 0.964, 1.452, 1.467, 0.961, 1.47, 0.9369999999999999, 0.272, 0.955, 0.976, 1.446, -0.501, 1.464, 0.893, 1.47, 0.9339999999999999, 1.393, 1.47, 1.476, 0.901, 1.427, 0.967, 1.077, 0.961, 1.306, 1.446, 0.957, 0.9199999999999999, 0.967, 1.467, 1.458, 1.467, 0.97, 1.4, 1.47, 1.458, 0.976, 0.951, -0.5, 1.431, 1.467, 1.4609999999999999, 0.97, 0.961, 0.662, 1.448, 1.446, 0.966, 1.4609999999999999, 1.4329999999999998, 1.455, 0.955, 0.975, 0.964, 0.976, 0.919, 0.97, 0.967, 1.47, 0.918, 1.389, 1.458, 1.4369999999999998, 0.949, 1.4609999999999999, 1.396, 0.976, 0.979, 0.967, 0.951, 1.195, 1.452, 1.4369999999999998, 1.44, 1.47, 1.4729999999999999, 0.946, 0.97, 1.458, 1.4729999999999999, 1.4, 0.979, 0.967, 1.448], "policy_blue_0_reward": [-1.001, -0.501, -1.001, -1.0, -1.002, -1.001, -1.003, -1.004, -1.004, -1.0, -1.002, -1.001, -1.002, -1.0019999999999998, -1.003, -1.001, -1.003, -1.001, -1.001, -1.003, 0.963, -1.001, -1.003, -1.0, -1.002, -1.001, -1.0, -1.003, 0.976, -1.001, -1.003, -0.007, -1.003, -1.001, -1.001, -1.005, -1.006, -0.512, -1.001, -1.001, -1.0, -1.002, -1.002, -1.012, -1.002, -1.002, -0.006, -1.003, -1.003, -1.002, -1.005, -1.0, -1.003, -1.001, -0.001, -1.002, -1.003, -1.001, -0.5009999999999999, -1.002, 0.963, -1.001, -1.004, -1.001, -1.002, 0.96, -1.002, -1.001, -0.002, -1.003, -1.001, -1.004, -1.001, -1.004, -1.003, -1.001, -1.002, -1.004, 0.9299999999999999, -1.003, -1.002, -1.002, -0.002, -1.002, -1.001, -1.001, -1.004, -1.001, -1.0039999999999998, -1.001, -1.002, -1.005, -1.003, -1.002, -1.0, -1.001, -1.0039999999999998, -1.004, -1.0, -0.5039999999999999, -1.004, -1.001, -1.003, -1.0039999999999998, -1.0, -1.003, -1.0, -1.003, -1.006, -0.5029999999999999, -1.004, -1.001, -1.0019999999999998, -1.001, -1.0039999999999998, -1.005, -1.001, -1.002, -1.002, -0.005, -0.002, -0.5029999999999999, -1.0, -1.013, 0.866, -0.502, -1.0, -1.006, -1.0, 1.439, -1.005, -1.002, -1.005, -1.002, -1.001, -1.001, -1.0039999999999998, -1.002, -1.003, -1.002, -1.003, -1.001, -1.001, -0.534, -1.003, -1.001, -1.002, 0.96, -1.001, -0.5059999999999999, -1.0, -1.002, -1.006, -1.002, -1.001, -1.002, -1.004, -1.0019999999999998, -1.017, -1.002, -1.0099999999999998, -0.501, -1.003, -0.5029999999999999, -1.0, -1.0, -1.001, -1.001, -1.001, -0.005, -1.001, -1.0, -0.5, -1.001, 0.969, -1.004, -1.0, -1.001, -0.503, -1.002, -1.012, -1.004, 0.498, -1.002, -1.002, -1.001, -0.002, -1.0, -1.001, -1.001, -1.003, -1.002, -1.0, -1.001, -1.002, -0.505, -0.506, -1.002, -1.004, -1.002, -1.002, -1.005, -1.002, -1.0, -1.003, -0.503, -1.01, -1.002, -0.004, -1.003, -1.0, -1.001, -1.004, -1.001, -1.0039999999999998, -1.001, -1.003, -1.001, -1.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23593720043382152, "mean_inference_ms": 1.4758955233719844, "mean_action_processing_ms": 0.06285044559746872, "mean_env_wait_ms": 0.08897449912869158, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01940862698988481, "StateBufferConnector_ms": 0.0015291300686922941, "ViewRequirementAgentConnector_ms": 0.03146594220941717}}, "episode_reward_max": 1.944, "episode_reward_min": -0.35, "episode_reward_mean": 0.3095636363636364, "episode_len_mean": 18.40909090909091, "episodes_this_iter": 220, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.439}, "policy_reward_mean": {"red_0": 1.1415500000000003, "blue_0": -0.8319863636363636}, "hist_stats": {"episode_reward": [-0.031000000000000028, 0.9630000000000001, -0.03700000000000003, -0.02100000000000002, 0.46199999999999997, 0.4630000000000001, -0.03700000000000003, 0.42999999999999994, 0.44799999999999995, 0.46399999999999997, 0.44399999999999995, 0.4630000000000001, 0.46499999999999986, -0.029999999999999916, 0.4670000000000001, -0.025000000000000022, 0.44300000000000006, -0.03399999999999992, -0.031000000000000028, -0.03399999999999992, -0.03699999999999992, 0.46899999999999986, 0.44899999999999984, -0.03700000000000003, -0.08399999999999996, -0.04300000000000004, -0.039000000000000035, 0.45500000000000007, -0.02400000000000002, -0.040000000000000036, 0.45699999999999985, 1.389, -0.09999999999999998, -0.03400000000000003, 0.45999999999999996, -0.03500000000000003, 0.373, 0.31699999999999995, -0.03399999999999992, -0.03700000000000003, -0.027000000000000024, 0.46199999999999997, -0.03500000000000003, -0.10899999999999999, -0.03200000000000003, -0.041000000000000036, 1.33, 0.4610000000000001, 0.4670000000000001, 0.46799999999999997, 0.42600000000000016, -0.03600000000000003, -0.04500000000000004, -0.04700000000000004, 1.4569999999999999, 0.46499999999999986, -0.03600000000000003, 0.44799999999999995, 0.41700000000000026, 0.4710000000000001, -0.03699999999999992, 0.46899999999999986, 0.45100000000000007, 0.4630000000000001, 0.46499999999999986, 0.45999999999999996, 0.45299999999999985, 0.46899999999999986, 1.4409999999999998, -0.027000000000000024, 0.4630000000000001, 0.42999999999999994, 0.46199999999999997, 0.45699999999999985, -0.03300000000000003, -0.031000000000000028, 0.46199999999999997, 0.45399999999999996, 0.42899999999999994, -0.04200000000000004, -0.026000000000000023, 0.44700000000000006, 1.443, -0.029000000000000026, 0.45699999999999985, 0.4630000000000001, -0.040000000000000036, -0.031000000000000028, 0.44500000000000006, 0.4630000000000001, -0.08099999999999996, 0.44399999999999995, 0.46099999999999985, 0.46799999999999997, 0.476, -0.038000000000000034, 0.4540000000000002, 0.42999999999999994, 0.46099999999999985, 0.45999999999999996, 0.46599999999999997, 0.472, 0.46099999999999985, 0.4540000000000002, -0.030000000000000027, -0.03300000000000003, 0.47299999999999986, 0.46399999999999997, 0.387, 0.4670000000000001, 0.3879999999999999, 0.4660000000000002, 0.45500000000000007, -0.028000000000000025, 0.44500000000000006, 0.4289999999999998, -0.031000000000000028, 0.45299999999999985, -0.04700000000000004, 1.4409999999999998, 1.4290000000000003, 0.4610000000000001, -0.030000000000000027, -0.30800000000000005, 0.366, 0.34099999999999997, -0.02400000000000002, -0.123, -0.02400000000000002, 0.43899999999999995, 0.44999999999999996, -0.02300000000000002, 0.3959999999999999, 0.43199999999999994, -0.031000000000000028, 0.46599999999999997, 0.44799999999999995, -0.038000000000000034, 0.44899999999999984, 0.46499999999999986, -0.041999999999999926, 0.46899999999999986, -0.06400000000000006, -0.262, -0.04800000000000004, -0.025000000000000022, 0.44399999999999995, 0.45899999999999996, 0.4630000000000001, 0.387, 0.47, -0.06800000000000006, 0.387, 0.46799999999999997, 0.4750000000000001, -0.10099999999999998, 0.42300000000000004, -0.03499999999999992, 0.06000000000000005, -0.041000000000000036, 0.29600000000000026, 0.9449999999999998, -0.04600000000000004, 0.41700000000000004, -0.03300000000000003, 0.4670000000000001, 0.45699999999999985, 0.46599999999999997, -0.031000000000000028, 1.395, 0.46899999999999986, 0.45799999999999996, 0.476, -0.04999999999999993, 0.469, 0.42700000000000005, 0.4670000000000001, 0.45999999999999996, 0.4670000000000001, -0.041000000000000036, -0.35, 0.44399999999999995, 1.944, -0.03600000000000003, 0.4590000000000001, 0.43199999999999994, 1.4529999999999998, -0.04500000000000004, -0.026000000000000023, -0.03700000000000003, -0.027000000000000024, -0.08299999999999996, -0.030000000000000027, -0.03400000000000003, 0.46799999999999997, 0.41300000000000003, 0.883, 0.45599999999999996, 0.43299999999999983, -0.05300000000000005, 0.4590000000000001, 0.391, -0.026000000000000023, -0.02100000000000002, -0.03600000000000003, 0.44799999999999995, 0.18500000000000005, 0.44999999999999996, 1.4329999999999998, 0.43699999999999983, 0.47, 0.472, -0.05800000000000005, -0.030999999999999917, 0.4540000000000002, 0.472, 0.397, -0.02200000000000002, -0.03500000000000003, 0.44799999999999995], "episode_lengths": [10, 12, 12, 7, 12, 12, 11, 22, 16, 12, 18, 12, 11, 9, 10, 8, 18, 11, 10, 10, 12, 10, 16, 12, 27, 14, 13, 14, 8, 13, 13, 34, 31, 11, 13, 10, 39, 56, 11, 12, 9, 12, 11, 32, 10, 13, 53, 12, 10, 10, 23, 12, 14, 15, 14, 11, 11, 17, 27, 9, 12, 10, 15, 12, 11, 13, 15, 10, 19, 8, 12, 22, 12, 13, 10, 10, 12, 14, 22, 13, 8, 17, 18, 9, 14, 12, 12, 10, 17, 12, 26, 17, 12, 10, 8, 12, 14, 22, 13, 12, 10, 9, 12, 14, 10, 10, 9, 11, 35, 10, 36, 11, 14, 9, 17, 22, 10, 15, 15, 18, 23, 11, 10, 87, 44, 50, 8, 34, 8, 20, 15, 7, 33, 22, 10, 11, 16, 12, 16, 11, 13, 10, 21, 241, 15, 8, 18, 13, 12, 31, 10, 22, 35, 10, 8, 31, 24, 11, 141, 13, 64, 18, 14, 24, 11, 11, 14, 11, 10, 33, 10, 14, 8, 15, 10, 23, 11, 13, 10, 13, 111, 17, 18, 11, 13, 22, 15, 15, 8, 12, 8, 27, 10, 11, 10, 26, 37, 14, 21, 17, 13, 34, 8, 7, 11, 16, 97, 16, 21, 20, 10, 9, 18, 10, 14, 9, 33, 7, 11, 17], "policy_red_0_reward": [0.97, 1.464, 0.964, 0.979, 1.464, 1.464, 0.966, 1.434, 1.452, 1.464, 1.446, 1.464, 1.467, 0.972, 1.47, 0.976, 1.446, 0.967, 0.97, 0.969, -1.0, 1.47, 1.452, 0.963, 0.918, 0.958, 0.961, 1.458, -1.0, 0.961, 1.46, 1.396, 0.903, 0.967, 1.4609999999999999, 0.97, 1.379, 0.829, 0.967, 0.964, 0.973, 1.464, 0.967, 0.903, 0.97, 0.961, 1.3359999999999999, 1.464, 1.47, 1.47, 1.431, 0.964, 0.958, 0.954, 1.458, 1.467, 0.967, 1.4489999999999998, 0.918, 1.4729999999999999, -1.0, 1.47, 1.455, 1.464, 1.467, -0.5, 1.455, 1.47, 1.443, 0.976, 1.464, 1.434, 1.463, 1.4609999999999999, 0.97, 0.97, 1.464, 1.458, -0.501, 0.961, 0.976, 1.4489999999999998, 1.4449999999999998, 0.973, 1.458, 1.464, 0.964, 0.97, 1.4489999999999998, 1.464, 0.921, 1.4489999999999998, 1.464, 1.47, 1.476, 0.963, 1.458, 1.434, 1.4609999999999999, 0.964, 1.47, 1.4729999999999999, 1.464, 1.458, 0.97, 0.97, 1.4729999999999999, 1.467, 1.393, 0.97, 1.392, 1.467, 1.4569999999999999, 0.973, 1.4489999999999998, 1.434, 0.97, 1.455, 0.955, 1.446, 1.431, 0.964, 0.97, 0.705, -0.5, 0.843, 0.976, 0.883, 0.976, -1.0, 1.455, 0.979, 1.401, 1.434, 0.97, 1.467, 1.452, 0.964, 1.452, 1.467, 0.961, 1.47, 0.9369999999999999, 0.272, 0.955, 0.976, 1.446, -0.501, 1.464, 0.893, 1.47, 0.9339999999999999, 1.393, 1.47, 1.476, 0.901, 1.427, 0.967, 1.077, 0.961, 1.306, 1.446, 0.957, 0.9199999999999999, 0.967, 1.467, 1.458, 1.467, 0.97, 1.4, 1.47, 1.458, 0.976, 0.951, -0.5, 1.431, 1.467, 1.4609999999999999, 0.97, 0.961, 0.662, 1.448, 1.446, 0.966, 1.4609999999999999, 1.4329999999999998, 1.455, 0.955, 0.975, 0.964, 0.976, 0.919, 0.97, 0.967, 1.47, 0.918, 1.389, 1.458, 1.4369999999999998, 0.949, 1.4609999999999999, 1.396, 0.976, 0.979, 0.967, 0.951, 1.195, 1.452, 1.4369999999999998, 1.44, 1.47, 1.4729999999999999, 0.946, 0.97, 1.458, 1.4729999999999999, 1.4, 0.979, 0.967, 1.448], "policy_blue_0_reward": [-1.001, -0.501, -1.001, -1.0, -1.002, -1.001, -1.003, -1.004, -1.004, -1.0, -1.002, -1.001, -1.002, -1.0019999999999998, -1.003, -1.001, -1.003, -1.001, -1.001, -1.003, 0.963, -1.001, -1.003, -1.0, -1.002, -1.001, -1.0, -1.003, 0.976, -1.001, -1.003, -0.007, -1.003, -1.001, -1.001, -1.005, -1.006, -0.512, -1.001, -1.001, -1.0, -1.002, -1.002, -1.012, -1.002, -1.002, -0.006, -1.003, -1.003, -1.002, -1.005, -1.0, -1.003, -1.001, -0.001, -1.002, -1.003, -1.001, -0.5009999999999999, -1.002, 0.963, -1.001, -1.004, -1.001, -1.002, 0.96, -1.002, -1.001, -0.002, -1.003, -1.001, -1.004, -1.001, -1.004, -1.003, -1.001, -1.002, -1.004, 0.9299999999999999, -1.003, -1.002, -1.002, -0.002, -1.002, -1.001, -1.001, -1.004, -1.001, -1.0039999999999998, -1.001, -1.002, -1.005, -1.003, -1.002, -1.0, -1.001, -1.0039999999999998, -1.004, -1.0, -0.5039999999999999, -1.004, -1.001, -1.003, -1.0039999999999998, -1.0, -1.003, -1.0, -1.003, -1.006, -0.5029999999999999, -1.004, -1.001, -1.0019999999999998, -1.001, -1.0039999999999998, -1.005, -1.001, -1.002, -1.002, -0.005, -0.002, -0.5029999999999999, -1.0, -1.013, 0.866, -0.502, -1.0, -1.006, -1.0, 1.439, -1.005, -1.002, -1.005, -1.002, -1.001, -1.001, -1.0039999999999998, -1.002, -1.003, -1.002, -1.003, -1.001, -1.001, -0.534, -1.003, -1.001, -1.002, 0.96, -1.001, -0.5059999999999999, -1.0, -1.002, -1.006, -1.002, -1.001, -1.002, -1.004, -1.0019999999999998, -1.017, -1.002, -1.0099999999999998, -0.501, -1.003, -0.5029999999999999, -1.0, -1.0, -1.001, -1.001, -1.001, -0.005, -1.001, -1.0, -0.5, -1.001, 0.969, -1.004, -1.0, -1.001, -0.503, -1.002, -1.012, -1.004, 0.498, -1.002, -1.002, -1.001, -0.002, -1.0, -1.001, -1.001, -1.003, -1.002, -1.0, -1.001, -1.002, -0.505, -0.506, -1.002, -1.004, -1.002, -1.002, -1.005, -1.002, -1.0, -1.003, -0.503, -1.01, -1.002, -0.004, -1.003, -1.0, -1.001, -1.004, -1.001, -1.0039999999999998, -1.001, -1.003, -1.001, -1.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23593720043382152, "mean_inference_ms": 1.4758955233719844, "mean_action_processing_ms": 0.06285044559746872, "mean_env_wait_ms": 0.08897449912869158, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01940862698988481, "StateBufferConnector_ms": 0.0015291300686922941, "ViewRequirementAgentConnector_ms": 0.03146594220941717}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000, "num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.49445391915216, "num_env_steps_trained_throughput_per_sec": 102.49445391915216, "timesteps_total": 116000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 232000, "timers": {"training_iteration_time_ms": 38863.9, "sample_time_ms": 7551.416, "learn_time_ms": 31295.108, "learn_throughput": 127.816, "synch_weights_time_ms": 16.871}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 116000, "num_agent_steps_sampled": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 2081, "training_iteration": 29, "trial_id": "d67e4_00000", "date": "2023-09-20_22-27-59", "timestamp": 1695263279, "time_this_iter_s": 39.03494691848755, "time_total_s": 1126.4833998680115, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687b370>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1126.4833998680115, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 33.573214285714286, "ram_util_percent": 48.40535714285714}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05612244897959184, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8979591836734694, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03571428571428571, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8979591836734694, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03571428571428571, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8979591836734694, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03571428571428571, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8046821656326453, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010575309185151127, "policy_loss": -0.021420643141997667, "vf_loss": 0.010095907448946189, "vf_explained_var": 0.685367769934237, "kl": 0.014069558214189561, "entropy": 0.5339206668858727, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 28320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "sampler_results": {"episode_reward_max": 1.458, "episode_reward_min": -0.4700000000000001, "episode_reward_mean": 0.33189795918367343, "episode_len_mean": 21.316326530612244, "episode_media": {}, "episodes_this_iter": 196, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.028}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.973}, "policy_reward_mean": {"red_0": 1.1716734693877553, "blue_0": -0.8397755102040817}, "custom_metrics": {"red_0/door_open_done_mean": 0.05612244897959184, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8979591836734694, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03571428571428571, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8979591836734694, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03571428571428571, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8979591836734694, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03571428571428571, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.45999999999999996, -0.04600000000000004, 1.4170000000000003, 0.43599999999999994, -0.041000000000000036, -0.02100000000000002, -0.03200000000000003, 0.46199999999999997, -0.030000000000000027, 0.1339999999999999, 1.454, -0.03500000000000003, -0.030000000000000027, 0.4670000000000001, -0.028000000000000025, 0.45999999999999996, 0.345, 0.43900000000000006, 0.4750000000000001, 0.42999999999999994, 0.45199999999999996, 0.474, 0.46199999999999997, -0.04700000000000004, 0.46599999999999997, -0.05400000000000005, -0.062000000000000055, 0.46599999999999997, -0.11599999999999999, 0.45500000000000007, -0.03300000000000003, 0.4159999999999999, 0.97, -0.030000000000000027, -0.04600000000000004, 0.263, 0.41999999999999993, 0.46399999999999997, -0.040000000000000036, -0.028000000000000025, 0.44099999999999995, 0.42599999999999993, -0.031000000000000028, 0.44799999999999995, 0.46799999999999997, 0.46499999999999986, -0.02400000000000002, -0.03299999999999992, 0.43100000000000005, 1.3860000000000001, 0.4630000000000001, 0.4630000000000001, 0.45699999999999985, 0.47, -0.028000000000000025, 0.46899999999999986, 0.45500000000000007, 0.45599999999999996, -0.04600000000000004, 0.4620000000000002, 0.43299999999999983, 0.45799999999999996, 0.45899999999999996, 0.47299999999999986, 0.45699999999999985, 0.476, -0.05300000000000005, 0.43900000000000006, -0.05400000000000005, 0.47299999999999986, 0.44399999999999995, -0.03300000000000003, 0.472, -0.139, 0.46899999999999986, -0.040000000000000036, 0.46399999999999997, 0.46599999999999997, 0.46099999999999985, -0.027000000000000024, -0.03400000000000003, 0.46099999999999985, -0.027000000000000024, 0.45100000000000007, -0.03200000000000003, 0.45799999999999996, 0.41700000000000004, 0.4630000000000001, 0.42700000000000005, 0.385, 1.4489999999999998, 0.44700000000000006, 0.44999999999999996, 0.43199999999999994, 0.45399999999999996, 0.43299999999999983, 0.46599999999999997, -0.039000000000000035, 0.361, 0.47, 0.46799999999999997, -0.03200000000000003, 1.429, -0.025000000000000022, -0.03300000000000003, 0.368, -0.03700000000000003, -0.03400000000000003, 0.45399999999999996, 0.9510000000000001, 0.46599999999999997, 0.45500000000000007, -0.029000000000000026, 1.424, -0.03600000000000003, -0.031000000000000028, -0.02300000000000002, 0.42399999999999993, 0.363, 0.9670000000000001, 0.81, -0.02100000000000002, 0.46899999999999986, 0.4670000000000001, 0.4670000000000001, -0.041000000000000036, -0.02400000000000002, 0.4500000000000002, -0.027000000000000024, -0.029000000000000026, -0.040000000000000036, 0.472, 1.424, 0.46499999999999986, 0.4590000000000001, 0.45100000000000007, -0.18400000000000005, -0.040000000000000036, -0.028000000000000025, 0.43699999999999983, 0.4750000000000001, 0.4750000000000001, -0.03200000000000003, 0.46199999999999997, 0.46199999999999997, -0.02400000000000002, -0.028000000000000025, -0.025000000000000022, -0.028000000000000025, 0.47, -0.029000000000000026, 0.4590000000000001, 0.4710000000000001, 0.4790000000000001, 0.47, 0.43999999999999995, 1.236, -0.025999999999999912, -0.4700000000000001, -0.028999999999999915, -0.04500000000000004, -0.03400000000000003, 0.44499999999999984, 0.45199999999999996, 0.42100000000000004, -0.03700000000000003, -0.027000000000000024, 0.9630000000000001, 0.46599999999999997, -0.21300000000000008, -0.04700000000000004, -0.027000000000000024, 0.42399999999999993, 0.46599999999999997, 0.47299999999999986, 0.4620000000000002, 1.458, -0.039000000000000035, 0.45699999999999985, -0.02100000000000002, 0.46599999999999997, 0.46499999999999986, 0.4790000000000001, -0.028000000000000025, -0.02400000000000002, 1.442, 1.4569999999999999, 0.44399999999999995, 0.472, 0.45399999999999996, -0.030999999999999917, 0.472, -0.028000000000000025, 0.4620000000000002, 0.363, 0.40000000000000013], "episode_lengths": [13, 15, 26, 20, 13, 7, 10, 12, 9, 99, 15, 11, 10, 11, 9, 13, 50, 19, 8, 22, 16, 8, 11, 15, 11, 18, 20, 11, 32, 14, 10, 26, 10, 9, 15, 76, 25, 11, 12, 9, 19, 24, 10, 16, 10, 11, 8, 10, 22, 36, 11, 12, 14, 10, 9, 10, 14, 14, 14, 12, 21, 14, 12, 9, 14, 8, 16, 20, 18, 9, 18, 11, 9, 203, 10, 13, 11, 11, 13, 9, 11, 12, 9, 16, 10, 13, 27, 12, 23, 36, 16, 16, 15, 22, 15, 21, 11, 12, 44, 10, 10, 10, 23, 8, 10, 42, 12, 11, 14, 16, 300, 14, 9, 24, 11, 10, 7, 24, 41, 11, 59, 7, 10, 11, 11, 13, 8, 14, 9, 9, 12, 9, 23, 11, 13, 16, 59, 13, 9, 20, 8, 8, 10, 12, 12, 8, 9, 8, 9, 10, 9, 13, 9, 7, 10, 19, 242, 8, 147, 9, 14, 11, 18, 15, 25, 12, 9, 12, 11, 61, 15, 9, 24, 11, 9, 11, 13, 12, 14, 7, 11, 11, 7, 9, 8, 19, 14, 17, 9, 300, 10, 9, 9, 12, 42, 31], "policy_red_0_reward": [-0.5, 0.955, 1.4220000000000002, 1.44, 0.961, 0.979, 0.97, 1.464, 0.972, 1.157, 1.455, 0.967, 0.97, 1.467, 0.973, 1.4609999999999999, 1.35, 1.443, 1.476, 1.4329999999999998, 1.452, 1.476, 1.467, 0.954, 1.467, 0.946, 0.94, 1.467, 0.892, 1.458, 0.97, 1.4220000000000002, 1.47, 0.973, 0.955, -0.5, 1.423, 1.467, 0.961, 0.973, 0.941, 1.428, 0.97, 1.452, 1.47, 1.467, 0.976, 0.97, 1.434, 1.391, 1.467, 1.464, 1.458, 1.47, 0.972, 1.47, 1.458, 1.458, 0.956, 1.464, 1.4369999999999998, 1.458, -0.5, 1.4729999999999999, 1.458, 1.476, 0.951, 1.44, 0.946, 1.4729999999999999, 1.446, 0.967, 1.4729999999999999, 0.889, 1.47, 0.961, -0.5, 1.467, 1.4609999999999999, 0.973, 0.967, 1.464, 0.973, 1.452, 0.97, 1.4609999999999999, 1.417, 1.464, 1.431, 1.392, 1.452, 1.452, 1.455, 1.434, 1.455, 1.4369999999999998, 1.467, 0.964, 1.366, 1.47, 1.47, 0.97, 1.431, 0.976, 0.97, -0.5, 0.964, 0.967, 1.458, 1.452, -0.001, 1.458, 0.973, 1.428, 0.967, 0.97, 0.979, 1.428, 1.3719999999999999, 1.467, 1.321, 0.979, 1.47, 1.467, 1.467, 0.961, 0.976, 1.458, -1.0, 0.973, 0.961, 1.4729999999999999, 1.429, 1.467, 1.4609999999999999, 1.452, 0.823, 0.961, 0.973, 1.44, 1.476, 1.476, 0.97, 1.464, 1.464, 0.976, 0.973, 0.976, 0.973, 0.97, 0.973, 1.4609999999999999, 1.4729999999999999, 0.979, 1.47, 1.442, 0.766, 0.976, 0.5529999999999999, 0.973, 0.958, 0.967, 1.446, 1.455, 1.424, 0.964, 0.973, 1.464, 1.467, 0.7959999999999999, 0.955, 0.973, 1.428, 1.467, 1.4729999999999999, 1.467, 1.4609999999999999, 0.964, 1.458, 0.979, 1.467, 1.467, 0.979, 0.973, 0.976, 1.443, 1.458, 1.448, 1.4729999999999999, 0.5, 0.97, -0.5, 0.973, 1.464, 1.37, 1.407], "policy_blue_0_reward": [0.96, -1.001, -0.005, -1.004, -1.002, -1.0, -1.002, -1.002, -1.002, -1.023, -0.001, -1.002, -1.0, -1.0, -1.001, -1.001, -1.005, -1.004, -1.001, -1.003, -1.0, -1.002, -1.005, -1.001, -1.001, -1.0, -1.002, -1.001, -1.008, -1.003, -1.003, -1.006, -0.5, -1.003, -1.001, 0.763, -1.003, -1.003, -1.001, -1.001, -0.5, -1.002, -1.001, -1.004, -1.002, -1.002, -1.0, -1.003, -1.003, -0.005, -1.004, -1.001, -1.001, -1.0, -1.0, -1.001, -1.003, -1.002, -1.002, -1.0019999999999998, -1.004, -1.0, 0.959, -1.0, -1.001, -1.0, -1.004, -1.001, -1.0, -1.0, -1.002, -1.0, -1.001, -1.028, -1.001, -1.001, 0.964, -1.001, -1.0, -1.0, -1.001, -1.003, -1.0, -1.001, -1.002, -1.003, -1.0, -1.001, -1.004, -1.007, -0.003, -1.005, -1.005, -1.002, -1.001, -1.004, -1.001, -1.003, -1.005, -1.0, -1.002, -1.002, -0.002, -1.001, -1.003, 0.868, -1.001, -1.001, -1.004, -0.501, 0.46699999999999997, -1.003, -1.002, -0.004, -1.003, -1.001, -1.002, -1.004, -1.009, -0.5, -0.511, -1.0, -1.001, -1.0, -1.0, -1.002, -1.0, -1.0079999999999998, 0.973, -1.002, -1.001, -1.001, -0.005, -1.002, -1.0019999999999998, -1.001, -1.007, -1.001, -1.001, -1.003, -1.001, -1.001, -1.002, -1.002, -1.002, -1.0, -1.001, -1.001, -1.001, -0.5, -1.002, -1.002, -1.002, -0.5, -1.0, -1.002, 0.47, -1.0019999999999998, -1.023, -1.0019999999999998, -1.003, -1.001, -1.001, -1.003, -1.003, -1.001, -1.0, -0.501, -1.001, -1.009, -1.002, -1.0, -1.004, -1.001, -1.0, -1.005, -0.003, -1.003, -1.001, -1.0, -1.001, -1.002, -0.5, -1.001, -1.0, -0.001, -0.001, -1.0039999999999998, -1.001, -0.046000000000000034, -1.001, 0.972, -1.001, -1.0019999999999998, -1.007, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23666669663460657, "mean_inference_ms": 1.4760683746991008, "mean_action_processing_ms": 0.06278257472133558, "mean_env_wait_ms": 0.0889398455632989, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01967336450304304, "StateBufferConnector_ms": 0.0016371814572081274, "ViewRequirementAgentConnector_ms": 0.03184159191287294}}, "episode_reward_max": 1.458, "episode_reward_min": -0.4700000000000001, "episode_reward_mean": 0.33189795918367343, "episode_len_mean": 21.316326530612244, "episodes_this_iter": 196, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.028}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.973}, "policy_reward_mean": {"red_0": 1.1716734693877553, "blue_0": -0.8397755102040817}, "hist_stats": {"episode_reward": [0.45999999999999996, -0.04600000000000004, 1.4170000000000003, 0.43599999999999994, -0.041000000000000036, -0.02100000000000002, -0.03200000000000003, 0.46199999999999997, -0.030000000000000027, 0.1339999999999999, 1.454, -0.03500000000000003, -0.030000000000000027, 0.4670000000000001, -0.028000000000000025, 0.45999999999999996, 0.345, 0.43900000000000006, 0.4750000000000001, 0.42999999999999994, 0.45199999999999996, 0.474, 0.46199999999999997, -0.04700000000000004, 0.46599999999999997, -0.05400000000000005, -0.062000000000000055, 0.46599999999999997, -0.11599999999999999, 0.45500000000000007, -0.03300000000000003, 0.4159999999999999, 0.97, -0.030000000000000027, -0.04600000000000004, 0.263, 0.41999999999999993, 0.46399999999999997, -0.040000000000000036, -0.028000000000000025, 0.44099999999999995, 0.42599999999999993, -0.031000000000000028, 0.44799999999999995, 0.46799999999999997, 0.46499999999999986, -0.02400000000000002, -0.03299999999999992, 0.43100000000000005, 1.3860000000000001, 0.4630000000000001, 0.4630000000000001, 0.45699999999999985, 0.47, -0.028000000000000025, 0.46899999999999986, 0.45500000000000007, 0.45599999999999996, -0.04600000000000004, 0.4620000000000002, 0.43299999999999983, 0.45799999999999996, 0.45899999999999996, 0.47299999999999986, 0.45699999999999985, 0.476, -0.05300000000000005, 0.43900000000000006, -0.05400000000000005, 0.47299999999999986, 0.44399999999999995, -0.03300000000000003, 0.472, -0.139, 0.46899999999999986, -0.040000000000000036, 0.46399999999999997, 0.46599999999999997, 0.46099999999999985, -0.027000000000000024, -0.03400000000000003, 0.46099999999999985, -0.027000000000000024, 0.45100000000000007, -0.03200000000000003, 0.45799999999999996, 0.41700000000000004, 0.4630000000000001, 0.42700000000000005, 0.385, 1.4489999999999998, 0.44700000000000006, 0.44999999999999996, 0.43199999999999994, 0.45399999999999996, 0.43299999999999983, 0.46599999999999997, -0.039000000000000035, 0.361, 0.47, 0.46799999999999997, -0.03200000000000003, 1.429, -0.025000000000000022, -0.03300000000000003, 0.368, -0.03700000000000003, -0.03400000000000003, 0.45399999999999996, 0.9510000000000001, 0.46599999999999997, 0.45500000000000007, -0.029000000000000026, 1.424, -0.03600000000000003, -0.031000000000000028, -0.02300000000000002, 0.42399999999999993, 0.363, 0.9670000000000001, 0.81, -0.02100000000000002, 0.46899999999999986, 0.4670000000000001, 0.4670000000000001, -0.041000000000000036, -0.02400000000000002, 0.4500000000000002, -0.027000000000000024, -0.029000000000000026, -0.040000000000000036, 0.472, 1.424, 0.46499999999999986, 0.4590000000000001, 0.45100000000000007, -0.18400000000000005, -0.040000000000000036, -0.028000000000000025, 0.43699999999999983, 0.4750000000000001, 0.4750000000000001, -0.03200000000000003, 0.46199999999999997, 0.46199999999999997, -0.02400000000000002, -0.028000000000000025, -0.025000000000000022, -0.028000000000000025, 0.47, -0.029000000000000026, 0.4590000000000001, 0.4710000000000001, 0.4790000000000001, 0.47, 0.43999999999999995, 1.236, -0.025999999999999912, -0.4700000000000001, -0.028999999999999915, -0.04500000000000004, -0.03400000000000003, 0.44499999999999984, 0.45199999999999996, 0.42100000000000004, -0.03700000000000003, -0.027000000000000024, 0.9630000000000001, 0.46599999999999997, -0.21300000000000008, -0.04700000000000004, -0.027000000000000024, 0.42399999999999993, 0.46599999999999997, 0.47299999999999986, 0.4620000000000002, 1.458, -0.039000000000000035, 0.45699999999999985, -0.02100000000000002, 0.46599999999999997, 0.46499999999999986, 0.4790000000000001, -0.028000000000000025, -0.02400000000000002, 1.442, 1.4569999999999999, 0.44399999999999995, 0.472, 0.45399999999999996, -0.030999999999999917, 0.472, -0.028000000000000025, 0.4620000000000002, 0.363, 0.40000000000000013], "episode_lengths": [13, 15, 26, 20, 13, 7, 10, 12, 9, 99, 15, 11, 10, 11, 9, 13, 50, 19, 8, 22, 16, 8, 11, 15, 11, 18, 20, 11, 32, 14, 10, 26, 10, 9, 15, 76, 25, 11, 12, 9, 19, 24, 10, 16, 10, 11, 8, 10, 22, 36, 11, 12, 14, 10, 9, 10, 14, 14, 14, 12, 21, 14, 12, 9, 14, 8, 16, 20, 18, 9, 18, 11, 9, 203, 10, 13, 11, 11, 13, 9, 11, 12, 9, 16, 10, 13, 27, 12, 23, 36, 16, 16, 15, 22, 15, 21, 11, 12, 44, 10, 10, 10, 23, 8, 10, 42, 12, 11, 14, 16, 300, 14, 9, 24, 11, 10, 7, 24, 41, 11, 59, 7, 10, 11, 11, 13, 8, 14, 9, 9, 12, 9, 23, 11, 13, 16, 59, 13, 9, 20, 8, 8, 10, 12, 12, 8, 9, 8, 9, 10, 9, 13, 9, 7, 10, 19, 242, 8, 147, 9, 14, 11, 18, 15, 25, 12, 9, 12, 11, 61, 15, 9, 24, 11, 9, 11, 13, 12, 14, 7, 11, 11, 7, 9, 8, 19, 14, 17, 9, 300, 10, 9, 9, 12, 42, 31], "policy_red_0_reward": [-0.5, 0.955, 1.4220000000000002, 1.44, 0.961, 0.979, 0.97, 1.464, 0.972, 1.157, 1.455, 0.967, 0.97, 1.467, 0.973, 1.4609999999999999, 1.35, 1.443, 1.476, 1.4329999999999998, 1.452, 1.476, 1.467, 0.954, 1.467, 0.946, 0.94, 1.467, 0.892, 1.458, 0.97, 1.4220000000000002, 1.47, 0.973, 0.955, -0.5, 1.423, 1.467, 0.961, 0.973, 0.941, 1.428, 0.97, 1.452, 1.47, 1.467, 0.976, 0.97, 1.434, 1.391, 1.467, 1.464, 1.458, 1.47, 0.972, 1.47, 1.458, 1.458, 0.956, 1.464, 1.4369999999999998, 1.458, -0.5, 1.4729999999999999, 1.458, 1.476, 0.951, 1.44, 0.946, 1.4729999999999999, 1.446, 0.967, 1.4729999999999999, 0.889, 1.47, 0.961, -0.5, 1.467, 1.4609999999999999, 0.973, 0.967, 1.464, 0.973, 1.452, 0.97, 1.4609999999999999, 1.417, 1.464, 1.431, 1.392, 1.452, 1.452, 1.455, 1.434, 1.455, 1.4369999999999998, 1.467, 0.964, 1.366, 1.47, 1.47, 0.97, 1.431, 0.976, 0.97, -0.5, 0.964, 0.967, 1.458, 1.452, -0.001, 1.458, 0.973, 1.428, 0.967, 0.97, 0.979, 1.428, 1.3719999999999999, 1.467, 1.321, 0.979, 1.47, 1.467, 1.467, 0.961, 0.976, 1.458, -1.0, 0.973, 0.961, 1.4729999999999999, 1.429, 1.467, 1.4609999999999999, 1.452, 0.823, 0.961, 0.973, 1.44, 1.476, 1.476, 0.97, 1.464, 1.464, 0.976, 0.973, 0.976, 0.973, 0.97, 0.973, 1.4609999999999999, 1.4729999999999999, 0.979, 1.47, 1.442, 0.766, 0.976, 0.5529999999999999, 0.973, 0.958, 0.967, 1.446, 1.455, 1.424, 0.964, 0.973, 1.464, 1.467, 0.7959999999999999, 0.955, 0.973, 1.428, 1.467, 1.4729999999999999, 1.467, 1.4609999999999999, 0.964, 1.458, 0.979, 1.467, 1.467, 0.979, 0.973, 0.976, 1.443, 1.458, 1.448, 1.4729999999999999, 0.5, 0.97, -0.5, 0.973, 1.464, 1.37, 1.407], "policy_blue_0_reward": [0.96, -1.001, -0.005, -1.004, -1.002, -1.0, -1.002, -1.002, -1.002, -1.023, -0.001, -1.002, -1.0, -1.0, -1.001, -1.001, -1.005, -1.004, -1.001, -1.003, -1.0, -1.002, -1.005, -1.001, -1.001, -1.0, -1.002, -1.001, -1.008, -1.003, -1.003, -1.006, -0.5, -1.003, -1.001, 0.763, -1.003, -1.003, -1.001, -1.001, -0.5, -1.002, -1.001, -1.004, -1.002, -1.002, -1.0, -1.003, -1.003, -0.005, -1.004, -1.001, -1.001, -1.0, -1.0, -1.001, -1.003, -1.002, -1.002, -1.0019999999999998, -1.004, -1.0, 0.959, -1.0, -1.001, -1.0, -1.004, -1.001, -1.0, -1.0, -1.002, -1.0, -1.001, -1.028, -1.001, -1.001, 0.964, -1.001, -1.0, -1.0, -1.001, -1.003, -1.0, -1.001, -1.002, -1.003, -1.0, -1.001, -1.004, -1.007, -0.003, -1.005, -1.005, -1.002, -1.001, -1.004, -1.001, -1.003, -1.005, -1.0, -1.002, -1.002, -0.002, -1.001, -1.003, 0.868, -1.001, -1.001, -1.004, -0.501, 0.46699999999999997, -1.003, -1.002, -0.004, -1.003, -1.001, -1.002, -1.004, -1.009, -0.5, -0.511, -1.0, -1.001, -1.0, -1.0, -1.002, -1.0, -1.0079999999999998, 0.973, -1.002, -1.001, -1.001, -0.005, -1.002, -1.0019999999999998, -1.001, -1.007, -1.001, -1.001, -1.003, -1.001, -1.001, -1.002, -1.002, -1.002, -1.0, -1.001, -1.001, -1.001, -0.5, -1.002, -1.002, -1.002, -0.5, -1.0, -1.002, 0.47, -1.0019999999999998, -1.023, -1.0019999999999998, -1.003, -1.001, -1.001, -1.003, -1.003, -1.001, -1.0, -0.501, -1.001, -1.009, -1.002, -1.0, -1.004, -1.001, -1.0, -1.005, -0.003, -1.003, -1.001, -1.0, -1.001, -1.002, -0.5, -1.001, -1.0, -0.001, -0.001, -1.0039999999999998, -1.001, -0.046000000000000034, -1.001, 0.972, -1.001, -1.0019999999999998, -1.007, -1.007]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23666669663460657, "mean_inference_ms": 1.4760683746991008, "mean_action_processing_ms": 0.06278257472133558, "mean_env_wait_ms": 0.0889398455632989, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01967336450304304, "StateBufferConnector_ms": 0.0016371814572081274, "ViewRequirementAgentConnector_ms": 0.03184159191287294}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000, "num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.69800976672003, "num_env_steps_trained_throughput_per_sec": 102.69800976672003, "timesteps_total": 120000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 240000, "timers": {"training_iteration_time_ms": 38909.884, "sample_time_ms": 7554.248, "learn_time_ms": 31338.244, "learn_throughput": 127.64, "synch_weights_time_ms": 16.89}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 120000, "num_agent_steps_sampled": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 2277, "training_iteration": 30, "trial_id": "d67e4_00000", "date": "2023-09-20_22-28-38", "timestamp": 1695263318, "time_this_iter_s": 38.956804037094116, "time_total_s": 1165.4402039051056, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fee60>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1165.4402039051056, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 34.99285714285714, "ram_util_percent": 48.39464285714286}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05371900826446281, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8966942148760331, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.049586776859504134, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8966942148760331, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.049586776859504134, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8966942148760331, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.049586776859504134, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7265077981166541, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00513169494382358, "policy_loss": -0.01439177095174576, "vf_loss": 0.012944003529264591, "vf_explained_var": 0.5663632126525044, "kl": 0.007284062850232753, "entropy": 0.48975386631985507, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 29280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "sampler_results": {"episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.4640000000000001, "episode_reward_mean": 0.2775041322314049, "episode_len_mean": 16.03305785123967, "episode_media": {}, "episodes_this_iter": 242, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.024}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.455}, "policy_reward_mean": {"red_0": 1.095900826446281, "blue_0": -0.8183966942148759}, "custom_metrics": {"red_0/door_open_done_mean": 0.05371900826446281, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8966942148760331, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.049586776859504134, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8966942148760331, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.049586776859504134, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8966942148760331, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.049586776859504134, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.435, -0.03400000000000003, 0.46799999999999997, -0.061000000000000054, -0.02400000000000002, -0.026000000000000023, 0.46399999999999997, -0.03200000000000003, 0.469, -0.02100000000000002, 0.2999999999999998, -0.027999999999999914, 0.4630000000000001, -0.04200000000000004, 1.45, 0.45599999999999996, 0.928, -0.08299999999999996, 0.353, 0.361, -0.03200000000000003, -0.030000000000000027, 0.44999999999999996, 0.9609999999999999, -0.029000000000000026, 0.3039999999999998, -0.040000000000000036, 0.47, -0.030999999999999917, -0.03700000000000003, 0.42100000000000004, -0.03799999999999992, 0.4670000000000001, 0.46699999999999997, -0.03600000000000003, -0.031000000000000028, -0.04699999999999993, 0.45100000000000007, -0.03200000000000003, -0.026999999999999913, -0.03399999999999992, 0.4670000000000001, 0.46599999999999997, 1.4249999999999998, -0.06399999999999995, -0.028000000000000025, 0.953, 0.45500000000000007, -0.03399999999999992, 0.44099999999999984, -0.03799999999999992, 0.45999999999999996, -0.026000000000000023, 0.472, -0.050000000000000044, 0.45999999999999996, -0.026000000000000023, 0.46799999999999997, -0.03300000000000003, -0.03500000000000003, -0.04399999999999993, 0.44100000000000006, 0.45599999999999996, -0.03199999999999992, -0.028000000000000025, 1.42, 0.45199999999999996, 0.44899999999999984, -0.03400000000000003, 0.34799999999999986, 1.456, 0.956, 0.46599999999999997, -0.02499999999999991, 1.434, 1.4180000000000001, 0.4590000000000001, 1.2690000000000001, 0.19799999999999995, -0.038000000000000034, 0.45999999999999996, -0.049000000000000044, -0.061000000000000054, -0.03200000000000003, 0.45699999999999985, -0.06900000000000006, -0.04500000000000004, 0.44899999999999984, 0.45599999999999996, -0.06300000000000006, 0.47, 0.4710000000000001, 0.40200000000000014, -0.02200000000000002, -0.03600000000000003, -0.025000000000000022, 0.4500000000000002, -0.03400000000000003, -0.07200000000000006, -0.027000000000000024, -0.027999999999999914, 0.43699999999999983, 0.45199999999999996, 0.46199999999999997, 0.472, -0.03200000000000003, 0.929, 0.46899999999999986, 0.45300000000000007, 0.46899999999999986, 0.46599999999999997, 0.45599999999999996, 0.4119999999999999, -0.06400000000000006, -0.04500000000000004, 0.4630000000000001, -0.03600000000000003, -0.06300000000000006, 0.4590000000000001, -0.03700000000000003, -0.031000000000000028, 0.43000000000000016, 0.45599999999999996, -0.03500000000000003, -0.049000000000000044, -0.031000000000000028, -0.018999999999999906, 0.46599999999999997, 0.46399999999999997, -0.05600000000000005, -0.041000000000000036, -0.04400000000000004, 0.41000000000000014, 0.4590000000000001, 0.4670000000000001, -0.06899999999999995, 1.435, 0.46099999999999985, -0.041000000000000036, -0.02100000000000002, 0.45999999999999996, 0.47, 0.45399999999999996, -0.02200000000000002, -0.031000000000000028, -0.4640000000000001, 0.01200000000000001, 1.4580000000000002, -0.028000000000000025, -0.038000000000000034, -0.04300000000000004, -0.029000000000000026, 0.44599999999999995, 0.46599999999999997, -0.05300000000000005, -0.03200000000000003, 0.46199999999999997, -0.031000000000000028, -0.03300000000000003, 1.4609999999999999, -0.030999999999999917, 0.45599999999999996, 0.472, 0.45399999999999996, -0.028999999999999915, 0.958, -0.04800000000000004, 0.44099999999999984, -0.03699999999999992, -0.03200000000000003, 0.4750000000000001, -0.029000000000000026, 0.44899999999999984, 0.45500000000000007, 0.4590000000000001, 0.44599999999999995, -0.02100000000000002, 0.46799999999999997, 0.4670000000000001, 0.4750000000000001, 0.46499999999999986, 0.9249999999999998, -0.04200000000000004, -0.02400000000000002, 0.45500000000000007, -0.03200000000000003, -0.04200000000000004, -0.03600000000000003, -0.08799999999999997, 0.923, -0.02200000000000002, 0.45199999999999996, 0.46799999999999997, 0.46599999999999997, -0.03200000000000003, 1.345, -0.040000000000000036, 0.472, -0.03600000000000003, -0.02100000000000002, 0.45500000000000007, 0.43799999999999994, -0.04300000000000004, 0.45100000000000007, 0.4630000000000001, 1.393, 0.46599999999999997, -0.038999999999999924, 0.46099999999999985, 0.46599999999999997, 0.44199999999999995, -0.025000000000000022, 0.46899999999999986, -0.049000000000000044, 0.46099999999999985, 0.46399999999999997, -0.02200000000000002, -0.038000000000000034, 0.46599999999999997, -0.03200000000000003, -0.07600000000000007, 0.43999999999999995, -0.12, -0.03500000000000003, 0.46399999999999997, 0.43199999999999994, -0.039000000000000035, -0.04600000000000004, -0.026000000000000023, -0.028000000000000025, -0.03600000000000003, 0.40900000000000003, -0.03200000000000003, -0.061999999999999944, 0.46399999999999997, -0.049000000000000044, -0.030000000000000027, 0.45599999999999996, 0.45999999999999996, -0.03700000000000003, -0.03300000000000003, 0.46199999999999997], "episode_lengths": [20, 11, 10, 19, 8, 8, 11, 10, 10, 7, 63, 9, 12, 13, 16, 14, 23, 27, 47, 43, 10, 10, 16, 13, 9, 56, 13, 9, 10, 12, 25, 12, 10, 11, 11, 10, 14, 15, 10, 8, 10, 11, 11, 24, 20, 9, 15, 15, 11, 18, 12, 13, 8, 9, 16, 12, 8, 10, 11, 11, 14, 18, 13, 10, 9, 25, 15, 16, 10, 46, 14, 14, 11, 8, 20, 26, 13, 64, 87, 12, 13, 16, 20, 10, 13, 21, 14, 16, 14, 20, 10, 9, 30, 7, 12, 8, 16, 11, 22, 9, 9, 20, 16, 12, 9, 10, 23, 9, 15, 10, 11, 14, 29, 19, 15, 12, 11, 19, 13, 12, 10, 22, 13, 11, 15, 10, 6, 11, 12, 18, 13, 14, 29, 13, 11, 22, 21, 12, 13, 7, 13, 10, 15, 7, 10, 146, 154, 13, 9, 12, 13, 9, 18, 11, 17, 10, 12, 10, 10, 13, 10, 14, 9, 14, 9, 13, 15, 19, 11, 10, 8, 9, 16, 14, 13, 18, 7, 10, 11, 8, 11, 24, 12, 8, 14, 10, 13, 11, 28, 23, 7, 15, 10, 11, 10, 49, 13, 9, 11, 7, 14, 20, 14, 16, 11, 33, 11, 12, 13, 11, 18, 8, 10, 16, 12, 11, 7, 12, 11, 10, 24, 19, 38, 11, 12, 22, 12, 14, 8, 9, 11, 29, 10, 19, 12, 16, 10, 14, 13, 12, 11, 12], "policy_red_0_reward": [1.44, 0.967, 1.47, 0.942, 0.976, 0.976, 1.467, 0.97, -0.5, 0.979, 1.31, 0.973, 1.464, 0.96, 1.452, 1.458, -0.501, 0.919, 1.357, 1.371, 0.97, 0.97, 1.452, 1.4609999999999999, 0.973, 1.311, 0.961, 1.4729999999999999, -1.0, 0.964, -0.501, 0.963, 1.47, -0.5, 0.967, 0.97, 0.957, 1.455, 0.97, 0.976, 0.968, 1.467, 1.467, 1.427, 0.94, 0.973, -0.502, 1.455, -1.001, 1.446, 0.964, 1.4609999999999999, 0.976, 1.4729999999999999, 0.952, 1.464, 0.976, 1.47, 0.967, 0.967, 0.958, 0.945, 1.4609999999999999, 0.97, 0.973, 1.425, 1.455, 1.452, 0.97, 1.359, 1.458, 1.458, 1.467, -1.0, 1.44, 1.42, 1.4609999999999999, 1.278, 0.711, 0.964, 1.4609999999999999, 0.952, 0.94, 0.97, 1.4609999999999999, 0.9349999999999999, 0.958, 0.951, 1.458, 0.94, 1.47, 1.4729999999999999, 1.409, 0.979, 0.964, 0.975, 1.452, 0.967, 0.9339999999999999, 0.973, 0.973, 1.44, 1.452, 1.464, -0.5, 0.97, 1.431, 1.4729999999999999, 1.455, 1.47, 1.467, 1.458, 1.413, 0.942, 0.955, 1.464, 0.967, 0.94, 1.4609999999999999, 0.964, 0.97, 1.434, 1.4609999999999999, 0.966, 0.955, 0.97, 0.982, 1.467, -0.5, 0.945, 0.961, 0.958, 1.413, 1.4609999999999999, 1.467, 0.9329999999999999, 1.4369999999999998, 1.464, 0.961, 0.979, 1.4609999999999999, 1.47, 1.455, 0.979, 0.97, 0.5599999999999999, 0.532, 1.4609999999999999, 0.973, 0.964, 0.961, 0.973, 1.446, 1.467, 0.947, 0.97, 1.464, 0.97, 0.97, 1.4609999999999999, 0.97, 1.458, 0.973, 1.458, 0.973, 1.4609999999999999, 0.955, 1.443, 0.967, 0.97, 1.476, 0.973, 1.452, 1.458, 1.4609999999999999, 1.446, 0.979, 1.47, 1.467, 0.975, 1.467, 1.427, 0.96, 0.976, 1.458, 0.97, 0.961, 0.967, 0.915, 1.4260000000000002, 0.979, 1.455, 1.47, 1.467, 0.97, 1.353, 0.961, 1.4729999999999999, 0.967, 0.979, 0.957, 1.44, 0.958, 1.452, 1.467, 1.401, 1.467, 0.963, 1.4609999999999999, 1.467, 1.4449999999999998, 0.975, 1.47, 0.951, 1.464, 1.467, 0.979, 0.963, 1.467, 0.97, 0.9279999999999999, 1.443, 0.884, 0.967, 1.464, 1.434, 0.964, 0.958, 0.976, 0.973, 0.967, 0.913, 0.97, -1.002, 1.464, 0.952, 0.97, 1.458, 1.4609999999999999, 0.964, -1.0, 1.464], "policy_blue_0_reward": [-0.005, -1.001, -1.0019999999999998, -1.003, -1.0, -1.002, -1.003, -1.002, 0.969, -1.0, -1.01, -1.001, -1.001, -1.002, -0.002, -1.002, 1.429, -1.002, -1.004, -1.01, -1.002, -1.0, -1.002, -0.5, -1.002, -1.007, -1.001, -1.003, 0.969, -1.001, 0.922, -1.001, -1.003, 0.967, -1.003, -1.001, -1.0039999999999998, -1.004, -1.002, -1.003, -1.0019999999999998, -1.0, -1.001, -0.002, -1.0039999999999998, -1.001, 1.455, -1.0, 0.967, -1.005, -1.0019999999999998, -1.001, -1.002, -1.001, -1.002, -1.004, -1.002, -1.002, -1.0, -1.002, -1.0019999999999998, -0.5039999999999999, -1.005, -1.0019999999999998, -1.001, -0.005, -1.003, -1.003, -1.004, -1.011, -0.002, -0.502, -1.001, 0.975, -0.006, -0.002, -1.002, -0.009000000000000001, -0.5129999999999999, -1.002, -1.001, -1.001, -1.001, -1.002, -1.004, -1.004, -1.003, -0.502, -1.002, -1.003, -1.0, -1.002, -1.007, -1.001, -1.0, -1.0, -1.0019999999999998, -1.001, -1.006, -1.0, -1.001, -1.003, -1.0, -1.002, 0.972, -1.002, -0.502, -1.004, -1.0019999999999998, -1.001, -1.001, -1.0019999999999998, -1.001, -1.006, -1.0, -1.001, -1.003, -1.003, -1.002, -1.001, -1.001, -1.0039999999999998, -1.005, -1.001, -1.004, -1.001, -1.001, -1.001, 0.964, -1.001, -1.002, -1.002, -1.003, -1.002, -1.0, -1.0019999999999998, -0.002, -1.003, -1.002, -1.0, -1.001, -1.0, -1.001, -1.001, -1.001, -1.024, -0.5199999999999999, -0.003, -1.001, -1.002, -1.004, -1.002, -1.0, -1.001, -1.0, -1.002, -1.002, -1.001, -1.003, 0.0, -1.001, -1.002, -0.501, -1.004, -1.0019999999999998, -0.503, -1.003, -1.002, -1.0039999999999998, -1.002, -1.001, -1.002, -1.003, -1.003, -1.002, -1.0, -1.0, -1.002, -1.0, -0.5, -1.002, -0.502, -1.002, -1.0, -1.003, -1.002, -1.003, -1.003, -1.003, -0.503, -1.001, -1.003, -1.002, -1.001, -1.002, -0.008, -1.001, -1.001, -1.003, -1.0, -0.5019999999999999, -1.002, -1.001, -1.001, -1.004, -0.008, -1.001, -1.0019999999999998, -1.0, -1.001, -1.003, -1.0, -1.001, -1.0, -1.003, -1.003, -1.001, -1.001, -1.001, -1.002, -1.004, -1.003, -1.004, -1.002, -1.0, -1.0019999999999998, -1.003, -1.004, -1.002, -1.001, -1.003, -0.504, -1.002, 0.94, -1.0, -1.001, -1.0, -1.0019999999999998, -1.001, -1.001, 0.967, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23755349300927223, "mean_inference_ms": 1.4752887544215658, "mean_action_processing_ms": 0.06278320759162892, "mean_env_wait_ms": 0.08895004780689461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021982833373645122, "StateBufferConnector_ms": 0.0016180444354853354, "ViewRequirementAgentConnector_ms": 0.033100232605106576}}, "episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.4640000000000001, "episode_reward_mean": 0.2775041322314049, "episode_len_mean": 16.03305785123967, "episodes_this_iter": 242, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.024}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.455}, "policy_reward_mean": {"red_0": 1.095900826446281, "blue_0": -0.8183966942148759}, "hist_stats": {"episode_reward": [1.435, -0.03400000000000003, 0.46799999999999997, -0.061000000000000054, -0.02400000000000002, -0.026000000000000023, 0.46399999999999997, -0.03200000000000003, 0.469, -0.02100000000000002, 0.2999999999999998, -0.027999999999999914, 0.4630000000000001, -0.04200000000000004, 1.45, 0.45599999999999996, 0.928, -0.08299999999999996, 0.353, 0.361, -0.03200000000000003, -0.030000000000000027, 0.44999999999999996, 0.9609999999999999, -0.029000000000000026, 0.3039999999999998, -0.040000000000000036, 0.47, -0.030999999999999917, -0.03700000000000003, 0.42100000000000004, -0.03799999999999992, 0.4670000000000001, 0.46699999999999997, -0.03600000000000003, -0.031000000000000028, -0.04699999999999993, 0.45100000000000007, -0.03200000000000003, -0.026999999999999913, -0.03399999999999992, 0.4670000000000001, 0.46599999999999997, 1.4249999999999998, -0.06399999999999995, -0.028000000000000025, 0.953, 0.45500000000000007, -0.03399999999999992, 0.44099999999999984, -0.03799999999999992, 0.45999999999999996, -0.026000000000000023, 0.472, -0.050000000000000044, 0.45999999999999996, -0.026000000000000023, 0.46799999999999997, -0.03300000000000003, -0.03500000000000003, -0.04399999999999993, 0.44100000000000006, 0.45599999999999996, -0.03199999999999992, -0.028000000000000025, 1.42, 0.45199999999999996, 0.44899999999999984, -0.03400000000000003, 0.34799999999999986, 1.456, 0.956, 0.46599999999999997, -0.02499999999999991, 1.434, 1.4180000000000001, 0.4590000000000001, 1.2690000000000001, 0.19799999999999995, -0.038000000000000034, 0.45999999999999996, -0.049000000000000044, -0.061000000000000054, -0.03200000000000003, 0.45699999999999985, -0.06900000000000006, -0.04500000000000004, 0.44899999999999984, 0.45599999999999996, -0.06300000000000006, 0.47, 0.4710000000000001, 0.40200000000000014, -0.02200000000000002, -0.03600000000000003, -0.025000000000000022, 0.4500000000000002, -0.03400000000000003, -0.07200000000000006, -0.027000000000000024, -0.027999999999999914, 0.43699999999999983, 0.45199999999999996, 0.46199999999999997, 0.472, -0.03200000000000003, 0.929, 0.46899999999999986, 0.45300000000000007, 0.46899999999999986, 0.46599999999999997, 0.45599999999999996, 0.4119999999999999, -0.06400000000000006, -0.04500000000000004, 0.4630000000000001, -0.03600000000000003, -0.06300000000000006, 0.4590000000000001, -0.03700000000000003, -0.031000000000000028, 0.43000000000000016, 0.45599999999999996, -0.03500000000000003, -0.049000000000000044, -0.031000000000000028, -0.018999999999999906, 0.46599999999999997, 0.46399999999999997, -0.05600000000000005, -0.041000000000000036, -0.04400000000000004, 0.41000000000000014, 0.4590000000000001, 0.4670000000000001, -0.06899999999999995, 1.435, 0.46099999999999985, -0.041000000000000036, -0.02100000000000002, 0.45999999999999996, 0.47, 0.45399999999999996, -0.02200000000000002, -0.031000000000000028, -0.4640000000000001, 0.01200000000000001, 1.4580000000000002, -0.028000000000000025, -0.038000000000000034, -0.04300000000000004, -0.029000000000000026, 0.44599999999999995, 0.46599999999999997, -0.05300000000000005, -0.03200000000000003, 0.46199999999999997, -0.031000000000000028, -0.03300000000000003, 1.4609999999999999, -0.030999999999999917, 0.45599999999999996, 0.472, 0.45399999999999996, -0.028999999999999915, 0.958, -0.04800000000000004, 0.44099999999999984, -0.03699999999999992, -0.03200000000000003, 0.4750000000000001, -0.029000000000000026, 0.44899999999999984, 0.45500000000000007, 0.4590000000000001, 0.44599999999999995, -0.02100000000000002, 0.46799999999999997, 0.4670000000000001, 0.4750000000000001, 0.46499999999999986, 0.9249999999999998, -0.04200000000000004, -0.02400000000000002, 0.45500000000000007, -0.03200000000000003, -0.04200000000000004, -0.03600000000000003, -0.08799999999999997, 0.923, -0.02200000000000002, 0.45199999999999996, 0.46799999999999997, 0.46599999999999997, -0.03200000000000003, 1.345, -0.040000000000000036, 0.472, -0.03600000000000003, -0.02100000000000002, 0.45500000000000007, 0.43799999999999994, -0.04300000000000004, 0.45100000000000007, 0.4630000000000001, 1.393, 0.46599999999999997, -0.038999999999999924, 0.46099999999999985, 0.46599999999999997, 0.44199999999999995, -0.025000000000000022, 0.46899999999999986, -0.049000000000000044, 0.46099999999999985, 0.46399999999999997, -0.02200000000000002, -0.038000000000000034, 0.46599999999999997, -0.03200000000000003, -0.07600000000000007, 0.43999999999999995, -0.12, -0.03500000000000003, 0.46399999999999997, 0.43199999999999994, -0.039000000000000035, -0.04600000000000004, -0.026000000000000023, -0.028000000000000025, -0.03600000000000003, 0.40900000000000003, -0.03200000000000003, -0.061999999999999944, 0.46399999999999997, -0.049000000000000044, -0.030000000000000027, 0.45599999999999996, 0.45999999999999996, -0.03700000000000003, -0.03300000000000003, 0.46199999999999997], "episode_lengths": [20, 11, 10, 19, 8, 8, 11, 10, 10, 7, 63, 9, 12, 13, 16, 14, 23, 27, 47, 43, 10, 10, 16, 13, 9, 56, 13, 9, 10, 12, 25, 12, 10, 11, 11, 10, 14, 15, 10, 8, 10, 11, 11, 24, 20, 9, 15, 15, 11, 18, 12, 13, 8, 9, 16, 12, 8, 10, 11, 11, 14, 18, 13, 10, 9, 25, 15, 16, 10, 46, 14, 14, 11, 8, 20, 26, 13, 64, 87, 12, 13, 16, 20, 10, 13, 21, 14, 16, 14, 20, 10, 9, 30, 7, 12, 8, 16, 11, 22, 9, 9, 20, 16, 12, 9, 10, 23, 9, 15, 10, 11, 14, 29, 19, 15, 12, 11, 19, 13, 12, 10, 22, 13, 11, 15, 10, 6, 11, 12, 18, 13, 14, 29, 13, 11, 22, 21, 12, 13, 7, 13, 10, 15, 7, 10, 146, 154, 13, 9, 12, 13, 9, 18, 11, 17, 10, 12, 10, 10, 13, 10, 14, 9, 14, 9, 13, 15, 19, 11, 10, 8, 9, 16, 14, 13, 18, 7, 10, 11, 8, 11, 24, 12, 8, 14, 10, 13, 11, 28, 23, 7, 15, 10, 11, 10, 49, 13, 9, 11, 7, 14, 20, 14, 16, 11, 33, 11, 12, 13, 11, 18, 8, 10, 16, 12, 11, 7, 12, 11, 10, 24, 19, 38, 11, 12, 22, 12, 14, 8, 9, 11, 29, 10, 19, 12, 16, 10, 14, 13, 12, 11, 12], "policy_red_0_reward": [1.44, 0.967, 1.47, 0.942, 0.976, 0.976, 1.467, 0.97, -0.5, 0.979, 1.31, 0.973, 1.464, 0.96, 1.452, 1.458, -0.501, 0.919, 1.357, 1.371, 0.97, 0.97, 1.452, 1.4609999999999999, 0.973, 1.311, 0.961, 1.4729999999999999, -1.0, 0.964, -0.501, 0.963, 1.47, -0.5, 0.967, 0.97, 0.957, 1.455, 0.97, 0.976, 0.968, 1.467, 1.467, 1.427, 0.94, 0.973, -0.502, 1.455, -1.001, 1.446, 0.964, 1.4609999999999999, 0.976, 1.4729999999999999, 0.952, 1.464, 0.976, 1.47, 0.967, 0.967, 0.958, 0.945, 1.4609999999999999, 0.97, 0.973, 1.425, 1.455, 1.452, 0.97, 1.359, 1.458, 1.458, 1.467, -1.0, 1.44, 1.42, 1.4609999999999999, 1.278, 0.711, 0.964, 1.4609999999999999, 0.952, 0.94, 0.97, 1.4609999999999999, 0.9349999999999999, 0.958, 0.951, 1.458, 0.94, 1.47, 1.4729999999999999, 1.409, 0.979, 0.964, 0.975, 1.452, 0.967, 0.9339999999999999, 0.973, 0.973, 1.44, 1.452, 1.464, -0.5, 0.97, 1.431, 1.4729999999999999, 1.455, 1.47, 1.467, 1.458, 1.413, 0.942, 0.955, 1.464, 0.967, 0.94, 1.4609999999999999, 0.964, 0.97, 1.434, 1.4609999999999999, 0.966, 0.955, 0.97, 0.982, 1.467, -0.5, 0.945, 0.961, 0.958, 1.413, 1.4609999999999999, 1.467, 0.9329999999999999, 1.4369999999999998, 1.464, 0.961, 0.979, 1.4609999999999999, 1.47, 1.455, 0.979, 0.97, 0.5599999999999999, 0.532, 1.4609999999999999, 0.973, 0.964, 0.961, 0.973, 1.446, 1.467, 0.947, 0.97, 1.464, 0.97, 0.97, 1.4609999999999999, 0.97, 1.458, 0.973, 1.458, 0.973, 1.4609999999999999, 0.955, 1.443, 0.967, 0.97, 1.476, 0.973, 1.452, 1.458, 1.4609999999999999, 1.446, 0.979, 1.47, 1.467, 0.975, 1.467, 1.427, 0.96, 0.976, 1.458, 0.97, 0.961, 0.967, 0.915, 1.4260000000000002, 0.979, 1.455, 1.47, 1.467, 0.97, 1.353, 0.961, 1.4729999999999999, 0.967, 0.979, 0.957, 1.44, 0.958, 1.452, 1.467, 1.401, 1.467, 0.963, 1.4609999999999999, 1.467, 1.4449999999999998, 0.975, 1.47, 0.951, 1.464, 1.467, 0.979, 0.963, 1.467, 0.97, 0.9279999999999999, 1.443, 0.884, 0.967, 1.464, 1.434, 0.964, 0.958, 0.976, 0.973, 0.967, 0.913, 0.97, -1.002, 1.464, 0.952, 0.97, 1.458, 1.4609999999999999, 0.964, -1.0, 1.464], "policy_blue_0_reward": [-0.005, -1.001, -1.0019999999999998, -1.003, -1.0, -1.002, -1.003, -1.002, 0.969, -1.0, -1.01, -1.001, -1.001, -1.002, -0.002, -1.002, 1.429, -1.002, -1.004, -1.01, -1.002, -1.0, -1.002, -0.5, -1.002, -1.007, -1.001, -1.003, 0.969, -1.001, 0.922, -1.001, -1.003, 0.967, -1.003, -1.001, -1.0039999999999998, -1.004, -1.002, -1.003, -1.0019999999999998, -1.0, -1.001, -0.002, -1.0039999999999998, -1.001, 1.455, -1.0, 0.967, -1.005, -1.0019999999999998, -1.001, -1.002, -1.001, -1.002, -1.004, -1.002, -1.002, -1.0, -1.002, -1.0019999999999998, -0.5039999999999999, -1.005, -1.0019999999999998, -1.001, -0.005, -1.003, -1.003, -1.004, -1.011, -0.002, -0.502, -1.001, 0.975, -0.006, -0.002, -1.002, -0.009000000000000001, -0.5129999999999999, -1.002, -1.001, -1.001, -1.001, -1.002, -1.004, -1.004, -1.003, -0.502, -1.002, -1.003, -1.0, -1.002, -1.007, -1.001, -1.0, -1.0, -1.0019999999999998, -1.001, -1.006, -1.0, -1.001, -1.003, -1.0, -1.002, 0.972, -1.002, -0.502, -1.004, -1.0019999999999998, -1.001, -1.001, -1.0019999999999998, -1.001, -1.006, -1.0, -1.001, -1.003, -1.003, -1.002, -1.001, -1.001, -1.0039999999999998, -1.005, -1.001, -1.004, -1.001, -1.001, -1.001, 0.964, -1.001, -1.002, -1.002, -1.003, -1.002, -1.0, -1.0019999999999998, -0.002, -1.003, -1.002, -1.0, -1.001, -1.0, -1.001, -1.001, -1.001, -1.024, -0.5199999999999999, -0.003, -1.001, -1.002, -1.004, -1.002, -1.0, -1.001, -1.0, -1.002, -1.002, -1.001, -1.003, 0.0, -1.001, -1.002, -0.501, -1.004, -1.0019999999999998, -0.503, -1.003, -1.002, -1.0039999999999998, -1.002, -1.001, -1.002, -1.003, -1.003, -1.002, -1.0, -1.0, -1.002, -1.0, -0.5, -1.002, -0.502, -1.002, -1.0, -1.003, -1.002, -1.003, -1.003, -1.003, -0.503, -1.001, -1.003, -1.002, -1.001, -1.002, -0.008, -1.001, -1.001, -1.003, -1.0, -0.5019999999999999, -1.002, -1.001, -1.001, -1.004, -0.008, -1.001, -1.0019999999999998, -1.0, -1.001, -1.003, -1.0, -1.001, -1.0, -1.003, -1.003, -1.001, -1.001, -1.001, -1.002, -1.004, -1.003, -1.004, -1.002, -1.0, -1.0019999999999998, -1.003, -1.004, -1.002, -1.001, -1.003, -0.504, -1.002, 0.94, -1.0, -1.001, -1.0, -1.0019999999999998, -1.001, -1.001, 0.967, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23755349300927223, "mean_inference_ms": 1.4752887544215658, "mean_action_processing_ms": 0.06278320759162892, "mean_env_wait_ms": 0.08895004780689461, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021982833373645122, "StateBufferConnector_ms": 0.0016180444354853354, "ViewRequirementAgentConnector_ms": 0.033100232605106576}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000, "num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.82128544959488, "num_env_steps_trained_throughput_per_sec": 101.82128544959488, "timesteps_total": 124000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 248000, "timers": {"training_iteration_time_ms": 38951.903, "sample_time_ms": 7582.983, "learn_time_ms": 31351.503, "learn_throughput": 127.586, "synch_weights_time_ms": 16.914}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 124000, "num_agent_steps_sampled": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 2519, "training_iteration": 31, "trial_id": "d67e4_00000", "date": "2023-09-20_22-29-18", "timestamp": 1695263358, "time_this_iter_s": 39.29360508918762, "time_total_s": 1204.7338089942932, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687b640>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1204.7338089942932, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 33.760714285714286, "ram_util_percent": 48.442857142857136}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05761316872427984, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9094650205761317, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03292181069958848, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9094650205761317, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02880658436213992, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9094650205761317, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02880658436213992, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9217164432009062, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00834095560227676, "policy_loss": -0.016197614869937146, "vf_loss": 0.010068596228181074, "vf_explained_var": 0.6359509725744525, "kl": 0.007241430573689437, "entropy": 0.43628226198876896, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 30240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "sampler_results": {"episode_reward_max": 1.458, "episode_reward_min": -0.126, "episode_reward_mean": 0.3149588477366255, "episode_len_mean": 16.05761316872428, "episode_media": {}, "episodes_this_iter": 243, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.976}, "policy_reward_mean": {"red_0": 1.1784814814814817, "blue_0": -0.8635226337448558}, "custom_metrics": {"red_0/door_open_done_mean": 0.05761316872427984, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9094650205761317, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03292181069958848, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9094650205761317, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02880658436213992, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9094650205761317, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02880658436213992, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44599999999999995, 0.46499999999999986, 1.428, 0.45699999999999985, -0.04399999999999993, 0.8200000000000001, 0.47, 0.45100000000000007, -0.06500000000000006, -0.05900000000000005, 0.44399999999999995, -0.03700000000000003, -0.04300000000000004, -0.03600000000000003, -0.031000000000000028, -0.03300000000000003, 0.4690000000000001, 0.46399999999999997, 0.4630000000000001, 0.46199999999999997, 0.46199999999999997, -0.028999999999999915, -0.04600000000000004, -0.02400000000000002, -0.05400000000000005, 0.45999999999999996, 0.43599999999999994, -0.027000000000000024, 0.3720000000000001, 0.4630000000000001, -0.03200000000000003, 0.958, -0.027000000000000024, -0.03200000000000003, 0.46499999999999986, 0.45999999999999996, 0.469, 0.47, -0.03300000000000003, 0.9590000000000001, 0.4670000000000001, -0.08299999999999985, -0.027000000000000024, -0.03500000000000003, 0.44300000000000006, 0.45599999999999996, 0.4660000000000002, -0.03200000000000003, 1.4289999999999998, -0.029999999999999916, -0.028000000000000025, -0.03400000000000003, 1.458, 0.44599999999999995, -0.03400000000000003, -0.03500000000000003, 0.46099999999999985, 0.46599999999999997, 1.444, -0.031000000000000028, -0.02200000000000002, 0.45100000000000007, 0.44999999999999996, 0.46799999999999997, -0.028000000000000025, -0.10099999999999987, 1.451, 0.46399999999999997, 0.46899999999999986, 0.45399999999999996, 0.4710000000000001, -0.041000000000000036, -0.038000000000000034, -0.03400000000000003, -0.06500000000000006, 0.4289999999999998, -0.026000000000000023, 0.45799999999999996, 0.46199999999999997, -0.04599999999999993, 0.45599999999999996, -0.029000000000000026, 0.45999999999999996, -0.027000000000000024, 0.46599999999999997, 0.46899999999999986, 0.4590000000000001, 1.4489999999999998, -0.040000000000000036, 0.47299999999999986, -0.04300000000000004, 0.46599999999999997, -0.06500000000000006, -0.029000000000000026, -0.03500000000000003, 0.44999999999999996, 0.44399999999999995, 0.45999999999999996, 0.43699999999999983, 0.45999999999999996, -0.03700000000000003, -0.03600000000000003, -0.040999999999999925, 0.472, 0.46099999999999985, 0.46099999999999985, 0.44300000000000006, -0.03199999999999992, -0.03500000000000003, -0.031000000000000028, 0.43999999999999995, 0.45299999999999985, -0.03299999999999992, -0.028000000000000025, 0.4710000000000001, 0.45500000000000007, -0.03700000000000003, 0.46499999999999986, -0.03499999999999992, 0.46099999999999985, 0.46199999999999997, -0.03299999999999992, -0.03199999999999992, -0.029000000000000026, -0.04200000000000004, -0.04200000000000004, -0.039000000000000035, -0.03700000000000003, 0.9359999999999999, 0.45500000000000007, 0.46399999999999997, 0.46599999999999997, -0.04400000000000004, -0.03400000000000003, 0.46499999999999986, 0.20000000000000018, -0.03400000000000003, -0.03600000000000003, 0.4750000000000001, 0.44399999999999995, 0.4630000000000001, 0.46199999999999997, 0.4630000000000001, 0.3880000000000001, 0.45199999999999996, -0.027000000000000024, 0.44700000000000006, 0.4690000000000001, 0.97, 0.8680000000000001, 0.43199999999999994, 0.45299999999999985, 0.46199999999999997, 0.41800000000000015, 0.43699999999999983, 0.41800000000000015, 0.4750000000000001, -0.031000000000000028, -0.030000000000000027, 0.472, 0.45299999999999985, -0.04800000000000004, 0.44700000000000006, 0.46099999999999985, 1.448, 0.44300000000000006, -0.04500000000000004, 0.46099999999999985, 1.4329999999999998, 0.45799999999999996, 0.46199999999999997, 0.4590000000000001, 1.4420000000000002, 0.46399999999999997, -0.052000000000000046, 0.25, -0.03400000000000003, 0.45299999999999985, -0.030000000000000027, -0.02499999999999991, 0.43799999999999994, -0.03400000000000003, -0.05499999999999994, 0.4670000000000001, -0.031000000000000028, 0.46499999999999986, -0.030000000000000027, 0.46399999999999997, 0.43299999999999983, 0.46399999999999997, 0.4590000000000001, -0.038000000000000034, -0.126, 0.43899999999999995, -0.05900000000000005, 1.434, 0.4620000000000002, -0.02400000000000002, 0.45599999999999996, -0.03500000000000003, -0.07199999999999995, 0.45999999999999996, 1.4100000000000001, 0.47299999999999986, 0.46399999999999997, -0.04300000000000004, -0.05300000000000005, 0.45799999999999996, 0.46899999999999986, 0.43199999999999994, -0.030000000000000027, 0.27700000000000014, 0.44999999999999996, 0.44499999999999995, 0.44499999999999984, 0.42600000000000016, -0.027000000000000024, 0.47299999999999986, 0.4630000000000001, -0.03400000000000003, -0.09999999999999998, -0.03300000000000003, 1.353, 0.44999999999999996, 0.4670000000000001, 0.4660000000000002, -0.049000000000000044, 0.45799999999999996, 0.45799999999999996, -0.027000000000000024, -0.03500000000000003, 0.42200000000000015, -0.031000000000000028, 0.43000000000000016, 1.452, -0.03299999999999992, 0.45999999999999996, -0.04500000000000004, 0.4670000000000001, -0.04600000000000004, 0.47, -0.02300000000000002, -0.029000000000000026], "episode_lengths": [17, 11, 23, 14, 13, 56, 10, 15, 19, 18, 18, 12, 14, 11, 10, 11, 10, 11, 12, 12, 12, 9, 14, 8, 17, 12, 20, 9, 40, 12, 10, 14, 9, 10, 11, 13, 10, 10, 10, 13, 11, 26, 9, 11, 18, 14, 10, 10, 22, 9, 9, 10, 13, 300, 11, 11, 13, 11, 18, 10, 7, 16, 16, 10, 9, 32, 16, 11, 10, 14, 9, 13, 12, 10, 20, 22, 8, 13, 12, 14, 13, 9, 12, 9, 11, 10, 13, 16, 13, 9, 14, 11, 20, 9, 11, 16, 18, 13, 20, 13, 11, 11, 12, 9, 13, 13, 18, 10, 11, 9, 19, 15, 10, 9, 9, 15, 12, 11, 11, 12, 12, 10, 10, 9, 13, 14, 12, 12, 20, 14, 11, 11, 14, 11, 11, 92, 11, 11, 8, 18, 11, 12, 12, 35, 16, 9, 16, 9, 10, 41, 22, 15, 12, 26, 20, 25, 8, 10, 10, 9, 14, 16, 17, 13, 16, 17, 14, 12, 22, 13, 12, 13, 18, 11, 16, 78, 11, 15, 9, 8, 20, 11, 17, 11, 10, 11, 10, 11, 22, 11, 13, 12, 41, 19, 18, 21, 12, 8, 14, 11, 23, 13, 29, 9, 12, 14, 17, 13, 10, 22, 10, 70, 16, 18, 18, 23, 9, 9, 12, 10, 32, 10, 44, 16, 11, 10, 16, 14, 13, 9, 11, 25, 10, 22, 15, 10, 13, 14, 10, 14, 10, 7, 9], "policy_red_0_reward": [1.4489999999999998, 1.467, 1.431, 1.458, 0.961, 1.326, 1.47, 1.455, 0.9369999999999999, 0.943, 1.446, 0.964, 0.958, 0.967, 0.97, 0.967, 1.47, 1.467, 1.464, 1.464, 1.464, 0.973, 0.956, 0.976, 0.949, 1.463, 1.44, 0.973, 0.876, 0.964, 0.97, 0.45799999999999996, 0.973, 0.97, 1.467, 1.4609999999999999, -0.5, 1.47, 0.968, 1.4609999999999999, 1.467, 0.922, 0.973, 0.966, 1.446, 1.458, 1.47, 0.97, 1.4329999999999998, -1.0, 0.973, 0.97, 1.4609999999999999, -0.012000000000000004, 0.966, 0.967, 1.4609999999999999, 1.467, 1.446, 0.97, 0.978, 1.452, 1.452, 1.47, 0.973, 0.904, 1.452, 1.467, 1.47, 1.458, 1.4729999999999999, 0.961, 0.964, 0.97, 0.94, 1.434, 0.975, 1.4609999999999999, 1.464, 0.958, 1.4609999999999999, 0.972, 1.464, 0.973, 1.467, 1.47, 0.961, 1.452, 0.961, 1.4729999999999999, 0.958, 1.467, 0.94, 0.973, 0.966, 1.452, 1.446, 1.4609999999999999, 1.44, 1.4609999999999999, 0.966, 0.967, 0.963, 1.4729999999999999, 1.4609999999999999, 1.4609999999999999, 1.446, 0.97, 0.967, 0.973, 1.443, 1.455, 0.97, 0.973, 1.4729999999999999, 1.455, 0.964, 1.467, 0.967, 1.464, 1.464, 0.969, 0.97, 0.973, 0.961, 0.958, 0.964, 0.963, 1.44, 1.458, 1.467, 1.467, 0.958, 0.966, 1.467, 1.216, 0.967, 0.967, 1.476, 1.4449999999999998, 1.467, 1.464, 1.464, 1.393, 1.452, 0.973, 1.452, 1.4729999999999999, 1.47, 1.374, 1.434, 1.455, 1.464, 1.421, 1.44, 1.423, 1.476, 0.97, 0.97, 1.4729999999999999, 1.458, 0.952, 1.4489999999999998, 1.4609999999999999, 1.452, 1.448, 0.958, 1.464, 1.434, 1.46, 1.464, 1.4609999999999999, 1.446, 1.467, 0.951, 1.266, 0.967, 1.455, 0.973, -1.001, 1.44, 0.966, 0.948, 1.467, 0.97, 1.467, 0.97, 1.467, 1.434, 1.467, 1.4609999999999999, 0.964, 0.877, -0.5, 0.945, 1.436, 1.464, 0.976, -0.5, 0.967, 0.931, 1.4609999999999999, 1.413, 1.4729999999999999, 1.464, 0.958, 0.949, 1.4609999999999999, 1.47, 1.434, 0.97, 1.2890000000000001, 1.452, -0.5, 1.446, 1.431, -1.0, 1.4729999999999999, 1.464, 0.968, 0.904, 0.97, 1.362, 1.452, 1.467, 1.47, 0.951, 1.458, 1.4609999999999999, 0.973, 0.967, 1.425, 0.97, 1.434, 1.455, 0.97, 1.4609999999999999, 0.957, 1.47, 0.958, 1.47, 0.979, 0.973], "policy_blue_0_reward": [-1.003, -1.002, -0.003, -1.001, -1.005, -0.5059999999999999, -1.0, -1.004, -1.002, -1.002, -1.002, -1.001, -1.001, -1.003, -1.001, -1.0, -1.001, -1.003, -1.001, -1.002, -1.002, -1.0019999999999998, -1.002, -1.0, -1.003, -1.003, -1.004, -1.0, -0.5039999999999999, -0.501, -1.002, 0.5, -1.0, -1.002, -1.002, -1.001, 0.969, -1.0, -1.001, -0.502, -1.0, -1.005, -1.0, -1.001, -1.003, -1.002, -1.0039999999999998, -1.002, -0.004, 0.97, -1.001, -1.004, -0.003, 0.45799999999999996, -1.0, -1.002, -1.0, -1.001, -0.002, -1.001, -1.0, -1.001, -1.002, -1.002, -1.001, -1.005, -0.001, -1.003, -1.001, -1.004, -1.002, -1.002, -1.002, -1.004, -1.005, -1.005, -1.001, -1.003, -1.002, -1.0039999999999998, -1.005, -1.001, -1.004, -1.0, -1.001, -1.001, -0.502, -0.003, -1.001, -1.0, -1.001, -1.001, -1.005, -1.002, -1.001, -1.002, -1.002, -1.001, -1.003, -1.001, -1.003, -1.003, -1.0039999999999998, -1.001, -1.0, -1.0, -1.003, -1.0019999999999998, -1.002, -1.004, -1.003, -1.002, -1.003, -1.001, -1.0019999999999998, -1.0, -1.001, -1.002, -1.0019999999999998, -1.003, -1.002, -1.0019999999999998, -1.0019999999999998, -1.002, -1.003, -1.0, -1.003, -1.0, -0.504, -1.003, -1.003, -1.001, -1.002, -1.0, -1.002, -1.0159999999999998, -1.001, -1.003, -1.001, -1.001, -1.0039999999999998, -1.002, -1.001, -1.005, -1.0, -1.0, -1.005, -1.0039999999999998, -0.5, -0.5059999999999999, -1.002, -1.002, -1.002, -1.003, -1.003, -1.005, -1.001, -1.001, -1.0, -1.001, -1.005, -1.0, -1.002, -1.0, -0.004, -1.005, -1.003, -1.003, -0.001, -1.002, -1.002, -1.002, -0.004, -1.003, -1.003, -1.016, -1.001, -1.002, -1.003, 0.976, -1.002, -1.0, -1.003, -1.0, -1.001, -1.002, -1.0, -1.003, -1.001, -1.003, -1.0019999999999998, -1.002, -1.003, 0.939, -1.004, -0.002, -1.0019999999999998, -1.0, 0.956, -1.002, -1.003, -1.001, -0.003, -1.0, -1.0, -1.001, -1.002, -1.003, -1.001, -1.002, -1.0, -1.012, -1.002, 0.945, -1.001, -1.005, 0.973, -1.0, -1.001, -1.002, -1.004, -1.003, -0.009000000000000001, -1.002, -1.0, -1.0039999999999998, -1.0, -1.0, -1.003, -1.0, -1.002, -1.003, -1.001, -1.0039999999999998, -0.003, -1.003, -1.001, -1.002, -1.003, -1.004, -1.0, -1.002, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23894380200765244, "mean_inference_ms": 1.475690824511602, "mean_action_processing_ms": 0.06283963987072225, "mean_env_wait_ms": 0.089055281856304, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021622210373113186, "StateBufferConnector_ms": 0.0015632605847017264, "ViewRequirementAgentConnector_ms": 0.03266864352756076}}, "episode_reward_max": 1.458, "episode_reward_min": -0.126, "episode_reward_mean": 0.3149588477366255, "episode_len_mean": 16.05761316872428, "episodes_this_iter": 243, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.976}, "policy_reward_mean": {"red_0": 1.1784814814814817, "blue_0": -0.8635226337448558}, "hist_stats": {"episode_reward": [0.44599999999999995, 0.46499999999999986, 1.428, 0.45699999999999985, -0.04399999999999993, 0.8200000000000001, 0.47, 0.45100000000000007, -0.06500000000000006, -0.05900000000000005, 0.44399999999999995, -0.03700000000000003, -0.04300000000000004, -0.03600000000000003, -0.031000000000000028, -0.03300000000000003, 0.4690000000000001, 0.46399999999999997, 0.4630000000000001, 0.46199999999999997, 0.46199999999999997, -0.028999999999999915, -0.04600000000000004, -0.02400000000000002, -0.05400000000000005, 0.45999999999999996, 0.43599999999999994, -0.027000000000000024, 0.3720000000000001, 0.4630000000000001, -0.03200000000000003, 0.958, -0.027000000000000024, -0.03200000000000003, 0.46499999999999986, 0.45999999999999996, 0.469, 0.47, -0.03300000000000003, 0.9590000000000001, 0.4670000000000001, -0.08299999999999985, -0.027000000000000024, -0.03500000000000003, 0.44300000000000006, 0.45599999999999996, 0.4660000000000002, -0.03200000000000003, 1.4289999999999998, -0.029999999999999916, -0.028000000000000025, -0.03400000000000003, 1.458, 0.44599999999999995, -0.03400000000000003, -0.03500000000000003, 0.46099999999999985, 0.46599999999999997, 1.444, -0.031000000000000028, -0.02200000000000002, 0.45100000000000007, 0.44999999999999996, 0.46799999999999997, -0.028000000000000025, -0.10099999999999987, 1.451, 0.46399999999999997, 0.46899999999999986, 0.45399999999999996, 0.4710000000000001, -0.041000000000000036, -0.038000000000000034, -0.03400000000000003, -0.06500000000000006, 0.4289999999999998, -0.026000000000000023, 0.45799999999999996, 0.46199999999999997, -0.04599999999999993, 0.45599999999999996, -0.029000000000000026, 0.45999999999999996, -0.027000000000000024, 0.46599999999999997, 0.46899999999999986, 0.4590000000000001, 1.4489999999999998, -0.040000000000000036, 0.47299999999999986, -0.04300000000000004, 0.46599999999999997, -0.06500000000000006, -0.029000000000000026, -0.03500000000000003, 0.44999999999999996, 0.44399999999999995, 0.45999999999999996, 0.43699999999999983, 0.45999999999999996, -0.03700000000000003, -0.03600000000000003, -0.040999999999999925, 0.472, 0.46099999999999985, 0.46099999999999985, 0.44300000000000006, -0.03199999999999992, -0.03500000000000003, -0.031000000000000028, 0.43999999999999995, 0.45299999999999985, -0.03299999999999992, -0.028000000000000025, 0.4710000000000001, 0.45500000000000007, -0.03700000000000003, 0.46499999999999986, -0.03499999999999992, 0.46099999999999985, 0.46199999999999997, -0.03299999999999992, -0.03199999999999992, -0.029000000000000026, -0.04200000000000004, -0.04200000000000004, -0.039000000000000035, -0.03700000000000003, 0.9359999999999999, 0.45500000000000007, 0.46399999999999997, 0.46599999999999997, -0.04400000000000004, -0.03400000000000003, 0.46499999999999986, 0.20000000000000018, -0.03400000000000003, -0.03600000000000003, 0.4750000000000001, 0.44399999999999995, 0.4630000000000001, 0.46199999999999997, 0.4630000000000001, 0.3880000000000001, 0.45199999999999996, -0.027000000000000024, 0.44700000000000006, 0.4690000000000001, 0.97, 0.8680000000000001, 0.43199999999999994, 0.45299999999999985, 0.46199999999999997, 0.41800000000000015, 0.43699999999999983, 0.41800000000000015, 0.4750000000000001, -0.031000000000000028, -0.030000000000000027, 0.472, 0.45299999999999985, -0.04800000000000004, 0.44700000000000006, 0.46099999999999985, 1.448, 0.44300000000000006, -0.04500000000000004, 0.46099999999999985, 1.4329999999999998, 0.45799999999999996, 0.46199999999999997, 0.4590000000000001, 1.4420000000000002, 0.46399999999999997, -0.052000000000000046, 0.25, -0.03400000000000003, 0.45299999999999985, -0.030000000000000027, -0.02499999999999991, 0.43799999999999994, -0.03400000000000003, -0.05499999999999994, 0.4670000000000001, -0.031000000000000028, 0.46499999999999986, -0.030000000000000027, 0.46399999999999997, 0.43299999999999983, 0.46399999999999997, 0.4590000000000001, -0.038000000000000034, -0.126, 0.43899999999999995, -0.05900000000000005, 1.434, 0.4620000000000002, -0.02400000000000002, 0.45599999999999996, -0.03500000000000003, -0.07199999999999995, 0.45999999999999996, 1.4100000000000001, 0.47299999999999986, 0.46399999999999997, -0.04300000000000004, -0.05300000000000005, 0.45799999999999996, 0.46899999999999986, 0.43199999999999994, -0.030000000000000027, 0.27700000000000014, 0.44999999999999996, 0.44499999999999995, 0.44499999999999984, 0.42600000000000016, -0.027000000000000024, 0.47299999999999986, 0.4630000000000001, -0.03400000000000003, -0.09999999999999998, -0.03300000000000003, 1.353, 0.44999999999999996, 0.4670000000000001, 0.4660000000000002, -0.049000000000000044, 0.45799999999999996, 0.45799999999999996, -0.027000000000000024, -0.03500000000000003, 0.42200000000000015, -0.031000000000000028, 0.43000000000000016, 1.452, -0.03299999999999992, 0.45999999999999996, -0.04500000000000004, 0.4670000000000001, -0.04600000000000004, 0.47, -0.02300000000000002, -0.029000000000000026], "episode_lengths": [17, 11, 23, 14, 13, 56, 10, 15, 19, 18, 18, 12, 14, 11, 10, 11, 10, 11, 12, 12, 12, 9, 14, 8, 17, 12, 20, 9, 40, 12, 10, 14, 9, 10, 11, 13, 10, 10, 10, 13, 11, 26, 9, 11, 18, 14, 10, 10, 22, 9, 9, 10, 13, 300, 11, 11, 13, 11, 18, 10, 7, 16, 16, 10, 9, 32, 16, 11, 10, 14, 9, 13, 12, 10, 20, 22, 8, 13, 12, 14, 13, 9, 12, 9, 11, 10, 13, 16, 13, 9, 14, 11, 20, 9, 11, 16, 18, 13, 20, 13, 11, 11, 12, 9, 13, 13, 18, 10, 11, 9, 19, 15, 10, 9, 9, 15, 12, 11, 11, 12, 12, 10, 10, 9, 13, 14, 12, 12, 20, 14, 11, 11, 14, 11, 11, 92, 11, 11, 8, 18, 11, 12, 12, 35, 16, 9, 16, 9, 10, 41, 22, 15, 12, 26, 20, 25, 8, 10, 10, 9, 14, 16, 17, 13, 16, 17, 14, 12, 22, 13, 12, 13, 18, 11, 16, 78, 11, 15, 9, 8, 20, 11, 17, 11, 10, 11, 10, 11, 22, 11, 13, 12, 41, 19, 18, 21, 12, 8, 14, 11, 23, 13, 29, 9, 12, 14, 17, 13, 10, 22, 10, 70, 16, 18, 18, 23, 9, 9, 12, 10, 32, 10, 44, 16, 11, 10, 16, 14, 13, 9, 11, 25, 10, 22, 15, 10, 13, 14, 10, 14, 10, 7, 9], "policy_red_0_reward": [1.4489999999999998, 1.467, 1.431, 1.458, 0.961, 1.326, 1.47, 1.455, 0.9369999999999999, 0.943, 1.446, 0.964, 0.958, 0.967, 0.97, 0.967, 1.47, 1.467, 1.464, 1.464, 1.464, 0.973, 0.956, 0.976, 0.949, 1.463, 1.44, 0.973, 0.876, 0.964, 0.97, 0.45799999999999996, 0.973, 0.97, 1.467, 1.4609999999999999, -0.5, 1.47, 0.968, 1.4609999999999999, 1.467, 0.922, 0.973, 0.966, 1.446, 1.458, 1.47, 0.97, 1.4329999999999998, -1.0, 0.973, 0.97, 1.4609999999999999, -0.012000000000000004, 0.966, 0.967, 1.4609999999999999, 1.467, 1.446, 0.97, 0.978, 1.452, 1.452, 1.47, 0.973, 0.904, 1.452, 1.467, 1.47, 1.458, 1.4729999999999999, 0.961, 0.964, 0.97, 0.94, 1.434, 0.975, 1.4609999999999999, 1.464, 0.958, 1.4609999999999999, 0.972, 1.464, 0.973, 1.467, 1.47, 0.961, 1.452, 0.961, 1.4729999999999999, 0.958, 1.467, 0.94, 0.973, 0.966, 1.452, 1.446, 1.4609999999999999, 1.44, 1.4609999999999999, 0.966, 0.967, 0.963, 1.4729999999999999, 1.4609999999999999, 1.4609999999999999, 1.446, 0.97, 0.967, 0.973, 1.443, 1.455, 0.97, 0.973, 1.4729999999999999, 1.455, 0.964, 1.467, 0.967, 1.464, 1.464, 0.969, 0.97, 0.973, 0.961, 0.958, 0.964, 0.963, 1.44, 1.458, 1.467, 1.467, 0.958, 0.966, 1.467, 1.216, 0.967, 0.967, 1.476, 1.4449999999999998, 1.467, 1.464, 1.464, 1.393, 1.452, 0.973, 1.452, 1.4729999999999999, 1.47, 1.374, 1.434, 1.455, 1.464, 1.421, 1.44, 1.423, 1.476, 0.97, 0.97, 1.4729999999999999, 1.458, 0.952, 1.4489999999999998, 1.4609999999999999, 1.452, 1.448, 0.958, 1.464, 1.434, 1.46, 1.464, 1.4609999999999999, 1.446, 1.467, 0.951, 1.266, 0.967, 1.455, 0.973, -1.001, 1.44, 0.966, 0.948, 1.467, 0.97, 1.467, 0.97, 1.467, 1.434, 1.467, 1.4609999999999999, 0.964, 0.877, -0.5, 0.945, 1.436, 1.464, 0.976, -0.5, 0.967, 0.931, 1.4609999999999999, 1.413, 1.4729999999999999, 1.464, 0.958, 0.949, 1.4609999999999999, 1.47, 1.434, 0.97, 1.2890000000000001, 1.452, -0.5, 1.446, 1.431, -1.0, 1.4729999999999999, 1.464, 0.968, 0.904, 0.97, 1.362, 1.452, 1.467, 1.47, 0.951, 1.458, 1.4609999999999999, 0.973, 0.967, 1.425, 0.97, 1.434, 1.455, 0.97, 1.4609999999999999, 0.957, 1.47, 0.958, 1.47, 0.979, 0.973], "policy_blue_0_reward": [-1.003, -1.002, -0.003, -1.001, -1.005, -0.5059999999999999, -1.0, -1.004, -1.002, -1.002, -1.002, -1.001, -1.001, -1.003, -1.001, -1.0, -1.001, -1.003, -1.001, -1.002, -1.002, -1.0019999999999998, -1.002, -1.0, -1.003, -1.003, -1.004, -1.0, -0.5039999999999999, -0.501, -1.002, 0.5, -1.0, -1.002, -1.002, -1.001, 0.969, -1.0, -1.001, -0.502, -1.0, -1.005, -1.0, -1.001, -1.003, -1.002, -1.0039999999999998, -1.002, -0.004, 0.97, -1.001, -1.004, -0.003, 0.45799999999999996, -1.0, -1.002, -1.0, -1.001, -0.002, -1.001, -1.0, -1.001, -1.002, -1.002, -1.001, -1.005, -0.001, -1.003, -1.001, -1.004, -1.002, -1.002, -1.002, -1.004, -1.005, -1.005, -1.001, -1.003, -1.002, -1.0039999999999998, -1.005, -1.001, -1.004, -1.0, -1.001, -1.001, -0.502, -0.003, -1.001, -1.0, -1.001, -1.001, -1.005, -1.002, -1.001, -1.002, -1.002, -1.001, -1.003, -1.001, -1.003, -1.003, -1.0039999999999998, -1.001, -1.0, -1.0, -1.003, -1.0019999999999998, -1.002, -1.004, -1.003, -1.002, -1.003, -1.001, -1.0019999999999998, -1.0, -1.001, -1.002, -1.0019999999999998, -1.003, -1.002, -1.0019999999999998, -1.0019999999999998, -1.002, -1.003, -1.0, -1.003, -1.0, -0.504, -1.003, -1.003, -1.001, -1.002, -1.0, -1.002, -1.0159999999999998, -1.001, -1.003, -1.001, -1.001, -1.0039999999999998, -1.002, -1.001, -1.005, -1.0, -1.0, -1.005, -1.0039999999999998, -0.5, -0.5059999999999999, -1.002, -1.002, -1.002, -1.003, -1.003, -1.005, -1.001, -1.001, -1.0, -1.001, -1.005, -1.0, -1.002, -1.0, -0.004, -1.005, -1.003, -1.003, -0.001, -1.002, -1.002, -1.002, -0.004, -1.003, -1.003, -1.016, -1.001, -1.002, -1.003, 0.976, -1.002, -1.0, -1.003, -1.0, -1.001, -1.002, -1.0, -1.003, -1.001, -1.003, -1.0019999999999998, -1.002, -1.003, 0.939, -1.004, -0.002, -1.0019999999999998, -1.0, 0.956, -1.002, -1.003, -1.001, -0.003, -1.0, -1.0, -1.001, -1.002, -1.003, -1.001, -1.002, -1.0, -1.012, -1.002, 0.945, -1.001, -1.005, 0.973, -1.0, -1.001, -1.002, -1.004, -1.003, -0.009000000000000001, -1.002, -1.0, -1.0039999999999998, -1.0, -1.0, -1.003, -1.0, -1.002, -1.003, -1.001, -1.0039999999999998, -0.003, -1.003, -1.001, -1.002, -1.003, -1.004, -1.0, -1.002, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23894380200765244, "mean_inference_ms": 1.475690824511602, "mean_action_processing_ms": 0.06283963987072225, "mean_env_wait_ms": 0.089055281856304, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021622210373113186, "StateBufferConnector_ms": 0.0015632605847017264, "ViewRequirementAgentConnector_ms": 0.03266864352756076}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000, "num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.58843674986382, "num_env_steps_trained_throughput_per_sec": 102.58843674986382, "timesteps_total": 128000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 256000, "timers": {"training_iteration_time_ms": 38958.916, "sample_time_ms": 7602.59, "learn_time_ms": 31338.969, "learn_throughput": 127.637, "synch_weights_time_ms": 16.858}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 128000, "num_agent_steps_sampled": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 2762, "training_iteration": 32, "trial_id": "d67e4_00000", "date": "2023-09-20_22-29-57", "timestamp": 1695263397, "time_this_iter_s": 38.99991989135742, "time_total_s": 1243.7337288856506, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687a560>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1243.7337288856506, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 33.56428571428571, "ram_util_percent": 48.464285714285715}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02564102564102564, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9282051282051282, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03076923076923077, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9282051282051282, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03076923076923077, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9282051282051282, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03076923076923077, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.6028142557789882, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01041977321962501, "policy_loss": -0.01776230372634018, "vf_loss": 0.008358972346710895, "vf_explained_var": 0.6913668084268768, "kl": 0.008249481822944441, "entropy": 0.5492226730411252, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 31200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "sampler_results": {"episode_reward_max": 1.444, "episode_reward_min": -0.44799999999999995, "episode_reward_mean": 0.31783076923076925, "episode_len_mean": 21.38974358974359, "episode_media": {}, "episodes_this_iter": 195, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.228}, "policy_reward_mean": {"red_0": 1.2050615384615384, "blue_0": -0.8872307692307692}, "custom_metrics": {"red_0/door_open_done_mean": 0.02564102564102564, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9282051282051282, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03076923076923077, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9282051282051282, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03076923076923077, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9282051282051282, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03076923076923077, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.21100000000000008, -0.026000000000000023, 0.46199999999999997, 0.46899999999999986, -0.44799999999999995, 0.4670000000000001, 0.3840000000000001, 0.47, -0.03400000000000003, 0.45599999999999996, 0.42700000000000005, 0.4710000000000001, -0.030000000000000027, -0.03500000000000003, 1.42, 0.476, 0.43100000000000005, 0.46199999999999997, 0.46399999999999997, -0.02499999999999991, 0.722, 0.30800000000000005, -0.031000000000000028, -0.030000000000000027, 0.4670000000000001, 0.46899999999999986, 0.46899999999999986, 0.46399999999999997, -0.031000000000000028, -0.03399999999999992, 0.956, -0.04500000000000004, -0.03200000000000003, -0.05700000000000005, 0.371, -0.07199999999999984, 1.361, 0.45699999999999985, 0.45699999999999985, 0.44999999999999996, 0.44500000000000006, 0.4670000000000001, -0.03299999999999992, 0.45599999999999996, -0.03300000000000003, 0.47, -0.025000000000000022, 0.4670000000000001, 0.472, 0.45999999999999996, 0.45500000000000007, -0.07200000000000006, -0.03200000000000003, -0.039000000000000035, 0.44300000000000006, 0.4540000000000002, -0.041000000000000036, 0.45999999999999996, -0.027999999999999914, -0.041000000000000036, 0.46899999999999986, 0.9580000000000002, 0.46899999999999986, -0.03799999999999992, 0.46599999999999997, -0.031000000000000028, 0.45500000000000007, -0.06800000000000006, 0.45300000000000007, 0.46199999999999997, 1.444, 0.45799999999999996, 0.43300000000000005, 0.31999999999999984, -0.049000000000000044, 0.46399999999999997, 0.4710000000000001, 0.46599999999999997, 0.474, 1.3690000000000002, 0.45999999999999996, -0.028000000000000025, 0.41800000000000015, 0.44300000000000006, -0.041000000000000036, 0.45999999999999996, -0.04600000000000004, 0.46599999999999997, 0.45599999999999996, -0.03400000000000003, -0.025000000000000022, 0.44099999999999995, 0.4590000000000001, 0.45699999999999985, 0.4590000000000001, 0.472, -0.04600000000000004, -0.027000000000000024, 0.45999999999999996, -0.03799999999999992, 0.46899999999999986, -0.029000000000000026, 0.45599999999999996, 0.4690000000000001, 0.45999999999999996, 0.4630000000000001, 0.44099999999999984, 0.958, 0.45699999999999985, -0.05900000000000005, -0.03400000000000003, 0.43399999999999994, 0.44300000000000006, 0.45699999999999985, 0.46899999999999986, 0.45199999999999996, 0.4630000000000001, 0.46899999999999986, 0.45699999999999985, -0.030000000000000027, -0.030000000000000027, -0.05200000000000004, -0.07400000000000007, 0.45799999999999996, -0.06000000000000005, 0.47, 0.47, 0.387, -0.03200000000000003, 0.4770000000000001, 0.44399999999999995, 0.46099999999999985, 0.381, -0.025000000000000022, -0.029999999999999916, 0.45699999999999985, -0.041000000000000036, -0.038000000000000034, 0.44599999999999995, -0.03199999999999992, 0.45999999999999996, 0.4610000000000001, -0.04000000000000003, -0.040000000000000036, 0.45999999999999996, 0.472, -0.04499999999999993, 0.44799999999999995, 0.44700000000000006, 0.4590000000000001, -0.04400000000000004, 0.4289999999999998, 0.44499999999999984, 0.46499999999999986, 0.361, 0.46499999999999986, -0.039000000000000035, 0.45799999999999996, 0.45999999999999996, 0.474, 0.3580000000000001, 0.45799999999999996, 0.43500000000000005, -0.031000000000000028, 0.46099999999999985, 0.4249999999999998, -0.03400000000000003, 0.43900000000000006, 0.45999999999999996, -0.018000000000000016, -0.04800000000000004, 0.45799999999999996, 0.44799999999999995, -0.04600000000000004, 0.47, 0.44799999999999995, 0.44300000000000006, 1.405, 0.4570000000000001, 0.44999999999999996, 0.46599999999999997, 0.46199999999999997, -0.041000000000000036, 0.44300000000000006, 0.46199999999999997, 0.45699999999999985, 0.379, 0.46399999999999997, 0.46799999999999997, -0.03199999999999992, -0.124, -0.027000000000000024, -0.028000000000000025, 0.4770000000000001, 0.47], "episode_lengths": [221, 8, 12, 10, 142, 10, 36, 9, 11, 13, 23, 9, 10, 11, 25, 8, 22, 12, 12, 8, 86, 62, 10, 10, 11, 10, 9, 11, 10, 11, 14, 14, 10, 19, 38, 23, 44, 14, 14, 16, 17, 11, 10, 14, 10, 10, 8, 11, 9, 12, 14, 22, 10, 12, 18, 14, 13, 13, 9, 12, 10, 13, 10, 11, 11, 9, 14, 21, 15, 12, 18, 13, 21, 56, 15, 11, 9, 11, 8, 40, 13, 9, 26, 18, 13, 12, 13, 11, 14, 10, 8, 18, 13, 14, 13, 9, 15, 9, 13, 12, 10, 9, 14, 9, 13, 12, 19, 14, 14, 18, 11, 21, 18, 14, 10, 300, 11, 10, 14, 10, 10, 300, 24, 14, 18, 10, 10, 35, 10, 7, 17, 12, 37, 8, 9, 14, 13, 12, 18, 10, 13, 12, 300, 13, 13, 9, 14, 16, 17, 13, 14, 22, 18, 11, 45, 11, 13, 14, 13, 8, 45, 14, 21, 10, 13, 24, 11, 19, 13, 6, 15, 14, 16, 14, 10, 17, 18, 30, 14, 16, 11, 12, 13, 17, 12, 13, 36, 12, 10, 10, 35, 9, 9, 7, 9], "policy_red_0_reward": [0.31799999999999995, 0.976, 1.464, 1.47, 0.5710000000000001, 1.47, 1.389, 1.4729999999999999, 0.967, 1.4609999999999999, 1.431, 1.4729999999999999, 0.97, 0.967, 1.424, 1.476, 1.434, 1.464, 1.464, 0.976, -0.506, 1.314, 0.97, 0.97, 1.467, 1.47, 1.4729999999999999, 1.467, 0.969, -1.001, 1.458, 0.958, 0.97, 0.943, 1.377, 0.931, 1.367, 1.458, 1.458, 1.452, 1.4489999999999998, 1.467, 0.969, 1.458, 0.97, 1.47, 0.975, 1.467, 1.4729999999999999, 1.464, 1.458, 0.9339999999999999, 0.97, 0.964, 1.446, 1.458, 0.961, 1.4609999999999999, -1.0, 0.963, 1.47, 1.4609999999999999, 1.47, 0.965, 1.467, 0.971, 1.458, 0.9369999999999999, 1.455, 1.464, 1.4449999999999998, 1.4609999999999999, 1.4369999999999998, 0.824, 0.954, 1.467, 1.4729999999999999, 1.467, 1.476, 1.3780000000000001, 1.4609999999999999, 0.973, 1.4220000000000002, 1.446, 0.961, 1.464, 0.96, 1.467, 1.458, 0.97, 0.976, -0.5, 1.4609999999999999, 1.458, 1.4609999999999999, 1.4729999999999999, 0.955, 0.973, 1.4609999999999999, 0.964, 1.47, 0.973, 1.458, 1.4729999999999999, 1.4609999999999999, 1.464, 1.443, 1.458, 1.458, 0.945, 0.967, 1.4369999999999998, 1.446, 1.458, 1.47, 0.492, 1.467, 1.47, 1.458, 0.97, 0.97, -0.007, 0.9279999999999999, 1.458, 0.943, -0.5, 1.47, 1.395, 0.97, 1.479, 1.4489999999999998, 1.464, 1.387, 0.976, 0.973, 1.458, 0.961, 0.964, 1.446, 0.97, 1.4609999999999999, 1.464, -0.006, 0.961, 1.4609999999999999, 1.4729999999999999, 0.957, 1.451, 1.4489999999999998, 1.4609999999999999, 0.958, 1.434, 1.446, 1.467, 1.3639999999999999, 1.467, 0.961, 1.458, 1.4609999999999999, 1.476, 1.3639999999999999, 1.458, 1.4369999999999998, 0.97, 1.4609999999999999, 1.427, 0.967, 1.443, 1.4609999999999999, -1.0, 0.954, 1.458, 1.452, 0.958, 1.47, 1.4489999999999998, 1.446, 1.4100000000000001, 1.458, 1.452, 1.467, 1.464, 0.961, 1.4489999999999998, 1.464, 1.4609999999999999, 1.387, 1.464, 1.4689999999999999, 0.97, 0.878, 0.973, 0.973, 1.479, 1.4729999999999999], "policy_blue_0_reward": [-0.529, -1.002, -1.002, -1.001, -1.019, -1.003, -1.005, -1.003, -1.001, -1.005, -1.004, -1.002, -1.0, -1.002, -0.004, -1.0, -1.003, -1.002, -1.0, -1.001, 1.228, -1.006, -1.001, -1.0, -1.0, -1.001, -1.004, -1.003, -1.0, 0.967, -0.5019999999999999, -1.003, -1.002, -1.0, -1.006, -1.003, -0.006, -1.001, -1.001, -1.002, -1.0039999999999998, -1.0, -1.0019999999999998, -1.002, -1.003, -1.0, -1.0, -1.0, -1.001, -1.004, -1.003, -1.006, -1.002, -1.003, -1.003, -1.0039999999999998, -1.002, -1.001, 0.972, -1.004, -1.001, -0.5029999999999999, -1.001, -1.003, -1.001, -1.002, -1.003, -1.005, -1.0019999999999998, -1.002, -0.001, -1.003, -1.0039999999999998, -0.504, -1.003, -1.003, -1.0019999999999998, -1.001, -1.002, -0.009000000000000001, -1.001, -1.001, -1.004, -1.003, -1.002, -1.0039999999999998, -1.006, -1.001, -1.002, -1.004, -1.001, 0.941, -1.002, -1.001, -1.0019999999999998, -1.001, -1.001, -1.0, -1.001, -1.0019999999999998, -1.001, -1.002, -1.002, -1.0039999999999998, -1.001, -1.001, -1.002, -0.5, -1.001, -1.004, -1.001, -1.003, -1.003, -1.001, -1.001, -0.04000000000000003, -1.004, -1.001, -1.001, -1.0, -1.0, -0.04500000000000003, -1.002, -1.0, -1.003, 0.97, -1.0, -1.008, -1.002, -1.0019999999999998, -1.005, -1.003, -1.006, -1.001, -1.003, -1.001, -1.002, -1.002, -1.0, -1.0019999999999998, -1.001, -1.003, -0.03400000000000002, -1.001, -1.001, -1.001, -1.0019999999999998, -1.003, -1.002, -1.002, -1.002, -1.005, -1.001, -1.002, -1.003, -1.002, -1.0, -1.0, -1.001, -1.002, -1.006, -1.0, -1.002, -1.001, -1.0, -1.002, -1.001, -1.0039999999999998, -1.001, 0.982, -1.002, -1.0, -1.0039999999999998, -1.004, -1.0, -1.001, -1.003, -0.005, -1.001, -1.002, -1.001, -1.002, -1.002, -1.0059999999999998, -1.002, -1.004, -1.0079999999999998, -1.0, -1.001, -1.0019999999999998, -1.002, -1.0, -1.001, -1.0019999999999998, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23987386672515812, "mean_inference_ms": 1.4750139301027652, "mean_action_processing_ms": 0.06280341123952914, "mean_env_wait_ms": 0.08906160400082627, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021950709514128856, "StateBufferConnector_ms": 0.0015743573506673176, "ViewRequirementAgentConnector_ms": 0.03268107389792418}}, "episode_reward_max": 1.444, "episode_reward_min": -0.44799999999999995, "episode_reward_mean": 0.31783076923076925, "episode_len_mean": 21.38974358974359, "episodes_this_iter": 195, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.228}, "policy_reward_mean": {"red_0": 1.2050615384615384, "blue_0": -0.8872307692307692}, "hist_stats": {"episode_reward": [-0.21100000000000008, -0.026000000000000023, 0.46199999999999997, 0.46899999999999986, -0.44799999999999995, 0.4670000000000001, 0.3840000000000001, 0.47, -0.03400000000000003, 0.45599999999999996, 0.42700000000000005, 0.4710000000000001, -0.030000000000000027, -0.03500000000000003, 1.42, 0.476, 0.43100000000000005, 0.46199999999999997, 0.46399999999999997, -0.02499999999999991, 0.722, 0.30800000000000005, -0.031000000000000028, -0.030000000000000027, 0.4670000000000001, 0.46899999999999986, 0.46899999999999986, 0.46399999999999997, -0.031000000000000028, -0.03399999999999992, 0.956, -0.04500000000000004, -0.03200000000000003, -0.05700000000000005, 0.371, -0.07199999999999984, 1.361, 0.45699999999999985, 0.45699999999999985, 0.44999999999999996, 0.44500000000000006, 0.4670000000000001, -0.03299999999999992, 0.45599999999999996, -0.03300000000000003, 0.47, -0.025000000000000022, 0.4670000000000001, 0.472, 0.45999999999999996, 0.45500000000000007, -0.07200000000000006, -0.03200000000000003, -0.039000000000000035, 0.44300000000000006, 0.4540000000000002, -0.041000000000000036, 0.45999999999999996, -0.027999999999999914, -0.041000000000000036, 0.46899999999999986, 0.9580000000000002, 0.46899999999999986, -0.03799999999999992, 0.46599999999999997, -0.031000000000000028, 0.45500000000000007, -0.06800000000000006, 0.45300000000000007, 0.46199999999999997, 1.444, 0.45799999999999996, 0.43300000000000005, 0.31999999999999984, -0.049000000000000044, 0.46399999999999997, 0.4710000000000001, 0.46599999999999997, 0.474, 1.3690000000000002, 0.45999999999999996, -0.028000000000000025, 0.41800000000000015, 0.44300000000000006, -0.041000000000000036, 0.45999999999999996, -0.04600000000000004, 0.46599999999999997, 0.45599999999999996, -0.03400000000000003, -0.025000000000000022, 0.44099999999999995, 0.4590000000000001, 0.45699999999999985, 0.4590000000000001, 0.472, -0.04600000000000004, -0.027000000000000024, 0.45999999999999996, -0.03799999999999992, 0.46899999999999986, -0.029000000000000026, 0.45599999999999996, 0.4690000000000001, 0.45999999999999996, 0.4630000000000001, 0.44099999999999984, 0.958, 0.45699999999999985, -0.05900000000000005, -0.03400000000000003, 0.43399999999999994, 0.44300000000000006, 0.45699999999999985, 0.46899999999999986, 0.45199999999999996, 0.4630000000000001, 0.46899999999999986, 0.45699999999999985, -0.030000000000000027, -0.030000000000000027, -0.05200000000000004, -0.07400000000000007, 0.45799999999999996, -0.06000000000000005, 0.47, 0.47, 0.387, -0.03200000000000003, 0.4770000000000001, 0.44399999999999995, 0.46099999999999985, 0.381, -0.025000000000000022, -0.029999999999999916, 0.45699999999999985, -0.041000000000000036, -0.038000000000000034, 0.44599999999999995, -0.03199999999999992, 0.45999999999999996, 0.4610000000000001, -0.04000000000000003, -0.040000000000000036, 0.45999999999999996, 0.472, -0.04499999999999993, 0.44799999999999995, 0.44700000000000006, 0.4590000000000001, -0.04400000000000004, 0.4289999999999998, 0.44499999999999984, 0.46499999999999986, 0.361, 0.46499999999999986, -0.039000000000000035, 0.45799999999999996, 0.45999999999999996, 0.474, 0.3580000000000001, 0.45799999999999996, 0.43500000000000005, -0.031000000000000028, 0.46099999999999985, 0.4249999999999998, -0.03400000000000003, 0.43900000000000006, 0.45999999999999996, -0.018000000000000016, -0.04800000000000004, 0.45799999999999996, 0.44799999999999995, -0.04600000000000004, 0.47, 0.44799999999999995, 0.44300000000000006, 1.405, 0.4570000000000001, 0.44999999999999996, 0.46599999999999997, 0.46199999999999997, -0.041000000000000036, 0.44300000000000006, 0.46199999999999997, 0.45699999999999985, 0.379, 0.46399999999999997, 0.46799999999999997, -0.03199999999999992, -0.124, -0.027000000000000024, -0.028000000000000025, 0.4770000000000001, 0.47], "episode_lengths": [221, 8, 12, 10, 142, 10, 36, 9, 11, 13, 23, 9, 10, 11, 25, 8, 22, 12, 12, 8, 86, 62, 10, 10, 11, 10, 9, 11, 10, 11, 14, 14, 10, 19, 38, 23, 44, 14, 14, 16, 17, 11, 10, 14, 10, 10, 8, 11, 9, 12, 14, 22, 10, 12, 18, 14, 13, 13, 9, 12, 10, 13, 10, 11, 11, 9, 14, 21, 15, 12, 18, 13, 21, 56, 15, 11, 9, 11, 8, 40, 13, 9, 26, 18, 13, 12, 13, 11, 14, 10, 8, 18, 13, 14, 13, 9, 15, 9, 13, 12, 10, 9, 14, 9, 13, 12, 19, 14, 14, 18, 11, 21, 18, 14, 10, 300, 11, 10, 14, 10, 10, 300, 24, 14, 18, 10, 10, 35, 10, 7, 17, 12, 37, 8, 9, 14, 13, 12, 18, 10, 13, 12, 300, 13, 13, 9, 14, 16, 17, 13, 14, 22, 18, 11, 45, 11, 13, 14, 13, 8, 45, 14, 21, 10, 13, 24, 11, 19, 13, 6, 15, 14, 16, 14, 10, 17, 18, 30, 14, 16, 11, 12, 13, 17, 12, 13, 36, 12, 10, 10, 35, 9, 9, 7, 9], "policy_red_0_reward": [0.31799999999999995, 0.976, 1.464, 1.47, 0.5710000000000001, 1.47, 1.389, 1.4729999999999999, 0.967, 1.4609999999999999, 1.431, 1.4729999999999999, 0.97, 0.967, 1.424, 1.476, 1.434, 1.464, 1.464, 0.976, -0.506, 1.314, 0.97, 0.97, 1.467, 1.47, 1.4729999999999999, 1.467, 0.969, -1.001, 1.458, 0.958, 0.97, 0.943, 1.377, 0.931, 1.367, 1.458, 1.458, 1.452, 1.4489999999999998, 1.467, 0.969, 1.458, 0.97, 1.47, 0.975, 1.467, 1.4729999999999999, 1.464, 1.458, 0.9339999999999999, 0.97, 0.964, 1.446, 1.458, 0.961, 1.4609999999999999, -1.0, 0.963, 1.47, 1.4609999999999999, 1.47, 0.965, 1.467, 0.971, 1.458, 0.9369999999999999, 1.455, 1.464, 1.4449999999999998, 1.4609999999999999, 1.4369999999999998, 0.824, 0.954, 1.467, 1.4729999999999999, 1.467, 1.476, 1.3780000000000001, 1.4609999999999999, 0.973, 1.4220000000000002, 1.446, 0.961, 1.464, 0.96, 1.467, 1.458, 0.97, 0.976, -0.5, 1.4609999999999999, 1.458, 1.4609999999999999, 1.4729999999999999, 0.955, 0.973, 1.4609999999999999, 0.964, 1.47, 0.973, 1.458, 1.4729999999999999, 1.4609999999999999, 1.464, 1.443, 1.458, 1.458, 0.945, 0.967, 1.4369999999999998, 1.446, 1.458, 1.47, 0.492, 1.467, 1.47, 1.458, 0.97, 0.97, -0.007, 0.9279999999999999, 1.458, 0.943, -0.5, 1.47, 1.395, 0.97, 1.479, 1.4489999999999998, 1.464, 1.387, 0.976, 0.973, 1.458, 0.961, 0.964, 1.446, 0.97, 1.4609999999999999, 1.464, -0.006, 0.961, 1.4609999999999999, 1.4729999999999999, 0.957, 1.451, 1.4489999999999998, 1.4609999999999999, 0.958, 1.434, 1.446, 1.467, 1.3639999999999999, 1.467, 0.961, 1.458, 1.4609999999999999, 1.476, 1.3639999999999999, 1.458, 1.4369999999999998, 0.97, 1.4609999999999999, 1.427, 0.967, 1.443, 1.4609999999999999, -1.0, 0.954, 1.458, 1.452, 0.958, 1.47, 1.4489999999999998, 1.446, 1.4100000000000001, 1.458, 1.452, 1.467, 1.464, 0.961, 1.4489999999999998, 1.464, 1.4609999999999999, 1.387, 1.464, 1.4689999999999999, 0.97, 0.878, 0.973, 0.973, 1.479, 1.4729999999999999], "policy_blue_0_reward": [-0.529, -1.002, -1.002, -1.001, -1.019, -1.003, -1.005, -1.003, -1.001, -1.005, -1.004, -1.002, -1.0, -1.002, -0.004, -1.0, -1.003, -1.002, -1.0, -1.001, 1.228, -1.006, -1.001, -1.0, -1.0, -1.001, -1.004, -1.003, -1.0, 0.967, -0.5019999999999999, -1.003, -1.002, -1.0, -1.006, -1.003, -0.006, -1.001, -1.001, -1.002, -1.0039999999999998, -1.0, -1.0019999999999998, -1.002, -1.003, -1.0, -1.0, -1.0, -1.001, -1.004, -1.003, -1.006, -1.002, -1.003, -1.003, -1.0039999999999998, -1.002, -1.001, 0.972, -1.004, -1.001, -0.5029999999999999, -1.001, -1.003, -1.001, -1.002, -1.003, -1.005, -1.0019999999999998, -1.002, -0.001, -1.003, -1.0039999999999998, -0.504, -1.003, -1.003, -1.0019999999999998, -1.001, -1.002, -0.009000000000000001, -1.001, -1.001, -1.004, -1.003, -1.002, -1.0039999999999998, -1.006, -1.001, -1.002, -1.004, -1.001, 0.941, -1.002, -1.001, -1.0019999999999998, -1.001, -1.001, -1.0, -1.001, -1.0019999999999998, -1.001, -1.002, -1.002, -1.0039999999999998, -1.001, -1.001, -1.002, -0.5, -1.001, -1.004, -1.001, -1.003, -1.003, -1.001, -1.001, -0.04000000000000003, -1.004, -1.001, -1.001, -1.0, -1.0, -0.04500000000000003, -1.002, -1.0, -1.003, 0.97, -1.0, -1.008, -1.002, -1.0019999999999998, -1.005, -1.003, -1.006, -1.001, -1.003, -1.001, -1.002, -1.002, -1.0, -1.0019999999999998, -1.001, -1.003, -0.03400000000000002, -1.001, -1.001, -1.001, -1.0019999999999998, -1.003, -1.002, -1.002, -1.002, -1.005, -1.001, -1.002, -1.003, -1.002, -1.0, -1.0, -1.001, -1.002, -1.006, -1.0, -1.002, -1.001, -1.0, -1.002, -1.001, -1.0039999999999998, -1.001, 0.982, -1.002, -1.0, -1.0039999999999998, -1.004, -1.0, -1.001, -1.003, -0.005, -1.001, -1.002, -1.001, -1.002, -1.002, -1.0059999999999998, -1.002, -1.004, -1.0079999999999998, -1.0, -1.001, -1.0019999999999998, -1.002, -1.0, -1.001, -1.0019999999999998, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.23987386672515812, "mean_inference_ms": 1.4750139301027652, "mean_action_processing_ms": 0.06280341123952914, "mean_env_wait_ms": 0.08906160400082627, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021950709514128856, "StateBufferConnector_ms": 0.0015743573506673176, "ViewRequirementAgentConnector_ms": 0.03268107389792418}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000, "num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.90396816439889, "num_env_steps_trained_throughput_per_sec": 102.90396816439889, "timesteps_total": 132000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 264000, "timers": {"training_iteration_time_ms": 38956.275, "sample_time_ms": 7607.669, "learn_time_ms": 31331.264, "learn_throughput": 127.668, "synch_weights_time_ms": 16.843}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 132000, "num_agent_steps_sampled": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 2957, "training_iteration": 33, "trial_id": "d67e4_00000", "date": "2023-09-20_22-30-36", "timestamp": 1695263436, "time_this_iter_s": 38.87894105911255, "time_total_s": 1282.6126699447632, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687ba30>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1282.6126699447632, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 35.71090909090909, "ram_util_percent": 48.51272727272726}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0694980694980695, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8996138996138996, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03088803088803089, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8996138996138996, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03088803088803089, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8996138996138996, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03088803088803089, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7007991844788193, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00801005660420439, "policy_loss": -0.01568800891521581, "vf_loss": 0.009878365080658114, "vf_explained_var": 0.6582395639891426, "kl": 0.0069629340708275735, "entropy": 0.39455023943446577, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 32160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "sampler_results": {"episode_reward_max": 1.9449999999999998, "episode_reward_min": -0.135, "episode_reward_mean": 0.38535521235521236, "episode_len_mean": 15.447876447876448, "episode_media": {}, "episodes_this_iter": 259, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.01}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 1.222888030888031, "blue_0": -0.8375328185328184}, "custom_metrics": {"red_0/door_open_done_mean": 0.0694980694980695, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8996138996138996, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03088803088803089, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8996138996138996, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03088803088803089, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8996138996138996, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03088803088803089, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46599999999999997, 0.41900000000000004, 0.44999999999999996, 0.45199999999999996, -0.03200000000000003, 0.954, 0.4630000000000001, 0.46799999999999997, 0.359, 0.45599999999999996, 0.46399999999999997, 0.47, 1.4409999999999998, 0.46399999999999997, 0.45999999999999996, 0.954, -0.038000000000000034, 0.46399999999999997, 0.42700000000000005, 1.451, -0.03299999999999992, 0.4620000000000002, -0.03300000000000003, 0.4630000000000001, 0.47, 0.46399999999999997, -0.03500000000000003, 0.45799999999999996, 0.45999999999999996, 0.44099999999999984, 0.4710000000000001, -0.03700000000000003, -0.06500000000000006, 0.4670000000000001, 1.909, 0.97, 0.4710000000000001, 0.44599999999999995, -0.135, 0.2410000000000001, 0.45199999999999996, -0.03200000000000003, 1.456, 0.46499999999999986, -0.031000000000000028, 0.46599999999999997, 1.459, 0.472, 0.42999999999999994, 0.44100000000000006, 0.45299999999999985, -0.03199999999999992, 0.46399999999999997, 0.43900000000000006, -0.031000000000000028, 1.325, 0.47, -0.039000000000000035, 0.473, -0.04400000000000004, -0.031000000000000028, 0.46199999999999997, 0.4690000000000001, 0.403, 0.4710000000000001, 0.46399999999999997, -0.025000000000000022, 1.435, -0.03699999999999992, -0.062000000000000055, 0.45699999999999985, 0.45799999999999996, 1.3239999999999998, 0.44099999999999995, 0.939, 0.46899999999999986, 0.39600000000000013, -0.06099999999999994, 0.43900000000000006, -0.03600000000000003, 0.45300000000000007, 0.46399999999999997, -0.05500000000000005, -0.04300000000000004, -0.07799999999999996, 1.3940000000000001, 0.44899999999999984, 0.44099999999999984, -0.061000000000000054, -0.03400000000000003, -0.028000000000000025, 0.46499999999999986, 0.46399999999999997, 0.43599999999999994, 0.4750000000000001, -0.027000000000000024, -0.027000000000000024, 0.43999999999999995, 0.46599999999999997, 0.9630000000000001, 0.46599999999999997, 0.4730000000000001, 0.45500000000000007, -0.03199999999999992, -0.07900000000000007, -0.03400000000000003, 1.3850000000000002, -0.03699999999999992, 0.4620000000000002, 0.45799999999999996, 0.46599999999999997, 0.47299999999999986, -0.025000000000000022, -0.031000000000000028, -0.030000000000000027, 0.4630000000000001, 0.4750000000000001, 0.44499999999999984, 0.44900000000000007, 0.46399999999999997, 0.45799999999999996, 0.43999999999999995, -0.031000000000000028, -0.07500000000000007, -0.07199999999999995, 0.45999999999999996, 0.4670000000000001, -0.04599999999999993, 0.43100000000000005, 0.46399999999999997, 0.45999999999999996, -0.02100000000000002, 0.43199999999999994, 0.47299999999999986, -0.026000000000000023, 0.44999999999999996, 0.4590000000000001, 0.46599999999999997, 0.46599999999999997, -0.03500000000000003, 0.44999999999999996, 0.4610000000000001, -0.02499999999999991, 0.45699999999999985, -0.031000000000000028, -0.02400000000000002, 0.45399999999999996, 0.4630000000000001, 0.45999999999999996, 0.46399999999999997, 0.3599999999999999, 0.45599999999999996, 0.45699999999999985, 1.443, -0.03200000000000003, 0.4590000000000001, -0.031000000000000028, 0.958, 0.44200000000000017, 1.417, 0.4670000000000001, 0.9630000000000001, -0.06500000000000006, 0.44399999999999995, -0.04500000000000004, -0.03300000000000003, 0.44599999999999995, 0.371, 0.47, 0.44700000000000006, 0.45199999999999996, 0.3780000000000001, 0.4540000000000002, 1.4569999999999999, 0.45399999999999996, 0.4710000000000001, -0.06300000000000006, 0.46599999999999997, 0.44999999999999996, 0.395, -0.029000000000000026, -0.03200000000000003, 0.42599999999999993, -0.030000000000000027, 1.459, -0.03400000000000003, -0.03700000000000003, 0.78, -0.03399999999999992, 0.45999999999999996, 0.46399999999999997, 0.46399999999999997, 0.45999999999999996, 0.45799999999999996, 0.46199999999999997, 0.46499999999999986, 0.4750000000000001, 0.45599999999999996, 0.4289999999999998, -0.041000000000000036, 0.4650000000000001, -0.027000000000000024, -0.025000000000000022, 0.45599999999999996, 1.458, -0.028000000000000025, 0.3039999999999998, 0.45999999999999996, 0.4670000000000001, 0.46799999999999997, -0.03600000000000003, 0.44700000000000006, -0.03200000000000003, 0.4590000000000001, -0.02100000000000002, 0.4630000000000001, 0.44499999999999984, -0.04999999999999993, 0.41200000000000014, 0.46599999999999997, -0.028000000000000025, 1.9449999999999998, 0.46399999999999997, -0.03200000000000003, 1.4420000000000002, 0.4700000000000002, -0.02400000000000002, 1.4529999999999998, 0.9289999999999999, -0.02100000000000002, -0.028000000000000025, 0.46399999999999997, 0.44999999999999996, -0.051000000000000045, -0.041000000000000036, 0.44499999999999984, 0.45500000000000007, 0.46899999999999986, 0.46199999999999997, 0.31499999999999995, -0.027000000000000024, 0.4670000000000001, 0.46399999999999997, 0.472, -0.03600000000000003, 0.42799999999999994, -0.03200000000000003, 0.44900000000000007, -0.02100000000000002, 0.4620000000000002, -0.11399999999999999, 0.3900000000000001, -0.04800000000000004, 0.43199999999999994, 0.46599999999999997, -0.03200000000000003, 0.46499999999999986, -0.025000000000000022, -0.041000000000000036], "episode_lengths": [11, 25, 16, 15, 10, 15, 11, 10, 40, 14, 11, 10, 19, 12, 13, 15, 12, 11, 23, 15, 10, 12, 11, 12, 10, 12, 11, 14, 13, 18, 9, 12, 21, 11, 29, 10, 9, 17, 43, 83, 15, 10, 14, 11, 10, 11, 13, 9, 22, 19, 15, 10, 11, 19, 10, 54, 10, 13, 9, 14, 10, 12, 10, 30, 9, 11, 8, 21, 11, 20, 14, 14, 49, 19, 19, 10, 32, 18, 19, 12, 14, 11, 17, 14, 25, 34, 16, 19, 19, 11, 9, 11, 12, 20, 8, 9, 9, 19, 11, 12, 11, 8, 15, 10, 24, 11, 35, 11, 12, 13, 11, 9, 8, 10, 10, 11, 8, 17, 16, 11, 13, 19, 10, 24, 23, 13, 11, 15, 22, 11, 12, 7, 22, 9, 8, 16, 13, 11, 11, 11, 15, 12, 8, 14, 10, 8, 14, 12, 13, 12, 40, 14, 14, 17, 10, 12, 10, 13, 18, 26, 11, 12, 21, 18, 14, 10, 16, 41, 10, 16, 15, 38, 14, 14, 15, 9, 20, 11, 16, 34, 9, 10, 24, 10, 13, 11, 11, 71, 11, 13, 12, 11, 13, 13, 12, 11, 8, 14, 22, 13, 11, 9, 8, 14, 14, 9, 61, 13, 10, 10, 11, 16, 10, 13, 7, 11, 18, 15, 27, 11, 9, 18, 12, 10, 18, 9, 8, 15, 22, 7, 9, 11, 16, 16, 13, 16, 13, 10, 12, 58, 9, 11, 12, 9, 11, 22, 10, 16, 7, 12, 34, 36, 15, 21, 11, 10, 11, 8, 13], "policy_red_0_reward": [1.467, 1.423, 1.452, 1.455, 0.97, 1.455, 1.467, 1.47, 1.367, 1.458, 1.467, 1.47, 1.443, 1.464, 1.4609999999999999, 1.455, 0.964, 1.467, 0.929, 1.455, 0.97, 1.464, 0.967, 1.464, 0.97, 1.464, 0.967, 1.458, 1.4609999999999999, 1.446, 1.4729999999999999, 0.964, 0.9369999999999999, 1.467, 1.413, 1.47, 1.4729999999999999, 1.4489999999999998, 0.869, 1.251, 1.455, 0.97, 1.458, 1.467, 0.97, 1.467, 1.4609999999999999, 1.4729999999999999, 1.434, 1.443, 1.455, 0.97, 1.467, 1.439, 0.97, 1.3359999999999999, 1.47, 0.961, -0.5, 0.958, 0.97, 1.464, 1.47, 1.408, 1.4729999999999999, 1.467, 0.976, 1.4369999999999998, 0.966, 0.94, 1.458, 1.458, 1.331, -0.501, -0.5, 1.47, 1.401, 0.946, 1.443, 0.964, 1.458, 1.467, 0.948, 0.958, 0.925, 1.397, 1.452, 1.443, 0.943, 0.966, 0.973, 1.467, 0.964, 1.439, 1.476, 0.973, 0.973, 1.443, 0.967, 1.463, 1.467, 1.476, 1.455, 0.97, 0.9239999999999999, 0.967, 1.392, 0.967, 1.464, 1.4609999999999999, 1.467, 1.4729999999999999, 0.976, 0.97, 0.97, 1.466, 1.476, 1.4489999999999998, 1.452, 1.467, 1.4609999999999999, 1.443, 0.97, 0.9279999999999999, 0.931, 1.4609999999999999, 1.467, 0.955, 1.434, 1.467, 1.464, 0.979, 1.434, 1.4729999999999999, 0.976, 1.452, 1.4609999999999999, 1.467, 1.467, 0.966, 1.455, 1.464, -1.0, 1.458, 0.97, 0.976, 1.458, 1.464, 1.4609999999999999, 1.464, 0.868, 1.458, 1.458, 1.4489999999999998, 0.97, 1.464, 0.97, -0.502, 1.446, 1.421, 1.467, 1.464, 0.9369999999999999, 1.446, 0.958, 0.968, 0.948, 1.377, 1.47, 1.452, 1.455, 1.385, 1.458, 1.458, -0.5, 1.4729999999999999, 0.94, 1.467, 1.452, 1.3980000000000001, 0.973, 0.97, 1.428, 0.97, 1.4609999999999999, 0.967, 0.967, 1.284, 0.967, 1.4609999999999999, 1.464, 1.467, 1.4609999999999999, 1.4609999999999999, 1.464, 1.467, 1.476, 1.458, 1.434, 0.961, 1.467, 0.973, 0.976, 1.458, 1.458, 0.973, 1.314, 1.4609999999999999, 1.47, 1.47, 0.967, 1.451, 0.97, 1.4609999999999999, 0.979, 1.467, 1.446, 0.954, 1.419, 1.467, 0.973, 1.446, -0.5, 0.969, 1.446, 1.4729999999999999, 0.976, 1.455, -0.5, 0.979, 0.973, 1.467, 1.452, 0.952, 0.961, 1.448, 1.4609999999999999, 1.47, 1.464, 1.3210000000000002, 0.973, 1.467, 1.464, 1.4729999999999999, 0.966, 1.434, 0.97, 1.452, 0.979, 1.464, 0.888, 0.892, 0.954, 1.4369999999999998, 1.467, 0.97, 1.467, 0.976, 0.961], "policy_blue_0_reward": [-1.001, -1.0039999999999998, -1.002, -1.003, -1.002, -0.501, -1.0039999999999998, -1.0019999999999998, -1.008, -1.002, -1.003, -1.0, -0.002, -1.0, -1.001, -0.501, -1.002, -1.003, -0.5019999999999999, -0.004, -1.003, -1.0019999999999998, -1.0, -1.001, -0.5, -1.0, -1.002, -1.0, -1.001, -1.005, -1.002, -1.001, -1.002, -1.0, 0.496, -0.5, -1.002, -1.003, -1.004, -1.01, -1.003, -1.002, -0.002, -1.002, -1.001, -1.001, -0.002, -1.001, -1.004, -1.0019999999999998, -1.002, -1.0019999999999998, -1.003, -1.0, -1.001, -0.011000000000000003, -1.0, -1.0, 0.973, -1.002, -1.001, -1.002, -1.001, -1.005, -1.002, -1.003, -1.001, -0.002, -1.003, -1.002, -1.001, -1.0, -0.007, 0.942, 1.439, -1.001, -1.005, -1.007, -1.0039999999999998, -1.0, -1.005, -1.003, -1.003, -1.001, -1.003, -0.003, -1.003, -1.002, -1.004, -1.0, -1.001, -1.002, -0.5, -1.003, -1.001, -1.0, -1.0, -1.003, -0.501, -0.5, -1.001, -1.003, -1.0, -1.0019999999999998, -1.003, -1.001, -0.007, -1.0039999999999998, -1.0019999999999998, -1.003, -1.001, -1.0, -1.001, -1.001, -1.0, -1.003, -1.001, -1.004, -1.003, -1.003, -1.003, -1.003, -1.001, -1.003, -1.003, -1.001, -1.0, -1.001, -1.003, -1.003, -1.0039999999999998, -1.0, -1.002, -1.0, -1.002, -1.002, -1.002, -1.001, -1.001, -1.001, -1.005, -1.003, 0.975, -1.001, -1.001, -1.0, -1.004, -1.001, -1.001, -1.0, -0.508, -1.002, -1.001, -0.006, -1.002, -1.005, -1.001, 1.46, -1.0039999999999998, -0.004, -1.0, -0.501, -1.002, -1.002, -1.003, -1.001, -0.502, -1.0059999999999998, -1.0, -1.005, -1.003, -1.007, -1.0039999999999998, -0.001, 0.954, -1.002, -1.003, -1.001, -1.002, -1.003, -1.002, -1.002, -1.002, -1.0, -0.002, -1.001, -1.004, -0.504, -1.001, -1.001, -1.0, -1.003, -1.001, -1.003, -1.002, -1.002, -1.001, -1.002, -1.005, -1.002, -1.0019999999999998, -1.0, -1.001, -1.002, 0.0, -1.001, -1.01, -1.001, -1.003, -1.002, -1.003, -1.004, -1.002, -1.002, -1.0, -1.004, -1.001, -1.0039999999999998, -1.007, -1.001, -1.001, 0.499, 0.964, -1.001, -0.004, -1.003, -1.0, -0.002, 1.4289999999999998, -1.0, -1.001, -1.003, -1.002, -1.003, -1.002, -1.003, -1.006, -1.001, -1.002, -1.006, -1.0, -1.0, -1.0, -1.001, -1.002, -1.006, -1.002, -1.003, -1.0, -1.0019999999999998, -1.002, -0.502, -1.002, -1.005, -1.001, -1.002, -1.002, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24091378428983676, "mean_inference_ms": 1.4756249389950393, "mean_action_processing_ms": 0.0629055796573295, "mean_env_wait_ms": 0.08915177624713802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02167818629143321, "StateBufferConnector_ms": 0.0015690980270562484, "ViewRequirementAgentConnector_ms": 0.032748356749192166}}, "episode_reward_max": 1.9449999999999998, "episode_reward_min": -0.135, "episode_reward_mean": 0.38535521235521236, "episode_len_mean": 15.447876447876448, "episodes_this_iter": 259, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.01}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 1.222888030888031, "blue_0": -0.8375328185328184}, "hist_stats": {"episode_reward": [0.46599999999999997, 0.41900000000000004, 0.44999999999999996, 0.45199999999999996, -0.03200000000000003, 0.954, 0.4630000000000001, 0.46799999999999997, 0.359, 0.45599999999999996, 0.46399999999999997, 0.47, 1.4409999999999998, 0.46399999999999997, 0.45999999999999996, 0.954, -0.038000000000000034, 0.46399999999999997, 0.42700000000000005, 1.451, -0.03299999999999992, 0.4620000000000002, -0.03300000000000003, 0.4630000000000001, 0.47, 0.46399999999999997, -0.03500000000000003, 0.45799999999999996, 0.45999999999999996, 0.44099999999999984, 0.4710000000000001, -0.03700000000000003, -0.06500000000000006, 0.4670000000000001, 1.909, 0.97, 0.4710000000000001, 0.44599999999999995, -0.135, 0.2410000000000001, 0.45199999999999996, -0.03200000000000003, 1.456, 0.46499999999999986, -0.031000000000000028, 0.46599999999999997, 1.459, 0.472, 0.42999999999999994, 0.44100000000000006, 0.45299999999999985, -0.03199999999999992, 0.46399999999999997, 0.43900000000000006, -0.031000000000000028, 1.325, 0.47, -0.039000000000000035, 0.473, -0.04400000000000004, -0.031000000000000028, 0.46199999999999997, 0.4690000000000001, 0.403, 0.4710000000000001, 0.46399999999999997, -0.025000000000000022, 1.435, -0.03699999999999992, -0.062000000000000055, 0.45699999999999985, 0.45799999999999996, 1.3239999999999998, 0.44099999999999995, 0.939, 0.46899999999999986, 0.39600000000000013, -0.06099999999999994, 0.43900000000000006, -0.03600000000000003, 0.45300000000000007, 0.46399999999999997, -0.05500000000000005, -0.04300000000000004, -0.07799999999999996, 1.3940000000000001, 0.44899999999999984, 0.44099999999999984, -0.061000000000000054, -0.03400000000000003, -0.028000000000000025, 0.46499999999999986, 0.46399999999999997, 0.43599999999999994, 0.4750000000000001, -0.027000000000000024, -0.027000000000000024, 0.43999999999999995, 0.46599999999999997, 0.9630000000000001, 0.46599999999999997, 0.4730000000000001, 0.45500000000000007, -0.03199999999999992, -0.07900000000000007, -0.03400000000000003, 1.3850000000000002, -0.03699999999999992, 0.4620000000000002, 0.45799999999999996, 0.46599999999999997, 0.47299999999999986, -0.025000000000000022, -0.031000000000000028, -0.030000000000000027, 0.4630000000000001, 0.4750000000000001, 0.44499999999999984, 0.44900000000000007, 0.46399999999999997, 0.45799999999999996, 0.43999999999999995, -0.031000000000000028, -0.07500000000000007, -0.07199999999999995, 0.45999999999999996, 0.4670000000000001, -0.04599999999999993, 0.43100000000000005, 0.46399999999999997, 0.45999999999999996, -0.02100000000000002, 0.43199999999999994, 0.47299999999999986, -0.026000000000000023, 0.44999999999999996, 0.4590000000000001, 0.46599999999999997, 0.46599999999999997, -0.03500000000000003, 0.44999999999999996, 0.4610000000000001, -0.02499999999999991, 0.45699999999999985, -0.031000000000000028, -0.02400000000000002, 0.45399999999999996, 0.4630000000000001, 0.45999999999999996, 0.46399999999999997, 0.3599999999999999, 0.45599999999999996, 0.45699999999999985, 1.443, -0.03200000000000003, 0.4590000000000001, -0.031000000000000028, 0.958, 0.44200000000000017, 1.417, 0.4670000000000001, 0.9630000000000001, -0.06500000000000006, 0.44399999999999995, -0.04500000000000004, -0.03300000000000003, 0.44599999999999995, 0.371, 0.47, 0.44700000000000006, 0.45199999999999996, 0.3780000000000001, 0.4540000000000002, 1.4569999999999999, 0.45399999999999996, 0.4710000000000001, -0.06300000000000006, 0.46599999999999997, 0.44999999999999996, 0.395, -0.029000000000000026, -0.03200000000000003, 0.42599999999999993, -0.030000000000000027, 1.459, -0.03400000000000003, -0.03700000000000003, 0.78, -0.03399999999999992, 0.45999999999999996, 0.46399999999999997, 0.46399999999999997, 0.45999999999999996, 0.45799999999999996, 0.46199999999999997, 0.46499999999999986, 0.4750000000000001, 0.45599999999999996, 0.4289999999999998, -0.041000000000000036, 0.4650000000000001, -0.027000000000000024, -0.025000000000000022, 0.45599999999999996, 1.458, -0.028000000000000025, 0.3039999999999998, 0.45999999999999996, 0.4670000000000001, 0.46799999999999997, -0.03600000000000003, 0.44700000000000006, -0.03200000000000003, 0.4590000000000001, -0.02100000000000002, 0.4630000000000001, 0.44499999999999984, -0.04999999999999993, 0.41200000000000014, 0.46599999999999997, -0.028000000000000025, 1.9449999999999998, 0.46399999999999997, -0.03200000000000003, 1.4420000000000002, 0.4700000000000002, -0.02400000000000002, 1.4529999999999998, 0.9289999999999999, -0.02100000000000002, -0.028000000000000025, 0.46399999999999997, 0.44999999999999996, -0.051000000000000045, -0.041000000000000036, 0.44499999999999984, 0.45500000000000007, 0.46899999999999986, 0.46199999999999997, 0.31499999999999995, -0.027000000000000024, 0.4670000000000001, 0.46399999999999997, 0.472, -0.03600000000000003, 0.42799999999999994, -0.03200000000000003, 0.44900000000000007, -0.02100000000000002, 0.4620000000000002, -0.11399999999999999, 0.3900000000000001, -0.04800000000000004, 0.43199999999999994, 0.46599999999999997, -0.03200000000000003, 0.46499999999999986, -0.025000000000000022, -0.041000000000000036], "episode_lengths": [11, 25, 16, 15, 10, 15, 11, 10, 40, 14, 11, 10, 19, 12, 13, 15, 12, 11, 23, 15, 10, 12, 11, 12, 10, 12, 11, 14, 13, 18, 9, 12, 21, 11, 29, 10, 9, 17, 43, 83, 15, 10, 14, 11, 10, 11, 13, 9, 22, 19, 15, 10, 11, 19, 10, 54, 10, 13, 9, 14, 10, 12, 10, 30, 9, 11, 8, 21, 11, 20, 14, 14, 49, 19, 19, 10, 32, 18, 19, 12, 14, 11, 17, 14, 25, 34, 16, 19, 19, 11, 9, 11, 12, 20, 8, 9, 9, 19, 11, 12, 11, 8, 15, 10, 24, 11, 35, 11, 12, 13, 11, 9, 8, 10, 10, 11, 8, 17, 16, 11, 13, 19, 10, 24, 23, 13, 11, 15, 22, 11, 12, 7, 22, 9, 8, 16, 13, 11, 11, 11, 15, 12, 8, 14, 10, 8, 14, 12, 13, 12, 40, 14, 14, 17, 10, 12, 10, 13, 18, 26, 11, 12, 21, 18, 14, 10, 16, 41, 10, 16, 15, 38, 14, 14, 15, 9, 20, 11, 16, 34, 9, 10, 24, 10, 13, 11, 11, 71, 11, 13, 12, 11, 13, 13, 12, 11, 8, 14, 22, 13, 11, 9, 8, 14, 14, 9, 61, 13, 10, 10, 11, 16, 10, 13, 7, 11, 18, 15, 27, 11, 9, 18, 12, 10, 18, 9, 8, 15, 22, 7, 9, 11, 16, 16, 13, 16, 13, 10, 12, 58, 9, 11, 12, 9, 11, 22, 10, 16, 7, 12, 34, 36, 15, 21, 11, 10, 11, 8, 13], "policy_red_0_reward": [1.467, 1.423, 1.452, 1.455, 0.97, 1.455, 1.467, 1.47, 1.367, 1.458, 1.467, 1.47, 1.443, 1.464, 1.4609999999999999, 1.455, 0.964, 1.467, 0.929, 1.455, 0.97, 1.464, 0.967, 1.464, 0.97, 1.464, 0.967, 1.458, 1.4609999999999999, 1.446, 1.4729999999999999, 0.964, 0.9369999999999999, 1.467, 1.413, 1.47, 1.4729999999999999, 1.4489999999999998, 0.869, 1.251, 1.455, 0.97, 1.458, 1.467, 0.97, 1.467, 1.4609999999999999, 1.4729999999999999, 1.434, 1.443, 1.455, 0.97, 1.467, 1.439, 0.97, 1.3359999999999999, 1.47, 0.961, -0.5, 0.958, 0.97, 1.464, 1.47, 1.408, 1.4729999999999999, 1.467, 0.976, 1.4369999999999998, 0.966, 0.94, 1.458, 1.458, 1.331, -0.501, -0.5, 1.47, 1.401, 0.946, 1.443, 0.964, 1.458, 1.467, 0.948, 0.958, 0.925, 1.397, 1.452, 1.443, 0.943, 0.966, 0.973, 1.467, 0.964, 1.439, 1.476, 0.973, 0.973, 1.443, 0.967, 1.463, 1.467, 1.476, 1.455, 0.97, 0.9239999999999999, 0.967, 1.392, 0.967, 1.464, 1.4609999999999999, 1.467, 1.4729999999999999, 0.976, 0.97, 0.97, 1.466, 1.476, 1.4489999999999998, 1.452, 1.467, 1.4609999999999999, 1.443, 0.97, 0.9279999999999999, 0.931, 1.4609999999999999, 1.467, 0.955, 1.434, 1.467, 1.464, 0.979, 1.434, 1.4729999999999999, 0.976, 1.452, 1.4609999999999999, 1.467, 1.467, 0.966, 1.455, 1.464, -1.0, 1.458, 0.97, 0.976, 1.458, 1.464, 1.4609999999999999, 1.464, 0.868, 1.458, 1.458, 1.4489999999999998, 0.97, 1.464, 0.97, -0.502, 1.446, 1.421, 1.467, 1.464, 0.9369999999999999, 1.446, 0.958, 0.968, 0.948, 1.377, 1.47, 1.452, 1.455, 1.385, 1.458, 1.458, -0.5, 1.4729999999999999, 0.94, 1.467, 1.452, 1.3980000000000001, 0.973, 0.97, 1.428, 0.97, 1.4609999999999999, 0.967, 0.967, 1.284, 0.967, 1.4609999999999999, 1.464, 1.467, 1.4609999999999999, 1.4609999999999999, 1.464, 1.467, 1.476, 1.458, 1.434, 0.961, 1.467, 0.973, 0.976, 1.458, 1.458, 0.973, 1.314, 1.4609999999999999, 1.47, 1.47, 0.967, 1.451, 0.97, 1.4609999999999999, 0.979, 1.467, 1.446, 0.954, 1.419, 1.467, 0.973, 1.446, -0.5, 0.969, 1.446, 1.4729999999999999, 0.976, 1.455, -0.5, 0.979, 0.973, 1.467, 1.452, 0.952, 0.961, 1.448, 1.4609999999999999, 1.47, 1.464, 1.3210000000000002, 0.973, 1.467, 1.464, 1.4729999999999999, 0.966, 1.434, 0.97, 1.452, 0.979, 1.464, 0.888, 0.892, 0.954, 1.4369999999999998, 1.467, 0.97, 1.467, 0.976, 0.961], "policy_blue_0_reward": [-1.001, -1.0039999999999998, -1.002, -1.003, -1.002, -0.501, -1.0039999999999998, -1.0019999999999998, -1.008, -1.002, -1.003, -1.0, -0.002, -1.0, -1.001, -0.501, -1.002, -1.003, -0.5019999999999999, -0.004, -1.003, -1.0019999999999998, -1.0, -1.001, -0.5, -1.0, -1.002, -1.0, -1.001, -1.005, -1.002, -1.001, -1.002, -1.0, 0.496, -0.5, -1.002, -1.003, -1.004, -1.01, -1.003, -1.002, -0.002, -1.002, -1.001, -1.001, -0.002, -1.001, -1.004, -1.0019999999999998, -1.002, -1.0019999999999998, -1.003, -1.0, -1.001, -0.011000000000000003, -1.0, -1.0, 0.973, -1.002, -1.001, -1.002, -1.001, -1.005, -1.002, -1.003, -1.001, -0.002, -1.003, -1.002, -1.001, -1.0, -0.007, 0.942, 1.439, -1.001, -1.005, -1.007, -1.0039999999999998, -1.0, -1.005, -1.003, -1.003, -1.001, -1.003, -0.003, -1.003, -1.002, -1.004, -1.0, -1.001, -1.002, -0.5, -1.003, -1.001, -1.0, -1.0, -1.003, -0.501, -0.5, -1.001, -1.003, -1.0, -1.0019999999999998, -1.003, -1.001, -0.007, -1.0039999999999998, -1.0019999999999998, -1.003, -1.001, -1.0, -1.001, -1.001, -1.0, -1.003, -1.001, -1.004, -1.003, -1.003, -1.003, -1.003, -1.001, -1.003, -1.003, -1.001, -1.0, -1.001, -1.003, -1.003, -1.0039999999999998, -1.0, -1.002, -1.0, -1.002, -1.002, -1.002, -1.001, -1.001, -1.001, -1.005, -1.003, 0.975, -1.001, -1.001, -1.0, -1.004, -1.001, -1.001, -1.0, -0.508, -1.002, -1.001, -0.006, -1.002, -1.005, -1.001, 1.46, -1.0039999999999998, -0.004, -1.0, -0.501, -1.002, -1.002, -1.003, -1.001, -0.502, -1.0059999999999998, -1.0, -1.005, -1.003, -1.007, -1.0039999999999998, -0.001, 0.954, -1.002, -1.003, -1.001, -1.002, -1.003, -1.002, -1.002, -1.002, -1.0, -0.002, -1.001, -1.004, -0.504, -1.001, -1.001, -1.0, -1.003, -1.001, -1.003, -1.002, -1.002, -1.001, -1.002, -1.005, -1.002, -1.0019999999999998, -1.0, -1.001, -1.002, 0.0, -1.001, -1.01, -1.001, -1.003, -1.002, -1.003, -1.004, -1.002, -1.002, -1.0, -1.004, -1.001, -1.0039999999999998, -1.007, -1.001, -1.001, 0.499, 0.964, -1.001, -0.004, -1.003, -1.0, -0.002, 1.4289999999999998, -1.0, -1.001, -1.003, -1.002, -1.003, -1.002, -1.003, -1.006, -1.001, -1.002, -1.006, -1.0, -1.0, -1.0, -1.001, -1.002, -1.006, -1.002, -1.003, -1.0, -1.0019999999999998, -1.002, -0.502, -1.002, -1.005, -1.001, -1.002, -1.002, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24091378428983676, "mean_inference_ms": 1.4756249389950393, "mean_action_processing_ms": 0.0629055796573295, "mean_env_wait_ms": 0.08915177624713802, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02167818629143321, "StateBufferConnector_ms": 0.0015690980270562484, "ViewRequirementAgentConnector_ms": 0.032748356749192166}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000, "num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.47436146107684, "num_env_steps_trained_throughput_per_sec": 102.47436146107684, "timesteps_total": 136000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 272000, "timers": {"training_iteration_time_ms": 38978.212, "sample_time_ms": 7623.819, "learn_time_ms": 31336.923, "learn_throughput": 127.645, "synch_weights_time_ms": 16.965}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 136000, "num_agent_steps_sampled": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 3216, "training_iteration": 34, "trial_id": "d67e4_00000", "date": "2023-09-20_22-31-16", "timestamp": 1695263476, "time_this_iter_s": 39.04411602020264, "time_total_s": 1321.6567859649658, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a6879f30>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1321.6567859649658, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 33.80357142857143, "ram_util_percent": 48.5017857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.05223880597014925, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9216417910447762, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.026119402985074626, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9216417910447762, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.026119402985074626, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9216417910447762, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.026119402985074626, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7546621983870865, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010107161386258667, "policy_loss": -0.017981929994130043, "vf_loss": 0.009386970219444872, "vf_explained_var": 0.647506873185436, "kl": 0.007942202425212723, "entropy": 0.39270791339998445, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 33120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "sampler_results": {"episode_reward_max": 1.946, "episode_reward_min": -0.15400000000000003, "episode_reward_mean": 0.3325223880597015, "episode_len_mean": 14.600746268656716, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.973}, "policy_reward_mean": {"red_0": 1.210436567164179, "blue_0": -0.8779141791044776}, "custom_metrics": {"red_0/door_open_done_mean": 0.05223880597014925, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9216417910447762, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.026119402985074626, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9216417910447762, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.026119402985074626, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9216417910447762, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.026119402985074626, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4249999999999998, -0.038999999999999924, 0.30000000000000004, 0.43199999999999994, 0.44700000000000006, 0.4590000000000001, 1.448, -0.03199999999999992, 0.43999999999999995, -0.027000000000000024, -0.026000000000000023, -0.09099999999999997, -0.04400000000000004, -0.03200000000000003, 0.45999999999999996, 0.46599999999999997, -0.041000000000000036, -0.04500000000000004, -0.04400000000000004, 0.9610000000000001, 0.46199999999999997, 0.4590000000000001, 0.45299999999999985, -0.05900000000000005, -0.03399999999999992, 0.4540000000000002, -0.028000000000000025, 0.46399999999999997, 0.45399999999999996, 0.45999999999999996, 0.4670000000000001, 0.4249999999999998, 0.4690000000000001, 0.4670000000000001, -0.030000000000000027, 0.42300000000000004, 0.42399999999999993, 0.45500000000000007, 0.46799999999999997, 0.4610000000000001, 0.4710000000000001, 0.4750000000000001, -0.03400000000000003, 0.45299999999999985, -0.06500000000000006, -0.038999999999999924, 0.42799999999999994, 0.44399999999999995, 0.43399999999999994, -0.050000000000000044, -0.03299999999999992, 0.472, 0.474, -0.03600000000000003, 0.4670000000000001, 0.45699999999999985, 0.44399999999999995, -0.03499999999999992, 0.46599999999999997, -0.028000000000000025, 0.44799999999999995, 0.929, -0.026000000000000023, -0.03200000000000003, 0.45599999999999996, 0.46899999999999986, 0.4710000000000001, 0.46399999999999997, -0.025000000000000022, 1.4529999999999998, 0.45500000000000007, -0.04500000000000004, 0.45599999999999996, 0.42700000000000005, 0.46599999999999997, 0.46499999999999986, -0.038000000000000034, 0.474, -0.038000000000000034, 0.4670000000000001, 0.46599999999999997, -0.029000000000000026, 0.45999999999999996, -0.03499999999999992, -0.041000000000000036, 0.45300000000000007, 1.4489999999999998, 0.46499999999999986, 0.4740000000000002, -0.027000000000000024, 0.42200000000000015, 0.4660000000000002, -0.03200000000000003, 0.46599999999999997, 1.454, -0.031000000000000028, -0.030000000000000027, 0.4630000000000001, 0.43999999999999995, -0.03700000000000003, 0.363, -0.03799999999999992, 0.4159999999999999, -0.02400000000000002, 0.45500000000000007, 1.946, 0.96, 0.45599999999999996, 0.935, -0.026999999999999913, -0.07200000000000006, -0.04200000000000004, 0.4670000000000001, 0.45699999999999985, -0.028000000000000025, 0.44999999999999996, -0.031000000000000028, 0.4590000000000001, 0.31400000000000006, -0.040000000000000036, 0.954, -0.03500000000000003, -0.03600000000000003, 0.45199999999999996, 0.46599999999999997, -0.06800000000000006, -0.039999999999999925, 0.46499999999999986, 0.4670000000000001, 0.903, -0.03200000000000003, 0.45699999999999985, -0.026000000000000023, 0.44100000000000006, -0.07699999999999996, -0.03300000000000003, 0.472, -0.05600000000000005, -0.03500000000000003, -0.041999999999999926, 0.46599999999999997, -0.03599999999999992, -0.030000000000000027, -0.03599999999999992, -0.049000000000000044, 0.44799999999999995, -0.031000000000000028, 0.4630000000000001, 0.45399999999999996, 0.8700000000000001, -0.02400000000000002, -0.027000000000000024, 0.46199999999999997, -0.03200000000000003, 0.472, -0.03199999999999992, 0.45299999999999985, -0.02200000000000002, -0.06600000000000006, -0.027000000000000024, -0.03300000000000003, -0.02100000000000002, -0.027000000000000024, 0.45699999999999985, 0.47299999999999986, 0.45399999999999996, 0.45999999999999996, 0.46399999999999997, 0.46799999999999997, 1.4200000000000002, -0.03600000000000003, -0.038000000000000034, 0.45999999999999996, -0.05700000000000005, 0.45399999999999996, 0.46799999999999997, -0.02100000000000002, 0.4630000000000001, 0.46399999999999997, 0.44799999999999995, 0.43599999999999994, 0.4590000000000001, 0.45199999999999996, 0.43299999999999983, 0.405, 0.44899999999999984, 0.46399999999999997, 0.3340000000000001, -0.05999999999999994, 0.4650000000000001, 0.4630000000000001, -0.025999999999999912, 1.409, 0.46299999999999997, 0.45199999999999996, 0.469, 1.431, 0.45999999999999996, -0.030000000000000027, 0.45599999999999996, 0.44200000000000017, 0.476, 0.45300000000000007, -0.031000000000000028, -0.04700000000000004, -0.03200000000000003, -0.04300000000000004, -0.02400000000000002, -0.039000000000000035, -0.03299999999999992, -0.03500000000000003, 1.4300000000000002, 0.395, -0.03200000000000003, 0.46399999999999997, -0.025000000000000022, 0.32899999999999996, 0.46199999999999997, 0.4630000000000001, 0.45599999999999996, 0.46499999999999986, 0.4630000000000001, 0.4630000000000001, 0.45100000000000007, -0.04800000000000004, 0.46499999999999986, -0.031000000000000028, -0.029999999999999916, 0.907, 0.46099999999999985, 0.46099999999999985, 0.4690000000000001, 1.451, 1.456, 0.46599999999999997, 0.43399999999999994, 0.4590000000000001, 0.4670000000000001, -0.03700000000000003, 0.42700000000000005, -0.031000000000000028, 0.45599999999999996, 0.9449999999999998, 0.47, 0.45699999999999985, 0.4790000000000001, 0.43699999999999983, -0.03500000000000003, 0.40100000000000025, 1.4609999999999999, 0.45199999999999996, 1.4409999999999998, 0.4620000000000002, -0.041000000000000036, -0.031000000000000028, -0.031000000000000028, -0.031000000000000028, 1.447, 0.44899999999999984, -0.03300000000000003, -0.06700000000000006, -0.15400000000000003, -0.05800000000000005, 0.43999999999999995, 0.44599999999999995, -0.03299999999999992, 0.44599999999999995, -0.03700000000000003], "episode_lengths": [24, 12, 62, 22, 17, 13, 16, 10, 19, 9, 8, 28, 14, 10, 12, 11, 13, 14, 14, 12, 12, 13, 15, 18, 10, 14, 9, 11, 15, 13, 11, 24, 10, 11, 10, 24, 24, 14, 10, 12, 9, 8, 11, 14, 18, 12, 23, 18, 22, 16, 10, 9, 8, 12, 11, 14, 18, 10, 11, 9, 17, 23, 8, 10, 14, 10, 9, 12, 8, 15, 14, 14, 14, 23, 11, 11, 12, 8, 12, 10, 11, 9, 12, 11, 13, 15, 16, 11, 8, 9, 25, 11, 10, 10, 15, 10, 10, 12, 19, 12, 42, 12, 26, 8, 14, 18, 12, 14, 21, 8, 22, 14, 10, 14, 9, 16, 10, 13, 57, 12, 15, 11, 12, 16, 11, 22, 12, 11, 10, 31, 10, 13, 8, 18, 25, 10, 9, 18, 11, 13, 11, 11, 10, 11, 15, 16, 10, 11, 15, 40, 8, 9, 12, 10, 9, 10, 15, 7, 21, 9, 11, 7, 9, 13, 9, 15, 13, 10, 10, 25, 11, 12, 13, 17, 15, 10, 7, 11, 12, 17, 20, 13, 15, 21, 30, 17, 12, 53, 19, 11, 12, 8, 29, 12, 15, 10, 22, 12, 10, 14, 18, 8, 15, 10, 14, 10, 14, 8, 12, 10, 11, 23, 34, 10, 12, 8, 54, 12, 12, 13, 11, 12, 12, 16, 15, 11, 10, 9, 29, 12, 13, 10, 16, 14, 11, 21, 13, 11, 12, 23, 10, 14, 18, 10, 14, 7, 20, 11, 31, 13, 15, 18, 12, 13, 10, 10, 10, 16, 17, 10, 20, 47, 17, 18, 17, 10, 17, 12], "policy_red_0_reward": [1.426, 0.964, 1.312, 1.434, 1.448, 1.4609999999999999, 1.452, 0.97, 1.443, 0.973, 0.976, 0.914, 0.956, 0.97, 1.464, 1.467, 0.961, 0.958, 0.957, 1.464, 1.464, 1.4609999999999999, 1.455, 0.945, 0.97, 1.458, 0.973, 1.467, 1.455, 1.4609999999999999, 1.467, 1.428, 1.47, 1.467, 0.97, 1.426, 1.428, 1.458, 1.47, 1.464, 1.4729999999999999, 1.476, 0.967, 1.458, 0.9369999999999999, 0.964, 1.4300000000000002, 1.446, 1.434, 0.952, 0.97, 1.4729999999999999, 1.476, 0.964, 1.467, 1.458, 1.4449999999999998, 0.97, 0.966, 0.973, 1.4489999999999998, 1.431, 0.976, 0.97, 1.458, 1.47, 1.4729999999999999, 1.464, 0.976, 1.455, 1.458, 0.958, 1.458, 1.431, 1.467, 1.467, 0.964, 1.476, 0.964, 1.47, 1.467, 0.973, 1.464, 0.967, 0.961, 1.454, 1.452, 1.467, 1.476, 0.973, 1.425, 1.467, 0.969, 1.47, 1.455, 0.97, 0.97, 1.464, 1.443, 0.963, 1.3719999999999999, 0.964, 1.4220000000000002, 0.976, 1.456, 1.446, 1.464, 1.4569999999999999, 1.4369999999999998, 0.976, 0.9309999999999999, 0.958, 1.47, 1.458, 0.973, 1.452, 0.97, 1.4609999999999999, 1.326, 0.96, 1.455, 0.967, 0.964, 1.452, 1.467, 0.9339999999999999, 0.963, 1.467, 1.47, 1.4060000000000001, 0.97, 1.4609999999999999, 0.976, 1.446, 0.925, 0.97, -0.5, 0.946, 0.967, 0.961, 1.467, 0.966, 0.97, 0.967, 0.954, 1.452, 0.97, 1.467, -0.5, 1.377, 0.976, -1.0, 1.464, 0.97, 1.4729999999999999, 0.97, 1.455, 0.979, 0.9359999999999999, 0.973, 0.967, 0.979, 0.973, 1.4609999999999999, 1.4729999999999999, 1.455, 1.4609999999999999, 1.47, 1.47, 1.423, 0.967, 0.964, 1.4609999999999999, 0.947, 1.455, 1.47, 0.979, 1.467, 1.464, 1.4489999999999998, 1.44, 1.4609999999999999, 1.454, 1.4369999999999998, 1.4100000000000001, 1.4489999999999998, 1.464, 1.337, 0.943, 1.467, 1.464, 0.976, 1.411, -0.5, 1.455, -0.5, 1.434, 1.464, 0.97, 1.4569999999999999, 1.446, 1.476, 1.455, 0.97, 0.958, -1.0, 0.958, 0.976, 0.964, 0.97, 0.967, 1.431, 1.397, 0.97, 1.464, 0.975, 1.334, 1.464, 1.464, 1.4609999999999999, 1.467, 1.464, 1.464, 1.452, 0.955, 1.467, 0.97, 0.973, 1.4100000000000001, 1.464, 1.4609999999999999, 1.47, 1.452, 1.458, 1.467, 1.4369999999999998, 1.4609999999999999, 1.467, 0.964, 1.431, 0.97, 1.458, 1.446, -0.5, 1.458, 1.479, 1.44, 0.966, 1.4060000000000001, 1.4609999999999999, 1.4529999999999998, 1.444, 1.464, 0.96, 0.97, 0.97, 0.97, 1.452, 1.4489999999999998, 0.969, 0.938, 0.857, 0.944, 1.446, 1.4489999999999998, 0.97, 1.4489999999999998, 0.964], "policy_blue_0_reward": [-1.001, -1.003, -1.012, -1.002, -1.001, -1.002, -0.004, -1.0019999999999998, -1.003, -1.0, -1.002, -1.005, -1.0, -1.002, -1.004, -1.001, -1.002, -1.003, -1.001, -0.5029999999999999, -1.002, -1.002, -1.002, -1.004, -1.0039999999999998, -1.0039999999999998, -1.001, -1.003, -1.001, -1.001, -1.0, -1.003, -1.001, -1.0, -1.0, -1.003, -1.004, -1.003, -1.002, -1.003, -1.002, -1.001, -1.001, -1.005, -1.002, -1.003, -1.002, -1.002, -1.0, -1.002, -1.003, -1.001, -1.002, -1.0, -1.0, -1.001, -1.001, -1.005, -0.5, -1.001, -1.001, -0.502, -1.002, -1.002, -1.0019999999999998, -1.001, -1.002, -1.0, -1.001, -0.002, -1.003, -1.003, -1.002, -1.0039999999999998, -1.001, -1.002, -1.002, -1.002, -1.002, -1.003, -1.001, -1.002, -1.0039999999999998, -1.0019999999999998, -1.002, -1.001, -0.003, -1.002, -1.0019999999999998, -1.0, -1.003, -1.001, -1.001, -1.004, -0.001, -1.001, -1.0, -1.001, -1.003, -1.0, -1.009, -1.0019999999999998, -1.006, -1.0, -1.001, 0.5, -0.504, -1.001, -0.5019999999999999, -1.003, -1.003, -1.0, -1.003, -1.001, -1.001, -1.002, -1.001, -1.002, -1.012, -1.0, -0.501, -1.002, -1.0, -1.0, -1.001, -1.002, -1.003, -1.002, -1.003, -0.503, -1.002, -1.004, -1.002, -1.005, -1.002, -1.003, 0.972, -1.002, -1.002, -1.003, -1.001, -1.0019999999999998, -1.0, -1.003, -1.003, -1.004, -1.001, -1.0039999999999998, 0.954, -0.507, -1.0, 0.973, -1.002, -1.002, -1.001, -1.0019999999999998, -1.002, -1.001, -1.002, -1.0, -1.0, -1.0, -1.0, -1.004, -1.0, -1.001, -1.001, -1.0059999999999998, -1.002, -0.003, -1.003, -1.002, -1.001, -1.004, -1.001, -1.002, -1.0, -1.004, -1.0, -1.001, -1.004, -1.002, -1.002, -1.004, -1.005, -1.0, -1.0, -1.003, -1.003, -1.0019999999999998, -1.001, -1.0019999999999998, -0.002, 0.963, -1.003, 0.969, -0.003, -1.0039999999999998, -1.0, -1.001, -1.0039999999999998, -1.0, -1.0019999999999998, -1.001, -1.005, 0.968, -1.001, -1.0, -1.003, -1.003, -1.002, -0.001, -1.002, -1.002, -1.0, -1.0, -1.005, -1.002, -1.001, -1.005, -1.002, -1.001, -1.001, -1.001, -1.003, -1.002, -1.001, -1.003, -0.5029999999999999, -1.003, -1.0, -1.001, -0.001, -0.002, -1.001, -1.003, -1.002, -1.0, -1.001, -1.004, -1.001, -1.002, -0.501, 0.97, -1.001, -1.0, -1.003, -1.001, -1.005, 0.0, -1.001, -0.003, -1.0019999999999998, -1.001, -1.001, -1.001, -1.001, -0.005, -1.0, -1.002, -1.005, -1.011, -1.002, -1.0059999999999998, -1.003, -1.003, -1.003, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.242117736313866, "mean_inference_ms": 1.475743302982603, "mean_action_processing_ms": 0.06293113175639653, "mean_env_wait_ms": 0.08922971275105546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02178545318432708, "StateBufferConnector_ms": 0.0015741853571649808, "ViewRequirementAgentConnector_ms": 0.03282521198044962}}, "episode_reward_max": 1.946, "episode_reward_min": -0.15400000000000003, "episode_reward_mean": 0.3325223880597015, "episode_len_mean": 14.600746268656716, "episodes_this_iter": 268, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.012}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.973}, "policy_reward_mean": {"red_0": 1.210436567164179, "blue_0": -0.8779141791044776}, "hist_stats": {"episode_reward": [0.4249999999999998, -0.038999999999999924, 0.30000000000000004, 0.43199999999999994, 0.44700000000000006, 0.4590000000000001, 1.448, -0.03199999999999992, 0.43999999999999995, -0.027000000000000024, -0.026000000000000023, -0.09099999999999997, -0.04400000000000004, -0.03200000000000003, 0.45999999999999996, 0.46599999999999997, -0.041000000000000036, -0.04500000000000004, -0.04400000000000004, 0.9610000000000001, 0.46199999999999997, 0.4590000000000001, 0.45299999999999985, -0.05900000000000005, -0.03399999999999992, 0.4540000000000002, -0.028000000000000025, 0.46399999999999997, 0.45399999999999996, 0.45999999999999996, 0.4670000000000001, 0.4249999999999998, 0.4690000000000001, 0.4670000000000001, -0.030000000000000027, 0.42300000000000004, 0.42399999999999993, 0.45500000000000007, 0.46799999999999997, 0.4610000000000001, 0.4710000000000001, 0.4750000000000001, -0.03400000000000003, 0.45299999999999985, -0.06500000000000006, -0.038999999999999924, 0.42799999999999994, 0.44399999999999995, 0.43399999999999994, -0.050000000000000044, -0.03299999999999992, 0.472, 0.474, -0.03600000000000003, 0.4670000000000001, 0.45699999999999985, 0.44399999999999995, -0.03499999999999992, 0.46599999999999997, -0.028000000000000025, 0.44799999999999995, 0.929, -0.026000000000000023, -0.03200000000000003, 0.45599999999999996, 0.46899999999999986, 0.4710000000000001, 0.46399999999999997, -0.025000000000000022, 1.4529999999999998, 0.45500000000000007, -0.04500000000000004, 0.45599999999999996, 0.42700000000000005, 0.46599999999999997, 0.46499999999999986, -0.038000000000000034, 0.474, -0.038000000000000034, 0.4670000000000001, 0.46599999999999997, -0.029000000000000026, 0.45999999999999996, -0.03499999999999992, -0.041000000000000036, 0.45300000000000007, 1.4489999999999998, 0.46499999999999986, 0.4740000000000002, -0.027000000000000024, 0.42200000000000015, 0.4660000000000002, -0.03200000000000003, 0.46599999999999997, 1.454, -0.031000000000000028, -0.030000000000000027, 0.4630000000000001, 0.43999999999999995, -0.03700000000000003, 0.363, -0.03799999999999992, 0.4159999999999999, -0.02400000000000002, 0.45500000000000007, 1.946, 0.96, 0.45599999999999996, 0.935, -0.026999999999999913, -0.07200000000000006, -0.04200000000000004, 0.4670000000000001, 0.45699999999999985, -0.028000000000000025, 0.44999999999999996, -0.031000000000000028, 0.4590000000000001, 0.31400000000000006, -0.040000000000000036, 0.954, -0.03500000000000003, -0.03600000000000003, 0.45199999999999996, 0.46599999999999997, -0.06800000000000006, -0.039999999999999925, 0.46499999999999986, 0.4670000000000001, 0.903, -0.03200000000000003, 0.45699999999999985, -0.026000000000000023, 0.44100000000000006, -0.07699999999999996, -0.03300000000000003, 0.472, -0.05600000000000005, -0.03500000000000003, -0.041999999999999926, 0.46599999999999997, -0.03599999999999992, -0.030000000000000027, -0.03599999999999992, -0.049000000000000044, 0.44799999999999995, -0.031000000000000028, 0.4630000000000001, 0.45399999999999996, 0.8700000000000001, -0.02400000000000002, -0.027000000000000024, 0.46199999999999997, -0.03200000000000003, 0.472, -0.03199999999999992, 0.45299999999999985, -0.02200000000000002, -0.06600000000000006, -0.027000000000000024, -0.03300000000000003, -0.02100000000000002, -0.027000000000000024, 0.45699999999999985, 0.47299999999999986, 0.45399999999999996, 0.45999999999999996, 0.46399999999999997, 0.46799999999999997, 1.4200000000000002, -0.03600000000000003, -0.038000000000000034, 0.45999999999999996, -0.05700000000000005, 0.45399999999999996, 0.46799999999999997, -0.02100000000000002, 0.4630000000000001, 0.46399999999999997, 0.44799999999999995, 0.43599999999999994, 0.4590000000000001, 0.45199999999999996, 0.43299999999999983, 0.405, 0.44899999999999984, 0.46399999999999997, 0.3340000000000001, -0.05999999999999994, 0.4650000000000001, 0.4630000000000001, -0.025999999999999912, 1.409, 0.46299999999999997, 0.45199999999999996, 0.469, 1.431, 0.45999999999999996, -0.030000000000000027, 0.45599999999999996, 0.44200000000000017, 0.476, 0.45300000000000007, -0.031000000000000028, -0.04700000000000004, -0.03200000000000003, -0.04300000000000004, -0.02400000000000002, -0.039000000000000035, -0.03299999999999992, -0.03500000000000003, 1.4300000000000002, 0.395, -0.03200000000000003, 0.46399999999999997, -0.025000000000000022, 0.32899999999999996, 0.46199999999999997, 0.4630000000000001, 0.45599999999999996, 0.46499999999999986, 0.4630000000000001, 0.4630000000000001, 0.45100000000000007, -0.04800000000000004, 0.46499999999999986, -0.031000000000000028, -0.029999999999999916, 0.907, 0.46099999999999985, 0.46099999999999985, 0.4690000000000001, 1.451, 1.456, 0.46599999999999997, 0.43399999999999994, 0.4590000000000001, 0.4670000000000001, -0.03700000000000003, 0.42700000000000005, -0.031000000000000028, 0.45599999999999996, 0.9449999999999998, 0.47, 0.45699999999999985, 0.4790000000000001, 0.43699999999999983, -0.03500000000000003, 0.40100000000000025, 1.4609999999999999, 0.45199999999999996, 1.4409999999999998, 0.4620000000000002, -0.041000000000000036, -0.031000000000000028, -0.031000000000000028, -0.031000000000000028, 1.447, 0.44899999999999984, -0.03300000000000003, -0.06700000000000006, -0.15400000000000003, -0.05800000000000005, 0.43999999999999995, 0.44599999999999995, -0.03299999999999992, 0.44599999999999995, -0.03700000000000003], "episode_lengths": [24, 12, 62, 22, 17, 13, 16, 10, 19, 9, 8, 28, 14, 10, 12, 11, 13, 14, 14, 12, 12, 13, 15, 18, 10, 14, 9, 11, 15, 13, 11, 24, 10, 11, 10, 24, 24, 14, 10, 12, 9, 8, 11, 14, 18, 12, 23, 18, 22, 16, 10, 9, 8, 12, 11, 14, 18, 10, 11, 9, 17, 23, 8, 10, 14, 10, 9, 12, 8, 15, 14, 14, 14, 23, 11, 11, 12, 8, 12, 10, 11, 9, 12, 11, 13, 15, 16, 11, 8, 9, 25, 11, 10, 10, 15, 10, 10, 12, 19, 12, 42, 12, 26, 8, 14, 18, 12, 14, 21, 8, 22, 14, 10, 14, 9, 16, 10, 13, 57, 12, 15, 11, 12, 16, 11, 22, 12, 11, 10, 31, 10, 13, 8, 18, 25, 10, 9, 18, 11, 13, 11, 11, 10, 11, 15, 16, 10, 11, 15, 40, 8, 9, 12, 10, 9, 10, 15, 7, 21, 9, 11, 7, 9, 13, 9, 15, 13, 10, 10, 25, 11, 12, 13, 17, 15, 10, 7, 11, 12, 17, 20, 13, 15, 21, 30, 17, 12, 53, 19, 11, 12, 8, 29, 12, 15, 10, 22, 12, 10, 14, 18, 8, 15, 10, 14, 10, 14, 8, 12, 10, 11, 23, 34, 10, 12, 8, 54, 12, 12, 13, 11, 12, 12, 16, 15, 11, 10, 9, 29, 12, 13, 10, 16, 14, 11, 21, 13, 11, 12, 23, 10, 14, 18, 10, 14, 7, 20, 11, 31, 13, 15, 18, 12, 13, 10, 10, 10, 16, 17, 10, 20, 47, 17, 18, 17, 10, 17, 12], "policy_red_0_reward": [1.426, 0.964, 1.312, 1.434, 1.448, 1.4609999999999999, 1.452, 0.97, 1.443, 0.973, 0.976, 0.914, 0.956, 0.97, 1.464, 1.467, 0.961, 0.958, 0.957, 1.464, 1.464, 1.4609999999999999, 1.455, 0.945, 0.97, 1.458, 0.973, 1.467, 1.455, 1.4609999999999999, 1.467, 1.428, 1.47, 1.467, 0.97, 1.426, 1.428, 1.458, 1.47, 1.464, 1.4729999999999999, 1.476, 0.967, 1.458, 0.9369999999999999, 0.964, 1.4300000000000002, 1.446, 1.434, 0.952, 0.97, 1.4729999999999999, 1.476, 0.964, 1.467, 1.458, 1.4449999999999998, 0.97, 0.966, 0.973, 1.4489999999999998, 1.431, 0.976, 0.97, 1.458, 1.47, 1.4729999999999999, 1.464, 0.976, 1.455, 1.458, 0.958, 1.458, 1.431, 1.467, 1.467, 0.964, 1.476, 0.964, 1.47, 1.467, 0.973, 1.464, 0.967, 0.961, 1.454, 1.452, 1.467, 1.476, 0.973, 1.425, 1.467, 0.969, 1.47, 1.455, 0.97, 0.97, 1.464, 1.443, 0.963, 1.3719999999999999, 0.964, 1.4220000000000002, 0.976, 1.456, 1.446, 1.464, 1.4569999999999999, 1.4369999999999998, 0.976, 0.9309999999999999, 0.958, 1.47, 1.458, 0.973, 1.452, 0.97, 1.4609999999999999, 1.326, 0.96, 1.455, 0.967, 0.964, 1.452, 1.467, 0.9339999999999999, 0.963, 1.467, 1.47, 1.4060000000000001, 0.97, 1.4609999999999999, 0.976, 1.446, 0.925, 0.97, -0.5, 0.946, 0.967, 0.961, 1.467, 0.966, 0.97, 0.967, 0.954, 1.452, 0.97, 1.467, -0.5, 1.377, 0.976, -1.0, 1.464, 0.97, 1.4729999999999999, 0.97, 1.455, 0.979, 0.9359999999999999, 0.973, 0.967, 0.979, 0.973, 1.4609999999999999, 1.4729999999999999, 1.455, 1.4609999999999999, 1.47, 1.47, 1.423, 0.967, 0.964, 1.4609999999999999, 0.947, 1.455, 1.47, 0.979, 1.467, 1.464, 1.4489999999999998, 1.44, 1.4609999999999999, 1.454, 1.4369999999999998, 1.4100000000000001, 1.4489999999999998, 1.464, 1.337, 0.943, 1.467, 1.464, 0.976, 1.411, -0.5, 1.455, -0.5, 1.434, 1.464, 0.97, 1.4569999999999999, 1.446, 1.476, 1.455, 0.97, 0.958, -1.0, 0.958, 0.976, 0.964, 0.97, 0.967, 1.431, 1.397, 0.97, 1.464, 0.975, 1.334, 1.464, 1.464, 1.4609999999999999, 1.467, 1.464, 1.464, 1.452, 0.955, 1.467, 0.97, 0.973, 1.4100000000000001, 1.464, 1.4609999999999999, 1.47, 1.452, 1.458, 1.467, 1.4369999999999998, 1.4609999999999999, 1.467, 0.964, 1.431, 0.97, 1.458, 1.446, -0.5, 1.458, 1.479, 1.44, 0.966, 1.4060000000000001, 1.4609999999999999, 1.4529999999999998, 1.444, 1.464, 0.96, 0.97, 0.97, 0.97, 1.452, 1.4489999999999998, 0.969, 0.938, 0.857, 0.944, 1.446, 1.4489999999999998, 0.97, 1.4489999999999998, 0.964], "policy_blue_0_reward": [-1.001, -1.003, -1.012, -1.002, -1.001, -1.002, -0.004, -1.0019999999999998, -1.003, -1.0, -1.002, -1.005, -1.0, -1.002, -1.004, -1.001, -1.002, -1.003, -1.001, -0.5029999999999999, -1.002, -1.002, -1.002, -1.004, -1.0039999999999998, -1.0039999999999998, -1.001, -1.003, -1.001, -1.001, -1.0, -1.003, -1.001, -1.0, -1.0, -1.003, -1.004, -1.003, -1.002, -1.003, -1.002, -1.001, -1.001, -1.005, -1.002, -1.003, -1.002, -1.002, -1.0, -1.002, -1.003, -1.001, -1.002, -1.0, -1.0, -1.001, -1.001, -1.005, -0.5, -1.001, -1.001, -0.502, -1.002, -1.002, -1.0019999999999998, -1.001, -1.002, -1.0, -1.001, -0.002, -1.003, -1.003, -1.002, -1.0039999999999998, -1.001, -1.002, -1.002, -1.002, -1.002, -1.003, -1.001, -1.002, -1.0039999999999998, -1.0019999999999998, -1.002, -1.001, -0.003, -1.002, -1.0019999999999998, -1.0, -1.003, -1.001, -1.001, -1.004, -0.001, -1.001, -1.0, -1.001, -1.003, -1.0, -1.009, -1.0019999999999998, -1.006, -1.0, -1.001, 0.5, -0.504, -1.001, -0.5019999999999999, -1.003, -1.003, -1.0, -1.003, -1.001, -1.001, -1.002, -1.001, -1.002, -1.012, -1.0, -0.501, -1.002, -1.0, -1.0, -1.001, -1.002, -1.003, -1.002, -1.003, -0.503, -1.002, -1.004, -1.002, -1.005, -1.002, -1.003, 0.972, -1.002, -1.002, -1.003, -1.001, -1.0019999999999998, -1.0, -1.003, -1.003, -1.004, -1.001, -1.0039999999999998, 0.954, -0.507, -1.0, 0.973, -1.002, -1.002, -1.001, -1.0019999999999998, -1.002, -1.001, -1.002, -1.0, -1.0, -1.0, -1.0, -1.004, -1.0, -1.001, -1.001, -1.0059999999999998, -1.002, -0.003, -1.003, -1.002, -1.001, -1.004, -1.001, -1.002, -1.0, -1.004, -1.0, -1.001, -1.004, -1.002, -1.002, -1.004, -1.005, -1.0, -1.0, -1.003, -1.003, -1.0019999999999998, -1.001, -1.0019999999999998, -0.002, 0.963, -1.003, 0.969, -0.003, -1.0039999999999998, -1.0, -1.001, -1.0039999999999998, -1.0, -1.0019999999999998, -1.001, -1.005, 0.968, -1.001, -1.0, -1.003, -1.003, -1.002, -0.001, -1.002, -1.002, -1.0, -1.0, -1.005, -1.002, -1.001, -1.005, -1.002, -1.001, -1.001, -1.001, -1.003, -1.002, -1.001, -1.003, -0.5029999999999999, -1.003, -1.0, -1.001, -0.001, -0.002, -1.001, -1.003, -1.002, -1.0, -1.001, -1.004, -1.001, -1.002, -0.501, 0.97, -1.001, -1.0, -1.003, -1.001, -1.005, 0.0, -1.001, -0.003, -1.0019999999999998, -1.001, -1.001, -1.001, -1.001, -0.005, -1.0, -1.002, -1.005, -1.011, -1.002, -1.0059999999999998, -1.003, -1.003, -1.003, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.242117736313866, "mean_inference_ms": 1.475743302982603, "mean_action_processing_ms": 0.06293113175639653, "mean_env_wait_ms": 0.08922971275105546, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02178545318432708, "StateBufferConnector_ms": 0.0015741853571649808, "ViewRequirementAgentConnector_ms": 0.03282521198044962}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000, "num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.30828971012484, "num_env_steps_trained_throughput_per_sec": 102.30828971012484, "timesteps_total": 140000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 280000, "timers": {"training_iteration_time_ms": 38994.312, "sample_time_ms": 7635.132, "learn_time_ms": 31341.739, "learn_throughput": 127.625, "synch_weights_time_ms": 16.939}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 140000, "num_agent_steps_sampled": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 3484, "training_iteration": 35, "trial_id": "d67e4_00000", "date": "2023-09-20_22-31-55", "timestamp": 1695263515, "time_this_iter_s": 39.10739994049072, "time_total_s": 1360.7641859054565, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4707370>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1360.7641859054565, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 34.066071428571426, "ram_util_percent": 48.56428571428571}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.04291845493562232, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.927038626609442, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.030042918454935622, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.927038626609442, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.030042918454935622, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.927038626609442, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.030042918454935622, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8641710901012023, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008506209000188392, "policy_loss": -0.016106388109134666, "vf_loss": 0.009221226073956737, "vf_explained_var": 0.6777135693157713, "kl": 0.007640817857900372, "entropy": 0.44880203204229474, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 34080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "sampler_results": {"episode_reward_max": 1.46, "episode_reward_min": -0.741, "episode_reward_mean": 0.35355793991416307, "episode_len_mean": 17.090128755364805, "episode_media": {}, "episodes_this_iter": 233, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.025}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.407}, "policy_reward_mean": {"red_0": 1.2308798283261804, "blue_0": -0.8773218884120172}, "custom_metrics": {"red_0/door_open_done_mean": 0.04291845493562232, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.927038626609442, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.030042918454935622, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.927038626609442, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.030042918454935622, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.927038626609442, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.030042918454935622, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.40200000000000014, 0.46599999999999997, 0.902, 0.4630000000000001, 0.43500000000000005, 1.416, 0.46599999999999997, 0.44500000000000006, -0.03700000000000003, 0.46199999999999997, 0.4710000000000001, 0.46499999999999986, 0.46599999999999997, 0.45799999999999996, 0.43100000000000005, 0.4630000000000001, -0.03299999999999992, 0.46399999999999997, 0.44200000000000017, 0.45699999999999985, -0.02400000000000002, -0.04200000000000004, 0.9609999999999999, -0.11299999999999999, 0.45399999999999996, 0.4630000000000001, 0.45599999999999996, 0.45500000000000007, 0.45999999999999996, 0.45199999999999996, -0.050000000000000044, 1.4449999999999998, -0.031000000000000028, 0.47, 0.46799999999999997, 0.44899999999999984, 0.45999999999999996, -0.03400000000000003, 0.923, -0.031000000000000028, 0.45199999999999996, -0.03300000000000003, 0.45599999999999996, 0.46399999999999997, 0.45799999999999996, 0.4590000000000001, 0.46499999999999986, 0.3340000000000001, 0.42199999999999993, 0.4670000000000001, -0.03199999999999992, 1.447, -0.3440000000000001, -0.05400000000000005, -0.03200000000000003, 0.46499999999999986, -0.030000000000000027, 0.385, -0.02300000000000002, 0.46799999999999997, 0.45699999999999985, 0.47, -0.04299999999999993, 0.46499999999999986, 0.45399999999999996, 0.46399999999999997, -0.02300000000000002, 0.44700000000000006, 1.4569999999999999, 0.46599999999999997, -0.030000000000000027, 0.47, 0.45599999999999996, -0.038999999999999924, -0.03200000000000003, 0.97, 0.476, 0.47, -0.02400000000000002, -0.026000000000000023, 0.46799999999999997, 0.46199999999999997, 0.4570000000000001, 0.45999999999999996, -0.018000000000000016, 0.4540000000000002, 1.4529999999999998, 0.43500000000000005, 0.4670000000000001, -0.03600000000000003, 0.952, 0.4630000000000001, 0.4590000000000001, -0.04400000000000004, -0.040999999999999925, 0.4590000000000001, 0.46099999999999985, 0.46099999999999985, 0.45300000000000007, 0.45999999999999996, -0.03600000000000003, -0.04400000000000004, -0.03399999999999992, -0.041000000000000036, 0.46499999999999986, 0.3580000000000001, 0.45999999999999996, -0.041000000000000036, -0.1299999999999999, -0.08799999999999997, 0.4630000000000001, 0.45199999999999996, 0.46799999999999997, -0.03300000000000003, -0.04800000000000004, 0.46599999999999997, 0.4630000000000001, 0.41999999999999993, 0.4660000000000002, 0.46899999999999986, -0.741, 0.46499999999999986, -0.04800000000000004, -0.02100000000000002, -0.03400000000000003, 0.46399999999999997, 0.4750000000000001, 0.472, 0.9489999999999998, -0.040000000000000036, 0.46899999999999986, -0.22799999999999998, 1.46, -0.04300000000000004, 0.44399999999999995, 0.47299999999999986, 0.46599999999999997, -0.028000000000000025, -0.031000000000000028, 0.958, 0.46799999999999997, -0.049000000000000044, -0.02400000000000002, -0.03700000000000003, 0.46499999999999986, 0.45999999999999996, -0.031000000000000028, -0.030000000000000027, 0.45799999999999996, -0.041000000000000036, -0.025000000000000022, 0.46099999999999997, 0.46599999999999997, 0.474, 0.45199999999999996, 1.425, 1.452, 0.4620000000000002, 0.4590000000000001, 0.45599999999999996, 0.45399999999999996, 0.43100000000000005, 0.472, -0.04300000000000004, 0.45399999999999996, 0.39800000000000013, 0.47299999999999986, -0.07100000000000006, 0.42700000000000005, -0.03400000000000003, -0.05400000000000005, 0.4710000000000001, -0.05500000000000005, -0.04600000000000004, 0.29600000000000004, 0.44300000000000006, -0.030000000000000027, 0.44300000000000006, 0.43500000000000005, 0.47299999999999986, 0.44099999999999984, 0.4289999999999998, 0.4670000000000001, 0.46499999999999986, 0.44499999999999984, 0.4790000000000001, -0.06699999999999995, 0.4590000000000001, 0.4690000000000001, -0.03400000000000003, -0.038999999999999924, -0.05899999999999994, 0.3900000000000001, 0.46599999999999997, 0.44300000000000006, 0.43999999999999995, 0.4690000000000001, -0.03500000000000003, 0.45199999999999996, 0.44999999999999996, -0.04400000000000004, -0.040000000000000036, 0.45799999999999996, -0.03400000000000003, -0.030000000000000027, -0.05600000000000005, 0.46899999999999986, 0.46499999999999986, 0.47, 0.41999999999999993, 0.3839999999999999, 0.47299999999999986, 1.362, 0.42999999999999994, 0.45500000000000007, 0.40600000000000014, 0.44799999999999995, -0.038000000000000034, 0.43100000000000005, 0.9650000000000001, -0.03300000000000003, 0.43999999999999995, 1.421, 0.4630000000000001, 0.46499999999999986, -0.10799999999999987, 0.476, 0.3919999999999999, 0.44599999999999995, 0.44799999999999995, 0.44799999999999995, 0.476, 0.44799999999999995], "episode_lengths": [31, 11, 30, 12, 21, 26, 11, 17, 12, 12, 9, 11, 11, 13, 22, 12, 10, 11, 17, 13, 8, 13, 13, 36, 15, 12, 14, 14, 12, 15, 16, 18, 10, 10, 10, 17, 13, 11, 24, 10, 15, 10, 14, 11, 13, 13, 11, 52, 24, 10, 10, 17, 267, 17, 10, 11, 10, 33, 7, 10, 14, 10, 13, 11, 15, 11, 7, 17, 14, 11, 9, 10, 14, 12, 10, 10, 8, 10, 8, 8, 10, 12, 13, 13, 6, 14, 15, 21, 11, 11, 16, 12, 13, 14, 13, 13, 12, 12, 15, 13, 12, 13, 10, 13, 10, 46, 12, 13, 41, 29, 12, 15, 10, 10, 14, 11, 11, 25, 10, 10, 238, 11, 15, 7, 11, 12, 8, 9, 16, 13, 10, 72, 13, 14, 18, 9, 11, 9, 10, 13, 10, 16, 8, 12, 11, 13, 10, 10, 13, 13, 8, 12, 11, 8, 15, 25, 15, 11, 13, 14, 15, 22, 9, 14, 15, 31, 9, 21, 23, 11, 17, 9, 17, 15, 64, 18, 10, 18, 20, 9, 18, 22, 11, 11, 18, 7, 20, 13, 10, 11, 12, 18, 34, 11, 17, 18, 10, 11, 16, 16, 14, 12, 14, 11, 9, 17, 10, 11, 10, 26, 36, 9, 40, 22, 14, 29, 15, 12, 22, 11, 10, 18, 25, 12, 11, 33, 8, 33, 17, 16, 17, 8, 16], "policy_red_0_reward": [1.405, 1.467, -0.505, 1.464, 1.436, 1.4220000000000002, 1.467, 1.4489999999999998, 0.964, 1.464, 1.4729999999999999, 1.467, 1.467, 1.4609999999999999, 1.434, 1.464, 0.969, 1.467, 1.4489999999999998, 1.4609999999999999, 0.976, 0.961, 1.4609999999999999, 0.892, -0.5, 1.464, 1.458, 1.458, 1.464, 1.455, 0.952, 1.446, 0.969, 1.47, 1.47, 1.4489999999999998, 1.4609999999999999, 0.966, 1.426, 0.97, 1.455, 0.97, 1.458, 1.467, 1.4609999999999999, 1.4609999999999999, 1.467, 1.3439999999999999, 1.426, 1.47, 0.97, 1.4489999999999998, 0.18999999999999995, 0.949, 0.97, 1.467, 0.97, 1.393, 0.979, 1.47, 1.458, 1.47, 0.959, 1.467, 1.455, -0.5, 0.979, 1.4489999999999998, 1.458, 1.467, 0.971, 1.47, 1.458, 0.964, 0.97, 1.47, 1.476, 1.47, 0.976, 0.976, 1.47, -0.501, 1.4609999999999999, 1.4609999999999999, 0.982, 1.458, 1.455, 1.435, 1.467, 0.967, 1.452, 1.464, 1.4609999999999999, 0.958, 0.961, 1.4609999999999999, 1.464, 1.464, 1.455, 1.4609999999999999, 0.964, 0.961, 0.97, 0.96, 1.47, 1.361, 1.464, -1.001, 0.873, 0.913, 1.464, 1.455, 1.47, 0.97, 0.957, 1.467, 1.467, 1.424, 1.47, 1.47, 0.28400000000000003, 1.467, 0.955, 0.979, 0.967, 1.464, 1.476, 1.4729999999999999, 1.452, 0.961, 1.47, 0.781, 1.4609999999999999, 0.958, 1.446, 1.4729999999999999, 0.967, 0.973, 0.97, 1.4609999999999999, 1.47, 0.952, 0.976, 0.964, 1.467, 1.4609999999999999, 0.969, 0.97, 1.4609999999999999, 0.961, 0.976, -0.5, 1.467, 1.476, 1.455, 1.425, 1.455, 1.467, 1.4609999999999999, 1.458, 0.955, 1.434, 1.4729999999999999, 0.958, 1.455, 1.405, 1.4729999999999999, 0.9319999999999999, 1.4300000000000002, 0.967, 0.949, 1.4729999999999999, 0.946, 0.955, 1.304, 1.4449999999999998, 0.97, 1.446, 1.44, 1.4729999999999999, 1.446, 1.4329999999999998, 1.467, 1.467, 1.446, 1.479, -1.001, 1.4609999999999999, 1.47, 0.967, 0.963, 0.945, 1.397, 1.467, 1.4489999999999998, 1.4449999999999998, 1.47, 0.967, 1.452, 1.452, 0.958, 0.962, 1.458, 0.967, 0.972, 0.949, 1.47, 1.467, 1.47, 1.4220000000000002, 1.389, 1.4729999999999999, 1.371, 1.432, 1.458, 1.412, 1.455, 0.964, 1.434, 1.467, 0.97, 1.444, 1.425, 1.464, 1.467, 0.9, 1.476, 1.4, 1.4489999999999998, 1.452, 1.4489999999999998, 1.476, 1.452], "policy_blue_0_reward": [-1.003, -1.001, 1.407, -1.001, -1.001, -0.006, -1.001, -1.0039999999999998, -1.001, -1.002, -1.002, -1.002, -1.001, -1.003, -1.003, -1.001, -1.0019999999999998, -1.003, -1.007, -1.004, -1.0, -1.003, -0.5, -1.005, 0.954, -1.001, -1.002, -1.003, -1.0039999999999998, -1.003, -1.002, -0.001, -1.0, -1.0, -1.002, -1.0, -1.001, -1.0, -0.5029999999999999, -1.001, -1.003, -1.003, -1.002, -1.003, -1.003, -1.002, -1.002, -1.0099999999999998, -1.004, -1.003, -1.0019999999999998, -0.002, -0.534, -1.003, -1.002, -1.002, -1.0, -1.008, -1.002, -1.002, -1.001, -1.0, -1.0019999999999998, -1.002, -1.001, 0.964, -1.002, -1.002, -0.001, -1.001, -1.001, -1.0, -1.002, -1.003, -1.002, -0.5, -1.0, -1.0, -1.0, -1.002, -1.002, 0.963, -1.0039999999999998, -1.001, -1.0, -1.0039999999999998, -0.002, -1.0, -1.0, -1.003, -0.5, -1.001, -1.0019999999999998, -1.002, -1.0019999999999998, -1.002, -1.003, -1.003, -1.0019999999999998, -1.001, -1.0, -1.005, -1.0039999999999998, -1.001, -1.005, -1.003, -1.004, 0.96, -1.003, -1.001, -1.001, -1.003, -1.002, -1.003, -1.005, -1.001, -1.004, -1.004, -1.0039999999999998, -1.001, -1.025, -1.002, -1.003, -1.0, -1.001, -1.0, -1.001, -1.001, -0.503, -1.001, -1.001, -1.009, -0.001, -1.001, -1.002, -1.0, -0.501, -1.001, -1.001, -0.503, -1.002, -1.001, -1.0, -1.001, -1.002, -1.001, -1.0, -1.0, -1.003, -1.002, -1.001, 0.961, -1.001, -1.002, -1.003, 0.0, -0.003, -1.005, -1.002, -1.002, -0.501, -1.003, -1.001, -1.001, -1.001, -1.007, -1.0, -1.003, -1.003, -1.001, -1.003, -1.002, -1.001, -1.001, -1.008, -1.002, -1.0, -1.003, -1.005, -1.0, -1.005, -1.004, -1.0, -1.002, -1.001, -1.0, 0.9339999999999999, -1.002, -1.001, -1.001, -1.0019999999999998, -1.0039999999999998, -1.007, -1.001, -1.006, -1.005, -1.001, -1.002, -1.0, -1.002, -1.002, -1.002, -1.0, -1.001, -1.002, -1.005, -1.001, -1.002, -1.0, -1.002, -1.005, -1.0, -0.009000000000000001, -1.002, -1.003, -1.006, -1.007, -1.002, -1.003, -0.5019999999999999, -1.003, -1.004, -0.004, -1.001, -1.002, -1.0079999999999998, -1.0, -1.008, -1.003, -1.004, -1.001, -1.0, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24313712109376664, "mean_inference_ms": 1.4758421721931403, "mean_action_processing_ms": 0.06299279050035368, "mean_env_wait_ms": 0.08931474952012436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022032281359889477, "StateBufferConnector_ms": 0.0015646091346577001, "ViewRequirementAgentConnector_ms": 0.03277672206895034}}, "episode_reward_max": 1.46, "episode_reward_min": -0.741, "episode_reward_mean": 0.35355793991416307, "episode_len_mean": 17.090128755364805, "episodes_this_iter": 233, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.025}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.407}, "policy_reward_mean": {"red_0": 1.2308798283261804, "blue_0": -0.8773218884120172}, "hist_stats": {"episode_reward": [0.40200000000000014, 0.46599999999999997, 0.902, 0.4630000000000001, 0.43500000000000005, 1.416, 0.46599999999999997, 0.44500000000000006, -0.03700000000000003, 0.46199999999999997, 0.4710000000000001, 0.46499999999999986, 0.46599999999999997, 0.45799999999999996, 0.43100000000000005, 0.4630000000000001, -0.03299999999999992, 0.46399999999999997, 0.44200000000000017, 0.45699999999999985, -0.02400000000000002, -0.04200000000000004, 0.9609999999999999, -0.11299999999999999, 0.45399999999999996, 0.4630000000000001, 0.45599999999999996, 0.45500000000000007, 0.45999999999999996, 0.45199999999999996, -0.050000000000000044, 1.4449999999999998, -0.031000000000000028, 0.47, 0.46799999999999997, 0.44899999999999984, 0.45999999999999996, -0.03400000000000003, 0.923, -0.031000000000000028, 0.45199999999999996, -0.03300000000000003, 0.45599999999999996, 0.46399999999999997, 0.45799999999999996, 0.4590000000000001, 0.46499999999999986, 0.3340000000000001, 0.42199999999999993, 0.4670000000000001, -0.03199999999999992, 1.447, -0.3440000000000001, -0.05400000000000005, -0.03200000000000003, 0.46499999999999986, -0.030000000000000027, 0.385, -0.02300000000000002, 0.46799999999999997, 0.45699999999999985, 0.47, -0.04299999999999993, 0.46499999999999986, 0.45399999999999996, 0.46399999999999997, -0.02300000000000002, 0.44700000000000006, 1.4569999999999999, 0.46599999999999997, -0.030000000000000027, 0.47, 0.45599999999999996, -0.038999999999999924, -0.03200000000000003, 0.97, 0.476, 0.47, -0.02400000000000002, -0.026000000000000023, 0.46799999999999997, 0.46199999999999997, 0.4570000000000001, 0.45999999999999996, -0.018000000000000016, 0.4540000000000002, 1.4529999999999998, 0.43500000000000005, 0.4670000000000001, -0.03600000000000003, 0.952, 0.4630000000000001, 0.4590000000000001, -0.04400000000000004, -0.040999999999999925, 0.4590000000000001, 0.46099999999999985, 0.46099999999999985, 0.45300000000000007, 0.45999999999999996, -0.03600000000000003, -0.04400000000000004, -0.03399999999999992, -0.041000000000000036, 0.46499999999999986, 0.3580000000000001, 0.45999999999999996, -0.041000000000000036, -0.1299999999999999, -0.08799999999999997, 0.4630000000000001, 0.45199999999999996, 0.46799999999999997, -0.03300000000000003, -0.04800000000000004, 0.46599999999999997, 0.4630000000000001, 0.41999999999999993, 0.4660000000000002, 0.46899999999999986, -0.741, 0.46499999999999986, -0.04800000000000004, -0.02100000000000002, -0.03400000000000003, 0.46399999999999997, 0.4750000000000001, 0.472, 0.9489999999999998, -0.040000000000000036, 0.46899999999999986, -0.22799999999999998, 1.46, -0.04300000000000004, 0.44399999999999995, 0.47299999999999986, 0.46599999999999997, -0.028000000000000025, -0.031000000000000028, 0.958, 0.46799999999999997, -0.049000000000000044, -0.02400000000000002, -0.03700000000000003, 0.46499999999999986, 0.45999999999999996, -0.031000000000000028, -0.030000000000000027, 0.45799999999999996, -0.041000000000000036, -0.025000000000000022, 0.46099999999999997, 0.46599999999999997, 0.474, 0.45199999999999996, 1.425, 1.452, 0.4620000000000002, 0.4590000000000001, 0.45599999999999996, 0.45399999999999996, 0.43100000000000005, 0.472, -0.04300000000000004, 0.45399999999999996, 0.39800000000000013, 0.47299999999999986, -0.07100000000000006, 0.42700000000000005, -0.03400000000000003, -0.05400000000000005, 0.4710000000000001, -0.05500000000000005, -0.04600000000000004, 0.29600000000000004, 0.44300000000000006, -0.030000000000000027, 0.44300000000000006, 0.43500000000000005, 0.47299999999999986, 0.44099999999999984, 0.4289999999999998, 0.4670000000000001, 0.46499999999999986, 0.44499999999999984, 0.4790000000000001, -0.06699999999999995, 0.4590000000000001, 0.4690000000000001, -0.03400000000000003, -0.038999999999999924, -0.05899999999999994, 0.3900000000000001, 0.46599999999999997, 0.44300000000000006, 0.43999999999999995, 0.4690000000000001, -0.03500000000000003, 0.45199999999999996, 0.44999999999999996, -0.04400000000000004, -0.040000000000000036, 0.45799999999999996, -0.03400000000000003, -0.030000000000000027, -0.05600000000000005, 0.46899999999999986, 0.46499999999999986, 0.47, 0.41999999999999993, 0.3839999999999999, 0.47299999999999986, 1.362, 0.42999999999999994, 0.45500000000000007, 0.40600000000000014, 0.44799999999999995, -0.038000000000000034, 0.43100000000000005, 0.9650000000000001, -0.03300000000000003, 0.43999999999999995, 1.421, 0.4630000000000001, 0.46499999999999986, -0.10799999999999987, 0.476, 0.3919999999999999, 0.44599999999999995, 0.44799999999999995, 0.44799999999999995, 0.476, 0.44799999999999995], "episode_lengths": [31, 11, 30, 12, 21, 26, 11, 17, 12, 12, 9, 11, 11, 13, 22, 12, 10, 11, 17, 13, 8, 13, 13, 36, 15, 12, 14, 14, 12, 15, 16, 18, 10, 10, 10, 17, 13, 11, 24, 10, 15, 10, 14, 11, 13, 13, 11, 52, 24, 10, 10, 17, 267, 17, 10, 11, 10, 33, 7, 10, 14, 10, 13, 11, 15, 11, 7, 17, 14, 11, 9, 10, 14, 12, 10, 10, 8, 10, 8, 8, 10, 12, 13, 13, 6, 14, 15, 21, 11, 11, 16, 12, 13, 14, 13, 13, 12, 12, 15, 13, 12, 13, 10, 13, 10, 46, 12, 13, 41, 29, 12, 15, 10, 10, 14, 11, 11, 25, 10, 10, 238, 11, 15, 7, 11, 12, 8, 9, 16, 13, 10, 72, 13, 14, 18, 9, 11, 9, 10, 13, 10, 16, 8, 12, 11, 13, 10, 10, 13, 13, 8, 12, 11, 8, 15, 25, 15, 11, 13, 14, 15, 22, 9, 14, 15, 31, 9, 21, 23, 11, 17, 9, 17, 15, 64, 18, 10, 18, 20, 9, 18, 22, 11, 11, 18, 7, 20, 13, 10, 11, 12, 18, 34, 11, 17, 18, 10, 11, 16, 16, 14, 12, 14, 11, 9, 17, 10, 11, 10, 26, 36, 9, 40, 22, 14, 29, 15, 12, 22, 11, 10, 18, 25, 12, 11, 33, 8, 33, 17, 16, 17, 8, 16], "policy_red_0_reward": [1.405, 1.467, -0.505, 1.464, 1.436, 1.4220000000000002, 1.467, 1.4489999999999998, 0.964, 1.464, 1.4729999999999999, 1.467, 1.467, 1.4609999999999999, 1.434, 1.464, 0.969, 1.467, 1.4489999999999998, 1.4609999999999999, 0.976, 0.961, 1.4609999999999999, 0.892, -0.5, 1.464, 1.458, 1.458, 1.464, 1.455, 0.952, 1.446, 0.969, 1.47, 1.47, 1.4489999999999998, 1.4609999999999999, 0.966, 1.426, 0.97, 1.455, 0.97, 1.458, 1.467, 1.4609999999999999, 1.4609999999999999, 1.467, 1.3439999999999999, 1.426, 1.47, 0.97, 1.4489999999999998, 0.18999999999999995, 0.949, 0.97, 1.467, 0.97, 1.393, 0.979, 1.47, 1.458, 1.47, 0.959, 1.467, 1.455, -0.5, 0.979, 1.4489999999999998, 1.458, 1.467, 0.971, 1.47, 1.458, 0.964, 0.97, 1.47, 1.476, 1.47, 0.976, 0.976, 1.47, -0.501, 1.4609999999999999, 1.4609999999999999, 0.982, 1.458, 1.455, 1.435, 1.467, 0.967, 1.452, 1.464, 1.4609999999999999, 0.958, 0.961, 1.4609999999999999, 1.464, 1.464, 1.455, 1.4609999999999999, 0.964, 0.961, 0.97, 0.96, 1.47, 1.361, 1.464, -1.001, 0.873, 0.913, 1.464, 1.455, 1.47, 0.97, 0.957, 1.467, 1.467, 1.424, 1.47, 1.47, 0.28400000000000003, 1.467, 0.955, 0.979, 0.967, 1.464, 1.476, 1.4729999999999999, 1.452, 0.961, 1.47, 0.781, 1.4609999999999999, 0.958, 1.446, 1.4729999999999999, 0.967, 0.973, 0.97, 1.4609999999999999, 1.47, 0.952, 0.976, 0.964, 1.467, 1.4609999999999999, 0.969, 0.97, 1.4609999999999999, 0.961, 0.976, -0.5, 1.467, 1.476, 1.455, 1.425, 1.455, 1.467, 1.4609999999999999, 1.458, 0.955, 1.434, 1.4729999999999999, 0.958, 1.455, 1.405, 1.4729999999999999, 0.9319999999999999, 1.4300000000000002, 0.967, 0.949, 1.4729999999999999, 0.946, 0.955, 1.304, 1.4449999999999998, 0.97, 1.446, 1.44, 1.4729999999999999, 1.446, 1.4329999999999998, 1.467, 1.467, 1.446, 1.479, -1.001, 1.4609999999999999, 1.47, 0.967, 0.963, 0.945, 1.397, 1.467, 1.4489999999999998, 1.4449999999999998, 1.47, 0.967, 1.452, 1.452, 0.958, 0.962, 1.458, 0.967, 0.972, 0.949, 1.47, 1.467, 1.47, 1.4220000000000002, 1.389, 1.4729999999999999, 1.371, 1.432, 1.458, 1.412, 1.455, 0.964, 1.434, 1.467, 0.97, 1.444, 1.425, 1.464, 1.467, 0.9, 1.476, 1.4, 1.4489999999999998, 1.452, 1.4489999999999998, 1.476, 1.452], "policy_blue_0_reward": [-1.003, -1.001, 1.407, -1.001, -1.001, -0.006, -1.001, -1.0039999999999998, -1.001, -1.002, -1.002, -1.002, -1.001, -1.003, -1.003, -1.001, -1.0019999999999998, -1.003, -1.007, -1.004, -1.0, -1.003, -0.5, -1.005, 0.954, -1.001, -1.002, -1.003, -1.0039999999999998, -1.003, -1.002, -0.001, -1.0, -1.0, -1.002, -1.0, -1.001, -1.0, -0.5029999999999999, -1.001, -1.003, -1.003, -1.002, -1.003, -1.003, -1.002, -1.002, -1.0099999999999998, -1.004, -1.003, -1.0019999999999998, -0.002, -0.534, -1.003, -1.002, -1.002, -1.0, -1.008, -1.002, -1.002, -1.001, -1.0, -1.0019999999999998, -1.002, -1.001, 0.964, -1.002, -1.002, -0.001, -1.001, -1.001, -1.0, -1.002, -1.003, -1.002, -0.5, -1.0, -1.0, -1.0, -1.002, -1.002, 0.963, -1.0039999999999998, -1.001, -1.0, -1.0039999999999998, -0.002, -1.0, -1.0, -1.003, -0.5, -1.001, -1.0019999999999998, -1.002, -1.0019999999999998, -1.002, -1.003, -1.003, -1.0019999999999998, -1.001, -1.0, -1.005, -1.0039999999999998, -1.001, -1.005, -1.003, -1.004, 0.96, -1.003, -1.001, -1.001, -1.003, -1.002, -1.003, -1.005, -1.001, -1.004, -1.004, -1.0039999999999998, -1.001, -1.025, -1.002, -1.003, -1.0, -1.001, -1.0, -1.001, -1.001, -0.503, -1.001, -1.001, -1.009, -0.001, -1.001, -1.002, -1.0, -0.501, -1.001, -1.001, -0.503, -1.002, -1.001, -1.0, -1.001, -1.002, -1.001, -1.0, -1.0, -1.003, -1.002, -1.001, 0.961, -1.001, -1.002, -1.003, 0.0, -0.003, -1.005, -1.002, -1.002, -0.501, -1.003, -1.001, -1.001, -1.001, -1.007, -1.0, -1.003, -1.003, -1.001, -1.003, -1.002, -1.001, -1.001, -1.008, -1.002, -1.0, -1.003, -1.005, -1.0, -1.005, -1.004, -1.0, -1.002, -1.001, -1.0, 0.9339999999999999, -1.002, -1.001, -1.001, -1.0019999999999998, -1.0039999999999998, -1.007, -1.001, -1.006, -1.005, -1.001, -1.002, -1.0, -1.002, -1.002, -1.002, -1.0, -1.001, -1.002, -1.005, -1.001, -1.002, -1.0, -1.002, -1.005, -1.0, -0.009000000000000001, -1.002, -1.003, -1.006, -1.007, -1.002, -1.003, -0.5019999999999999, -1.003, -1.004, -0.004, -1.001, -1.002, -1.0079999999999998, -1.0, -1.008, -1.003, -1.004, -1.001, -1.0, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24313712109376664, "mean_inference_ms": 1.4758421721931403, "mean_action_processing_ms": 0.06299279050035368, "mean_env_wait_ms": 0.08931474952012436, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022032281359889477, "StateBufferConnector_ms": 0.0015646091346577001, "ViewRequirementAgentConnector_ms": 0.03277672206895034}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000, "num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.54941707944207, "num_env_steps_trained_throughput_per_sec": 102.54941707944207, "timesteps_total": 144000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 288000, "timers": {"training_iteration_time_ms": 39007.002, "sample_time_ms": 7643.199, "learn_time_ms": 31346.433, "learn_throughput": 127.606, "synch_weights_time_ms": 16.869}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 144000, "num_agent_steps_sampled": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 3717, "training_iteration": 36, "trial_id": "d67e4_00000", "date": "2023-09-20_22-32-34", "timestamp": 1695263554, "time_this_iter_s": 39.01438903808594, "time_total_s": 1399.7785749435425, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46feb90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1399.7785749435425, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 34.660714285714285, "ram_util_percent": 48.56071428571429}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.04736842105263158, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05263157894736842, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.05263157894736842, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05263157894736842, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7672154245898128, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010502195201600747, "policy_loss": -0.01904313001080785, "vf_loss": 0.0101407056657384, "vf_explained_var": 0.6286581384638945, "kl": 0.00883387171220041, "entropy": 0.5046600127903124, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 35040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "sampler_results": {"episode_reward_max": 1.943, "episode_reward_min": -0.6020000000000001, "episode_reward_mean": 0.37023684210526314, "episode_len_mean": 20.094736842105263, "episode_media": {}, "episodes_this_iter": 190, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.028}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.979}, "policy_reward_mean": {"red_0": 1.1961736842105264, "blue_0": -0.825936842105263}, "custom_metrics": {"red_0/door_open_done_mean": 0.04736842105263158, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05263157894736842, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.05263157894736842, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05263157894736842, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.405, 0.10499999999999998, 0.479, 0.46399999999999997, 0.43999999999999995, -0.049000000000000044, 0.4740000000000002, 0.46599999999999997, -0.025000000000000022, -0.030000000000000027, 0.45999999999999996, -0.061000000000000054, -0.031000000000000028, 0.4660000000000002, 0.45999999999999996, -0.030000000000000027, 1.222, 0.4670000000000001, 0.2809999999999999, -0.02400000000000002, 0.469, -0.08999999999999997, 1.4529999999999998, 0.40900000000000003, -0.03499999999999992, -0.03700000000000003, 0.45199999999999996, 0.45999999999999996, 0.41999999999999993, 1.943, 0.2869999999999999, -0.03300000000000003, 0.45999999999999996, 0.4710000000000001, 0.43500000000000005, 0.47, 0.46499999999999986, 0.45599999999999996, 0.4039999999999999, 0.45199999999999996, -0.02100000000000002, -0.04399999999999993, 0.45699999999999985, 0.839, 0.43199999999999994, 0.42399999999999993, -0.07499999999999996, 0.44499999999999984, 0.47, 0.46499999999999986, 0.46799999999999997, 0.476, -0.05499999999999994, 0.4710000000000001, 0.44599999999999995, 0.44899999999999984, 0.9690000000000001, -0.026000000000000023, 0.46599999999999997, 0.46499999999999986, 0.46799999999999997, -0.025000000000000022, -0.050000000000000044, 0.47, -0.03400000000000003, -0.03400000000000003, 0.43900000000000006, 0.45699999999999985, -0.030999999999999917, 0.43500000000000005, 0.45699999999999985, -0.03700000000000003, -0.03700000000000003, 0.45599999999999996, 0.46499999999999986, -0.02300000000000002, 0.43300000000000005, 0.669, 0.4710000000000001, 0.45999999999999996, 0.3700000000000001, 0.45999999999999996, -0.03299999999999992, 0.3540000000000001, 0.46199999999999997, 0.45999999999999996, 0.4670000000000001, 0.42999999999999994, 0.46899999999999986, 0.44399999999999995, -0.04200000000000004, 0.43999999999999995, 0.44899999999999984, 0.45299999999999985, -0.03700000000000003, 0.46499999999999986, -0.041999999999999926, 0.3860000000000001, 0.45599999999999996, 0.46599999999999997, 0.4670000000000001, 0.478, 1.451, 0.45999999999999996, 0.47299999999999986, 0.44499999999999984, -0.04700000000000004, 0.3879999999999999, -0.030000000000000027, 0.46399999999999997, -0.03700000000000003, 0.46499999999999986, 0.45100000000000007, 0.46399999999999997, 0.46199999999999997, -0.03700000000000003, 0.4700000000000002, 0.16199999999999992, 0.45999999999999996, 0.45999999999999996, 0.45399999999999996, 0.45500000000000007, 0.4289999999999998, 0.44999999999999996, -0.029999999999999916, 1.452, -0.02400000000000002, -0.03300000000000003, 0.46199999999999997, 0.3420000000000001, 0.45199999999999996, 0.44499999999999984, -0.03600000000000003, -0.03300000000000003, 0.4750000000000001, -0.039000000000000035, 0.46899999999999986, 0.45999999999999996, 0.472, 1.458, 0.4630000000000001, 0.4670000000000001, 0.46499999999999986, -0.030000000000000027, 0.46799999999999997, 0.45699999999999985, 0.46599999999999997, 0.46299999999999997, -0.028000000000000025, 0.44199999999999995, 0.45500000000000007, 0.46499999999999986, 0.45500000000000007, 0.45799999999999996, 1.376, 0.8009999999999999, -0.02400000000000002, -0.03799999999999992, -0.6020000000000001, 0.46099999999999985, -0.03200000000000003, -0.02400000000000002, -0.040000000000000036, 0.40900000000000003, 0.45100000000000007, 0.44999999999999996, -0.04500000000000004, 0.12699999999999978, 0.44700000000000006, 0.3919999999999999, 0.4590000000000001, 1.458, -0.04399999999999993, 0.2909999999999999, 0.4740000000000002, -0.04200000000000004, 0.47, 0.47, 0.8, 0.45799999999999996, 0.4500000000000002, 0.46599999999999997, 0.42199999999999993, 0.45199999999999996, 0.4650000000000001, 0.365, -0.03200000000000003, 0.46599999999999997, 0.45199999999999996, 0.46399999999999997], "episode_lengths": [31, 122, 7, 12, 19, 15, 8, 11, 8, 10, 13, 20, 10, 11, 12, 10, 87, 11, 69, 7, 10, 185, 15, 27, 11, 11, 15, 13, 25, 18, 66, 10, 13, 9, 21, 9, 11, 14, 30, 15, 7, 14, 14, 50, 21, 25, 22, 17, 10, 11, 10, 8, 17, 9, 17, 15, 10, 8, 11, 11, 10, 8, 16, 10, 11, 10, 19, 13, 10, 21, 14, 12, 11, 14, 11, 7, 20, 103, 9, 12, 40, 12, 10, 45, 12, 13, 10, 22, 10, 17, 14, 18, 17, 14, 12, 11, 13, 35, 14, 11, 10, 7, 15, 13, 9, 18, 14, 34, 10, 12, 12, 11, 15, 11, 12, 12, 9, 105, 12, 13, 15, 14, 22, 16, 9, 16, 8, 11, 12, 49, 15, 17, 11, 11, 8, 12, 10, 13, 9, 13, 12, 11, 11, 10, 10, 13, 11, 12, 9, 19, 15, 11, 15, 13, 40, 61, 8, 12, 191, 13, 10, 8, 13, 28, 16, 16, 14, 114, 17, 34, 13, 13, 14, 64, 8, 13, 10, 10, 62, 13, 15, 11, 24, 16, 11, 42, 10, 11, 15, 12], "policy_red_0_reward": [1.407, 1.124, -0.5, 1.464, 1.443, 0.955, 1.476, 1.467, 0.976, 0.97, 0.96, 0.94, 0.97, 1.467, 1.464, 0.97, 1.2349999999999999, 1.467, 1.2919999999999998, 0.979, -0.5, 0.938, 1.455, 1.417, 0.966, -1.001, 1.455, -0.5, 1.424, 1.446, 1.299, 0.97, 1.4609999999999999, 1.4729999999999999, 1.4369999999999998, 1.4729999999999999, 1.467, 1.458, 1.409, 1.455, 0.979, 0.958, 1.458, 1.349, -0.501, 1.425, 0.9309999999999999, 1.4489999999999998, -0.5, 1.467, 1.47, 1.476, 0.949, 1.4729999999999999, 1.448, 1.455, 1.47, 0.976, 1.467, 1.467, 1.47, 0.976, 0.951, 1.47, 0.967, 0.97, 1.443, 1.4609999999999999, 0.97, 1.4369999999999998, 1.458, 0.964, 0.964, 1.458, 1.467, 0.979, 1.439, 1.182, 1.4729999999999999, 1.464, 1.377, 1.464, 0.97, 1.362, 1.464, 0.961, 1.47, 1.434, 1.47, 0.946, 0.958, 1.446, 1.4489999999999998, 1.458, 0.964, 1.467, 0.961, 1.3940000000000001, 1.458, 1.467, 1.47, -0.5, 1.455, 1.4609999999999999, 1.4729999999999999, 1.446, 0.957, 1.395, 0.97, 1.464, 0.964, 1.467, 1.455, 1.467, 1.464, 0.964, 1.4729999999999999, 1.174, 1.464, -0.5, 1.455, 1.458, 1.434, 1.452, 0.973, 1.452, 0.976, 0.967, 1.464, 1.35, 1.454, 1.4489999999999998, 0.966, 0.967, 1.476, 0.964, 1.47, 1.4609999999999999, 1.4729999999999999, 1.4609999999999999, 1.464, 1.467, 1.467, 0.97, 1.47, 1.4609999999999999, 1.467, -0.5, 0.973, 1.443, 1.455, 1.467, 1.455, 1.4609999999999999, 1.379, 1.309, 0.976, 0.964, 0.42599999999999993, 1.4609999999999999, 0.97, 0.976, 0.961, 1.4140000000000001, 1.452, 1.452, 0.958, 1.149, 1.448, 1.396, 1.4609999999999999, 1.4609999999999999, 0.958, 1.306, 0.975, 0.961, 1.47, -0.5, 1.314, 1.4609999999999999, 1.455, 1.467, 1.4249999999999998, 1.452, 1.467, 1.371, 0.97, 1.467, 1.455, 1.464], "policy_blue_0_reward": [-0.002, -1.019, 0.979, -1.0, -1.003, -1.004, -1.0019999999999998, -1.001, -1.001, -1.0, -0.5, -1.001, -1.001, -1.001, -1.0039999999999998, -1.0, -0.013000000000000005, -1.0, -1.011, -1.003, 0.969, -1.0279999999999998, -0.002, -1.008, -1.001, 0.964, -1.003, 0.96, -1.004, 0.497, -1.012, -1.003, -1.001, -1.002, -1.002, -1.003, -1.002, -1.002, -1.005, -1.003, -1.0, -1.0019999999999998, -1.001, -0.51, 0.9329999999999999, -1.001, -1.0059999999999998, -1.004, 0.97, -1.002, -1.0019999999999998, -1.0, -1.0039999999999998, -1.0019999999999998, -1.002, -1.006, -0.5009999999999999, -1.002, -1.001, -1.002, -1.002, -1.001, -1.001, -1.0, -1.001, -1.004, -1.004, -1.004, -1.001, -1.002, -1.001, -1.001, -1.001, -1.002, -1.002, -1.002, -1.0059999999999998, -0.5129999999999999, -1.002, -1.004, -1.007, -1.004, -1.003, -1.008, -1.002, -0.501, -1.003, -1.004, -1.001, -0.502, -1.0, -1.006, -1.0, -1.005, -1.001, -1.002, -1.003, -1.008, -1.002, -1.001, -1.003, 0.978, -0.004, -1.001, -1.0, -1.001, -1.004, -1.007, -1.0, -1.0, -1.001, -1.002, -1.0039999999999998, -1.003, -1.002, -1.001, -1.003, -1.012, -1.0039999999999998, 0.96, -1.001, -1.003, -1.005, -1.002, -1.003, 0.0, -1.0, -1.0, -1.002, -1.008, -1.002, -1.004, -1.002, -1.0, -1.001, -1.003, -1.001, -1.001, -1.001, -0.003, -1.001, -1.0, -1.002, -1.0, -1.0019999999999998, -1.004, -1.001, 0.963, -1.001, -1.001, -1.0, -1.002, -1.0, -1.003, -0.003, -0.508, -1.0, -1.0019999999999998, -1.028, -1.0, -1.002, -1.0, -1.001, -1.005, -1.001, -1.002, -1.003, -1.022, -1.001, -1.004, -1.002, -0.003, -1.0019999999999998, -1.015, -0.5009999999999999, -1.003, -1.0, 0.97, -0.514, -1.003, -1.005, -1.001, -1.003, -1.0, -1.0019999999999998, -1.006, -1.002, -1.001, -1.003, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24321585011596947, "mean_inference_ms": 1.4747974552704202, "mean_action_processing_ms": 0.06294386976239211, "mean_env_wait_ms": 0.0892232066742215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019399178655524003, "StateBufferConnector_ms": 0.0015425682067871094, "ViewRequirementAgentConnector_ms": 0.03162208356355366}}, "episode_reward_max": 1.943, "episode_reward_min": -0.6020000000000001, "episode_reward_mean": 0.37023684210526314, "episode_len_mean": 20.094736842105263, "episodes_this_iter": 190, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.028}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.979}, "policy_reward_mean": {"red_0": 1.1961736842105264, "blue_0": -0.825936842105263}, "hist_stats": {"episode_reward": [1.405, 0.10499999999999998, 0.479, 0.46399999999999997, 0.43999999999999995, -0.049000000000000044, 0.4740000000000002, 0.46599999999999997, -0.025000000000000022, -0.030000000000000027, 0.45999999999999996, -0.061000000000000054, -0.031000000000000028, 0.4660000000000002, 0.45999999999999996, -0.030000000000000027, 1.222, 0.4670000000000001, 0.2809999999999999, -0.02400000000000002, 0.469, -0.08999999999999997, 1.4529999999999998, 0.40900000000000003, -0.03499999999999992, -0.03700000000000003, 0.45199999999999996, 0.45999999999999996, 0.41999999999999993, 1.943, 0.2869999999999999, -0.03300000000000003, 0.45999999999999996, 0.4710000000000001, 0.43500000000000005, 0.47, 0.46499999999999986, 0.45599999999999996, 0.4039999999999999, 0.45199999999999996, -0.02100000000000002, -0.04399999999999993, 0.45699999999999985, 0.839, 0.43199999999999994, 0.42399999999999993, -0.07499999999999996, 0.44499999999999984, 0.47, 0.46499999999999986, 0.46799999999999997, 0.476, -0.05499999999999994, 0.4710000000000001, 0.44599999999999995, 0.44899999999999984, 0.9690000000000001, -0.026000000000000023, 0.46599999999999997, 0.46499999999999986, 0.46799999999999997, -0.025000000000000022, -0.050000000000000044, 0.47, -0.03400000000000003, -0.03400000000000003, 0.43900000000000006, 0.45699999999999985, -0.030999999999999917, 0.43500000000000005, 0.45699999999999985, -0.03700000000000003, -0.03700000000000003, 0.45599999999999996, 0.46499999999999986, -0.02300000000000002, 0.43300000000000005, 0.669, 0.4710000000000001, 0.45999999999999996, 0.3700000000000001, 0.45999999999999996, -0.03299999999999992, 0.3540000000000001, 0.46199999999999997, 0.45999999999999996, 0.4670000000000001, 0.42999999999999994, 0.46899999999999986, 0.44399999999999995, -0.04200000000000004, 0.43999999999999995, 0.44899999999999984, 0.45299999999999985, -0.03700000000000003, 0.46499999999999986, -0.041999999999999926, 0.3860000000000001, 0.45599999999999996, 0.46599999999999997, 0.4670000000000001, 0.478, 1.451, 0.45999999999999996, 0.47299999999999986, 0.44499999999999984, -0.04700000000000004, 0.3879999999999999, -0.030000000000000027, 0.46399999999999997, -0.03700000000000003, 0.46499999999999986, 0.45100000000000007, 0.46399999999999997, 0.46199999999999997, -0.03700000000000003, 0.4700000000000002, 0.16199999999999992, 0.45999999999999996, 0.45999999999999996, 0.45399999999999996, 0.45500000000000007, 0.4289999999999998, 0.44999999999999996, -0.029999999999999916, 1.452, -0.02400000000000002, -0.03300000000000003, 0.46199999999999997, 0.3420000000000001, 0.45199999999999996, 0.44499999999999984, -0.03600000000000003, -0.03300000000000003, 0.4750000000000001, -0.039000000000000035, 0.46899999999999986, 0.45999999999999996, 0.472, 1.458, 0.4630000000000001, 0.4670000000000001, 0.46499999999999986, -0.030000000000000027, 0.46799999999999997, 0.45699999999999985, 0.46599999999999997, 0.46299999999999997, -0.028000000000000025, 0.44199999999999995, 0.45500000000000007, 0.46499999999999986, 0.45500000000000007, 0.45799999999999996, 1.376, 0.8009999999999999, -0.02400000000000002, -0.03799999999999992, -0.6020000000000001, 0.46099999999999985, -0.03200000000000003, -0.02400000000000002, -0.040000000000000036, 0.40900000000000003, 0.45100000000000007, 0.44999999999999996, -0.04500000000000004, 0.12699999999999978, 0.44700000000000006, 0.3919999999999999, 0.4590000000000001, 1.458, -0.04399999999999993, 0.2909999999999999, 0.4740000000000002, -0.04200000000000004, 0.47, 0.47, 0.8, 0.45799999999999996, 0.4500000000000002, 0.46599999999999997, 0.42199999999999993, 0.45199999999999996, 0.4650000000000001, 0.365, -0.03200000000000003, 0.46599999999999997, 0.45199999999999996, 0.46399999999999997], "episode_lengths": [31, 122, 7, 12, 19, 15, 8, 11, 8, 10, 13, 20, 10, 11, 12, 10, 87, 11, 69, 7, 10, 185, 15, 27, 11, 11, 15, 13, 25, 18, 66, 10, 13, 9, 21, 9, 11, 14, 30, 15, 7, 14, 14, 50, 21, 25, 22, 17, 10, 11, 10, 8, 17, 9, 17, 15, 10, 8, 11, 11, 10, 8, 16, 10, 11, 10, 19, 13, 10, 21, 14, 12, 11, 14, 11, 7, 20, 103, 9, 12, 40, 12, 10, 45, 12, 13, 10, 22, 10, 17, 14, 18, 17, 14, 12, 11, 13, 35, 14, 11, 10, 7, 15, 13, 9, 18, 14, 34, 10, 12, 12, 11, 15, 11, 12, 12, 9, 105, 12, 13, 15, 14, 22, 16, 9, 16, 8, 11, 12, 49, 15, 17, 11, 11, 8, 12, 10, 13, 9, 13, 12, 11, 11, 10, 10, 13, 11, 12, 9, 19, 15, 11, 15, 13, 40, 61, 8, 12, 191, 13, 10, 8, 13, 28, 16, 16, 14, 114, 17, 34, 13, 13, 14, 64, 8, 13, 10, 10, 62, 13, 15, 11, 24, 16, 11, 42, 10, 11, 15, 12], "policy_red_0_reward": [1.407, 1.124, -0.5, 1.464, 1.443, 0.955, 1.476, 1.467, 0.976, 0.97, 0.96, 0.94, 0.97, 1.467, 1.464, 0.97, 1.2349999999999999, 1.467, 1.2919999999999998, 0.979, -0.5, 0.938, 1.455, 1.417, 0.966, -1.001, 1.455, -0.5, 1.424, 1.446, 1.299, 0.97, 1.4609999999999999, 1.4729999999999999, 1.4369999999999998, 1.4729999999999999, 1.467, 1.458, 1.409, 1.455, 0.979, 0.958, 1.458, 1.349, -0.501, 1.425, 0.9309999999999999, 1.4489999999999998, -0.5, 1.467, 1.47, 1.476, 0.949, 1.4729999999999999, 1.448, 1.455, 1.47, 0.976, 1.467, 1.467, 1.47, 0.976, 0.951, 1.47, 0.967, 0.97, 1.443, 1.4609999999999999, 0.97, 1.4369999999999998, 1.458, 0.964, 0.964, 1.458, 1.467, 0.979, 1.439, 1.182, 1.4729999999999999, 1.464, 1.377, 1.464, 0.97, 1.362, 1.464, 0.961, 1.47, 1.434, 1.47, 0.946, 0.958, 1.446, 1.4489999999999998, 1.458, 0.964, 1.467, 0.961, 1.3940000000000001, 1.458, 1.467, 1.47, -0.5, 1.455, 1.4609999999999999, 1.4729999999999999, 1.446, 0.957, 1.395, 0.97, 1.464, 0.964, 1.467, 1.455, 1.467, 1.464, 0.964, 1.4729999999999999, 1.174, 1.464, -0.5, 1.455, 1.458, 1.434, 1.452, 0.973, 1.452, 0.976, 0.967, 1.464, 1.35, 1.454, 1.4489999999999998, 0.966, 0.967, 1.476, 0.964, 1.47, 1.4609999999999999, 1.4729999999999999, 1.4609999999999999, 1.464, 1.467, 1.467, 0.97, 1.47, 1.4609999999999999, 1.467, -0.5, 0.973, 1.443, 1.455, 1.467, 1.455, 1.4609999999999999, 1.379, 1.309, 0.976, 0.964, 0.42599999999999993, 1.4609999999999999, 0.97, 0.976, 0.961, 1.4140000000000001, 1.452, 1.452, 0.958, 1.149, 1.448, 1.396, 1.4609999999999999, 1.4609999999999999, 0.958, 1.306, 0.975, 0.961, 1.47, -0.5, 1.314, 1.4609999999999999, 1.455, 1.467, 1.4249999999999998, 1.452, 1.467, 1.371, 0.97, 1.467, 1.455, 1.464], "policy_blue_0_reward": [-0.002, -1.019, 0.979, -1.0, -1.003, -1.004, -1.0019999999999998, -1.001, -1.001, -1.0, -0.5, -1.001, -1.001, -1.001, -1.0039999999999998, -1.0, -0.013000000000000005, -1.0, -1.011, -1.003, 0.969, -1.0279999999999998, -0.002, -1.008, -1.001, 0.964, -1.003, 0.96, -1.004, 0.497, -1.012, -1.003, -1.001, -1.002, -1.002, -1.003, -1.002, -1.002, -1.005, -1.003, -1.0, -1.0019999999999998, -1.001, -0.51, 0.9329999999999999, -1.001, -1.0059999999999998, -1.004, 0.97, -1.002, -1.0019999999999998, -1.0, -1.0039999999999998, -1.0019999999999998, -1.002, -1.006, -0.5009999999999999, -1.002, -1.001, -1.002, -1.002, -1.001, -1.001, -1.0, -1.001, -1.004, -1.004, -1.004, -1.001, -1.002, -1.001, -1.001, -1.001, -1.002, -1.002, -1.002, -1.0059999999999998, -0.5129999999999999, -1.002, -1.004, -1.007, -1.004, -1.003, -1.008, -1.002, -0.501, -1.003, -1.004, -1.001, -0.502, -1.0, -1.006, -1.0, -1.005, -1.001, -1.002, -1.003, -1.008, -1.002, -1.001, -1.003, 0.978, -0.004, -1.001, -1.0, -1.001, -1.004, -1.007, -1.0, -1.0, -1.001, -1.002, -1.0039999999999998, -1.003, -1.002, -1.001, -1.003, -1.012, -1.0039999999999998, 0.96, -1.001, -1.003, -1.005, -1.002, -1.003, 0.0, -1.0, -1.0, -1.002, -1.008, -1.002, -1.004, -1.002, -1.0, -1.001, -1.003, -1.001, -1.001, -1.001, -0.003, -1.001, -1.0, -1.002, -1.0, -1.0019999999999998, -1.004, -1.001, 0.963, -1.001, -1.001, -1.0, -1.002, -1.0, -1.003, -0.003, -0.508, -1.0, -1.0019999999999998, -1.028, -1.0, -1.002, -1.0, -1.001, -1.005, -1.001, -1.002, -1.003, -1.022, -1.001, -1.004, -1.002, -0.003, -1.0019999999999998, -1.015, -0.5009999999999999, -1.003, -1.0, 0.97, -0.514, -1.003, -1.005, -1.001, -1.003, -1.0, -1.0019999999999998, -1.006, -1.002, -1.001, -1.003, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24321585011596947, "mean_inference_ms": 1.4747974552704202, "mean_action_processing_ms": 0.06294386976239211, "mean_env_wait_ms": 0.0892232066742215, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019399178655524003, "StateBufferConnector_ms": 0.0015425682067871094, "ViewRequirementAgentConnector_ms": 0.03162208356355366}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000, "num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.27038738983894, "num_env_steps_trained_throughput_per_sec": 102.27038738983894, "timesteps_total": 148000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 296000, "timers": {"training_iteration_time_ms": 39027.236, "sample_time_ms": 7640.569, "learn_time_ms": 31369.305, "learn_throughput": 127.513, "synch_weights_time_ms": 16.868}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 148000, "num_agent_steps_sampled": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 3907, "training_iteration": 37, "trial_id": "d67e4_00000", "date": "2023-09-20_22-33-14", "timestamp": 1695263594, "time_this_iter_s": 39.11957883834839, "time_total_s": 1438.8981537818909, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687a290>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1438.8981537818909, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 34.65892857142857, "ram_util_percent": 48.69642857142858}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.08021390374331551, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8556149732620321, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.058823529411764705, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8556149732620321, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.058823529411764705, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8556149732620321, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.058823529411764705, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8753493408982953, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010931509067692484, "policy_loss": -0.018937911845569033, "vf_loss": 0.009933799985204435, "vf_explained_var": 0.6407467323044936, "kl": 0.007806646932748939, "entropy": 0.4734881524617473, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "sampler_results": {"episode_reward_max": 1.9540000000000002, "episode_reward_min": -0.5650000000000001, "episode_reward_mean": 0.39725668449197865, "episode_len_mean": 22.941176470588236, "episode_media": {}, "episodes_this_iter": 187, "policy_reward_min": {"red_0": -1.008, "blue_0": -1.031}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.458}, "policy_reward_mean": {"red_0": 1.1735828877005348, "blue_0": -0.7763262032085562}, "custom_metrics": {"red_0/door_open_done_mean": 0.08021390374331551, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8556149732620321, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.058823529411764705, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8556149732620321, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.058823529411764705, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8556149732620321, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.058823529411764705, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.43500000000000005, 0.46899999999999986, 0.45699999999999985, 0.44199999999999995, 0.4630000000000001, 0.46099999999999985, 0.953, 0.46799999999999997, 1.3780000000000001, -0.03700000000000003, -0.03700000000000003, 0.4590000000000001, -0.027999999999999914, 0.44399999999999995, -0.018000000000000016, 0.4660000000000002, 0.44199999999999995, 0.45199999999999996, -0.02400000000000002, -0.06300000000000006, 1.355, -0.030000000000000027, 0.45299999999999985, 0.4670000000000001, -0.03200000000000003, 0.43599999999999994, 0.4670000000000001, 0.45500000000000007, -0.029999999999999916, 0.47, 0.4590000000000001, 0.45599999999999996, -0.03700000000000003, 0.44200000000000017, 0.42500000000000027, -0.27400000000000013, -0.030999999999999917, 0.4630000000000001, -0.03600000000000003, 0.473, 1.454, 0.45399999999999996, 0.46199999999999997, -0.03200000000000003, -0.031000000000000028, -0.5650000000000001, -0.027000000000000024, 0.45100000000000007, -0.30900000000000005, 1.9540000000000002, 0.42399999999999993, 0.46799999999999997, 0.18700000000000006, -0.03400000000000003, 0.46099999999999985, -0.04200000000000004, -0.027999999999999914, 0.475, 0.45999999999999996, 0.45799999999999996, -0.02200000000000002, 0.44999999999999996, 0.46899999999999986, 0.46399999999999997, 0.4630000000000001, 0.45399999999999996, 0.4119999999999999, 0.44199999999999995, -0.03600000000000003, 0.14800000000000013, -0.028999999999999915, 1.417, 0.46399999999999997, -0.07200000000000006, 0.45100000000000007, -0.04700000000000004, 0.44899999999999984, 0.968, 0.41000000000000014, 0.44499999999999995, 0.401, 0.45199999999999996, 0.45999999999999996, 0.21599999999999997, 1.46, 0.45299999999999985, 1.2879999999999998, -0.031000000000000028, -0.03799999999999992, 0.46799999999999997, 0.45499999999999996, 0.472, 0.9170000000000003, 0.4670000000000001, 0.45599999999999996, 0.47, -0.030999999999999917, 1.391, 0.42700000000000005, -0.03400000000000003, -0.025000000000000022, 0.46399999999999997, 1.447, 1.451, 0.40000000000000013, 0.4710000000000001, 0.3420000000000001, 0.46499999999999986, -0.10099999999999998, -0.03400000000000003, 0.44899999999999984, 0.4690000000000001, 0.47299999999999986, -0.025000000000000022, -0.030000000000000027, -0.029999999999999916, 0.4590000000000001, 0.44999999999999996, 0.4590000000000001, -0.027000000000000024, 0.46599999999999997, 0.43199999999999994, 0.45399999999999996, 0.4630000000000001, 0.45599999999999996, 0.44999999999999996, 0.43599999999999994, 0.45199999999999996, 0.45299999999999985, -0.040000000000000036, 0.4209999999999998, -0.03700000000000003, 0.964, 0.952, 0.46399999999999997, 0.4590000000000001, 0.45399999999999996, -0.17200000000000004, 0.4710000000000001, 0.45599999999999996, -0.03200000000000003, -0.031000000000000028, 0.44899999999999984, 0.397, 0.46599999999999997, 0.4580000000000002, 0.41300000000000026, -0.030000000000000027, 0.45699999999999985, 0.45599999999999996, 1.451, 0.23099999999999998, 0.4710000000000001, 0.45699999999999985, 1.4300000000000002, 0.46099999999999985, 0.46399999999999997, 0.4710000000000001, 0.45799999999999996, -0.025000000000000022, -0.16800000000000004, 0.472, 1.4500000000000002, 0.46899999999999986, 0.4590000000000001, 0.21199999999999997, 1.3639999999999999, 0.45599999999999996, 0.46499999999999986, 0.47299999999999986, -0.03500000000000003, 0.45999999999999996, -0.051000000000000045, 0.43199999999999994, -0.040000000000000036, 0.46199999999999997, 0.44099999999999984, 0.45500000000000007, -0.247, -0.04299999999999993, -0.031000000000000028, 0.472, 0.45199999999999996, 0.4670000000000001, 1.293, 0.4630000000000001, 0.43999999999999995], "episode_lengths": [21, 10, 14, 18, 11, 13, 300, 10, 35, 11, 12, 13, 8, 18, 6, 11, 18, 15, 8, 19, 45, 10, 15, 11, 10, 21, 11, 14, 9, 10, 13, 14, 12, 18, 23, 240, 10, 12, 12, 9, 15, 15, 12, 10, 10, 178, 9, 16, 257, 15, 24, 10, 101, 11, 12, 14, 9, 8, 13, 13, 7, 15, 10, 12, 12, 15, 27, 19, 11, 109, 9, 26, 12, 21, 15, 14, 15, 10, 28, 17, 31, 15, 13, 88, 13, 15, 65, 10, 12, 10, 15, 9, 26, 11, 14, 10, 9, 34, 23, 11, 8, 11, 16, 16, 32, 9, 50, 11, 28, 11, 16, 10, 9, 8, 9, 9, 13, 16, 13, 8, 11, 22, 15, 12, 14, 16, 21, 15, 15, 12, 24, 12, 11, 15, 11, 13, 15, 55, 9, 14, 10, 10, 16, 33, 11, 13, 27, 10, 14, 14, 16, 84, 9, 13, 22, 12, 12, 9, 13, 8, 52, 9, 16, 10, 13, 89, 44, 14, 11, 9, 11, 13, 16, 21, 13, 12, 19, 14, 79, 14, 10, 9, 15, 10, 65, 12, 19], "policy_red_0_reward": [1.4369999999999998, 1.47, 1.458, 1.446, 1.467, 1.4609999999999999, 0.499, 1.47, 1.383, 0.967, 0.964, 1.46, 0.976, 1.446, -1.0, 1.467, 1.4449999999999998, 1.455, 0.976, 0.939, 1.361, 0.97, 1.455, 1.467, 0.97, 1.4369999999999998, 1.467, 1.458, 0.972, 1.47, 1.4609999999999999, 1.458, 0.964, 1.446, 1.4300000000000002, -0.51, 0.97, 1.464, 0.964, 0.973, 1.455, 1.455, 1.464, 0.97, 0.97, 0.45899999999999996, 0.973, 1.452, 0.722, 1.455, 1.427, 1.47, 1.1960000000000002, 0.967, 1.464, 0.958, 0.973, -0.5, 1.4609999999999999, 1.4609999999999999, 0.979, 1.455, 1.47, 1.464, 1.464, 1.455, 1.419, 1.443, 0.967, 1.17, 0.973, 1.42, 1.464, 0.9299999999999999, 1.452, 0.958, 1.455, 1.47, 1.415, -0.5, -0.502, 1.455, 1.4609999999999999, 1.233, 1.4609999999999999, 1.455, 1.298, 0.97, 0.964, 1.47, -0.5, 1.4729999999999999, 1.419, 1.467, 1.458, 1.47, 0.973, 1.3980000000000001, 0.931, 0.967, 0.976, 1.467, 1.452, 1.452, 1.404, 1.4729999999999999, 1.347, 1.467, 0.9, 0.967, 1.452, 1.47, 1.4729999999999999, 0.976, 0.972, -1.0, 1.4609999999999999, 1.452, 1.46, 0.975, 1.467, 1.434, 1.455, 1.464, 1.458, 1.452, 0.9369999999999999, 1.455, 1.455, 0.962, 1.426, 0.964, 1.467, 1.455, 1.467, 1.4609999999999999, 1.454, 0.833, 1.4729999999999999, 1.456, 0.97, 0.97, 1.452, 1.4, 1.467, 1.4609999999999999, 1.419, 0.97, 1.458, 1.458, 1.452, -0.501, 0.973, 1.4609999999999999, 1.4329999999999998, 1.464, 1.464, 1.4729999999999999, -1.0, 0.976, 0.844, -0.5, 1.452, 1.47, 1.4609999999999999, -1.008, 1.367, 1.458, 1.467, 1.4729999999999999, 0.967, 1.4609999999999999, 0.952, 1.436, 0.961, 1.464, 1.442, 1.458, 0.763, 0.958, 0.97, 1.4729999999999999, 1.455, 1.47, 1.2999999999999998, 1.464, 1.442], "policy_blue_0_reward": [-1.002, -1.001, -1.001, -1.004, -1.004, -1.0, 0.45399999999999996, -1.002, -0.005, -1.004, -1.001, -1.001, -1.0039999999999998, -1.002, 0.982, -1.001, -1.003, -1.003, -1.0, -1.002, -0.006, -1.0, -1.002, -1.0, -1.002, -1.001, -1.0, -1.003, -1.0019999999999998, -1.0, -1.002, -1.002, -1.001, -1.0039999999999998, -1.005, 0.23599999999999988, -1.001, -1.001, -1.0, -0.5, -0.001, -1.001, -1.002, -1.002, -1.001, -1.024, -1.0, -1.001, -1.031, 0.499, -1.003, -1.002, -1.009, -1.001, -1.003, -1.0, -1.001, 0.975, -1.001, -1.003, -1.001, -1.005, -1.001, -1.0, -1.001, -1.001, -1.007, -1.001, -1.003, -1.022, -1.0019999999999998, -0.003, -1.0, -1.002, -1.001, -1.005, -1.006, -0.5019999999999999, -1.005, 0.945, 0.903, -1.003, -1.001, -1.017, -0.001, -1.002, -0.010000000000000002, -1.001, -1.0019999999999998, -1.002, 0.955, -1.001, -0.5019999999999999, -1.0, -1.002, -1.0, -1.0039999999999998, -0.007, -0.504, -1.001, -1.001, -1.003, -0.005, -0.001, -1.0039999999999998, -1.002, -1.005, -1.002, -1.001, -1.001, -1.003, -1.001, -1.0, -1.001, -1.002, 0.97, -1.002, -1.002, -1.001, -1.002, -1.001, -1.002, -1.001, -1.001, -1.002, -1.002, -0.501, -1.003, -1.002, -1.002, -1.005, -1.001, -0.503, -0.503, -1.003, -1.002, -1.0, -1.005, -1.002, -1.0, -1.002, -1.001, -1.003, -1.003, -1.001, -1.003, -1.0059999999999998, -1.0, -1.001, -1.002, -0.001, 0.732, -0.502, -1.004, -0.003, -1.003, -1.0, -1.002, 1.458, -1.001, -1.012, 0.972, -0.002, -1.001, -1.002, 1.22, -0.003, -1.002, -1.002, -1.0, -1.002, -1.001, -1.003, -1.004, -1.001, -1.002, -1.001, -1.003, -1.01, -1.001, -1.001, -1.001, -1.003, -1.003, -0.007, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24354622730150824, "mean_inference_ms": 1.4751950505343372, "mean_action_processing_ms": 0.06290395740604196, "mean_env_wait_ms": 0.08920707534392583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019374441973028338, "StateBufferConnector_ms": 0.0015608767137170476, "ViewRequirementAgentConnector_ms": 0.031515939987917}}, "episode_reward_max": 1.9540000000000002, "episode_reward_min": -0.5650000000000001, "episode_reward_mean": 0.39725668449197865, "episode_len_mean": 22.941176470588236, "episodes_this_iter": 187, "policy_reward_min": {"red_0": -1.008, "blue_0": -1.031}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 1.458}, "policy_reward_mean": {"red_0": 1.1735828877005348, "blue_0": -0.7763262032085562}, "hist_stats": {"episode_reward": [0.43500000000000005, 0.46899999999999986, 0.45699999999999985, 0.44199999999999995, 0.4630000000000001, 0.46099999999999985, 0.953, 0.46799999999999997, 1.3780000000000001, -0.03700000000000003, -0.03700000000000003, 0.4590000000000001, -0.027999999999999914, 0.44399999999999995, -0.018000000000000016, 0.4660000000000002, 0.44199999999999995, 0.45199999999999996, -0.02400000000000002, -0.06300000000000006, 1.355, -0.030000000000000027, 0.45299999999999985, 0.4670000000000001, -0.03200000000000003, 0.43599999999999994, 0.4670000000000001, 0.45500000000000007, -0.029999999999999916, 0.47, 0.4590000000000001, 0.45599999999999996, -0.03700000000000003, 0.44200000000000017, 0.42500000000000027, -0.27400000000000013, -0.030999999999999917, 0.4630000000000001, -0.03600000000000003, 0.473, 1.454, 0.45399999999999996, 0.46199999999999997, -0.03200000000000003, -0.031000000000000028, -0.5650000000000001, -0.027000000000000024, 0.45100000000000007, -0.30900000000000005, 1.9540000000000002, 0.42399999999999993, 0.46799999999999997, 0.18700000000000006, -0.03400000000000003, 0.46099999999999985, -0.04200000000000004, -0.027999999999999914, 0.475, 0.45999999999999996, 0.45799999999999996, -0.02200000000000002, 0.44999999999999996, 0.46899999999999986, 0.46399999999999997, 0.4630000000000001, 0.45399999999999996, 0.4119999999999999, 0.44199999999999995, -0.03600000000000003, 0.14800000000000013, -0.028999999999999915, 1.417, 0.46399999999999997, -0.07200000000000006, 0.45100000000000007, -0.04700000000000004, 0.44899999999999984, 0.968, 0.41000000000000014, 0.44499999999999995, 0.401, 0.45199999999999996, 0.45999999999999996, 0.21599999999999997, 1.46, 0.45299999999999985, 1.2879999999999998, -0.031000000000000028, -0.03799999999999992, 0.46799999999999997, 0.45499999999999996, 0.472, 0.9170000000000003, 0.4670000000000001, 0.45599999999999996, 0.47, -0.030999999999999917, 1.391, 0.42700000000000005, -0.03400000000000003, -0.025000000000000022, 0.46399999999999997, 1.447, 1.451, 0.40000000000000013, 0.4710000000000001, 0.3420000000000001, 0.46499999999999986, -0.10099999999999998, -0.03400000000000003, 0.44899999999999984, 0.4690000000000001, 0.47299999999999986, -0.025000000000000022, -0.030000000000000027, -0.029999999999999916, 0.4590000000000001, 0.44999999999999996, 0.4590000000000001, -0.027000000000000024, 0.46599999999999997, 0.43199999999999994, 0.45399999999999996, 0.4630000000000001, 0.45599999999999996, 0.44999999999999996, 0.43599999999999994, 0.45199999999999996, 0.45299999999999985, -0.040000000000000036, 0.4209999999999998, -0.03700000000000003, 0.964, 0.952, 0.46399999999999997, 0.4590000000000001, 0.45399999999999996, -0.17200000000000004, 0.4710000000000001, 0.45599999999999996, -0.03200000000000003, -0.031000000000000028, 0.44899999999999984, 0.397, 0.46599999999999997, 0.4580000000000002, 0.41300000000000026, -0.030000000000000027, 0.45699999999999985, 0.45599999999999996, 1.451, 0.23099999999999998, 0.4710000000000001, 0.45699999999999985, 1.4300000000000002, 0.46099999999999985, 0.46399999999999997, 0.4710000000000001, 0.45799999999999996, -0.025000000000000022, -0.16800000000000004, 0.472, 1.4500000000000002, 0.46899999999999986, 0.4590000000000001, 0.21199999999999997, 1.3639999999999999, 0.45599999999999996, 0.46499999999999986, 0.47299999999999986, -0.03500000000000003, 0.45999999999999996, -0.051000000000000045, 0.43199999999999994, -0.040000000000000036, 0.46199999999999997, 0.44099999999999984, 0.45500000000000007, -0.247, -0.04299999999999993, -0.031000000000000028, 0.472, 0.45199999999999996, 0.4670000000000001, 1.293, 0.4630000000000001, 0.43999999999999995], "episode_lengths": [21, 10, 14, 18, 11, 13, 300, 10, 35, 11, 12, 13, 8, 18, 6, 11, 18, 15, 8, 19, 45, 10, 15, 11, 10, 21, 11, 14, 9, 10, 13, 14, 12, 18, 23, 240, 10, 12, 12, 9, 15, 15, 12, 10, 10, 178, 9, 16, 257, 15, 24, 10, 101, 11, 12, 14, 9, 8, 13, 13, 7, 15, 10, 12, 12, 15, 27, 19, 11, 109, 9, 26, 12, 21, 15, 14, 15, 10, 28, 17, 31, 15, 13, 88, 13, 15, 65, 10, 12, 10, 15, 9, 26, 11, 14, 10, 9, 34, 23, 11, 8, 11, 16, 16, 32, 9, 50, 11, 28, 11, 16, 10, 9, 8, 9, 9, 13, 16, 13, 8, 11, 22, 15, 12, 14, 16, 21, 15, 15, 12, 24, 12, 11, 15, 11, 13, 15, 55, 9, 14, 10, 10, 16, 33, 11, 13, 27, 10, 14, 14, 16, 84, 9, 13, 22, 12, 12, 9, 13, 8, 52, 9, 16, 10, 13, 89, 44, 14, 11, 9, 11, 13, 16, 21, 13, 12, 19, 14, 79, 14, 10, 9, 15, 10, 65, 12, 19], "policy_red_0_reward": [1.4369999999999998, 1.47, 1.458, 1.446, 1.467, 1.4609999999999999, 0.499, 1.47, 1.383, 0.967, 0.964, 1.46, 0.976, 1.446, -1.0, 1.467, 1.4449999999999998, 1.455, 0.976, 0.939, 1.361, 0.97, 1.455, 1.467, 0.97, 1.4369999999999998, 1.467, 1.458, 0.972, 1.47, 1.4609999999999999, 1.458, 0.964, 1.446, 1.4300000000000002, -0.51, 0.97, 1.464, 0.964, 0.973, 1.455, 1.455, 1.464, 0.97, 0.97, 0.45899999999999996, 0.973, 1.452, 0.722, 1.455, 1.427, 1.47, 1.1960000000000002, 0.967, 1.464, 0.958, 0.973, -0.5, 1.4609999999999999, 1.4609999999999999, 0.979, 1.455, 1.47, 1.464, 1.464, 1.455, 1.419, 1.443, 0.967, 1.17, 0.973, 1.42, 1.464, 0.9299999999999999, 1.452, 0.958, 1.455, 1.47, 1.415, -0.5, -0.502, 1.455, 1.4609999999999999, 1.233, 1.4609999999999999, 1.455, 1.298, 0.97, 0.964, 1.47, -0.5, 1.4729999999999999, 1.419, 1.467, 1.458, 1.47, 0.973, 1.3980000000000001, 0.931, 0.967, 0.976, 1.467, 1.452, 1.452, 1.404, 1.4729999999999999, 1.347, 1.467, 0.9, 0.967, 1.452, 1.47, 1.4729999999999999, 0.976, 0.972, -1.0, 1.4609999999999999, 1.452, 1.46, 0.975, 1.467, 1.434, 1.455, 1.464, 1.458, 1.452, 0.9369999999999999, 1.455, 1.455, 0.962, 1.426, 0.964, 1.467, 1.455, 1.467, 1.4609999999999999, 1.454, 0.833, 1.4729999999999999, 1.456, 0.97, 0.97, 1.452, 1.4, 1.467, 1.4609999999999999, 1.419, 0.97, 1.458, 1.458, 1.452, -0.501, 0.973, 1.4609999999999999, 1.4329999999999998, 1.464, 1.464, 1.4729999999999999, -1.0, 0.976, 0.844, -0.5, 1.452, 1.47, 1.4609999999999999, -1.008, 1.367, 1.458, 1.467, 1.4729999999999999, 0.967, 1.4609999999999999, 0.952, 1.436, 0.961, 1.464, 1.442, 1.458, 0.763, 0.958, 0.97, 1.4729999999999999, 1.455, 1.47, 1.2999999999999998, 1.464, 1.442], "policy_blue_0_reward": [-1.002, -1.001, -1.001, -1.004, -1.004, -1.0, 0.45399999999999996, -1.002, -0.005, -1.004, -1.001, -1.001, -1.0039999999999998, -1.002, 0.982, -1.001, -1.003, -1.003, -1.0, -1.002, -0.006, -1.0, -1.002, -1.0, -1.002, -1.001, -1.0, -1.003, -1.0019999999999998, -1.0, -1.002, -1.002, -1.001, -1.0039999999999998, -1.005, 0.23599999999999988, -1.001, -1.001, -1.0, -0.5, -0.001, -1.001, -1.002, -1.002, -1.001, -1.024, -1.0, -1.001, -1.031, 0.499, -1.003, -1.002, -1.009, -1.001, -1.003, -1.0, -1.001, 0.975, -1.001, -1.003, -1.001, -1.005, -1.001, -1.0, -1.001, -1.001, -1.007, -1.001, -1.003, -1.022, -1.0019999999999998, -0.003, -1.0, -1.002, -1.001, -1.005, -1.006, -0.5019999999999999, -1.005, 0.945, 0.903, -1.003, -1.001, -1.017, -0.001, -1.002, -0.010000000000000002, -1.001, -1.0019999999999998, -1.002, 0.955, -1.001, -0.5019999999999999, -1.0, -1.002, -1.0, -1.0039999999999998, -0.007, -0.504, -1.001, -1.001, -1.003, -0.005, -0.001, -1.0039999999999998, -1.002, -1.005, -1.002, -1.001, -1.001, -1.003, -1.001, -1.0, -1.001, -1.002, 0.97, -1.002, -1.002, -1.001, -1.002, -1.001, -1.002, -1.001, -1.001, -1.002, -1.002, -0.501, -1.003, -1.002, -1.002, -1.005, -1.001, -0.503, -0.503, -1.003, -1.002, -1.0, -1.005, -1.002, -1.0, -1.002, -1.001, -1.003, -1.003, -1.001, -1.003, -1.0059999999999998, -1.0, -1.001, -1.002, -0.001, 0.732, -0.502, -1.004, -0.003, -1.003, -1.0, -1.002, 1.458, -1.001, -1.012, 0.972, -0.002, -1.001, -1.002, 1.22, -0.003, -1.002, -1.002, -1.0, -1.002, -1.001, -1.003, -1.004, -1.001, -1.002, -1.001, -1.003, -1.01, -1.001, -1.001, -1.001, -1.003, -1.003, -0.007, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24354622730150824, "mean_inference_ms": 1.4751950505343372, "mean_action_processing_ms": 0.06290395740604196, "mean_env_wait_ms": 0.08920707534392583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019374441973028338, "StateBufferConnector_ms": 0.0015608767137170476, "ViewRequirementAgentConnector_ms": 0.031515939987917}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000, "num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.5688968669784, "num_env_steps_trained_throughput_per_sec": 102.5688968669784, "timesteps_total": 152000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 304000, "timers": {"training_iteration_time_ms": 39036.94, "sample_time_ms": 7634.975, "learn_time_ms": 31384.564, "learn_throughput": 127.451, "synch_weights_time_ms": 16.906}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 152000, "num_agent_steps_sampled": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 4094, "training_iteration": 38, "trial_id": "d67e4_00000", "date": "2023-09-20_22-33-53", "timestamp": 1695263633, "time_this_iter_s": 39.00570273399353, "time_total_s": 1477.9038565158844, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a68784c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1477.9038565158844, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 34.59107142857143, "ram_util_percent": 48.685714285714276}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.02252252252252252, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.954954954954955, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02252252252252252, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.954954954954955, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02252252252252252, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.954954954954955, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02252252252252252, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.067201084829867, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009503054983482192, "policy_loss": -0.016575304084835808, "vf_loss": 0.007220275879808469, "vf_explained_var": 0.7439024966210127, "kl": 0.00870552046074786, "entropy": 0.45537316544602313, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 36960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "sampler_results": {"episode_reward_max": 1.4569999999999999, "episode_reward_min": -0.22099999999999997, "episode_reward_mean": 0.3549594594594594, "episode_len_mean": 17.31081081081081, "episode_media": {}, "episodes_this_iter": 222, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.975}, "policy_reward_mean": {"red_0": 1.2731486486486487, "blue_0": -0.918189189189189}, "custom_metrics": {"red_0/door_open_done_mean": 0.02252252252252252, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.954954954954955, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02252252252252252, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.954954954954955, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02252252252252252, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.954954954954955, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02252252252252252, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.039000000000000035, 0.44799999999999995, 0.44599999999999995, 0.46499999999999986, 1.447, 0.45799999999999996, -0.03499999999999992, -0.03699999999999992, 0.45300000000000007, 0.45100000000000007, 0.45599999999999996, 0.45199999999999996, 0.4590000000000001, 0.44599999999999995, 0.45699999999999985, 0.472, 0.45300000000000007, -0.06000000000000005, 0.43900000000000006, 0.46599999999999997, 0.471, -0.02200000000000002, 0.42999999999999994, 0.43900000000000006, 0.44399999999999995, 0.389, 1.383, 0.45500000000000007, 0.46599999999999997, 0.42900000000000005, 0.47299999999999986, 0.46799999999999997, 0.35599999999999987, 0.4159999999999999, 0.9380000000000002, 0.45699999999999985, -0.03400000000000003, 0.45500000000000007, 0.47299999999999986, -0.03399999999999992, 0.43900000000000006, -0.02100000000000002, 0.45799999999999996, 0.43399999999999994, 0.45299999999999985, -0.03599999999999992, 0.4670000000000001, 0.45999999999999996, 0.46599999999999997, -0.03500000000000003, -0.11499999999999988, 0.43399999999999994, 0.45399999999999996, 0.46599999999999997, 0.47, 0.374, 0.46599999999999997, -0.03600000000000003, 0.44499999999999984, 0.46199999999999997, 0.4590000000000001, 0.30299999999999994, 0.46199999999999997, -0.040000000000000036, -0.10599999999999998, -0.03400000000000003, 0.4590000000000001, 0.46799999999999997, 0.42100000000000026, -0.030000000000000027, 0.46099999999999985, 0.3599999999999999, 0.4710000000000001, 0.9670000000000001, 0.4590000000000001, 0.4590000000000001, 0.43299999999999983, 0.2280000000000002, 0.47299999999999986, 1.4569999999999999, 0.41300000000000003, -0.031000000000000028, 0.4750000000000001, 0.41500000000000004, 0.46499999999999986, -0.041000000000000036, 0.45699999999999985, 0.46599999999999997, 0.476, -0.04200000000000004, 0.47, 0.45100000000000007, 0.45999999999999996, 0.4620000000000002, 0.4750000000000001, 0.4610000000000001, 0.46899999999999986, 0.476, 0.46799999999999997, 0.46199999999999997, 0.4690000000000001, 0.44999999999999996, -0.04200000000000004, 0.4590000000000001, -0.031000000000000028, 0.45799999999999996, 0.46399999999999997, 0.41700000000000004, 0.45399999999999996, 0.43699999999999983, -0.025000000000000022, 0.4500000000000002, 0.45999999999999996, 0.42799999999999994, -0.030000000000000027, 0.46799999999999997, 0.44999999999999996, 0.43699999999999983, -0.062000000000000055, 0.44799999999999995, 0.09099999999999997, -0.041999999999999926, 0.14100000000000001, 0.46599999999999997, 0.44700000000000006, 0.41100000000000003, 0.45299999999999985, -0.040000000000000036, -0.039999999999999925, 0.43799999999999994, 0.45999999999999996, 0.4660000000000002, 0.964, 0.45399999999999996, 0.42700000000000005, 0.45100000000000007, -0.03599999999999992, 0.4770000000000001, 0.46799999999999997, 0.45599999999999996, -0.03500000000000003, 0.4630000000000001, 0.2729999999999999, -0.05500000000000005, 0.827, -0.08400000000000007, 0.46499999999999986, -0.038999999999999924, -0.03200000000000003, 0.43900000000000006, -0.03700000000000003, 0.44799999999999995, -0.03600000000000003, 0.44999999999999996, 0.45999999999999996, -0.03200000000000003, -0.02499999999999991, 0.4670000000000001, 0.45599999999999996, 0.43900000000000006, 0.4750000000000001, -0.025000000000000022, 0.45699999999999985, 0.45199999999999996, -0.062000000000000055, 0.46799999999999997, 0.46399999999999997, 0.46599999999999997, 0.46799999999999997, 0.45799999999999996, 0.46199999999999997, -0.03700000000000003, 1.444, -0.03500000000000003, 0.45100000000000007, -0.025000000000000022, 0.4710000000000001, -0.03500000000000003, 0.45799999999999996, 0.46399999999999997, 0.46499999999999986, 0.45799999999999996, -0.038000000000000034, -0.02100000000000002, 0.44999999999999996, 0.43900000000000006, 0.45999999999999996, -0.061000000000000054, -0.028999999999999915, 0.45799999999999996, -0.04200000000000004, 0.45599999999999996, 0.42300000000000004, 0.44300000000000006, 0.44099999999999984, 0.45799999999999996, -0.10499999999999998, -0.22099999999999997, 1.4489999999999998, 0.381, 0.4710000000000001, 0.244, 0.41300000000000026, 0.4630000000000001, -0.04400000000000004, 0.47, 0.40900000000000003, 0.44899999999999984, -0.031000000000000028, 0.45099999999999996, 0.46599999999999997, 0.45899999999999996, 0.4670000000000001, 0.45199999999999996, 0.46099999999999985, 0.47, 0.881, 0.42700000000000005, -0.030000000000000027, 0.44899999999999984, -0.039999999999999925, -0.03300000000000003], "episode_lengths": [12, 16, 17, 11, 17, 13, 11, 12, 14, 16, 14, 15, 13, 17, 14, 9, 15, 19, 18, 11, 9, 7, 22, 19, 18, 35, 36, 15, 11, 23, 9, 10, 44, 27, 19, 14, 11, 15, 9, 11, 19, 7, 13, 20, 15, 11, 11, 13, 11, 11, 30, 21, 15, 11, 10, 40, 11, 12, 18, 12, 13, 64, 12, 13, 34, 11, 12, 10, 25, 9, 13, 44, 9, 11, 13, 13, 22, 85, 9, 14, 27, 10, 8, 27, 11, 13, 14, 11, 8, 13, 10, 15, 13, 12, 8, 12, 10, 8, 10, 12, 10, 16, 13, 13, 10, 13, 12, 26, 15, 20, 8, 15, 13, 23, 10, 10, 16, 19, 20, 17, 127, 13, 113, 11, 17, 28, 15, 12, 12, 20, 13, 10, 12, 15, 23, 15, 11, 7, 10, 14, 11, 11, 73, 17, 53, 24, 11, 11, 10, 19, 12, 16, 12, 16, 12, 10, 8, 11, 14, 19, 8, 8, 14, 15, 20, 10, 12, 11, 10, 13, 12, 11, 18, 11, 16, 8, 9, 11, 13, 11, 11, 13, 12, 7, 16, 19, 13, 17, 9, 13, 13, 14, 24, 18, 19, 14, 33, 64, 16, 37, 9, 81, 28, 12, 14, 10, 29, 16, 10, 16, 11, 13, 11, 15, 11, 10, 38, 23, 10, 16, 13, 10], "policy_red_0_reward": [0.964, 1.452, 1.4489999999999998, 1.467, 1.448, 1.4609999999999999, 0.967, 0.964, 1.458, 1.452, 1.458, 1.455, 1.4609999999999999, 1.4489999999999998, 1.458, 1.4729999999999999, 1.455, 0.942, 1.446, 1.467, 0.973, 0.979, 1.432, 1.4409999999999998, 1.446, 1.395, 1.3900000000000001, 1.455, 1.467, 1.4300000000000002, 1.4729999999999999, 1.47, 1.365, 1.4180000000000001, 1.442, 1.4569999999999999, 0.967, 1.455, 1.4729999999999999, 0.967, 1.443, 0.979, 1.4609999999999999, 1.44, 1.455, 0.967, 1.467, 1.4609999999999999, 1.467, 0.967, 0.894, 1.4369999999999998, 1.455, 1.467, 1.47, -0.5, 1.467, 0.964, 1.446, 1.464, 1.4609999999999999, 1.308, 1.464, 0.961, 0.898, 0.967, 1.464, 1.47, 1.424, 0.973, 1.4609999999999999, 1.365, 1.4729999999999999, 1.467, 1.46, 1.4609999999999999, 1.434, 1.2429999999999999, 1.4729999999999999, 1.458, 1.419, 0.97, 1.476, 1.419, 1.467, 0.961, 1.458, 1.467, 1.476, 0.961, 0.97, 1.455, 1.4609999999999999, 1.464, 1.476, 1.463, 1.47, 1.476, 1.47, 1.464, 1.47, 1.452, 0.961, 1.4609999999999999, 0.97, 1.4609999999999999, 1.464, 1.42, 1.455, 1.44, 0.976, 1.454, 1.4609999999999999, 1.4300000000000002, 0.97, 1.47, 1.452, 1.443, 0.939, -0.5, 1.1099999999999999, 0.96, 1.157, 1.467, 1.4489999999999998, 1.416, 1.455, 0.962, 0.964, 1.44, 1.4609999999999999, 1.47, 1.464, 1.455, 1.431, 1.455, 0.967, 1.479, 1.47, 1.458, 0.967, 1.467, 1.279, 0.945, 1.334, 0.9209999999999999, 1.467, 0.967, 0.97, 1.443, 0.964, 1.452, 0.964, 1.452, 1.464, 0.97, -1.0, 1.467, 1.458, 1.443, 1.476, 0.976, 1.458, 1.455, 0.94, 1.47, 1.464, 1.467, 1.47, 1.4609999999999999, 1.464, 0.966, 1.446, 0.967, 1.452, 0.976, 1.4729999999999999, 0.967, 1.4609999999999999, 1.467, 1.467, 1.4609999999999999, 0.964, 0.979, 1.452, 1.443, 1.4609999999999999, 0.943, 0.973, 1.4609999999999999, 0.961, 1.458, 1.426, 1.446, 1.443, 1.458, 0.899, 0.789, 1.452, 1.388, 1.4729999999999999, 1.2570000000000001, 1.416, 1.464, 0.958, 1.47, 1.413, 1.452, 0.97, -0.5, 1.467, -0.5, 1.467, 1.4529999999999998, 1.467, 0.97, 1.3860000000000001, 1.4300000000000002, 0.97, 1.452, 0.961, 0.97], "policy_blue_0_reward": [-1.003, -1.004, -1.003, -1.002, -0.001, -1.003, -1.0019999999999998, -1.001, -1.005, -1.001, -1.0019999999999998, -1.003, -1.002, -1.003, -1.001, -1.001, -1.0019999999999998, -1.002, -1.007, -1.001, -0.502, -1.001, -1.002, -1.002, -1.002, -1.006, -0.007, -1.0, -1.001, -1.001, -1.0, -1.0019999999999998, -1.009, -1.002, -0.5039999999999999, -1.0, -1.001, -1.0, -1.0, -1.001, -1.0039999999999998, -1.0, -1.003, -1.006, -1.002, -1.003, -1.0, -1.001, -1.001, -1.002, -1.009, -1.003, -1.001, -1.001, -1.0, 0.874, -1.001, -1.0, -1.001, -1.002, -1.002, -1.005, -1.002, -1.001, -1.004, -1.001, -1.005, -1.002, -1.003, -1.003, -1.0, -1.005, -1.002, -0.5, -1.001, -1.002, -1.001, -1.015, -1.0, -0.001, -1.006, -1.001, -1.001, -1.004, -1.002, -1.002, -1.001, -1.001, -1.0, -1.003, -0.5, -1.004, -1.001, -1.0019999999999998, -1.001, -1.0019999999999998, -1.001, -1.0, -1.002, -1.002, -1.001, -1.002, -1.003, -1.002, -1.001, -1.003, -1.0, -1.003, -1.001, -1.003, -1.001, -1.0039999999999998, -1.001, -1.002, -1.0, -1.002, -1.002, -1.006, -1.001, 0.948, -1.019, -1.0019999999999998, -1.016, -1.001, -1.002, -1.005, -1.002, -1.002, -1.0039999999999998, -1.002, -1.001, -1.0039999999999998, -0.5, -1.001, -1.004, -1.004, -1.003, -1.0019999999999998, -1.002, -1.002, -1.002, -1.004, -1.006, -1.0, -0.507, -1.005, -1.002, -1.0059999999999998, -1.002, -1.0039999999999998, -1.001, -1.004, -1.0, -1.002, -1.004, -1.002, 0.975, -1.0, -1.002, -1.004, -1.001, -1.001, -1.001, -1.003, -1.002, -1.002, -1.0, -1.001, -1.002, -1.003, -1.002, -1.003, -0.002, -1.002, -1.001, -1.001, -1.002, -1.002, -1.003, -1.003, -1.002, -1.003, -1.002, -1.0, -1.002, -1.0039999999999998, -1.001, -1.004, -1.0019999999999998, -1.003, -1.003, -1.002, -1.003, -1.003, -1.002, -1.0, -1.004, -1.01, -0.003, -1.007, -1.002, -1.013, -1.003, -1.001, -1.002, -1.0, -1.004, -1.003, -1.001, 0.951, -1.001, 0.959, -1.0, -1.001, -1.006, -0.5, -0.505, -1.003, -1.0, -1.003, -1.001, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24446589784048553, "mean_inference_ms": 1.476113905485787, "mean_action_processing_ms": 0.06301745226528555, "mean_env_wait_ms": 0.08932808927904223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01920746253417419, "StateBufferConnector_ms": 0.001504614546492293, "ViewRequirementAgentConnector_ms": 0.031261777018641565}}, "episode_reward_max": 1.4569999999999999, "episode_reward_min": -0.22099999999999997, "episode_reward_mean": 0.3549594594594594, "episode_len_mean": 17.31081081081081, "episodes_this_iter": 222, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.975}, "policy_reward_mean": {"red_0": 1.2731486486486487, "blue_0": -0.918189189189189}, "hist_stats": {"episode_reward": [-0.039000000000000035, 0.44799999999999995, 0.44599999999999995, 0.46499999999999986, 1.447, 0.45799999999999996, -0.03499999999999992, -0.03699999999999992, 0.45300000000000007, 0.45100000000000007, 0.45599999999999996, 0.45199999999999996, 0.4590000000000001, 0.44599999999999995, 0.45699999999999985, 0.472, 0.45300000000000007, -0.06000000000000005, 0.43900000000000006, 0.46599999999999997, 0.471, -0.02200000000000002, 0.42999999999999994, 0.43900000000000006, 0.44399999999999995, 0.389, 1.383, 0.45500000000000007, 0.46599999999999997, 0.42900000000000005, 0.47299999999999986, 0.46799999999999997, 0.35599999999999987, 0.4159999999999999, 0.9380000000000002, 0.45699999999999985, -0.03400000000000003, 0.45500000000000007, 0.47299999999999986, -0.03399999999999992, 0.43900000000000006, -0.02100000000000002, 0.45799999999999996, 0.43399999999999994, 0.45299999999999985, -0.03599999999999992, 0.4670000000000001, 0.45999999999999996, 0.46599999999999997, -0.03500000000000003, -0.11499999999999988, 0.43399999999999994, 0.45399999999999996, 0.46599999999999997, 0.47, 0.374, 0.46599999999999997, -0.03600000000000003, 0.44499999999999984, 0.46199999999999997, 0.4590000000000001, 0.30299999999999994, 0.46199999999999997, -0.040000000000000036, -0.10599999999999998, -0.03400000000000003, 0.4590000000000001, 0.46799999999999997, 0.42100000000000026, -0.030000000000000027, 0.46099999999999985, 0.3599999999999999, 0.4710000000000001, 0.9670000000000001, 0.4590000000000001, 0.4590000000000001, 0.43299999999999983, 0.2280000000000002, 0.47299999999999986, 1.4569999999999999, 0.41300000000000003, -0.031000000000000028, 0.4750000000000001, 0.41500000000000004, 0.46499999999999986, -0.041000000000000036, 0.45699999999999985, 0.46599999999999997, 0.476, -0.04200000000000004, 0.47, 0.45100000000000007, 0.45999999999999996, 0.4620000000000002, 0.4750000000000001, 0.4610000000000001, 0.46899999999999986, 0.476, 0.46799999999999997, 0.46199999999999997, 0.4690000000000001, 0.44999999999999996, -0.04200000000000004, 0.4590000000000001, -0.031000000000000028, 0.45799999999999996, 0.46399999999999997, 0.41700000000000004, 0.45399999999999996, 0.43699999999999983, -0.025000000000000022, 0.4500000000000002, 0.45999999999999996, 0.42799999999999994, -0.030000000000000027, 0.46799999999999997, 0.44999999999999996, 0.43699999999999983, -0.062000000000000055, 0.44799999999999995, 0.09099999999999997, -0.041999999999999926, 0.14100000000000001, 0.46599999999999997, 0.44700000000000006, 0.41100000000000003, 0.45299999999999985, -0.040000000000000036, -0.039999999999999925, 0.43799999999999994, 0.45999999999999996, 0.4660000000000002, 0.964, 0.45399999999999996, 0.42700000000000005, 0.45100000000000007, -0.03599999999999992, 0.4770000000000001, 0.46799999999999997, 0.45599999999999996, -0.03500000000000003, 0.4630000000000001, 0.2729999999999999, -0.05500000000000005, 0.827, -0.08400000000000007, 0.46499999999999986, -0.038999999999999924, -0.03200000000000003, 0.43900000000000006, -0.03700000000000003, 0.44799999999999995, -0.03600000000000003, 0.44999999999999996, 0.45999999999999996, -0.03200000000000003, -0.02499999999999991, 0.4670000000000001, 0.45599999999999996, 0.43900000000000006, 0.4750000000000001, -0.025000000000000022, 0.45699999999999985, 0.45199999999999996, -0.062000000000000055, 0.46799999999999997, 0.46399999999999997, 0.46599999999999997, 0.46799999999999997, 0.45799999999999996, 0.46199999999999997, -0.03700000000000003, 1.444, -0.03500000000000003, 0.45100000000000007, -0.025000000000000022, 0.4710000000000001, -0.03500000000000003, 0.45799999999999996, 0.46399999999999997, 0.46499999999999986, 0.45799999999999996, -0.038000000000000034, -0.02100000000000002, 0.44999999999999996, 0.43900000000000006, 0.45999999999999996, -0.061000000000000054, -0.028999999999999915, 0.45799999999999996, -0.04200000000000004, 0.45599999999999996, 0.42300000000000004, 0.44300000000000006, 0.44099999999999984, 0.45799999999999996, -0.10499999999999998, -0.22099999999999997, 1.4489999999999998, 0.381, 0.4710000000000001, 0.244, 0.41300000000000026, 0.4630000000000001, -0.04400000000000004, 0.47, 0.40900000000000003, 0.44899999999999984, -0.031000000000000028, 0.45099999999999996, 0.46599999999999997, 0.45899999999999996, 0.4670000000000001, 0.45199999999999996, 0.46099999999999985, 0.47, 0.881, 0.42700000000000005, -0.030000000000000027, 0.44899999999999984, -0.039999999999999925, -0.03300000000000003], "episode_lengths": [12, 16, 17, 11, 17, 13, 11, 12, 14, 16, 14, 15, 13, 17, 14, 9, 15, 19, 18, 11, 9, 7, 22, 19, 18, 35, 36, 15, 11, 23, 9, 10, 44, 27, 19, 14, 11, 15, 9, 11, 19, 7, 13, 20, 15, 11, 11, 13, 11, 11, 30, 21, 15, 11, 10, 40, 11, 12, 18, 12, 13, 64, 12, 13, 34, 11, 12, 10, 25, 9, 13, 44, 9, 11, 13, 13, 22, 85, 9, 14, 27, 10, 8, 27, 11, 13, 14, 11, 8, 13, 10, 15, 13, 12, 8, 12, 10, 8, 10, 12, 10, 16, 13, 13, 10, 13, 12, 26, 15, 20, 8, 15, 13, 23, 10, 10, 16, 19, 20, 17, 127, 13, 113, 11, 17, 28, 15, 12, 12, 20, 13, 10, 12, 15, 23, 15, 11, 7, 10, 14, 11, 11, 73, 17, 53, 24, 11, 11, 10, 19, 12, 16, 12, 16, 12, 10, 8, 11, 14, 19, 8, 8, 14, 15, 20, 10, 12, 11, 10, 13, 12, 11, 18, 11, 16, 8, 9, 11, 13, 11, 11, 13, 12, 7, 16, 19, 13, 17, 9, 13, 13, 14, 24, 18, 19, 14, 33, 64, 16, 37, 9, 81, 28, 12, 14, 10, 29, 16, 10, 16, 11, 13, 11, 15, 11, 10, 38, 23, 10, 16, 13, 10], "policy_red_0_reward": [0.964, 1.452, 1.4489999999999998, 1.467, 1.448, 1.4609999999999999, 0.967, 0.964, 1.458, 1.452, 1.458, 1.455, 1.4609999999999999, 1.4489999999999998, 1.458, 1.4729999999999999, 1.455, 0.942, 1.446, 1.467, 0.973, 0.979, 1.432, 1.4409999999999998, 1.446, 1.395, 1.3900000000000001, 1.455, 1.467, 1.4300000000000002, 1.4729999999999999, 1.47, 1.365, 1.4180000000000001, 1.442, 1.4569999999999999, 0.967, 1.455, 1.4729999999999999, 0.967, 1.443, 0.979, 1.4609999999999999, 1.44, 1.455, 0.967, 1.467, 1.4609999999999999, 1.467, 0.967, 0.894, 1.4369999999999998, 1.455, 1.467, 1.47, -0.5, 1.467, 0.964, 1.446, 1.464, 1.4609999999999999, 1.308, 1.464, 0.961, 0.898, 0.967, 1.464, 1.47, 1.424, 0.973, 1.4609999999999999, 1.365, 1.4729999999999999, 1.467, 1.46, 1.4609999999999999, 1.434, 1.2429999999999999, 1.4729999999999999, 1.458, 1.419, 0.97, 1.476, 1.419, 1.467, 0.961, 1.458, 1.467, 1.476, 0.961, 0.97, 1.455, 1.4609999999999999, 1.464, 1.476, 1.463, 1.47, 1.476, 1.47, 1.464, 1.47, 1.452, 0.961, 1.4609999999999999, 0.97, 1.4609999999999999, 1.464, 1.42, 1.455, 1.44, 0.976, 1.454, 1.4609999999999999, 1.4300000000000002, 0.97, 1.47, 1.452, 1.443, 0.939, -0.5, 1.1099999999999999, 0.96, 1.157, 1.467, 1.4489999999999998, 1.416, 1.455, 0.962, 0.964, 1.44, 1.4609999999999999, 1.47, 1.464, 1.455, 1.431, 1.455, 0.967, 1.479, 1.47, 1.458, 0.967, 1.467, 1.279, 0.945, 1.334, 0.9209999999999999, 1.467, 0.967, 0.97, 1.443, 0.964, 1.452, 0.964, 1.452, 1.464, 0.97, -1.0, 1.467, 1.458, 1.443, 1.476, 0.976, 1.458, 1.455, 0.94, 1.47, 1.464, 1.467, 1.47, 1.4609999999999999, 1.464, 0.966, 1.446, 0.967, 1.452, 0.976, 1.4729999999999999, 0.967, 1.4609999999999999, 1.467, 1.467, 1.4609999999999999, 0.964, 0.979, 1.452, 1.443, 1.4609999999999999, 0.943, 0.973, 1.4609999999999999, 0.961, 1.458, 1.426, 1.446, 1.443, 1.458, 0.899, 0.789, 1.452, 1.388, 1.4729999999999999, 1.2570000000000001, 1.416, 1.464, 0.958, 1.47, 1.413, 1.452, 0.97, -0.5, 1.467, -0.5, 1.467, 1.4529999999999998, 1.467, 0.97, 1.3860000000000001, 1.4300000000000002, 0.97, 1.452, 0.961, 0.97], "policy_blue_0_reward": [-1.003, -1.004, -1.003, -1.002, -0.001, -1.003, -1.0019999999999998, -1.001, -1.005, -1.001, -1.0019999999999998, -1.003, -1.002, -1.003, -1.001, -1.001, -1.0019999999999998, -1.002, -1.007, -1.001, -0.502, -1.001, -1.002, -1.002, -1.002, -1.006, -0.007, -1.0, -1.001, -1.001, -1.0, -1.0019999999999998, -1.009, -1.002, -0.5039999999999999, -1.0, -1.001, -1.0, -1.0, -1.001, -1.0039999999999998, -1.0, -1.003, -1.006, -1.002, -1.003, -1.0, -1.001, -1.001, -1.002, -1.009, -1.003, -1.001, -1.001, -1.0, 0.874, -1.001, -1.0, -1.001, -1.002, -1.002, -1.005, -1.002, -1.001, -1.004, -1.001, -1.005, -1.002, -1.003, -1.003, -1.0, -1.005, -1.002, -0.5, -1.001, -1.002, -1.001, -1.015, -1.0, -0.001, -1.006, -1.001, -1.001, -1.004, -1.002, -1.002, -1.001, -1.001, -1.0, -1.003, -0.5, -1.004, -1.001, -1.0019999999999998, -1.001, -1.0019999999999998, -1.001, -1.0, -1.002, -1.002, -1.001, -1.002, -1.003, -1.002, -1.001, -1.003, -1.0, -1.003, -1.001, -1.003, -1.001, -1.0039999999999998, -1.001, -1.002, -1.0, -1.002, -1.002, -1.006, -1.001, 0.948, -1.019, -1.0019999999999998, -1.016, -1.001, -1.002, -1.005, -1.002, -1.002, -1.0039999999999998, -1.002, -1.001, -1.0039999999999998, -0.5, -1.001, -1.004, -1.004, -1.003, -1.0019999999999998, -1.002, -1.002, -1.002, -1.004, -1.006, -1.0, -0.507, -1.005, -1.002, -1.0059999999999998, -1.002, -1.0039999999999998, -1.001, -1.004, -1.0, -1.002, -1.004, -1.002, 0.975, -1.0, -1.002, -1.004, -1.001, -1.001, -1.001, -1.003, -1.002, -1.002, -1.0, -1.001, -1.002, -1.003, -1.002, -1.003, -0.002, -1.002, -1.001, -1.001, -1.002, -1.002, -1.003, -1.003, -1.002, -1.003, -1.002, -1.0, -1.002, -1.0039999999999998, -1.001, -1.004, -1.0019999999999998, -1.003, -1.003, -1.002, -1.003, -1.003, -1.002, -1.0, -1.004, -1.01, -0.003, -1.007, -1.002, -1.013, -1.003, -1.001, -1.002, -1.0, -1.004, -1.003, -1.001, 0.951, -1.001, 0.959, -1.0, -1.001, -1.006, -0.5, -0.505, -1.003, -1.0, -1.003, -1.001, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24446589784048553, "mean_inference_ms": 1.476113905485787, "mean_action_processing_ms": 0.06301745226528555, "mean_env_wait_ms": 0.08932808927904223, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01920746253417419, "StateBufferConnector_ms": 0.001504614546492293, "ViewRequirementAgentConnector_ms": 0.031261777018641565}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000, "num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.29315223018241, "num_env_steps_trained_throughput_per_sec": 102.29315223018241, "timesteps_total": 156000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 312000, "timers": {"training_iteration_time_ms": 39044.62, "sample_time_ms": 7638.215, "learn_time_ms": 31388.995, "learn_throughput": 127.433, "synch_weights_time_ms": 16.916}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 156000, "num_agent_steps_sampled": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 4316, "training_iteration": 39, "trial_id": "d67e4_00000", "date": "2023-09-20_22-34-32", "timestamp": 1695263672, "time_this_iter_s": 39.111818075180054, "time_total_s": 1517.0156745910645, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706d40>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1517.0156745910645, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 35.06181818181818, "ram_util_percent": 48.705454545454515}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06077348066298342, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8729281767955801, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06077348066298342, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8729281767955801, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.06077348066298342, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8729281767955801, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06077348066298342, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8943282469175755, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.014492749985462676, "policy_loss": -0.022958480283705285, "vf_loss": 0.009875163007139538, "vf_explained_var": 0.6872772586221496, "kl": 0.008905599234488666, "entropy": 0.4793711713515222, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 37920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "sampler_results": {"episode_reward_max": 1.459, "episode_reward_min": -0.369, "episode_reward_mean": 0.40818232044198893, "episode_len_mean": 22.607734806629836, "episode_media": {}, "episodes_this_iter": 181, "policy_reward_min": {"red_0": -1.067, "blue_0": -1.024}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 1.1989447513812155, "blue_0": -0.7907624309392266}, "custom_metrics": {"red_0/door_open_done_mean": 0.06077348066298342, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8729281767955801, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06077348066298342, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8729281767955801, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.06077348066298342, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8729281767955801, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06077348066298342, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.369, 0.47, -0.03500000000000003, 0.4670000000000001, 0.45299999999999985, -0.03300000000000003, -0.04300000000000004, 0.46199999999999997, 0.46199999999999997, 0.45699999999999985, -0.05800000000000005, 0.4630000000000001, 0.45699999999999985, 0.379, 0.44999999999999996, -0.029000000000000026, 0.4580000000000002, 0.45399999999999996, 0.45399999999999996, 0.45500000000000007, 0.43299999999999994, 0.43900000000000006, 0.395, 0.4119999999999999, 1.45, -0.038000000000000034, 0.9590000000000001, 0.44999999999999996, 0.44899999999999984, 0.4610000000000001, 0.47299999999999986, 0.44399999999999995, 0.45500000000000007, -0.09099999999999997, 0.2719999999999998, 0.4610000000000001, 0.43500000000000005, 0.96, -0.04500000000000004, 0.43000000000000016, 0.4660000000000002, -0.030000000000000027, -0.041000000000000036, -0.025999999999999912, -0.07300000000000006, -0.040000000000000036, -0.026000000000000023, 0.47, 0.4249999999999998, 0.46599999999999997, 1.452, 0.472, 1.459, 0.248, 0.4079999999999999, 0.45399999999999996, 0.9609999999999999, -0.02400000000000002, -0.04700000000000004, -0.028000000000000025, -0.02200000000000002, 0.44999999999999996, 0.45299999999999985, 1.448, 0.44599999999999995, 0.11499999999999999, 0.46399999999999997, 0.46499999999999986, 0.45399999999999996, 0.29800000000000004, 0.4710000000000001, 0.46199999999999997, -0.030000000000000027, 0.45199999999999996, -0.04299999999999993, -0.04699999999999993, 0.4710000000000001, 0.41400000000000015, 0.47299999999999986, -0.05599999999999994, 0.46599999999999997, -0.03399999999999992, 0.46899999999999986, 1.448, -0.031000000000000028, 1.458, 0.45300000000000007, 0.3759999999999999, 0.47299999999999986, 0.44599999999999995, -0.03700000000000003, -0.03200000000000003, 0.472, 0.4630000000000001, 1.097, 0.44399999999999995, 0.46599999999999997, 0.14, 0.41100000000000003, 0.9569999999999999, -0.027999999999999914, 0.45499999999999996, 0.45799999999999996, 0.46199999999999997, -0.025000000000000022, 0.46199999999999997, 0.373, 0.45299999999999985, -0.03600000000000003, -0.03700000000000003, 0.45699999999999985, 0.45199999999999996, 0.6389999999999998, -0.04400000000000004, 0.45199999999999996, 0.45999999999999996, 0.32499999999999996, 0.30800000000000005, 0.383, 0.45999999999999996, 0.43599999999999994, 0.43700000000000006, 0.476, 0.46499999999999986, 0.42900000000000005, 0.45999999999999996, -0.03200000000000003, 0.955, 0.44700000000000006, -0.027000000000000024, 0.826, 0.44799999999999995, 0.4630000000000001, -0.08000000000000007, -0.031000000000000028, 0.46599999999999997, 0.476, -0.039000000000000035, 0.8919999999999999, 0.45100000000000007, 0.4500000000000002, 0.4670000000000001, 0.45399999999999996, -0.025000000000000022, 0.46099999999999985, 0.4590000000000001, 0.4630000000000001, 0.45399999999999996, 0.4590000000000001, 0.46599999999999997, 0.46399999999999997, 0.44999999999999996, 0.47, 0.45299999999999985, -0.041000000000000036, 0.3820000000000001, 0.4750000000000001, 0.45500000000000007, -0.03400000000000003, 0.5009999999999999, 0.46899999999999986, 1.448, 0.962, 0.45399999999999996, 1.396, 0.45899999999999996, 0.45599999999999996, -0.029999999999999916, 1.442, 0.4650000000000001, -0.07399999999999995, 0.4670000000000001, 0.9510000000000001, 0.46499999999999986, 0.38900000000000023, 0.45599999999999996, 0.42599999999999993, 1.434, 0.43300000000000005, -0.05300000000000005, 0.46899999999999986], "episode_lengths": [98, 10, 11, 11, 15, 11, 14, 12, 12, 14, 18, 12, 14, 38, 16, 9, 13, 15, 14, 14, 21, 19, 34, 28, 16, 12, 13, 15, 16, 12, 9, 17, 14, 29, 73, 12, 19, 13, 14, 22, 11, 9, 13, 8, 181, 13, 8, 10, 24, 11, 15, 9, 13, 80, 29, 15, 12, 8, 15, 9, 7, 16, 15, 17, 17, 121, 12, 11, 15, 62, 9, 12, 10, 15, 14, 15, 9, 27, 9, 18, 11, 10, 10, 16, 10, 14, 15, 39, 9, 18, 12, 10, 9, 12, 125, 18, 11, 115, 27, 14, 9, 15, 13, 12, 8, 12, 41, 14, 11, 12, 14, 15, 114, 13, 15, 13, 54, 61, 36, 13, 20, 18, 8, 11, 23, 13, 10, 300, 16, 8, 56, 16, 12, 24, 10, 11, 8, 13, 35, 16, 15, 10, 15, 8, 12, 13, 11, 15, 13, 11, 12, 15, 10, 15, 13, 38, 8, 14, 11, 156, 10, 17, 12, 14, 32, 13, 14, 9, 19, 11, 20, 10, 16, 11, 32, 14, 24, 21, 21, 17, 9], "policy_red_0_reward": [-1.067, 1.47, 0.967, 1.467, 1.455, 0.967, 0.958, 1.464, 1.464, 1.458, 0.946, 1.464, 1.458, -0.501, 1.452, 0.973, 1.4609999999999999, 1.455, 1.458, 1.458, -0.5, 1.443, 1.3980000000000001, 1.416, 1.452, 0.964, 1.46, 1.455, 1.452, 1.464, 1.4729999999999999, 1.4489999999999998, 1.4569999999999999, 0.913, 1.279, 1.464, 1.4409999999999998, -0.5, 0.958, 1.434, 1.467, 0.973, 0.961, 0.976, 0.951, 0.961, 0.976, 1.47, 1.428, 1.467, 1.455, 1.4729999999999999, 1.4609999999999999, 1.258, 1.412, 1.455, 1.464, 0.976, 0.955, 0.973, 0.979, 1.451, 1.455, 1.4489999999999998, 1.4489999999999998, -0.503, 1.464, 1.467, 1.455, 1.304, 1.4729999999999999, 1.464, 0.97, 1.455, 0.958, 0.955, 1.4729999999999999, 1.4180000000000001, 1.4729999999999999, 0.946, 1.467, 0.969, 1.47, 1.452, 0.97, 1.458, 1.455, 1.3820000000000001, 1.4729999999999999, 1.446, 0.964, 0.97, 1.4729999999999999, 1.464, 1.121, 1.446, 1.467, -0.502, 1.417, 1.4569999999999999, -1.001, -0.5, 1.4609999999999999, 1.464, 0.976, 1.464, 1.376, 1.4569999999999999, 0.967, 0.964, 1.458, 1.455, 1.156, 0.961, 1.455, 1.4609999999999999, 1.3359999999999999, 1.315, 1.3900000000000001, 1.4609999999999999, 0.94, 1.444, 1.476, 1.467, 1.4300000000000002, 1.4609999999999999, 0.97, 0.492, 1.452, 0.976, -0.5, -0.501, 1.464, 0.9259999999999999, 0.97, 1.467, 1.476, 0.961, 1.395, 1.452, 1.454, 1.4689999999999999, 1.455, 0.976, 1.464, 1.4609999999999999, 1.467, 1.455, 1.4609999999999999, 1.467, 1.464, 1.455, 1.47, 1.455, 0.961, 1.385, 1.476, 1.458, 0.967, 1.0230000000000001, 1.47, 1.4489999999999998, 1.464, 1.458, 1.4020000000000001, -0.5, 1.458, 0.973, 1.443, 1.467, 0.9329999999999999, 1.47, 1.452, 1.467, 1.401, 1.458, 1.427, 1.4369999999999998, 1.4369999999999998, 0.948, 1.4729999999999999], "policy_blue_0_reward": [0.698, -1.0, -1.002, -1.0, -1.002, -1.0, -1.001, -1.002, -1.002, -1.001, -1.004, -1.001, -1.001, 0.88, -1.002, -1.002, -1.003, -1.001, -1.004, -1.003, 0.9329999999999999, -1.004, -1.003, -1.004, -0.002, -1.002, -0.501, -1.005, -1.003, -1.003, -1.0, -1.005, -1.002, -1.004, -1.007, -1.003, -1.0059999999999998, 1.46, -1.003, -1.0039999999999998, -1.001, -1.003, -1.002, -1.0019999999999998, -1.024, -1.001, -1.002, -1.0, -1.003, -1.001, -0.003, -1.001, -0.002, -1.01, -1.004, -1.001, -0.503, -1.0, -1.002, -1.001, -1.001, -1.001, -1.002, -0.001, -1.003, 0.618, -1.0, -1.002, -1.001, -1.006, -1.002, -1.002, -1.0, -1.003, -1.001, -1.0019999999999998, -1.002, -1.004, -1.0, -1.0019999999999998, -1.001, -1.003, -1.001, -0.004, -1.001, 0.0, -1.0019999999999998, -1.006, -1.0, -1.0, -1.001, -1.002, -1.001, -1.001, -0.024000000000000014, -1.0019999999999998, -1.001, 0.642, -1.006, -0.5, 0.973, 0.955, -1.003, -1.002, -1.001, -1.002, -1.003, -1.004, -1.003, -1.001, -1.001, -1.003, -0.517, -1.005, -1.003, -1.001, -1.011, -1.007, -1.007, -1.001, -0.504, -1.007, -1.0, -1.002, -1.001, -1.001, -1.002, 0.46299999999999997, -1.005, -1.003, 1.326, 0.949, -1.001, -1.006, -1.001, -1.001, -1.0, -1.0, -0.503, -1.001, -1.0039999999999998, -1.002, -1.001, -1.001, -1.003, -1.002, -1.0039999999999998, -1.001, -1.002, -1.001, -1.0, -1.005, -1.0, -1.002, -1.002, -1.003, -1.001, -1.003, -1.001, -0.522, -1.001, -0.001, -0.502, -1.004, -0.006, 0.959, -1.002, -1.003, -0.001, -1.0019999999999998, -1.007, -1.003, -0.501, -1.002, -1.0119999999999998, -1.002, -1.001, -0.003, -1.0039999999999998, -1.001, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24465666128795735, "mean_inference_ms": 1.4763934936471073, "mean_action_processing_ms": 0.06302050272951229, "mean_env_wait_ms": 0.0893081037258953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01901328892997615, "StateBufferConnector_ms": 0.0015093476732791458, "ViewRequirementAgentConnector_ms": 0.03134842077012879}}, "episode_reward_max": 1.459, "episode_reward_min": -0.369, "episode_reward_mean": 0.40818232044198893, "episode_len_mean": 22.607734806629836, "episodes_this_iter": 181, "policy_reward_min": {"red_0": -1.067, "blue_0": -1.024}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.46}, "policy_reward_mean": {"red_0": 1.1989447513812155, "blue_0": -0.7907624309392266}, "hist_stats": {"episode_reward": [-0.369, 0.47, -0.03500000000000003, 0.4670000000000001, 0.45299999999999985, -0.03300000000000003, -0.04300000000000004, 0.46199999999999997, 0.46199999999999997, 0.45699999999999985, -0.05800000000000005, 0.4630000000000001, 0.45699999999999985, 0.379, 0.44999999999999996, -0.029000000000000026, 0.4580000000000002, 0.45399999999999996, 0.45399999999999996, 0.45500000000000007, 0.43299999999999994, 0.43900000000000006, 0.395, 0.4119999999999999, 1.45, -0.038000000000000034, 0.9590000000000001, 0.44999999999999996, 0.44899999999999984, 0.4610000000000001, 0.47299999999999986, 0.44399999999999995, 0.45500000000000007, -0.09099999999999997, 0.2719999999999998, 0.4610000000000001, 0.43500000000000005, 0.96, -0.04500000000000004, 0.43000000000000016, 0.4660000000000002, -0.030000000000000027, -0.041000000000000036, -0.025999999999999912, -0.07300000000000006, -0.040000000000000036, -0.026000000000000023, 0.47, 0.4249999999999998, 0.46599999999999997, 1.452, 0.472, 1.459, 0.248, 0.4079999999999999, 0.45399999999999996, 0.9609999999999999, -0.02400000000000002, -0.04700000000000004, -0.028000000000000025, -0.02200000000000002, 0.44999999999999996, 0.45299999999999985, 1.448, 0.44599999999999995, 0.11499999999999999, 0.46399999999999997, 0.46499999999999986, 0.45399999999999996, 0.29800000000000004, 0.4710000000000001, 0.46199999999999997, -0.030000000000000027, 0.45199999999999996, -0.04299999999999993, -0.04699999999999993, 0.4710000000000001, 0.41400000000000015, 0.47299999999999986, -0.05599999999999994, 0.46599999999999997, -0.03399999999999992, 0.46899999999999986, 1.448, -0.031000000000000028, 1.458, 0.45300000000000007, 0.3759999999999999, 0.47299999999999986, 0.44599999999999995, -0.03700000000000003, -0.03200000000000003, 0.472, 0.4630000000000001, 1.097, 0.44399999999999995, 0.46599999999999997, 0.14, 0.41100000000000003, 0.9569999999999999, -0.027999999999999914, 0.45499999999999996, 0.45799999999999996, 0.46199999999999997, -0.025000000000000022, 0.46199999999999997, 0.373, 0.45299999999999985, -0.03600000000000003, -0.03700000000000003, 0.45699999999999985, 0.45199999999999996, 0.6389999999999998, -0.04400000000000004, 0.45199999999999996, 0.45999999999999996, 0.32499999999999996, 0.30800000000000005, 0.383, 0.45999999999999996, 0.43599999999999994, 0.43700000000000006, 0.476, 0.46499999999999986, 0.42900000000000005, 0.45999999999999996, -0.03200000000000003, 0.955, 0.44700000000000006, -0.027000000000000024, 0.826, 0.44799999999999995, 0.4630000000000001, -0.08000000000000007, -0.031000000000000028, 0.46599999999999997, 0.476, -0.039000000000000035, 0.8919999999999999, 0.45100000000000007, 0.4500000000000002, 0.4670000000000001, 0.45399999999999996, -0.025000000000000022, 0.46099999999999985, 0.4590000000000001, 0.4630000000000001, 0.45399999999999996, 0.4590000000000001, 0.46599999999999997, 0.46399999999999997, 0.44999999999999996, 0.47, 0.45299999999999985, -0.041000000000000036, 0.3820000000000001, 0.4750000000000001, 0.45500000000000007, -0.03400000000000003, 0.5009999999999999, 0.46899999999999986, 1.448, 0.962, 0.45399999999999996, 1.396, 0.45899999999999996, 0.45599999999999996, -0.029999999999999916, 1.442, 0.4650000000000001, -0.07399999999999995, 0.4670000000000001, 0.9510000000000001, 0.46499999999999986, 0.38900000000000023, 0.45599999999999996, 0.42599999999999993, 1.434, 0.43300000000000005, -0.05300000000000005, 0.46899999999999986], "episode_lengths": [98, 10, 11, 11, 15, 11, 14, 12, 12, 14, 18, 12, 14, 38, 16, 9, 13, 15, 14, 14, 21, 19, 34, 28, 16, 12, 13, 15, 16, 12, 9, 17, 14, 29, 73, 12, 19, 13, 14, 22, 11, 9, 13, 8, 181, 13, 8, 10, 24, 11, 15, 9, 13, 80, 29, 15, 12, 8, 15, 9, 7, 16, 15, 17, 17, 121, 12, 11, 15, 62, 9, 12, 10, 15, 14, 15, 9, 27, 9, 18, 11, 10, 10, 16, 10, 14, 15, 39, 9, 18, 12, 10, 9, 12, 125, 18, 11, 115, 27, 14, 9, 15, 13, 12, 8, 12, 41, 14, 11, 12, 14, 15, 114, 13, 15, 13, 54, 61, 36, 13, 20, 18, 8, 11, 23, 13, 10, 300, 16, 8, 56, 16, 12, 24, 10, 11, 8, 13, 35, 16, 15, 10, 15, 8, 12, 13, 11, 15, 13, 11, 12, 15, 10, 15, 13, 38, 8, 14, 11, 156, 10, 17, 12, 14, 32, 13, 14, 9, 19, 11, 20, 10, 16, 11, 32, 14, 24, 21, 21, 17, 9], "policy_red_0_reward": [-1.067, 1.47, 0.967, 1.467, 1.455, 0.967, 0.958, 1.464, 1.464, 1.458, 0.946, 1.464, 1.458, -0.501, 1.452, 0.973, 1.4609999999999999, 1.455, 1.458, 1.458, -0.5, 1.443, 1.3980000000000001, 1.416, 1.452, 0.964, 1.46, 1.455, 1.452, 1.464, 1.4729999999999999, 1.4489999999999998, 1.4569999999999999, 0.913, 1.279, 1.464, 1.4409999999999998, -0.5, 0.958, 1.434, 1.467, 0.973, 0.961, 0.976, 0.951, 0.961, 0.976, 1.47, 1.428, 1.467, 1.455, 1.4729999999999999, 1.4609999999999999, 1.258, 1.412, 1.455, 1.464, 0.976, 0.955, 0.973, 0.979, 1.451, 1.455, 1.4489999999999998, 1.4489999999999998, -0.503, 1.464, 1.467, 1.455, 1.304, 1.4729999999999999, 1.464, 0.97, 1.455, 0.958, 0.955, 1.4729999999999999, 1.4180000000000001, 1.4729999999999999, 0.946, 1.467, 0.969, 1.47, 1.452, 0.97, 1.458, 1.455, 1.3820000000000001, 1.4729999999999999, 1.446, 0.964, 0.97, 1.4729999999999999, 1.464, 1.121, 1.446, 1.467, -0.502, 1.417, 1.4569999999999999, -1.001, -0.5, 1.4609999999999999, 1.464, 0.976, 1.464, 1.376, 1.4569999999999999, 0.967, 0.964, 1.458, 1.455, 1.156, 0.961, 1.455, 1.4609999999999999, 1.3359999999999999, 1.315, 1.3900000000000001, 1.4609999999999999, 0.94, 1.444, 1.476, 1.467, 1.4300000000000002, 1.4609999999999999, 0.97, 0.492, 1.452, 0.976, -0.5, -0.501, 1.464, 0.9259999999999999, 0.97, 1.467, 1.476, 0.961, 1.395, 1.452, 1.454, 1.4689999999999999, 1.455, 0.976, 1.464, 1.4609999999999999, 1.467, 1.455, 1.4609999999999999, 1.467, 1.464, 1.455, 1.47, 1.455, 0.961, 1.385, 1.476, 1.458, 0.967, 1.0230000000000001, 1.47, 1.4489999999999998, 1.464, 1.458, 1.4020000000000001, -0.5, 1.458, 0.973, 1.443, 1.467, 0.9329999999999999, 1.47, 1.452, 1.467, 1.401, 1.458, 1.427, 1.4369999999999998, 1.4369999999999998, 0.948, 1.4729999999999999], "policy_blue_0_reward": [0.698, -1.0, -1.002, -1.0, -1.002, -1.0, -1.001, -1.002, -1.002, -1.001, -1.004, -1.001, -1.001, 0.88, -1.002, -1.002, -1.003, -1.001, -1.004, -1.003, 0.9329999999999999, -1.004, -1.003, -1.004, -0.002, -1.002, -0.501, -1.005, -1.003, -1.003, -1.0, -1.005, -1.002, -1.004, -1.007, -1.003, -1.0059999999999998, 1.46, -1.003, -1.0039999999999998, -1.001, -1.003, -1.002, -1.0019999999999998, -1.024, -1.001, -1.002, -1.0, -1.003, -1.001, -0.003, -1.001, -0.002, -1.01, -1.004, -1.001, -0.503, -1.0, -1.002, -1.001, -1.001, -1.001, -1.002, -0.001, -1.003, 0.618, -1.0, -1.002, -1.001, -1.006, -1.002, -1.002, -1.0, -1.003, -1.001, -1.0019999999999998, -1.002, -1.004, -1.0, -1.0019999999999998, -1.001, -1.003, -1.001, -0.004, -1.001, 0.0, -1.0019999999999998, -1.006, -1.0, -1.0, -1.001, -1.002, -1.001, -1.001, -0.024000000000000014, -1.0019999999999998, -1.001, 0.642, -1.006, -0.5, 0.973, 0.955, -1.003, -1.002, -1.001, -1.002, -1.003, -1.004, -1.003, -1.001, -1.001, -1.003, -0.517, -1.005, -1.003, -1.001, -1.011, -1.007, -1.007, -1.001, -0.504, -1.007, -1.0, -1.002, -1.001, -1.001, -1.002, 0.46299999999999997, -1.005, -1.003, 1.326, 0.949, -1.001, -1.006, -1.001, -1.001, -1.0, -1.0, -0.503, -1.001, -1.0039999999999998, -1.002, -1.001, -1.001, -1.003, -1.002, -1.0039999999999998, -1.001, -1.002, -1.001, -1.0, -1.005, -1.0, -1.002, -1.002, -1.003, -1.001, -1.003, -1.001, -0.522, -1.001, -0.001, -0.502, -1.004, -0.006, 0.959, -1.002, -1.003, -0.001, -1.0019999999999998, -1.007, -1.003, -0.501, -1.002, -1.0119999999999998, -1.002, -1.001, -0.003, -1.0039999999999998, -1.001, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24465666128795735, "mean_inference_ms": 1.4763934936471073, "mean_action_processing_ms": 0.06302050272951229, "mean_env_wait_ms": 0.0893081037258953, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01901328892997615, "StateBufferConnector_ms": 0.0015093476732791458, "ViewRequirementAgentConnector_ms": 0.03134842077012879}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000, "num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.77318068497489, "num_env_steps_trained_throughput_per_sec": 102.77318068497489, "timesteps_total": 160000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 320000, "timers": {"training_iteration_time_ms": 39041.772, "sample_time_ms": 7640.043, "learn_time_ms": 31384.333, "learn_throughput": 127.452, "synch_weights_time_ms": 16.903}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 160000, "num_agent_steps_sampled": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 4497, "training_iteration": 40, "trial_id": "d67e4_00000", "date": "2023-09-20_22-35-12", "timestamp": 1695263712, "time_this_iter_s": 38.92795991897583, "time_total_s": 1555.9436345100403, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706950>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1555.9436345100403, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 33.12678571428571, "ram_util_percent": 48.78214285714286}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0684931506849315, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8698630136986302, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0547945205479452, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8698630136986302, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0547945205479452, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8698630136986302, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0547945205479452, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1319637431452674, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009677579317819133, "policy_loss": -0.01670082388809533, "vf_loss": 0.008093542259302922, "vf_explained_var": 0.7232552150885264, "kl": 0.007814237208409845, "entropy": 0.5399332036885123, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 38880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "sampler_results": {"episode_reward_max": 1.895, "episode_reward_min": -0.30100000000000005, "episode_reward_mean": 0.4461780821917808, "episode_len_mean": 24.41780821917808, "episode_media": {}, "episodes_this_iter": 146, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.014}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.0699999999999998}, "policy_reward_mean": {"red_0": 1.2220068493150686, "blue_0": -0.7758287671232876}, "custom_metrics": {"red_0/door_open_done_mean": 0.0684931506849315, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8698630136986302, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0547945205479452, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8698630136986302, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0547945205479452, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8698630136986302, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0547945205479452, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46199999999999997, 0.22099999999999986, 0.4650000000000001, -0.02399999999999991, 0.43199999999999994, -0.03300000000000003, 0.44799999999999995, 0.956, -0.030999999999999917, 0.45999999999999996, 0.46099999999999985, 0.952, 0.4670000000000001, 0.45500000000000007, -0.03200000000000003, 0.43999999999999995, 0.45599999999999996, 0.952, 0.9689999999999999, 0.43599999999999994, 0.44899999999999984, 0.1499999999999999, 1.457, 0.41300000000000003, 0.45599999999999996, 0.42599999999999993, 0.45799999999999996, 0.39300000000000024, 0.46499999999999986, -0.041000000000000036, 0.46599999999999997, 1.895, -0.04299999999999993, -0.029999999999999916, 0.43199999999999994, 0.41999999999999993, -0.03600000000000003, -0.025000000000000022, 0.4590000000000001, 0.44199999999999995, 0.43399999999999994, 0.46599999999999997, 1.4409999999999998, 0.21799999999999997, 0.46899999999999986, 0.3700000000000001, 0.42900000000000005, 0.45100000000000007, 0.45799999999999996, -0.04700000000000004, 0.44799999999999995, 0.45100000000000007, 0.33299999999999996, 0.34799999999999986, 0.45699999999999985, -0.03700000000000003, 0.4650000000000001, 0.946, 0.4610000000000001, -0.04600000000000004, 1.438, 0.46899999999999986, -0.052000000000000046, 0.42799999999999994, -0.04400000000000004, 0.42799999999999994, 0.4590000000000001, 0.9620000000000002, -0.028000000000000025, 0.1629999999999998, 0.4119999999999999, 0.474, 0.476, -0.11199999999999999, 0.44799999999999995, 0.45299999999999985, -0.028000000000000025, -0.05800000000000005, 0.46799999999999997, 0.45699999999999985, 0.44399999999999995, 0.45499999999999996, 0.44700000000000006, 0.42200000000000015, 1.325, -0.03599999999999992, 0.4630000000000001, -0.30100000000000005, 0.47299999999999986, 0.569, 0.9670000000000001, 0.46199999999999997, -0.03400000000000003, 0.373, 0.4670000000000001, -0.03200000000000003, 0.46099999999999985, 0.46199999999999997, 1.4489999999999998, 0.3919999999999999, 0.46399999999999997, 0.46599999999999997, 0.33299999999999996, -0.050000000000000044, -0.039000000000000035, 0.45599999999999996, 0.45399999999999996, 1.891, -0.038000000000000034, 0.405, 1.401, -0.04500000000000004, 0.42700000000000005, 0.44499999999999984, 1.424, 0.4750000000000001, 0.46899999999999986, 0.4630000000000001, -0.031000000000000028, 0.4630000000000001, -0.02400000000000002, 0.45500000000000007, 0.956, 0.46099999999999985, 0.96, 0.46199999999999997, 0.44999999999999996, 0.42399999999999993, 0.4630000000000001, 0.43500000000000005, 0.46599999999999997, 1.4409999999999998, 0.9750000000000001, 0.45299999999999985, 0.46499999999999986, 0.45999999999999996, 0.31099999999999994, 0.43599999999999994, 0.403, -0.04500000000000004, 0.45699999999999985, 0.45500000000000007, 0.42999999999999994, 0.14400000000000013, 0.4750000000000001, 0.4670000000000001], "episode_lengths": [12, 243, 11, 7, 22, 11, 17, 14, 10, 13, 13, 16, 11, 14, 10, 19, 14, 15, 10, 20, 17, 112, 14, 28, 14, 24, 14, 34, 11, 13, 10, 33, 14, 9, 22, 25, 12, 8, 13, 19, 21, 11, 19, 90, 10, 39, 23, 15, 14, 15, 16, 15, 52, 49, 13, 12, 11, 17, 12, 14, 19, 10, 17, 21, 13, 22, 13, 12, 9, 108, 29, 8, 8, 36, 17, 15, 9, 18, 10, 14, 18, 300, 17, 24, 56, 11, 12, 96, 9, 137, 11, 12, 11, 39, 11, 10, 13, 12, 16, 34, 11, 11, 54, 16, 13, 14, 14, 35, 12, 30, 30, 14, 23, 17, 24, 8, 10, 12, 10, 12, 8, 14, 14, 12, 13, 12, 16, 24, 11, 20, 11, 19, 8, 15, 11, 13, 58, 20, 28, 14, 14, 14, 22, 113, 8, 10], "policy_red_0_reward": [1.464, 0.7519999999999999, 1.467, 0.979, 1.434, 0.967, 1.4489999999999998, 1.458, 0.97, 1.4609999999999999, 1.4609999999999999, 1.452, 1.467, 1.458, 0.97, 1.443, 1.458, 1.455, 1.47, 1.44, 1.4489999999999998, 1.1629999999999998, 1.458, 1.416, 1.458, -0.5, 1.458, 1.3980000000000001, 1.467, 0.96, 1.47, 1.399, -1.0, 0.973, 1.434, 1.423, 0.964, 0.976, 1.4609999999999999, 1.442, 1.4369999999999998, 1.467, 1.443, 1.226, 1.47, 1.3820000000000001, 1.431, 1.454, 1.458, 0.954, 1.451, 1.455, 1.339, 1.351, 1.4609999999999999, 0.964, 1.467, 1.4489999999999998, 1.464, 0.958, 1.442, 1.47, 0.949, 1.435, 0.957, 1.434, 1.4609999999999999, 1.464, 0.973, 1.176, 1.413, -0.5, 1.476, -1.001, -0.5, 1.455, 0.973, 0.946, 1.47, 1.458, 1.446, 0.498, 1.4489999999999998, 1.428, 1.331, 0.967, 1.464, 0.712, 1.4729999999999999, -0.501, 1.467, 1.464, 0.967, 1.3820000000000001, 1.467, 0.97, 1.4609999999999999, 1.464, 1.451, 1.397, 1.467, 1.467, 1.337, 0.952, 0.961, 1.458, -0.5, 1.393, 0.964, 1.408, 1.405, 0.958, 1.4300000000000002, 1.448, 1.427, 1.476, 1.47, 1.464, 0.97, 1.464, 0.976, 1.458, 1.458, 1.464, 1.4609999999999999, 1.464, -0.5, 1.427, 1.467, 1.44, 1.467, 1.443, 1.476, 1.454, 1.467, 1.4609999999999999, 1.318, 1.44, 1.408, 0.958, 1.458, 1.458, 1.434, 1.158, 1.476, 1.47], "policy_blue_0_reward": [-1.002, -0.531, -1.0019999999999998, -1.003, -1.002, -1.0, -1.001, -0.502, -1.001, -1.001, -1.0, -0.5, -1.0, -1.003, -1.002, -1.003, -1.0019999999999998, -0.5029999999999999, -0.501, -1.004, -1.0, -1.013, -0.001, -1.003, -1.002, 0.9259999999999999, -1.0, -1.005, -1.002, -1.001, -1.004, 0.496, 0.957, -1.003, -1.002, -1.003, -1.0, -1.001, -1.002, -1.0, -1.003, -1.001, -0.002, -1.008, -1.001, -1.012, -1.002, -1.003, -1.0, -1.001, -1.003, -1.0039999999999998, -1.006, -1.003, -1.004, -1.001, -1.0019999999999998, -0.503, -1.003, -1.004, -0.004, -1.001, -1.001, -1.007, -1.001, -1.006, -1.002, -0.5019999999999999, -1.001, -1.013, -1.001, 0.974, -1.0, 0.889, 0.948, -1.002, -1.001, -1.004, -1.002, -1.001, -1.002, -0.04300000000000003, -1.002, -1.0059999999999998, -0.006, -1.003, -1.001, -1.013, -1.0, 1.0699999999999998, -0.5, -1.002, -1.001, -1.009, -1.0, -1.002, -1.0, -1.002, -0.002, -1.005, -1.003, -1.001, -1.004, -1.002, -1.0, -1.002, 0.954, 0.498, -1.002, -1.003, -0.004, -1.003, -1.003, -1.003, -0.003, -1.001, -1.001, -1.001, -1.001, -1.001, -1.0, -1.003, -0.5019999999999999, -1.003, -0.501, -1.002, 0.95, -1.003, -1.0039999999999998, -1.005, -1.001, -0.002, -0.501, -1.001, -1.002, -1.001, -1.007, -1.004, -1.005, -1.003, -1.001, -1.003, -1.004, -1.014, -1.001, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2447806526325031, "mean_inference_ms": 1.4757931530108959, "mean_action_processing_ms": 0.06296694179498184, "mean_env_wait_ms": 0.08924143446664665, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019651243131454676, "StateBufferConnector_ms": 0.0014870134118485125, "ViewRequirementAgentConnector_ms": 0.031357105464151463}}, "episode_reward_max": 1.895, "episode_reward_min": -0.30100000000000005, "episode_reward_mean": 0.4461780821917808, "episode_len_mean": 24.41780821917808, "episodes_this_iter": 146, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.014}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.0699999999999998}, "policy_reward_mean": {"red_0": 1.2220068493150686, "blue_0": -0.7758287671232876}, "hist_stats": {"episode_reward": [0.46199999999999997, 0.22099999999999986, 0.4650000000000001, -0.02399999999999991, 0.43199999999999994, -0.03300000000000003, 0.44799999999999995, 0.956, -0.030999999999999917, 0.45999999999999996, 0.46099999999999985, 0.952, 0.4670000000000001, 0.45500000000000007, -0.03200000000000003, 0.43999999999999995, 0.45599999999999996, 0.952, 0.9689999999999999, 0.43599999999999994, 0.44899999999999984, 0.1499999999999999, 1.457, 0.41300000000000003, 0.45599999999999996, 0.42599999999999993, 0.45799999999999996, 0.39300000000000024, 0.46499999999999986, -0.041000000000000036, 0.46599999999999997, 1.895, -0.04299999999999993, -0.029999999999999916, 0.43199999999999994, 0.41999999999999993, -0.03600000000000003, -0.025000000000000022, 0.4590000000000001, 0.44199999999999995, 0.43399999999999994, 0.46599999999999997, 1.4409999999999998, 0.21799999999999997, 0.46899999999999986, 0.3700000000000001, 0.42900000000000005, 0.45100000000000007, 0.45799999999999996, -0.04700000000000004, 0.44799999999999995, 0.45100000000000007, 0.33299999999999996, 0.34799999999999986, 0.45699999999999985, -0.03700000000000003, 0.4650000000000001, 0.946, 0.4610000000000001, -0.04600000000000004, 1.438, 0.46899999999999986, -0.052000000000000046, 0.42799999999999994, -0.04400000000000004, 0.42799999999999994, 0.4590000000000001, 0.9620000000000002, -0.028000000000000025, 0.1629999999999998, 0.4119999999999999, 0.474, 0.476, -0.11199999999999999, 0.44799999999999995, 0.45299999999999985, -0.028000000000000025, -0.05800000000000005, 0.46799999999999997, 0.45699999999999985, 0.44399999999999995, 0.45499999999999996, 0.44700000000000006, 0.42200000000000015, 1.325, -0.03599999999999992, 0.4630000000000001, -0.30100000000000005, 0.47299999999999986, 0.569, 0.9670000000000001, 0.46199999999999997, -0.03400000000000003, 0.373, 0.4670000000000001, -0.03200000000000003, 0.46099999999999985, 0.46199999999999997, 1.4489999999999998, 0.3919999999999999, 0.46399999999999997, 0.46599999999999997, 0.33299999999999996, -0.050000000000000044, -0.039000000000000035, 0.45599999999999996, 0.45399999999999996, 1.891, -0.038000000000000034, 0.405, 1.401, -0.04500000000000004, 0.42700000000000005, 0.44499999999999984, 1.424, 0.4750000000000001, 0.46899999999999986, 0.4630000000000001, -0.031000000000000028, 0.4630000000000001, -0.02400000000000002, 0.45500000000000007, 0.956, 0.46099999999999985, 0.96, 0.46199999999999997, 0.44999999999999996, 0.42399999999999993, 0.4630000000000001, 0.43500000000000005, 0.46599999999999997, 1.4409999999999998, 0.9750000000000001, 0.45299999999999985, 0.46499999999999986, 0.45999999999999996, 0.31099999999999994, 0.43599999999999994, 0.403, -0.04500000000000004, 0.45699999999999985, 0.45500000000000007, 0.42999999999999994, 0.14400000000000013, 0.4750000000000001, 0.4670000000000001], "episode_lengths": [12, 243, 11, 7, 22, 11, 17, 14, 10, 13, 13, 16, 11, 14, 10, 19, 14, 15, 10, 20, 17, 112, 14, 28, 14, 24, 14, 34, 11, 13, 10, 33, 14, 9, 22, 25, 12, 8, 13, 19, 21, 11, 19, 90, 10, 39, 23, 15, 14, 15, 16, 15, 52, 49, 13, 12, 11, 17, 12, 14, 19, 10, 17, 21, 13, 22, 13, 12, 9, 108, 29, 8, 8, 36, 17, 15, 9, 18, 10, 14, 18, 300, 17, 24, 56, 11, 12, 96, 9, 137, 11, 12, 11, 39, 11, 10, 13, 12, 16, 34, 11, 11, 54, 16, 13, 14, 14, 35, 12, 30, 30, 14, 23, 17, 24, 8, 10, 12, 10, 12, 8, 14, 14, 12, 13, 12, 16, 24, 11, 20, 11, 19, 8, 15, 11, 13, 58, 20, 28, 14, 14, 14, 22, 113, 8, 10], "policy_red_0_reward": [1.464, 0.7519999999999999, 1.467, 0.979, 1.434, 0.967, 1.4489999999999998, 1.458, 0.97, 1.4609999999999999, 1.4609999999999999, 1.452, 1.467, 1.458, 0.97, 1.443, 1.458, 1.455, 1.47, 1.44, 1.4489999999999998, 1.1629999999999998, 1.458, 1.416, 1.458, -0.5, 1.458, 1.3980000000000001, 1.467, 0.96, 1.47, 1.399, -1.0, 0.973, 1.434, 1.423, 0.964, 0.976, 1.4609999999999999, 1.442, 1.4369999999999998, 1.467, 1.443, 1.226, 1.47, 1.3820000000000001, 1.431, 1.454, 1.458, 0.954, 1.451, 1.455, 1.339, 1.351, 1.4609999999999999, 0.964, 1.467, 1.4489999999999998, 1.464, 0.958, 1.442, 1.47, 0.949, 1.435, 0.957, 1.434, 1.4609999999999999, 1.464, 0.973, 1.176, 1.413, -0.5, 1.476, -1.001, -0.5, 1.455, 0.973, 0.946, 1.47, 1.458, 1.446, 0.498, 1.4489999999999998, 1.428, 1.331, 0.967, 1.464, 0.712, 1.4729999999999999, -0.501, 1.467, 1.464, 0.967, 1.3820000000000001, 1.467, 0.97, 1.4609999999999999, 1.464, 1.451, 1.397, 1.467, 1.467, 1.337, 0.952, 0.961, 1.458, -0.5, 1.393, 0.964, 1.408, 1.405, 0.958, 1.4300000000000002, 1.448, 1.427, 1.476, 1.47, 1.464, 0.97, 1.464, 0.976, 1.458, 1.458, 1.464, 1.4609999999999999, 1.464, -0.5, 1.427, 1.467, 1.44, 1.467, 1.443, 1.476, 1.454, 1.467, 1.4609999999999999, 1.318, 1.44, 1.408, 0.958, 1.458, 1.458, 1.434, 1.158, 1.476, 1.47], "policy_blue_0_reward": [-1.002, -0.531, -1.0019999999999998, -1.003, -1.002, -1.0, -1.001, -0.502, -1.001, -1.001, -1.0, -0.5, -1.0, -1.003, -1.002, -1.003, -1.0019999999999998, -0.5029999999999999, -0.501, -1.004, -1.0, -1.013, -0.001, -1.003, -1.002, 0.9259999999999999, -1.0, -1.005, -1.002, -1.001, -1.004, 0.496, 0.957, -1.003, -1.002, -1.003, -1.0, -1.001, -1.002, -1.0, -1.003, -1.001, -0.002, -1.008, -1.001, -1.012, -1.002, -1.003, -1.0, -1.001, -1.003, -1.0039999999999998, -1.006, -1.003, -1.004, -1.001, -1.0019999999999998, -0.503, -1.003, -1.004, -0.004, -1.001, -1.001, -1.007, -1.001, -1.006, -1.002, -0.5019999999999999, -1.001, -1.013, -1.001, 0.974, -1.0, 0.889, 0.948, -1.002, -1.001, -1.004, -1.002, -1.001, -1.002, -0.04300000000000003, -1.002, -1.0059999999999998, -0.006, -1.003, -1.001, -1.013, -1.0, 1.0699999999999998, -0.5, -1.002, -1.001, -1.009, -1.0, -1.002, -1.0, -1.002, -0.002, -1.005, -1.003, -1.001, -1.004, -1.002, -1.0, -1.002, 0.954, 0.498, -1.002, -1.003, -0.004, -1.003, -1.003, -1.003, -0.003, -1.001, -1.001, -1.001, -1.001, -1.001, -1.0, -1.003, -0.5019999999999999, -1.003, -0.501, -1.002, 0.95, -1.003, -1.0039999999999998, -1.005, -1.001, -0.002, -0.501, -1.001, -1.002, -1.001, -1.007, -1.004, -1.005, -1.003, -1.001, -1.003, -1.004, -1.014, -1.001, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2447806526325031, "mean_inference_ms": 1.4757931530108959, "mean_action_processing_ms": 0.06296694179498184, "mean_env_wait_ms": 0.08924143446664665, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019651243131454676, "StateBufferConnector_ms": 0.0014870134118485125, "ViewRequirementAgentConnector_ms": 0.031357105464151463}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000, "num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.76985354838168, "num_env_steps_trained_throughput_per_sec": 102.76985354838168, "timesteps_total": 164000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 328000, "timers": {"training_iteration_time_ms": 39005.512, "sample_time_ms": 7613.196, "learn_time_ms": 31374.9, "learn_throughput": 127.49, "synch_weights_time_ms": 16.922}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 164000, "num_agent_steps_sampled": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 4643, "training_iteration": 41, "trial_id": "d67e4_00000", "date": "2023-09-20_22-35-51", "timestamp": 1695263751, "time_this_iter_s": 38.9281280040741, "time_total_s": 1594.8717625141144, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4707eb0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1594.8717625141144, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 33.50892857142857, "ram_util_percent": 48.82142857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.03896103896103896, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9285714285714286, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.032467532467532464, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9285714285714286, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.032467532467532464, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9285714285714286, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.032467532467532464, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.951558322024842, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007415557673569614, "policy_loss": -0.013390573522823008, "vf_loss": 0.006613409672718262, "vf_explained_var": 0.7672828466941913, "kl": 0.007034946170086497, "entropy": 0.4974145337318381, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 39840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "sampler_results": {"episode_reward_max": 1.891, "episode_reward_min": -0.137, "episode_reward_mean": 0.4073701298701299, "episode_len_mean": 26.253246753246753, "episode_media": {}, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.03}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.975}, "policy_reward_mean": {"red_0": 1.2670129870129871, "blue_0": -0.859642857142857}, "custom_metrics": {"red_0/door_open_done_mean": 0.03896103896103896, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9285714285714286, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.032467532467532464, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9285714285714286, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.032467532467532464, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9285714285714286, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.032467532467532464, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4620000000000002, 0.4660000000000002, 0.399, 1.891, 0.21399999999999997, 0.823, 0.4590000000000001, 0.4540000000000002, 0.41500000000000004, -0.04300000000000004, 0.42700000000000005, 0.47299999999999986, 0.4690000000000001, -0.03799999999999992, 0.45599999999999996, 0.4650000000000001, 0.45799999999999996, -0.03200000000000003, 1.4489999999999998, 0.46899999999999986, 0.46599999999999997, -0.041000000000000036, 0.45999999999999996, 0.42700000000000005, -0.05500000000000005, 0.44399999999999995, 0.46499999999999986, 0.46399999999999997, 0.45199999999999996, -0.03500000000000003, 0.44099999999999984, 0.46799999999999997, 0.45100000000000007, 0.44099999999999984, 0.43399999999999994, 0.45999999999999996, -0.05300000000000005, 0.46799999999999997, 0.45100000000000007, 0.4630000000000001, 0.45699999999999985, -0.03600000000000003, 0.39800000000000013, 0.256, 0.4630000000000001, 0.956, 0.31299999999999994, 0.2530000000000001, 0.45999999999999996, 0.45399999999999996, 0.46799999999999997, 0.4670000000000001, 0.44399999999999995, 0.381, 0.43800000000000017, 0.40000000000000013, 0.42200000000000015, 0.45799999999999996, 0.30400000000000005, 0.4670000000000001, 0.45999999999999996, 0.41400000000000015, 0.46599999999999997, 0.9259999999999999, 0.5819999999999999, 0.43500000000000005, 0.41100000000000003, 0.476, -0.04300000000000004, 0.349, 0.46099999999999985, 0.46799999999999997, -0.027000000000000024, 0.43299999999999983, 1.43, 0.44099999999999984, 0.46399999999999997, 0.9649999999999999, 0.43799999999999994, 0.45599999999999996, 0.44300000000000006, 0.46399999999999997, -0.09499999999999997, 0.45100000000000007, -0.03200000000000003, 1.4409999999999998, 0.43000000000000016, 0.4590000000000001, 1.4609999999999999, -0.137, 0.44899999999999984, -0.025000000000000022, -0.02400000000000002, 0.4620000000000002, -0.09299999999999997, 0.46399999999999997, 0.3919999999999999, -0.026999999999999913, 0.45199999999999996, 0.44899999999999984, 0.45999999999999996, 0.4119999999999999, 0.877, 0.44700000000000006, 0.4670000000000001, -0.07799999999999996, 0.475, -0.039000000000000035, -0.04800000000000004, 0.45500000000000007, -0.030000000000000027, 0.5950000000000002, 0.44999999999999996, 0.42600000000000016, 0.47, -0.04800000000000004, 0.4660000000000002, 0.244, 0.42999999999999994, 0.46499999999999986, -0.04400000000000004, 0.44099999999999984, 0.43699999999999983, 0.45999999999999996, 0.44700000000000006, 0.46799999999999997, 0.4670000000000001, 0.05499999999999994, -0.02200000000000002, 0.4610000000000001, 0.44300000000000006, 0.4590000000000001, -0.04300000000000004, 0.46499999999999986, 0.45199999999999996, 0.9259999999999999, 0.4630000000000001, 0.3740000000000001, -0.02299999999999991, 0.9609999999999999, 0.46599999999999997, -0.025000000000000022, -0.061000000000000054, 0.4670000000000001, 1.435, 0.9670000000000001, 0.4620000000000002, 0.4650000000000001, -0.04200000000000004, -0.03600000000000003, 0.44200000000000017, 0.46899999999999986, -0.09100000000000008, 0.45500000000000007], "episode_lengths": [12, 11, 33, 34, 90, 56, 13, 14, 27, 14, 23, 9, 10, 11, 14, 11, 13, 10, 17, 10, 11, 13, 13, 23, 17, 18, 11, 12, 15, 11, 18, 10, 15, 18, 21, 13, 17, 10, 16, 12, 14, 12, 31, 76, 12, 14, 60, 79, 13, 14, 10, 10, 18, 38, 20, 32, 25, 13, 62, 11, 13, 28, 11, 24, 131, 20, 29, 8, 13, 205, 12, 10, 8, 21, 22, 19, 12, 11, 20, 14, 18, 12, 30, 16, 10, 19, 23, 13, 13, 202, 15, 8, 8, 12, 29, 11, 35, 8, 14, 16, 12, 28, 39, 16, 11, 25, 8, 13, 15, 14, 10, 127, 16, 23, 10, 15, 10, 81, 21, 11, 14, 19, 19, 13, 17, 10, 11, 300, 7, 12, 19, 13, 14, 11, 15, 24, 12, 200, 7, 13, 11, 8, 19, 10, 21, 11, 12, 11, 13, 10, 19, 10, 185, 15], "policy_red_0_reward": [1.464, 1.467, -0.5, 1.395, 1.2269999999999999, 1.331, 1.4609999999999999, 1.4569999999999999, 1.4180000000000001, 0.958, 1.429, 1.4729999999999999, 1.47, -1.003, 1.458, 1.467, 1.4609999999999999, 0.97, 1.4489999999999998, 1.47, 1.467, 0.961, 1.4609999999999999, 1.4300000000000002, 0.949, 1.446, 1.467, 1.464, 1.455, 0.967, 1.446, 1.47, 1.454, 1.443, 1.4369999999999998, 1.4609999999999999, 0.948, 1.47, 1.452, 1.464, 1.458, 0.964, 1.403, 1.267, 1.464, 1.458, 1.319, 1.262, 1.4609999999999999, 1.456, 1.47, 1.47, 1.446, 1.385, 1.44, 1.404, 1.425, 1.4609999999999999, 1.314, 1.467, 1.4609999999999999, 1.416, 1.467, 1.428, 1.101, 1.438, 1.413, 1.476, 0.961, 0.874, 1.464, 1.47, 0.975, 1.435, 1.434, 1.443, 1.464, 1.467, 1.439, 1.458, 1.446, 1.464, 0.91, 1.452, 0.97, 1.443, 1.431, 1.4609999999999999, 1.4609999999999999, -0.51, 1.455, 0.976, 0.976, 1.464, -1.001, 1.467, 1.395, 0.976, 1.456, 1.452, 1.464, 1.415, 1.381, 1.452, 1.467, 0.925, -0.5, 0.961, 0.955, 1.458, 0.97, 1.1139999999999999, 1.452, 1.431, 1.47, 0.955, 1.47, 1.256, 1.4329999999999998, 1.467, 0.958, 1.443, 1.4409999999999998, 1.4609999999999999, 1.4489999999999998, 1.47, 1.467, 0.596, 0.979, 1.464, 1.443, 1.4609999999999999, 0.958, 1.467, 1.455, 1.428, 1.464, 0.899, 0.979, 1.4609999999999999, 1.467, 0.976, 0.942, 1.47, 1.4369999999999998, 1.467, 1.464, 1.467, 0.961, 0.967, 1.443, 1.47, 0.939, 1.455], "policy_blue_0_reward": [-1.0019999999999998, -1.001, 0.899, 0.496, -1.013, -0.508, -1.002, -1.003, -1.003, -1.001, -1.002, -1.0, -1.001, 0.965, -1.002, -1.0019999999999998, -1.003, -1.002, 0.0, -1.001, -1.001, -1.002, -1.001, -1.003, -1.004, -1.002, -1.002, -1.0, -1.003, -1.002, -1.005, -1.002, -1.003, -1.002, -1.003, -1.001, -1.001, -1.002, -1.001, -1.001, -1.001, -1.0, -1.005, -1.011, -1.001, -0.502, -1.006, -1.009, -1.001, -1.002, -1.0019999999999998, -1.003, -1.002, -1.004, -1.0019999999999998, -1.0039999999999998, -1.003, -1.003, -1.01, -1.0, -1.001, -1.002, -1.001, -0.502, -0.519, -1.003, -1.002, -1.0, -1.004, -0.525, -1.003, -1.0019999999999998, -1.002, -1.002, -0.004, -1.002, -1.0, -0.502, -1.001, -1.002, -1.003, -1.0, -1.005, -1.001, -1.002, -0.002, -1.001, -1.002, 0.0, 0.373, -1.006, -1.001, -1.0, -1.0019999999999998, 0.908, -1.003, -1.003, -1.003, -1.004, -1.003, -1.004, -1.003, -0.504, -1.005, -1.0, -1.003, 0.975, -1.0, -1.003, -1.003, -1.0, -0.5189999999999999, -1.002, -1.005, -1.0, -1.003, -1.0039999999999998, -1.012, -1.003, -1.002, -1.002, -1.002, -1.004, -1.001, -1.002, -1.0019999999999998, -1.0, -0.541, -1.001, -1.003, -1.0, -1.002, -1.001, -1.002, -1.003, -0.502, -1.001, -0.5249999999999999, -1.0019999999999998, -0.5, -1.001, -1.001, -1.003, -1.003, -0.002, -0.5, -1.0019999999999998, -1.0019999999999998, -1.003, -1.003, -1.001, -1.001, -1.03, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24475638827945545, "mean_inference_ms": 1.4768084971877484, "mean_action_processing_ms": 0.06300721694905961, "mean_env_wait_ms": 0.08923485323798817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01972201582673308, "StateBufferConnector_ms": 0.0014859360533875305, "ViewRequirementAgentConnector_ms": 0.03159301621573312}}, "episode_reward_max": 1.891, "episode_reward_min": -0.137, "episode_reward_mean": 0.4073701298701299, "episode_len_mean": 26.253246753246753, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.03}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.975}, "policy_reward_mean": {"red_0": 1.2670129870129871, "blue_0": -0.859642857142857}, "hist_stats": {"episode_reward": [0.4620000000000002, 0.4660000000000002, 0.399, 1.891, 0.21399999999999997, 0.823, 0.4590000000000001, 0.4540000000000002, 0.41500000000000004, -0.04300000000000004, 0.42700000000000005, 0.47299999999999986, 0.4690000000000001, -0.03799999999999992, 0.45599999999999996, 0.4650000000000001, 0.45799999999999996, -0.03200000000000003, 1.4489999999999998, 0.46899999999999986, 0.46599999999999997, -0.041000000000000036, 0.45999999999999996, 0.42700000000000005, -0.05500000000000005, 0.44399999999999995, 0.46499999999999986, 0.46399999999999997, 0.45199999999999996, -0.03500000000000003, 0.44099999999999984, 0.46799999999999997, 0.45100000000000007, 0.44099999999999984, 0.43399999999999994, 0.45999999999999996, -0.05300000000000005, 0.46799999999999997, 0.45100000000000007, 0.4630000000000001, 0.45699999999999985, -0.03600000000000003, 0.39800000000000013, 0.256, 0.4630000000000001, 0.956, 0.31299999999999994, 0.2530000000000001, 0.45999999999999996, 0.45399999999999996, 0.46799999999999997, 0.4670000000000001, 0.44399999999999995, 0.381, 0.43800000000000017, 0.40000000000000013, 0.42200000000000015, 0.45799999999999996, 0.30400000000000005, 0.4670000000000001, 0.45999999999999996, 0.41400000000000015, 0.46599999999999997, 0.9259999999999999, 0.5819999999999999, 0.43500000000000005, 0.41100000000000003, 0.476, -0.04300000000000004, 0.349, 0.46099999999999985, 0.46799999999999997, -0.027000000000000024, 0.43299999999999983, 1.43, 0.44099999999999984, 0.46399999999999997, 0.9649999999999999, 0.43799999999999994, 0.45599999999999996, 0.44300000000000006, 0.46399999999999997, -0.09499999999999997, 0.45100000000000007, -0.03200000000000003, 1.4409999999999998, 0.43000000000000016, 0.4590000000000001, 1.4609999999999999, -0.137, 0.44899999999999984, -0.025000000000000022, -0.02400000000000002, 0.4620000000000002, -0.09299999999999997, 0.46399999999999997, 0.3919999999999999, -0.026999999999999913, 0.45199999999999996, 0.44899999999999984, 0.45999999999999996, 0.4119999999999999, 0.877, 0.44700000000000006, 0.4670000000000001, -0.07799999999999996, 0.475, -0.039000000000000035, -0.04800000000000004, 0.45500000000000007, -0.030000000000000027, 0.5950000000000002, 0.44999999999999996, 0.42600000000000016, 0.47, -0.04800000000000004, 0.4660000000000002, 0.244, 0.42999999999999994, 0.46499999999999986, -0.04400000000000004, 0.44099999999999984, 0.43699999999999983, 0.45999999999999996, 0.44700000000000006, 0.46799999999999997, 0.4670000000000001, 0.05499999999999994, -0.02200000000000002, 0.4610000000000001, 0.44300000000000006, 0.4590000000000001, -0.04300000000000004, 0.46499999999999986, 0.45199999999999996, 0.9259999999999999, 0.4630000000000001, 0.3740000000000001, -0.02299999999999991, 0.9609999999999999, 0.46599999999999997, -0.025000000000000022, -0.061000000000000054, 0.4670000000000001, 1.435, 0.9670000000000001, 0.4620000000000002, 0.4650000000000001, -0.04200000000000004, -0.03600000000000003, 0.44200000000000017, 0.46899999999999986, -0.09100000000000008, 0.45500000000000007], "episode_lengths": [12, 11, 33, 34, 90, 56, 13, 14, 27, 14, 23, 9, 10, 11, 14, 11, 13, 10, 17, 10, 11, 13, 13, 23, 17, 18, 11, 12, 15, 11, 18, 10, 15, 18, 21, 13, 17, 10, 16, 12, 14, 12, 31, 76, 12, 14, 60, 79, 13, 14, 10, 10, 18, 38, 20, 32, 25, 13, 62, 11, 13, 28, 11, 24, 131, 20, 29, 8, 13, 205, 12, 10, 8, 21, 22, 19, 12, 11, 20, 14, 18, 12, 30, 16, 10, 19, 23, 13, 13, 202, 15, 8, 8, 12, 29, 11, 35, 8, 14, 16, 12, 28, 39, 16, 11, 25, 8, 13, 15, 14, 10, 127, 16, 23, 10, 15, 10, 81, 21, 11, 14, 19, 19, 13, 17, 10, 11, 300, 7, 12, 19, 13, 14, 11, 15, 24, 12, 200, 7, 13, 11, 8, 19, 10, 21, 11, 12, 11, 13, 10, 19, 10, 185, 15], "policy_red_0_reward": [1.464, 1.467, -0.5, 1.395, 1.2269999999999999, 1.331, 1.4609999999999999, 1.4569999999999999, 1.4180000000000001, 0.958, 1.429, 1.4729999999999999, 1.47, -1.003, 1.458, 1.467, 1.4609999999999999, 0.97, 1.4489999999999998, 1.47, 1.467, 0.961, 1.4609999999999999, 1.4300000000000002, 0.949, 1.446, 1.467, 1.464, 1.455, 0.967, 1.446, 1.47, 1.454, 1.443, 1.4369999999999998, 1.4609999999999999, 0.948, 1.47, 1.452, 1.464, 1.458, 0.964, 1.403, 1.267, 1.464, 1.458, 1.319, 1.262, 1.4609999999999999, 1.456, 1.47, 1.47, 1.446, 1.385, 1.44, 1.404, 1.425, 1.4609999999999999, 1.314, 1.467, 1.4609999999999999, 1.416, 1.467, 1.428, 1.101, 1.438, 1.413, 1.476, 0.961, 0.874, 1.464, 1.47, 0.975, 1.435, 1.434, 1.443, 1.464, 1.467, 1.439, 1.458, 1.446, 1.464, 0.91, 1.452, 0.97, 1.443, 1.431, 1.4609999999999999, 1.4609999999999999, -0.51, 1.455, 0.976, 0.976, 1.464, -1.001, 1.467, 1.395, 0.976, 1.456, 1.452, 1.464, 1.415, 1.381, 1.452, 1.467, 0.925, -0.5, 0.961, 0.955, 1.458, 0.97, 1.1139999999999999, 1.452, 1.431, 1.47, 0.955, 1.47, 1.256, 1.4329999999999998, 1.467, 0.958, 1.443, 1.4409999999999998, 1.4609999999999999, 1.4489999999999998, 1.47, 1.467, 0.596, 0.979, 1.464, 1.443, 1.4609999999999999, 0.958, 1.467, 1.455, 1.428, 1.464, 0.899, 0.979, 1.4609999999999999, 1.467, 0.976, 0.942, 1.47, 1.4369999999999998, 1.467, 1.464, 1.467, 0.961, 0.967, 1.443, 1.47, 0.939, 1.455], "policy_blue_0_reward": [-1.0019999999999998, -1.001, 0.899, 0.496, -1.013, -0.508, -1.002, -1.003, -1.003, -1.001, -1.002, -1.0, -1.001, 0.965, -1.002, -1.0019999999999998, -1.003, -1.002, 0.0, -1.001, -1.001, -1.002, -1.001, -1.003, -1.004, -1.002, -1.002, -1.0, -1.003, -1.002, -1.005, -1.002, -1.003, -1.002, -1.003, -1.001, -1.001, -1.002, -1.001, -1.001, -1.001, -1.0, -1.005, -1.011, -1.001, -0.502, -1.006, -1.009, -1.001, -1.002, -1.0019999999999998, -1.003, -1.002, -1.004, -1.0019999999999998, -1.0039999999999998, -1.003, -1.003, -1.01, -1.0, -1.001, -1.002, -1.001, -0.502, -0.519, -1.003, -1.002, -1.0, -1.004, -0.525, -1.003, -1.0019999999999998, -1.002, -1.002, -0.004, -1.002, -1.0, -0.502, -1.001, -1.002, -1.003, -1.0, -1.005, -1.001, -1.002, -0.002, -1.001, -1.002, 0.0, 0.373, -1.006, -1.001, -1.0, -1.0019999999999998, 0.908, -1.003, -1.003, -1.003, -1.004, -1.003, -1.004, -1.003, -0.504, -1.005, -1.0, -1.003, 0.975, -1.0, -1.003, -1.003, -1.0, -0.5189999999999999, -1.002, -1.005, -1.0, -1.003, -1.0039999999999998, -1.012, -1.003, -1.002, -1.002, -1.002, -1.004, -1.001, -1.002, -1.0019999999999998, -1.0, -0.541, -1.001, -1.003, -1.0, -1.002, -1.001, -1.002, -1.003, -0.502, -1.001, -0.5249999999999999, -1.0019999999999998, -0.5, -1.001, -1.001, -1.003, -1.003, -0.002, -0.5, -1.0019999999999998, -1.0019999999999998, -1.003, -1.003, -1.001, -1.001, -1.03, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24475638827945545, "mean_inference_ms": 1.4768084971877484, "mean_action_processing_ms": 0.06300721694905961, "mean_env_wait_ms": 0.08923485323798817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01972201582673308, "StateBufferConnector_ms": 0.0014859360533875305, "ViewRequirementAgentConnector_ms": 0.03159301621573312}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000, "num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.76943617634944, "num_env_steps_trained_throughput_per_sec": 102.76943617634944, "timesteps_total": 168000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 336000, "timers": {"training_iteration_time_ms": 38998.645, "sample_time_ms": 7601.356, "learn_time_ms": 31379.81, "learn_throughput": 127.47, "synch_weights_time_ms": 16.984}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 168000, "num_agent_steps_sampled": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 4797, "training_iteration": 42, "trial_id": "d67e4_00000", "date": "2023-09-20_22-36-30", "timestamp": 1695263790, "time_this_iter_s": 38.92857503890991, "time_total_s": 1633.8003375530243, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706830>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1633.8003375530243, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 34.5875, "ram_util_percent": 48.7875}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.92, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.92, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.92, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.93405160450687, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.013357454261131352, "policy_loss": -0.01925861596003718, "vf_loss": 0.004207218252607466, "vf_explained_var": 0.8062994659567873, "kl": 0.009609865159043432, "entropy": 0.5268869443796576, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 40800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "sampler_results": {"episode_reward_max": 1.3920000000000001, "episode_reward_min": -0.244, "episode_reward_mean": 0.38223000000000007, "episode_len_mean": 37.55, "episode_media": {}, "episodes_this_iter": 97, "policy_reward_min": {"red_0": -0.501, "blue_0": -1.03}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.968}, "policy_reward_mean": {"red_0": 1.23573, "blue_0": -0.8535}, "custom_metrics": {"red_0/door_open_done_mean": 0.01, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.92, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.92, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.92, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46899999999999986, -0.09100000000000008, 0.45500000000000007, -0.08299999999999996, 0.45599999999999996, 0.235, 0.42200000000000015, 0.4750000000000001, -0.02100000000000002, 0.45799999999999996, 0.46199999999999997, 0.45100000000000007, 0.46099999999999985, 0.955, 0.45699999999999985, -0.05800000000000005, 0.45299999999999985, 0.44499999999999984, 0.4700000000000002, 0.46799999999999997, -0.052000000000000046, -0.03400000000000003, 0.4690000000000001, 0.373, 0.956, 0.44899999999999995, 0.45100000000000007, 0.45299999999999985, 0.45699999999999985, 0.46399999999999997, -0.050000000000000044, 0.44700000000000006, -0.11399999999999999, 0.46399999999999997, 0.9239999999999999, 0.46199999999999997, 0.46099999999999985, 0.44700000000000006, 0.47299999999999986, 0.46799999999999997, -0.04899999999999993, 0.24299999999999988, -0.02400000000000002, 0.4710000000000001, 0.46799999999999997, 0.4690000000000001, 0.46399999999999997, 0.4119999999999999, 0.45699999999999985, -0.04700000000000004, -0.03600000000000003, 0.8940000000000001, 0.47, 0.45999999999999996, 0.764, 0.42600000000000016, -0.027000000000000024, 0.4630000000000001, 0.45299999999999985, 0.45399999999999996, 0.45199999999999996, 0.45500000000000007, 0.45300000000000007, 0.45299999999999985, 0.46599999999999997, 0.44199999999999995, -0.04400000000000004, 0.45100000000000007, 0.46899999999999986, -0.03400000000000003, 0.28500000000000014, 0.44300000000000006, 0.45399999999999996, 0.4650000000000001, 1.3920000000000001, 0.397, 0.45500000000000007, -0.041999999999999926, 0.42999999999999994, 0.4249999999999998, 0.46099999999999985, 0.46099999999999985, 0.43699999999999983, 0.4670000000000001, -0.031000000000000028, -0.244, 0.45599999999999996, 0.4670000000000001, 0.44399999999999995, 0.46799999999999997, -0.06600000000000006, 0.44899999999999984, 0.42300000000000004, 0.4710000000000001, 0.46599999999999997, 0.599, 0.948, 0.46599999999999997, 0.46599999999999997, -0.14400000000000002], "episode_lengths": [10, 185, 15, 185, 14, 82, 25, 8, 7, 13, 12, 16, 12, 300, 14, 18, 15, 18, 9, 10, 17, 10, 9, 41, 14, 300, 15, 15, 14, 12, 16, 17, 35, 11, 24, 12, 12, 17, 8, 10, 15, 83, 8, 9, 10, 10, 11, 28, 14, 14, 12, 33, 10, 13, 76, 22, 9, 12, 15, 15, 15, 14, 15, 174, 11, 19, 14, 15, 10, 11, 69, 18, 15, 11, 33, 33, 14, 13, 22, 24, 13, 12, 19, 10, 10, 77, 14, 10, 300, 10, 22, 15, 23, 9, 11, 125, 300, 11, 11, 207], "policy_red_0_reward": [1.47, 0.939, 1.455, 0.944, 1.4569999999999999, -0.501, 1.424, 1.476, 0.979, 1.4609999999999999, 1.464, 1.452, 1.464, 0.5, 1.458, 0.946, 0.955, 1.446, 1.4729999999999999, -0.5, 0.949, 0.969, 1.4729999999999999, 1.377, 1.458, 0.495, 1.454, 1.455, 1.458, 1.464, 0.952, 1.4489999999999998, 0.892, 1.467, 1.427, 1.464, 1.464, 1.4489999999999998, 1.476, -0.5, 0.952, 1.25, 0.976, 1.4729999999999999, 1.47, 1.47, 1.467, 1.4140000000000001, 1.458, 0.956, 0.964, 1.4, 1.47, 1.4609999999999999, 1.271, 1.432, 0.973, 1.464, 1.455, 1.455, 1.455, 1.4569999999999999, 1.455, 0.974, 1.467, 1.443, 0.958, 1.455, 1.47, 0.967, 1.293, 1.4449999999999998, 1.455, 1.467, 1.4, 1.4, 1.458, 0.961, 1.434, 1.428, 1.4609999999999999, 1.464, 1.443, 1.47, 0.97, 0.769, 1.458, 1.47, 0.495, 1.47, 0.9339999999999999, 1.454, 1.427, 1.4729999999999999, 1.467, 1.115, 0.495, 1.467, 1.467, 0.877], "policy_blue_0_reward": [-1.001, -1.03, -1.0, -1.027, -1.001, 0.736, -1.002, -1.001, -1.0, -1.003, -1.002, -1.001, -1.003, 0.45499999999999996, -1.001, -1.004, -0.502, -1.001, -1.003, 0.968, -1.001, -1.003, -1.0039999999999998, -1.004, -0.502, -0.046000000000000034, -1.003, -1.002, -1.001, -1.0, -1.002, -1.002, -1.006, -1.003, -0.5029999999999999, -1.002, -1.003, -1.002, -1.003, 0.968, -1.001, -1.007, -1.0, -1.0019999999999998, -1.002, -1.001, -1.003, -1.002, -1.001, -1.003, -1.0, -0.506, -1.0, -1.001, -0.507, -1.0059999999999998, -1.0, -1.001, -1.002, -1.001, -1.003, -1.002, -1.0019999999999998, -0.521, -1.001, -1.001, -1.002, -1.0039999999999998, -1.001, -1.001, -1.0079999999999998, -1.002, -1.001, -1.0019999999999998, -0.008, -1.003, -1.003, -1.003, -1.004, -1.003, -1.0, -1.003, -1.006, -1.003, -1.001, -1.013, -1.002, -1.003, -0.05100000000000004, -1.002, -1.0, -1.005, -1.004, -1.002, -1.001, -0.516, 0.45299999999999996, -1.001, -1.001, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24447830494743542, "mean_inference_ms": 1.4747343987713812, "mean_action_processing_ms": 0.06290587554134387, "mean_env_wait_ms": 0.08907798670289054, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019173264503479004, "StateBufferConnector_ms": 0.0014805793762207031, "ViewRequirementAgentConnector_ms": 0.0314023494720459}}, "episode_reward_max": 1.3920000000000001, "episode_reward_min": -0.244, "episode_reward_mean": 0.38223000000000007, "episode_len_mean": 37.55, "episodes_this_iter": 97, "policy_reward_min": {"red_0": -0.501, "blue_0": -1.03}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.968}, "policy_reward_mean": {"red_0": 1.23573, "blue_0": -0.8535}, "hist_stats": {"episode_reward": [0.46899999999999986, -0.09100000000000008, 0.45500000000000007, -0.08299999999999996, 0.45599999999999996, 0.235, 0.42200000000000015, 0.4750000000000001, -0.02100000000000002, 0.45799999999999996, 0.46199999999999997, 0.45100000000000007, 0.46099999999999985, 0.955, 0.45699999999999985, -0.05800000000000005, 0.45299999999999985, 0.44499999999999984, 0.4700000000000002, 0.46799999999999997, -0.052000000000000046, -0.03400000000000003, 0.4690000000000001, 0.373, 0.956, 0.44899999999999995, 0.45100000000000007, 0.45299999999999985, 0.45699999999999985, 0.46399999999999997, -0.050000000000000044, 0.44700000000000006, -0.11399999999999999, 0.46399999999999997, 0.9239999999999999, 0.46199999999999997, 0.46099999999999985, 0.44700000000000006, 0.47299999999999986, 0.46799999999999997, -0.04899999999999993, 0.24299999999999988, -0.02400000000000002, 0.4710000000000001, 0.46799999999999997, 0.4690000000000001, 0.46399999999999997, 0.4119999999999999, 0.45699999999999985, -0.04700000000000004, -0.03600000000000003, 0.8940000000000001, 0.47, 0.45999999999999996, 0.764, 0.42600000000000016, -0.027000000000000024, 0.4630000000000001, 0.45299999999999985, 0.45399999999999996, 0.45199999999999996, 0.45500000000000007, 0.45300000000000007, 0.45299999999999985, 0.46599999999999997, 0.44199999999999995, -0.04400000000000004, 0.45100000000000007, 0.46899999999999986, -0.03400000000000003, 0.28500000000000014, 0.44300000000000006, 0.45399999999999996, 0.4650000000000001, 1.3920000000000001, 0.397, 0.45500000000000007, -0.041999999999999926, 0.42999999999999994, 0.4249999999999998, 0.46099999999999985, 0.46099999999999985, 0.43699999999999983, 0.4670000000000001, -0.031000000000000028, -0.244, 0.45599999999999996, 0.4670000000000001, 0.44399999999999995, 0.46799999999999997, -0.06600000000000006, 0.44899999999999984, 0.42300000000000004, 0.4710000000000001, 0.46599999999999997, 0.599, 0.948, 0.46599999999999997, 0.46599999999999997, -0.14400000000000002], "episode_lengths": [10, 185, 15, 185, 14, 82, 25, 8, 7, 13, 12, 16, 12, 300, 14, 18, 15, 18, 9, 10, 17, 10, 9, 41, 14, 300, 15, 15, 14, 12, 16, 17, 35, 11, 24, 12, 12, 17, 8, 10, 15, 83, 8, 9, 10, 10, 11, 28, 14, 14, 12, 33, 10, 13, 76, 22, 9, 12, 15, 15, 15, 14, 15, 174, 11, 19, 14, 15, 10, 11, 69, 18, 15, 11, 33, 33, 14, 13, 22, 24, 13, 12, 19, 10, 10, 77, 14, 10, 300, 10, 22, 15, 23, 9, 11, 125, 300, 11, 11, 207], "policy_red_0_reward": [1.47, 0.939, 1.455, 0.944, 1.4569999999999999, -0.501, 1.424, 1.476, 0.979, 1.4609999999999999, 1.464, 1.452, 1.464, 0.5, 1.458, 0.946, 0.955, 1.446, 1.4729999999999999, -0.5, 0.949, 0.969, 1.4729999999999999, 1.377, 1.458, 0.495, 1.454, 1.455, 1.458, 1.464, 0.952, 1.4489999999999998, 0.892, 1.467, 1.427, 1.464, 1.464, 1.4489999999999998, 1.476, -0.5, 0.952, 1.25, 0.976, 1.4729999999999999, 1.47, 1.47, 1.467, 1.4140000000000001, 1.458, 0.956, 0.964, 1.4, 1.47, 1.4609999999999999, 1.271, 1.432, 0.973, 1.464, 1.455, 1.455, 1.455, 1.4569999999999999, 1.455, 0.974, 1.467, 1.443, 0.958, 1.455, 1.47, 0.967, 1.293, 1.4449999999999998, 1.455, 1.467, 1.4, 1.4, 1.458, 0.961, 1.434, 1.428, 1.4609999999999999, 1.464, 1.443, 1.47, 0.97, 0.769, 1.458, 1.47, 0.495, 1.47, 0.9339999999999999, 1.454, 1.427, 1.4729999999999999, 1.467, 1.115, 0.495, 1.467, 1.467, 0.877], "policy_blue_0_reward": [-1.001, -1.03, -1.0, -1.027, -1.001, 0.736, -1.002, -1.001, -1.0, -1.003, -1.002, -1.001, -1.003, 0.45499999999999996, -1.001, -1.004, -0.502, -1.001, -1.003, 0.968, -1.001, -1.003, -1.0039999999999998, -1.004, -0.502, -0.046000000000000034, -1.003, -1.002, -1.001, -1.0, -1.002, -1.002, -1.006, -1.003, -0.5029999999999999, -1.002, -1.003, -1.002, -1.003, 0.968, -1.001, -1.007, -1.0, -1.0019999999999998, -1.002, -1.001, -1.003, -1.002, -1.001, -1.003, -1.0, -0.506, -1.0, -1.001, -0.507, -1.0059999999999998, -1.0, -1.001, -1.002, -1.001, -1.003, -1.002, -1.0019999999999998, -0.521, -1.001, -1.001, -1.002, -1.0039999999999998, -1.001, -1.001, -1.0079999999999998, -1.002, -1.001, -1.0019999999999998, -0.008, -1.003, -1.003, -1.003, -1.004, -1.003, -1.0, -1.003, -1.006, -1.003, -1.001, -1.013, -1.002, -1.003, -0.05100000000000004, -1.002, -1.0, -1.005, -1.004, -1.002, -1.001, -0.516, 0.45299999999999996, -1.001, -1.001, -1.021]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24447830494743542, "mean_inference_ms": 1.4747343987713812, "mean_action_processing_ms": 0.06290587554134387, "mean_env_wait_ms": 0.08907798670289054, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019173264503479004, "StateBufferConnector_ms": 0.0014805793762207031, "ViewRequirementAgentConnector_ms": 0.0314023494720459}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000, "num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.13048219404796, "num_env_steps_trained_throughput_per_sec": 103.13048219404796, "timesteps_total": 172000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 344000, "timers": {"training_iteration_time_ms": 38990.107, "sample_time_ms": 7589.338, "learn_time_ms": 31383.237, "learn_throughput": 127.457, "synch_weights_time_ms": 17.039}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 172000, "num_agent_steps_sampled": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 4894, "training_iteration": 43, "trial_id": "d67e4_00000", "date": "2023-09-20_22-37-09", "timestamp": 1695263829, "time_this_iter_s": 38.79059410095215, "time_total_s": 1672.5909316539764, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d08a8c0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1672.5909316539764, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 33.91818181818182, "ram_util_percent": 48.889090909090925}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.0364963503649635, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9197080291970803, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.021897810218978103, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9197080291970803, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.021897810218978103, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9197080291970803, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.021897810218978103, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0510535494734845, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009531006436494257, "policy_loss": -0.014831296639264717, "vf_loss": 0.005220602289530992, "vf_explained_var": 0.8296049181371927, "kl": 0.007121242660299269, "entropy": 0.5145689834530155, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 41760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "sampler_results": {"episode_reward_max": 1.752, "episode_reward_min": -0.16100000000000003, "episode_reward_mean": 0.4353284671532846, "episode_len_mean": 32.481751824817515, "episode_media": {}, "episodes_this_iter": 137, "policy_reward_min": {"red_0": -0.501, "blue_0": -1.034}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.966}, "policy_reward_mean": {"red_0": 1.305956204379562, "blue_0": -0.8706277372262774}, "custom_metrics": {"red_0/door_open_done_mean": 0.0364963503649635, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9197080291970803, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.021897810218978103, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9197080291970803, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.021897810218978103, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9197080291970803, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.021897810218978103, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.6419999999999999, 0.44700000000000006, 0.9300000000000002, 0.43100000000000005, 0.4590000000000001, 0.46799999999999997, 0.31099999999999994, 0.4670000000000001, 0.44999999999999996, -0.03500000000000003, 0.46899999999999986, 0.472, 0.45799999999999996, -0.05400000000000005, 0.4630000000000001, 0.45699999999999985, 0.43699999999999983, 0.32600000000000007, -0.06900000000000006, 0.44300000000000006, 0.45500000000000007, 0.42700000000000005, 0.385, 0.46499999999999986, 0.43999999999999995, 0.47, 0.4630000000000001, 0.43500000000000005, 0.45500000000000007, 0.44300000000000006, 0.4630000000000001, 0.45699999999999985, 0.4159999999999999, 0.46599999999999997, -0.04200000000000004, 0.45499999999999996, 0.46599999999999997, 0.46199999999999997, -0.16100000000000003, -0.051000000000000045, 0.45599999999999996, 0.353, 0.44300000000000006, -0.03599999999999992, 0.472, 0.45100000000000007, 0.4119999999999999, 0.365, 0.44799999999999995, 0.387, 0.41700000000000004, 0.45599999999999996, 0.9729999999999999, -0.11099999999999988, 0.46199999999999997, 0.2290000000000001, 0.45099999999999996, 0.43699999999999983, -0.031000000000000028, 0.44099999999999984, 0.45500000000000007, 0.31000000000000005, 0.41300000000000003, 0.42999999999999994, 0.27700000000000014, 0.16000000000000014, 0.42800000000000016, 0.4630000000000001, 1.435, 0.4750000000000001, 0.46099999999999985, 0.4670000000000001, -0.08000000000000007, 0.42899999999999994, 0.46099999999999985, 0.4590000000000001, 0.46099999999999985, 0.43599999999999994, 0.957, 0.45999999999999996, -0.04200000000000004, 0.4590000000000001, 0.24399999999999977, 0.44199999999999995, 0.615, 0.4690000000000001, 0.44799999999999995, 0.4630000000000001, 0.4630000000000001, 1.4449999999999998, 0.877, 0.4590000000000001, 0.4650000000000001, 1.4180000000000001, 0.3999999999999999, 0.40700000000000003, 1.388, 0.46199999999999997, -0.028000000000000025, 0.44799999999999995, 0.44199999999999995, 0.4630000000000001, -0.025000000000000022, 0.42900000000000005, 0.4650000000000001, 0.4670000000000001, 0.258, 0.4590000000000001, 0.4670000000000001, 1.752, 0.45500000000000007, 0.46099999999999985, 0.4590000000000001, 0.46899999999999986, 0.4590000000000001, 0.33000000000000007, -0.02400000000000002, 0.42300000000000004, 0.4670000000000001, 0.4630000000000001, 0.43199999999999994, 0.46399999999999997, 0.74, 0.47, 0.45999999999999996, -0.118, 0.46099999999999985, 0.43999999999999995, 0.43500000000000005, 0.45599999999999996, 0.44099999999999984, 0.45799999999999996, 0.46399999999999997, 0.256, 0.4650000000000001, 0.2829999999999999, 0.41900000000000004], "episode_lengths": [113, 17, 23, 22, 13, 10, 60, 10, 16, 11, 10, 9, 13, 17, 12, 13, 19, 56, 22, 18, 14, 23, 35, 11, 19, 10, 11, 20, 15, 18, 12, 14, 27, 11, 14, 300, 11, 12, 52, 16, 14, 47, 18, 11, 9, 15, 27, 42, 17, 35, 26, 14, 9, 35, 12, 85, 16, 21, 10, 19, 14, 59, 27, 22, 70, 107, 23, 12, 20, 8, 12, 11, 181, 22, 13, 13, 13, 21, 300, 13, 13, 13, 237, 18, 122, 10, 16, 12, 12, 18, 38, 13, 11, 26, 32, 29, 35, 12, 8, 17, 19, 11, 8, 22, 11, 10, 77, 13, 11, 79, 14, 12, 13, 10, 13, 54, 8, 24, 11, 12, 22, 11, 83, 9, 13, 34, 12, 19, 21, 14, 19, 14, 300, 78, 11, 68, 26], "policy_red_0_reward": [1.158, 1.4489999999999998, 1.431, 1.434, 1.46, 1.47, 1.319, 1.47, 1.452, 0.967, 1.47, 1.4729999999999999, 1.4609999999999999, 0.949, 1.464, 1.4609999999999999, 1.442, 1.331, 0.9339999999999999, 1.446, 1.458, 1.4300000000000002, 1.391, 1.467, 1.443, 1.47, 1.467, 1.44, 1.455, 1.446, 1.464, 1.458, 1.419, -0.5, 0.958, 0.497, 1.467, 1.464, 0.844, 0.952, 1.458, 1.359, 1.444, 0.967, 1.4729999999999999, 1.455, 1.417, 1.369, 1.448, 1.3940000000000001, 1.4220000000000002, 1.458, 1.4729999999999999, 0.895, 1.464, 1.245, -0.5, 1.4369999999999998, 0.97, 1.443, 1.458, 1.323, 1.4180000000000001, 1.434, 1.286, 1.177, 1.431, 1.464, 1.44, 1.476, 1.464, 1.467, 0.954, -0.501, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.4369999999999998, 0.5, 1.4609999999999999, 0.961, 1.4609999999999999, 0.7839999999999999, 1.4449999999999998, 1.131, 1.47, 1.452, 1.464, 1.464, 1.446, 1.384, 1.4609999999999999, 1.467, 1.421, 1.404, 1.409, 1.3940000000000001, 1.464, 0.976, 1.4489999999999998, 1.442, 1.467, 0.976, 1.4329999999999998, 1.467, 1.47, 1.2690000000000001, 1.4609999999999999, 1.467, 1.259, 1.458, 1.464, 1.46, 1.47, 1.4609999999999999, 1.337, 0.976, 1.427, 1.467, 1.464, 1.434, 1.467, 1.249, 1.4729999999999999, 1.4609999999999999, 0.888, 1.464, 1.443, 1.4369999999999998, 1.458, 1.443, 1.458, 0.499, 1.262, 1.467, 1.296, 1.421], "policy_blue_0_reward": [-0.516, -1.002, -0.501, -1.003, -1.001, -1.002, -1.008, -1.003, -1.002, -1.002, -1.001, -1.001, -1.003, -1.003, -1.001, -1.004, -1.005, -1.005, -1.003, -1.003, -1.003, -1.003, -1.006, -1.002, -1.003, -1.0, -1.0039999999999998, -1.005, -1.0, -1.003, -1.001, -1.001, -1.003, 0.966, -1.0, -0.04200000000000003, -1.001, -1.002, -1.005, -1.003, -1.002, -1.006, -1.001, -1.003, -1.001, -1.004, -1.005, -1.004, -1.0, -1.007, -1.005, -1.002, -0.5, -1.0059999999999998, -1.002, -1.016, 0.951, -1.0, -1.001, -1.002, -1.003, -1.013, -1.005, -1.004, -1.009, -1.017, -1.003, -1.001, -0.005, -1.001, -1.003, -1.0, -1.034, 0.9299999999999999, -1.0, -1.002, -1.0, -1.001, 0.45699999999999996, -1.001, -1.003, -1.002, -0.54, -1.003, -0.516, -1.001, -1.0039999999999998, -1.001, -1.001, -0.001, -0.507, -1.0019999999999998, -1.0019999999999998, -0.003, -1.004, -1.002, -0.006, -1.002, -1.004, -1.001, -1.0, -1.004, -1.001, -1.0039999999999998, -1.0019999999999998, -1.003, -1.011, -1.002, -1.0, 0.493, -1.003, -1.003, -1.001, -1.001, -1.002, -1.007, -1.0, -1.004, -1.0, -1.001, -1.002, -1.003, -0.509, -1.003, -1.001, -1.006, -1.003, -1.003, -1.002, -1.002, -1.002, -1.0, -0.035000000000000024, -1.006, -1.0019999999999998, -1.013, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24483853566373864, "mean_inference_ms": 1.4766756127448606, "mean_action_processing_ms": 0.06297947358170043, "mean_env_wait_ms": 0.0891208896262183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01917816426632178, "StateBufferConnector_ms": 0.001472713303391951, "ViewRequirementAgentConnector_ms": 0.031308188055553576}}, "episode_reward_max": 1.752, "episode_reward_min": -0.16100000000000003, "episode_reward_mean": 0.4353284671532846, "episode_len_mean": 32.481751824817515, "episodes_this_iter": 137, "policy_reward_min": {"red_0": -0.501, "blue_0": -1.034}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.966}, "policy_reward_mean": {"red_0": 1.305956204379562, "blue_0": -0.8706277372262774}, "hist_stats": {"episode_reward": [0.6419999999999999, 0.44700000000000006, 0.9300000000000002, 0.43100000000000005, 0.4590000000000001, 0.46799999999999997, 0.31099999999999994, 0.4670000000000001, 0.44999999999999996, -0.03500000000000003, 0.46899999999999986, 0.472, 0.45799999999999996, -0.05400000000000005, 0.4630000000000001, 0.45699999999999985, 0.43699999999999983, 0.32600000000000007, -0.06900000000000006, 0.44300000000000006, 0.45500000000000007, 0.42700000000000005, 0.385, 0.46499999999999986, 0.43999999999999995, 0.47, 0.4630000000000001, 0.43500000000000005, 0.45500000000000007, 0.44300000000000006, 0.4630000000000001, 0.45699999999999985, 0.4159999999999999, 0.46599999999999997, -0.04200000000000004, 0.45499999999999996, 0.46599999999999997, 0.46199999999999997, -0.16100000000000003, -0.051000000000000045, 0.45599999999999996, 0.353, 0.44300000000000006, -0.03599999999999992, 0.472, 0.45100000000000007, 0.4119999999999999, 0.365, 0.44799999999999995, 0.387, 0.41700000000000004, 0.45599999999999996, 0.9729999999999999, -0.11099999999999988, 0.46199999999999997, 0.2290000000000001, 0.45099999999999996, 0.43699999999999983, -0.031000000000000028, 0.44099999999999984, 0.45500000000000007, 0.31000000000000005, 0.41300000000000003, 0.42999999999999994, 0.27700000000000014, 0.16000000000000014, 0.42800000000000016, 0.4630000000000001, 1.435, 0.4750000000000001, 0.46099999999999985, 0.4670000000000001, -0.08000000000000007, 0.42899999999999994, 0.46099999999999985, 0.4590000000000001, 0.46099999999999985, 0.43599999999999994, 0.957, 0.45999999999999996, -0.04200000000000004, 0.4590000000000001, 0.24399999999999977, 0.44199999999999995, 0.615, 0.4690000000000001, 0.44799999999999995, 0.4630000000000001, 0.4630000000000001, 1.4449999999999998, 0.877, 0.4590000000000001, 0.4650000000000001, 1.4180000000000001, 0.3999999999999999, 0.40700000000000003, 1.388, 0.46199999999999997, -0.028000000000000025, 0.44799999999999995, 0.44199999999999995, 0.4630000000000001, -0.025000000000000022, 0.42900000000000005, 0.4650000000000001, 0.4670000000000001, 0.258, 0.4590000000000001, 0.4670000000000001, 1.752, 0.45500000000000007, 0.46099999999999985, 0.4590000000000001, 0.46899999999999986, 0.4590000000000001, 0.33000000000000007, -0.02400000000000002, 0.42300000000000004, 0.4670000000000001, 0.4630000000000001, 0.43199999999999994, 0.46399999999999997, 0.74, 0.47, 0.45999999999999996, -0.118, 0.46099999999999985, 0.43999999999999995, 0.43500000000000005, 0.45599999999999996, 0.44099999999999984, 0.45799999999999996, 0.46399999999999997, 0.256, 0.4650000000000001, 0.2829999999999999, 0.41900000000000004], "episode_lengths": [113, 17, 23, 22, 13, 10, 60, 10, 16, 11, 10, 9, 13, 17, 12, 13, 19, 56, 22, 18, 14, 23, 35, 11, 19, 10, 11, 20, 15, 18, 12, 14, 27, 11, 14, 300, 11, 12, 52, 16, 14, 47, 18, 11, 9, 15, 27, 42, 17, 35, 26, 14, 9, 35, 12, 85, 16, 21, 10, 19, 14, 59, 27, 22, 70, 107, 23, 12, 20, 8, 12, 11, 181, 22, 13, 13, 13, 21, 300, 13, 13, 13, 237, 18, 122, 10, 16, 12, 12, 18, 38, 13, 11, 26, 32, 29, 35, 12, 8, 17, 19, 11, 8, 22, 11, 10, 77, 13, 11, 79, 14, 12, 13, 10, 13, 54, 8, 24, 11, 12, 22, 11, 83, 9, 13, 34, 12, 19, 21, 14, 19, 14, 300, 78, 11, 68, 26], "policy_red_0_reward": [1.158, 1.4489999999999998, 1.431, 1.434, 1.46, 1.47, 1.319, 1.47, 1.452, 0.967, 1.47, 1.4729999999999999, 1.4609999999999999, 0.949, 1.464, 1.4609999999999999, 1.442, 1.331, 0.9339999999999999, 1.446, 1.458, 1.4300000000000002, 1.391, 1.467, 1.443, 1.47, 1.467, 1.44, 1.455, 1.446, 1.464, 1.458, 1.419, -0.5, 0.958, 0.497, 1.467, 1.464, 0.844, 0.952, 1.458, 1.359, 1.444, 0.967, 1.4729999999999999, 1.455, 1.417, 1.369, 1.448, 1.3940000000000001, 1.4220000000000002, 1.458, 1.4729999999999999, 0.895, 1.464, 1.245, -0.5, 1.4369999999999998, 0.97, 1.443, 1.458, 1.323, 1.4180000000000001, 1.434, 1.286, 1.177, 1.431, 1.464, 1.44, 1.476, 1.464, 1.467, 0.954, -0.501, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.4369999999999998, 0.5, 1.4609999999999999, 0.961, 1.4609999999999999, 0.7839999999999999, 1.4449999999999998, 1.131, 1.47, 1.452, 1.464, 1.464, 1.446, 1.384, 1.4609999999999999, 1.467, 1.421, 1.404, 1.409, 1.3940000000000001, 1.464, 0.976, 1.4489999999999998, 1.442, 1.467, 0.976, 1.4329999999999998, 1.467, 1.47, 1.2690000000000001, 1.4609999999999999, 1.467, 1.259, 1.458, 1.464, 1.46, 1.47, 1.4609999999999999, 1.337, 0.976, 1.427, 1.467, 1.464, 1.434, 1.467, 1.249, 1.4729999999999999, 1.4609999999999999, 0.888, 1.464, 1.443, 1.4369999999999998, 1.458, 1.443, 1.458, 0.499, 1.262, 1.467, 1.296, 1.421], "policy_blue_0_reward": [-0.516, -1.002, -0.501, -1.003, -1.001, -1.002, -1.008, -1.003, -1.002, -1.002, -1.001, -1.001, -1.003, -1.003, -1.001, -1.004, -1.005, -1.005, -1.003, -1.003, -1.003, -1.003, -1.006, -1.002, -1.003, -1.0, -1.0039999999999998, -1.005, -1.0, -1.003, -1.001, -1.001, -1.003, 0.966, -1.0, -0.04200000000000003, -1.001, -1.002, -1.005, -1.003, -1.002, -1.006, -1.001, -1.003, -1.001, -1.004, -1.005, -1.004, -1.0, -1.007, -1.005, -1.002, -0.5, -1.0059999999999998, -1.002, -1.016, 0.951, -1.0, -1.001, -1.002, -1.003, -1.013, -1.005, -1.004, -1.009, -1.017, -1.003, -1.001, -0.005, -1.001, -1.003, -1.0, -1.034, 0.9299999999999999, -1.0, -1.002, -1.0, -1.001, 0.45699999999999996, -1.001, -1.003, -1.002, -0.54, -1.003, -0.516, -1.001, -1.0039999999999998, -1.001, -1.001, -0.001, -0.507, -1.0019999999999998, -1.0019999999999998, -0.003, -1.004, -1.002, -0.006, -1.002, -1.004, -1.001, -1.0, -1.004, -1.001, -1.0039999999999998, -1.0019999999999998, -1.003, -1.011, -1.002, -1.0, 0.493, -1.003, -1.003, -1.001, -1.001, -1.002, -1.007, -1.0, -1.004, -1.0, -1.001, -1.002, -1.003, -0.509, -1.003, -1.001, -1.006, -1.003, -1.003, -1.002, -1.002, -1.002, -1.0, -0.035000000000000024, -1.006, -1.0019999999999998, -1.013, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24483853566373864, "mean_inference_ms": 1.4766756127448606, "mean_action_processing_ms": 0.06297947358170043, "mean_env_wait_ms": 0.0891208896262183, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01917816426632178, "StateBufferConnector_ms": 0.001472713303391951, "ViewRequirementAgentConnector_ms": 0.031308188055553576}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000, "num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.01130583185255, "num_env_steps_trained_throughput_per_sec": 103.01130583185255, "timesteps_total": 176000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 352000, "timers": {"training_iteration_time_ms": 38969.761, "sample_time_ms": 7573.1, "learn_time_ms": 31379.19, "learn_throughput": 127.473, "synch_weights_time_ms": 16.982}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 176000, "num_agent_steps_sampled": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 5031, "training_iteration": 44, "trial_id": "d67e4_00000", "date": "2023-09-20_22-37-48", "timestamp": 1695263868, "time_this_iter_s": 38.836755990982056, "time_total_s": 1711.4276876449585, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d089e10>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1711.4276876449585, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 34.653571428571425, "ram_util_percent": 48.91785714285714}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.07432432432432433, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8716216216216216, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.033783783783783786, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8716216216216216, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.033783783783783786, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8716216216216216, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.033783783783783786, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8941357525375981, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01323979978915304, "policy_loss": -0.01997455087209043, "vf_loss": 0.00649615020180742, "vf_explained_var": 0.7783969034751256, "kl": 0.008843103301394943, "entropy": 0.49272008628274006, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 42720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "sampler_results": {"episode_reward_max": 1.46, "episode_reward_min": -0.247, "episode_reward_mean": 0.40664864864864875, "episode_len_mean": 28.905405405405407, "episode_media": {}, "episodes_this_iter": 148, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.961}, "policy_reward_mean": {"red_0": 1.1986081081081081, "blue_0": -0.7919594594594593}, "custom_metrics": {"red_0/door_open_done_mean": 0.07432432432432433, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8716216216216216, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.033783783783783786, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8716216216216216, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.033783783783783786, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8716216216216216, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.033783783783783786, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.45499999999999996, 0.46199999999999997, 0.45100000000000007, -0.11699999999999999, -0.03699999999999992, -0.06600000000000006, 0.403, 0.44799999999999995, -0.03300000000000003, 0.46599999999999997, 0.813, 0.43699999999999983, 0.4590000000000001, 0.45299999999999985, -0.049000000000000044, -0.03700000000000003, -0.09599999999999986, 0.45100000000000007, -0.052000000000000046, 0.44799999999999995, 0.45699999999999985, -0.027000000000000024, -0.031000000000000028, 1.447, 0.3780000000000001, 0.44300000000000006, -0.24499999999999988, 0.96, 0.46099999999999985, 0.45599999999999996, 0.46899999999999986, -0.038000000000000034, 0.45999999999999996, 1.46, -0.02499999999999991, 0.472, -0.038999999999999924, -0.04599999999999993, 0.472, -0.03399999999999992, 0.4630000000000001, 0.9280000000000002, 1.442, 0.4119999999999999, 0.756, 0.47299999999999986, 0.46499999999999986, 0.958, -0.027999999999999914, 0.42700000000000005, 0.46599999999999997, -0.06799999999999995, 0.4670000000000001, 0.45999999999999996, -0.039000000000000035, 0.46799999999999997, -0.247, 0.29699999999999993, -0.03300000000000003, -0.04700000000000004, 0.849, 1.2349999999999999, 0.44599999999999995, -0.03500000000000003, -0.02100000000000002, 0.2549999999999999, 0.45100000000000007, 0.4750000000000001, -0.03600000000000003, 0.46099999999999985, 0.45999999999999996, 0.04600000000000004, -0.039000000000000035, 0.472, -0.05200000000000004, 0.43300000000000005, 0.4750000000000001, 0.9670000000000001, 0.4630000000000001, 0.44799999999999995, 0.47299999999999986, -0.028999999999999915, 0.46899999999999986, 1.452, 0.33999999999999997, 0.45199999999999996, 0.21499999999999997, 0.45500000000000007, 0.472, 0.4630000000000001, 0.44399999999999995, 0.956, 0.45599999999999996, 0.46399999999999997, 1.442, 0.262, -0.07000000000000006, -0.06599999999999995, 0.4710000000000001, 0.4710000000000001, 0.45999999999999996, 0.45999999999999996, -0.027000000000000024, -0.040000000000000036, 0.43900000000000006, 0.4500000000000002, 1.439, 0.46399999999999997, 0.44499999999999984, 0.09299999999999997, 0.42200000000000015, -0.025000000000000022, -0.03700000000000003, 0.405, 0.43399999999999994, 0.44300000000000006, 1.452, 0.9329999999999998, 0.46099999999999985, 0.46599999999999997, 0.9590000000000001, 1.45, -0.04499999999999993, -0.04300000000000004, 0.44099999999999984, -0.04400000000000004, 0.4630000000000001, 0.8900000000000001, 0.44199999999999995, 0.42900000000000005, 0.43399999999999994, -0.039000000000000035, -0.06500000000000006, 0.45799999999999996, -0.04500000000000004, 0.968, 1.45, 0.44499999999999984, -0.040999999999999925, -0.07399999999999995, 0.46899999999999986, -0.02400000000000002, -0.05700000000000005, 0.943, 1.332, 0.958, 0.472, 0.44700000000000006], "episode_lengths": [300, 12, 16, 37, 11, 20, 31, 16, 11, 11, 60, 20, 12, 15, 16, 12, 31, 16, 15, 17, 13, 9, 10, 17, 39, 18, 76, 13, 13, 14, 10, 12, 13, 13, 8, 9, 12, 14, 9, 10, 12, 23, 19, 28, 77, 9, 11, 13, 9, 24, 11, 22, 11, 13, 12, 10, 78, 65, 11, 15, 48, 84, 17, 11, 7, 78, 15, 8, 12, 13, 13, 144, 12, 9, 300, 21, 8, 11, 12, 16, 9, 9, 10, 15, 49, 15, 90, 14, 9, 12, 17, 14, 13, 12, 18, 234, 181, 21, 9, 9, 13, 12, 9, 12, 19, 14, 18, 11, 17, 130, 25, 8, 12, 31, 21, 18, 15, 22, 12, 11, 13, 16, 14, 14, 19, 14, 12, 33, 18, 23, 21, 13, 21, 13, 15, 10, 16, 17, 13, 23, 10, 8, 17, 300, 52, 14, 9, 17], "policy_red_0_reward": [0.497, 1.464, 1.452, 0.889, 0.967, 0.9349999999999999, 1.4060000000000001, 1.452, 0.967, 1.467, 1.319, 1.439, 1.464, 1.455, 0.952, 0.964, -1.0, 1.452, 0.954, 1.4489999999999998, 1.4609999999999999, 0.973, 0.97, 1.4489999999999998, 1.3820000000000001, 1.446, 0.772, 1.4609999999999999, 1.4609999999999999, 1.458, 1.47, 0.964, 1.4609999999999999, 1.4609999999999999, 0.976, 1.4729999999999999, 0.963, 0.958, 1.4729999999999999, 0.969, 1.464, 1.431, 1.443, 1.4140000000000001, 1.2690000000000001, 1.4729999999999999, 1.467, 1.4609999999999999, 0.973, 1.428, 1.467, 0.9339999999999999, 1.467, 1.4609999999999999, 0.964, 1.4689999999999999, 0.765, 1.3039999999999998, 0.967, 0.955, 1.3559999999999999, 1.244, 1.4489999999999998, 0.967, 0.979, 1.266, 1.455, 1.476, 0.964, 1.4609999999999999, 1.4609999999999999, 1.0670000000000002, 0.964, 1.4729999999999999, -0.010000000000000002, 1.4369999999999998, 1.476, 1.467, 1.464, 1.452, 1.4729999999999999, 0.972, 1.47, 1.455, -0.503, 1.455, -0.501, 1.458, 1.4729999999999999, 1.464, 1.4489999999999998, 1.458, 1.4609999999999999, 1.464, 1.446, 0.7959999999999999, 0.957, -1.0, 1.4729999999999999, 1.4729999999999999, 1.4609999999999999, 1.464, 0.973, 0.964, 1.442, 1.458, 1.4449999999999998, 1.467, 1.4489999999999998, 1.109, 1.425, 0.976, 0.964, 1.407, 1.4369999999999998, 1.446, 1.455, 1.434, 1.464, 1.467, 1.4609999999999999, 1.452, 0.958, 0.958, 1.443, 0.956, 1.464, 1.395, 1.444, 0.931, 1.436, -1.0, 0.9369999999999999, 1.4609999999999999, 0.955, 1.47, 1.452, 1.447, 0.961, 0.93, 1.47, 0.976, 0.947, 0.479, 1.342, 1.458, 1.4729999999999999, 1.4489999999999998], "policy_blue_0_reward": [-0.04200000000000003, -1.002, -1.001, -1.006, -1.0039999999999998, -1.001, -1.003, -1.004, -1.0, -1.001, -0.506, -1.002, -1.005, -1.002, -1.001, -1.001, 0.904, -1.001, -1.006, -1.001, -1.004, -1.0, -1.001, -0.002, -1.004, -1.003, -1.017, -0.501, -1.0, -1.002, -1.001, -1.002, -1.001, -0.001, -1.001, -1.001, -1.0019999999999998, -1.0039999999999998, -1.001, -1.003, -1.001, -0.5029999999999999, -0.001, -1.002, -0.513, -1.0, -1.002, -0.503, -1.001, -1.001, -1.001, -1.0019999999999998, -1.0, -1.001, -1.003, -1.001, -1.012, -1.007, -1.0, -1.002, -0.507, -0.009000000000000001, -1.003, -1.002, -1.0, -1.011, -1.004, -1.001, -1.0, -1.0, -1.001, -1.021, -1.003, -1.001, -0.04200000000000003, -1.0039999999999998, -1.001, -0.5, -1.001, -1.004, -1.0, -1.001, -1.001, -0.003, 0.843, -1.003, 0.716, -1.003, -1.001, -1.001, -1.005, -0.502, -1.005, -1.0, -0.004, -0.534, -1.027, 0.9339999999999999, -1.002, -1.002, -1.001, -1.0039999999999998, -1.0, -1.004, -1.003, -1.0079999999999998, -0.006, -1.003, -1.004, -1.016, -1.003, -1.001, -1.001, -1.002, -1.003, -1.003, -0.003, -0.501, -1.003, -1.001, -0.502, -0.002, -1.003, -1.001, -1.002, -1.0, -1.001, -0.505, -1.002, -0.502, -1.002, 0.961, -1.002, -1.003, -1.0, -0.502, -0.002, -1.002, -1.0019999999999998, -1.004, -1.001, -1.0, -1.004, 0.46399999999999997, -0.010000000000000002, -0.5, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24447710397081743, "mean_inference_ms": 1.4752203496953378, "mean_action_processing_ms": 0.06287828140315835, "mean_env_wait_ms": 0.08894457867472086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019293862420159416, "StateBufferConnector_ms": 0.0015372360074842298, "ViewRequirementAgentConnector_ms": 0.031344632844667174}}, "episode_reward_max": 1.46, "episode_reward_min": -0.247, "episode_reward_mean": 0.40664864864864875, "episode_len_mean": 28.905405405405407, "episodes_this_iter": 148, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.961}, "policy_reward_mean": {"red_0": 1.1986081081081081, "blue_0": -0.7919594594594593}, "hist_stats": {"episode_reward": [0.45499999999999996, 0.46199999999999997, 0.45100000000000007, -0.11699999999999999, -0.03699999999999992, -0.06600000000000006, 0.403, 0.44799999999999995, -0.03300000000000003, 0.46599999999999997, 0.813, 0.43699999999999983, 0.4590000000000001, 0.45299999999999985, -0.049000000000000044, -0.03700000000000003, -0.09599999999999986, 0.45100000000000007, -0.052000000000000046, 0.44799999999999995, 0.45699999999999985, -0.027000000000000024, -0.031000000000000028, 1.447, 0.3780000000000001, 0.44300000000000006, -0.24499999999999988, 0.96, 0.46099999999999985, 0.45599999999999996, 0.46899999999999986, -0.038000000000000034, 0.45999999999999996, 1.46, -0.02499999999999991, 0.472, -0.038999999999999924, -0.04599999999999993, 0.472, -0.03399999999999992, 0.4630000000000001, 0.9280000000000002, 1.442, 0.4119999999999999, 0.756, 0.47299999999999986, 0.46499999999999986, 0.958, -0.027999999999999914, 0.42700000000000005, 0.46599999999999997, -0.06799999999999995, 0.4670000000000001, 0.45999999999999996, -0.039000000000000035, 0.46799999999999997, -0.247, 0.29699999999999993, -0.03300000000000003, -0.04700000000000004, 0.849, 1.2349999999999999, 0.44599999999999995, -0.03500000000000003, -0.02100000000000002, 0.2549999999999999, 0.45100000000000007, 0.4750000000000001, -0.03600000000000003, 0.46099999999999985, 0.45999999999999996, 0.04600000000000004, -0.039000000000000035, 0.472, -0.05200000000000004, 0.43300000000000005, 0.4750000000000001, 0.9670000000000001, 0.4630000000000001, 0.44799999999999995, 0.47299999999999986, -0.028999999999999915, 0.46899999999999986, 1.452, 0.33999999999999997, 0.45199999999999996, 0.21499999999999997, 0.45500000000000007, 0.472, 0.4630000000000001, 0.44399999999999995, 0.956, 0.45599999999999996, 0.46399999999999997, 1.442, 0.262, -0.07000000000000006, -0.06599999999999995, 0.4710000000000001, 0.4710000000000001, 0.45999999999999996, 0.45999999999999996, -0.027000000000000024, -0.040000000000000036, 0.43900000000000006, 0.4500000000000002, 1.439, 0.46399999999999997, 0.44499999999999984, 0.09299999999999997, 0.42200000000000015, -0.025000000000000022, -0.03700000000000003, 0.405, 0.43399999999999994, 0.44300000000000006, 1.452, 0.9329999999999998, 0.46099999999999985, 0.46599999999999997, 0.9590000000000001, 1.45, -0.04499999999999993, -0.04300000000000004, 0.44099999999999984, -0.04400000000000004, 0.4630000000000001, 0.8900000000000001, 0.44199999999999995, 0.42900000000000005, 0.43399999999999994, -0.039000000000000035, -0.06500000000000006, 0.45799999999999996, -0.04500000000000004, 0.968, 1.45, 0.44499999999999984, -0.040999999999999925, -0.07399999999999995, 0.46899999999999986, -0.02400000000000002, -0.05700000000000005, 0.943, 1.332, 0.958, 0.472, 0.44700000000000006], "episode_lengths": [300, 12, 16, 37, 11, 20, 31, 16, 11, 11, 60, 20, 12, 15, 16, 12, 31, 16, 15, 17, 13, 9, 10, 17, 39, 18, 76, 13, 13, 14, 10, 12, 13, 13, 8, 9, 12, 14, 9, 10, 12, 23, 19, 28, 77, 9, 11, 13, 9, 24, 11, 22, 11, 13, 12, 10, 78, 65, 11, 15, 48, 84, 17, 11, 7, 78, 15, 8, 12, 13, 13, 144, 12, 9, 300, 21, 8, 11, 12, 16, 9, 9, 10, 15, 49, 15, 90, 14, 9, 12, 17, 14, 13, 12, 18, 234, 181, 21, 9, 9, 13, 12, 9, 12, 19, 14, 18, 11, 17, 130, 25, 8, 12, 31, 21, 18, 15, 22, 12, 11, 13, 16, 14, 14, 19, 14, 12, 33, 18, 23, 21, 13, 21, 13, 15, 10, 16, 17, 13, 23, 10, 8, 17, 300, 52, 14, 9, 17], "policy_red_0_reward": [0.497, 1.464, 1.452, 0.889, 0.967, 0.9349999999999999, 1.4060000000000001, 1.452, 0.967, 1.467, 1.319, 1.439, 1.464, 1.455, 0.952, 0.964, -1.0, 1.452, 0.954, 1.4489999999999998, 1.4609999999999999, 0.973, 0.97, 1.4489999999999998, 1.3820000000000001, 1.446, 0.772, 1.4609999999999999, 1.4609999999999999, 1.458, 1.47, 0.964, 1.4609999999999999, 1.4609999999999999, 0.976, 1.4729999999999999, 0.963, 0.958, 1.4729999999999999, 0.969, 1.464, 1.431, 1.443, 1.4140000000000001, 1.2690000000000001, 1.4729999999999999, 1.467, 1.4609999999999999, 0.973, 1.428, 1.467, 0.9339999999999999, 1.467, 1.4609999999999999, 0.964, 1.4689999999999999, 0.765, 1.3039999999999998, 0.967, 0.955, 1.3559999999999999, 1.244, 1.4489999999999998, 0.967, 0.979, 1.266, 1.455, 1.476, 0.964, 1.4609999999999999, 1.4609999999999999, 1.0670000000000002, 0.964, 1.4729999999999999, -0.010000000000000002, 1.4369999999999998, 1.476, 1.467, 1.464, 1.452, 1.4729999999999999, 0.972, 1.47, 1.455, -0.503, 1.455, -0.501, 1.458, 1.4729999999999999, 1.464, 1.4489999999999998, 1.458, 1.4609999999999999, 1.464, 1.446, 0.7959999999999999, 0.957, -1.0, 1.4729999999999999, 1.4729999999999999, 1.4609999999999999, 1.464, 0.973, 0.964, 1.442, 1.458, 1.4449999999999998, 1.467, 1.4489999999999998, 1.109, 1.425, 0.976, 0.964, 1.407, 1.4369999999999998, 1.446, 1.455, 1.434, 1.464, 1.467, 1.4609999999999999, 1.452, 0.958, 0.958, 1.443, 0.956, 1.464, 1.395, 1.444, 0.931, 1.436, -1.0, 0.9369999999999999, 1.4609999999999999, 0.955, 1.47, 1.452, 1.447, 0.961, 0.93, 1.47, 0.976, 0.947, 0.479, 1.342, 1.458, 1.4729999999999999, 1.4489999999999998], "policy_blue_0_reward": [-0.04200000000000003, -1.002, -1.001, -1.006, -1.0039999999999998, -1.001, -1.003, -1.004, -1.0, -1.001, -0.506, -1.002, -1.005, -1.002, -1.001, -1.001, 0.904, -1.001, -1.006, -1.001, -1.004, -1.0, -1.001, -0.002, -1.004, -1.003, -1.017, -0.501, -1.0, -1.002, -1.001, -1.002, -1.001, -0.001, -1.001, -1.001, -1.0019999999999998, -1.0039999999999998, -1.001, -1.003, -1.001, -0.5029999999999999, -0.001, -1.002, -0.513, -1.0, -1.002, -0.503, -1.001, -1.001, -1.001, -1.0019999999999998, -1.0, -1.001, -1.003, -1.001, -1.012, -1.007, -1.0, -1.002, -0.507, -0.009000000000000001, -1.003, -1.002, -1.0, -1.011, -1.004, -1.001, -1.0, -1.0, -1.001, -1.021, -1.003, -1.001, -0.04200000000000003, -1.0039999999999998, -1.001, -0.5, -1.001, -1.004, -1.0, -1.001, -1.001, -0.003, 0.843, -1.003, 0.716, -1.003, -1.001, -1.001, -1.005, -0.502, -1.005, -1.0, -0.004, -0.534, -1.027, 0.9339999999999999, -1.002, -1.002, -1.001, -1.0039999999999998, -1.0, -1.004, -1.003, -1.0079999999999998, -0.006, -1.003, -1.004, -1.016, -1.003, -1.001, -1.001, -1.002, -1.003, -1.003, -0.003, -0.501, -1.003, -1.001, -0.502, -0.002, -1.003, -1.001, -1.002, -1.0, -1.001, -0.505, -1.002, -0.502, -1.002, 0.961, -1.002, -1.003, -1.0, -0.502, -0.002, -1.002, -1.0019999999999998, -1.004, -1.001, -1.0, -1.004, 0.46399999999999997, -0.010000000000000002, -0.5, -1.001, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24447710397081743, "mean_inference_ms": 1.4752203496953378, "mean_action_processing_ms": 0.06287828140315835, "mean_env_wait_ms": 0.08894457867472086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019293862420159416, "StateBufferConnector_ms": 0.0015372360074842298, "ViewRequirementAgentConnector_ms": 0.031344632844667174}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000, "num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.34551622706067, "num_env_steps_trained_throughput_per_sec": 103.34551622706067, "timesteps_total": 180000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 360000, "timers": {"training_iteration_time_ms": 38930.521, "sample_time_ms": 7559.683, "learn_time_ms": 31353.334, "learn_throughput": 127.578, "synch_weights_time_ms": 17.013}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 180000, "num_agent_steps_sampled": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 5179, "training_iteration": 45, "trial_id": "d67e4_00000", "date": "2023-09-20_22-38-27", "timestamp": 1695263907, "time_this_iter_s": 38.711355686187744, "time_total_s": 1750.1390433311462, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687b490>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1750.1390433311462, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 34.970909090909096, "ram_util_percent": 48.9309090909091}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.024390243902439025, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9349593495934959, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.016260162601626018, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9349593495934959, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.016260162601626018, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9349593495934959, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.016260162601626018, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.984334351681173, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.014407120124451467, "policy_loss": -0.02056535403971793, "vf_loss": 0.004457024276052835, "vf_explained_var": 0.8561345594624679, "kl": 0.009947538396460771, "entropy": 0.5466700931079685, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 43680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "sampler_results": {"episode_reward_max": 1.454, "episode_reward_min": -0.10799999999999998, "episode_reward_mean": 0.42062601626016255, "episode_len_mean": 28.21951219512195, "episode_media": {}, "episodes_this_iter": 123, "policy_reward_min": {"red_0": -0.5, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.962}, "policy_reward_mean": {"red_0": 1.3131544715447157, "blue_0": -0.8925284552845529}, "custom_metrics": {"red_0/door_open_done_mean": 0.024390243902439025, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.9349593495934959, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.016260162601626018, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.9349593495934959, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.016260162601626018, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.9349593495934959, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.016260162601626018, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.941, 0.569, 0.43799999999999994, 0.4630000000000001, 0.46599999999999997, 0.44099999999999984, 0.4710000000000001, 0.43599999999999994, 0.42900000000000005, 0.43699999999999983, 0.44799999999999995, 0.45999999999999996, 0.577, 0.45199999999999996, 0.46599999999999997, 0.44300000000000006, 0.43900000000000006, 0.46399999999999997, -0.02400000000000002, 0.20199999999999996, 0.45399999999999996, 0.45999999999999996, 0.44700000000000006, -0.07799999999999996, 0.29800000000000004, 0.45199999999999996, 0.954, 1.1920000000000002, 0.44399999999999995, 0.472, 0.46799999999999997, 0.46899999999999986, 0.46099999999999997, 0.44300000000000006, 0.4119999999999999, 0.4710000000000001, 0.3999999999999999, -0.10799999999999998, 0.46499999999999986, 0.46799999999999997, 0.46399999999999997, 0.43100000000000005, 0.02400000000000002, 0.4590000000000001, 0.46599999999999997, 0.2869999999999999, -0.030000000000000027, 0.45500000000000007, -0.06500000000000006, 0.677, 0.45599999999999996, 0.4740000000000002, 0.4650000000000001, 0.47299999999999986, -0.041000000000000036, 0.43800000000000017, -0.03700000000000003, 0.46199999999999997, 0.29000000000000004, 0.43900000000000006, 0.4620000000000002, 0.931, 0.45799999999999996, 0.45399999999999996, 0.45799999999999996, -0.03400000000000003, 1.454, 0.45500000000000007, 0.46799999999999997, 0.46199999999999997, 0.45599999999999996, 0.4710000000000001, -0.03500000000000003, 0.44399999999999995, 0.47299999999999986, 0.365, 0.46599999999999997, 0.4650000000000001, 0.4590000000000001, 0.34099999999999997, 0.45500000000000007, 0.46499999999999986, 0.47, -0.04300000000000004, 0.4590000000000001, 0.45399999999999996, 0.46899999999999986, 0.45699999999999985, 0.45199999999999996, -0.04499999999999993, 0.43199999999999994, 0.4670000000000001, 0.4590000000000001, 0.44399999999999995, 0.46899999999999986, 0.46599999999999997, 0.46599999999999997, 0.46799999999999997, -0.031000000000000028, 0.46599999999999997, -0.031000000000000028, 0.46499999999999986, 0.46799999999999997, 0.46099999999999985, 0.44700000000000006, -0.028000000000000025, 0.45100000000000007, 0.46899999999999986, 0.45599999999999996, 0.44499999999999984, 0.4590000000000001, 0.357, 0.4179999999999999, -0.05800000000000005, 0.44300000000000006, -0.025000000000000022, 0.46499999999999986, 0.46199999999999997, 0.45399999999999996, 0.4670000000000001, 0.46599999999999997, 0.9649999999999999, 1.44], "episode_lengths": [300, 135, 20, 12, 11, 19, 9, 21, 23, 20, 17, 13, 135, 16, 11, 18, 20, 12, 8, 96, 15, 13, 17, 25, 64, 15, 300, 95, 17, 9, 10, 10, 300, 18, 29, 9, 29, 32, 11, 10, 11, 21, 151, 13, 11, 67, 10, 14, 21, 101, 14, 8, 11, 8, 13, 19, 11, 12, 68, 19, 12, 22, 13, 15, 13, 10, 15, 15, 10, 12, 14, 9, 11, 17, 9, 43, 11, 11, 13, 51, 14, 11, 10, 14, 13, 14, 10, 14, 15, 13, 22, 11, 13, 18, 10, 11, 11, 10, 10, 11, 9, 11, 10, 13, 17, 9, 16, 10, 14, 18, 13, 45, 24, 19, 18, 8, 11, 11, 15, 11, 11, 11, 19], "policy_red_0_reward": [0.485, 1.093, 1.44, 1.464, 1.467, 1.443, 1.4729999999999999, 1.4369999999999998, 1.431, 1.439, 1.4489999999999998, 1.4609999999999999, 1.0939999999999999, 1.452, 1.467, 1.4449999999999998, 1.44, 1.464, 0.976, -0.5, 1.455, 1.4609999999999999, 1.4489999999999998, 0.925, 1.308, 1.454, 0.497, 1.202, 1.4489999999999998, 1.4729999999999999, 1.47, 1.47, 0.499, 1.444, 1.413, 1.4729999999999999, 1.405, 0.897, 1.467, 1.47, 1.467, 1.4369999999999998, 1.0430000000000001, 1.4609999999999999, 1.467, 1.298, 0.97, 1.458, 0.9369999999999999, 1.189, 1.458, 1.476, 1.467, 1.476, 0.961, 1.4409999999999998, 0.965, -0.5, 1.296, 1.4409999999999998, 1.464, 1.432, 1.4609999999999999, 1.455, 1.4609999999999999, 0.968, 1.455, 1.455, 0.97, 1.464, 1.458, 1.4729999999999999, 0.967, 1.448, 1.4729999999999999, 1.37, 1.467, 1.467, 1.4609999999999999, 1.347, 1.458, 1.467, 1.47, 0.958, 1.4609999999999999, 1.458, 1.47, 1.458, 1.455, 0.958, 1.434, 1.467, 1.4609999999999999, 1.446, 1.47, 1.467, 1.467, 1.47, 0.97, 1.467, 0.973, 1.467, 1.47, 1.4609999999999999, 1.4489999999999998, 0.973, 1.452, 1.47, 1.458, 1.446, 1.4609999999999999, 1.363, 1.42, 0.943, 1.446, 0.976, 1.467, 1.467, 1.455, 1.467, 1.467, 1.467, 1.443], "policy_blue_0_reward": [0.45599999999999996, -0.5239999999999999, -1.002, -1.001, -1.001, -1.002, -1.002, -1.001, -1.002, -1.002, -1.001, -1.001, -0.5169999999999999, -1.0, -1.001, -1.0019999999999998, -1.001, -1.0, -1.0, 0.702, -1.001, -1.001, -1.002, -1.003, -1.01, -1.002, 0.45699999999999996, -0.010000000000000002, -1.005, -1.001, -1.0019999999999998, -1.001, -0.03800000000000003, -1.001, -1.001, -1.002, -1.005, -1.005, -1.002, -1.002, -1.003, -1.006, -1.019, -1.0019999999999998, -1.001, -1.011, -1.0, -1.003, -1.002, -0.512, -1.002, -1.0019999999999998, -1.0019999999999998, -1.003, -1.002, -1.003, -1.002, 0.962, -1.006, -1.0019999999999998, -1.0019999999999998, -0.501, -1.003, -1.001, -1.003, -1.002, -0.001, -1.0, -0.502, -1.002, -1.002, -1.002, -1.002, -1.004, -1.0, -1.005, -1.001, -1.0019999999999998, -1.002, -1.006, -1.003, -1.002, -1.0, -1.001, -1.002, -1.004, -1.001, -1.001, -1.003, -1.003, -1.002, -1.0, -1.002, -1.002, -1.001, -1.001, -1.001, -1.002, -1.001, -1.001, -1.004, -1.002, -1.002, -1.0, -1.0019999999999998, -1.001, -1.001, -1.001, -1.002, -1.001, -1.002, -1.006, -1.002, -1.001, -1.003, -1.001, -1.002, -1.005, -1.001, -1.0, -1.001, -0.502, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2446627520633112, "mean_inference_ms": 1.4754089600813332, "mean_action_processing_ms": 0.06289964159131112, "mean_env_wait_ms": 0.08893848115410632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022092001224921002, "StateBufferConnector_ms": 0.00152394054381828, "ViewRequirementAgentConnector_ms": 0.03273874763550797}}, "episode_reward_max": 1.454, "episode_reward_min": -0.10799999999999998, "episode_reward_mean": 0.42062601626016255, "episode_len_mean": 28.21951219512195, "episodes_this_iter": 123, "policy_reward_min": {"red_0": -0.5, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.962}, "policy_reward_mean": {"red_0": 1.3131544715447157, "blue_0": -0.8925284552845529}, "hist_stats": {"episode_reward": [0.941, 0.569, 0.43799999999999994, 0.4630000000000001, 0.46599999999999997, 0.44099999999999984, 0.4710000000000001, 0.43599999999999994, 0.42900000000000005, 0.43699999999999983, 0.44799999999999995, 0.45999999999999996, 0.577, 0.45199999999999996, 0.46599999999999997, 0.44300000000000006, 0.43900000000000006, 0.46399999999999997, -0.02400000000000002, 0.20199999999999996, 0.45399999999999996, 0.45999999999999996, 0.44700000000000006, -0.07799999999999996, 0.29800000000000004, 0.45199999999999996, 0.954, 1.1920000000000002, 0.44399999999999995, 0.472, 0.46799999999999997, 0.46899999999999986, 0.46099999999999997, 0.44300000000000006, 0.4119999999999999, 0.4710000000000001, 0.3999999999999999, -0.10799999999999998, 0.46499999999999986, 0.46799999999999997, 0.46399999999999997, 0.43100000000000005, 0.02400000000000002, 0.4590000000000001, 0.46599999999999997, 0.2869999999999999, -0.030000000000000027, 0.45500000000000007, -0.06500000000000006, 0.677, 0.45599999999999996, 0.4740000000000002, 0.4650000000000001, 0.47299999999999986, -0.041000000000000036, 0.43800000000000017, -0.03700000000000003, 0.46199999999999997, 0.29000000000000004, 0.43900000000000006, 0.4620000000000002, 0.931, 0.45799999999999996, 0.45399999999999996, 0.45799999999999996, -0.03400000000000003, 1.454, 0.45500000000000007, 0.46799999999999997, 0.46199999999999997, 0.45599999999999996, 0.4710000000000001, -0.03500000000000003, 0.44399999999999995, 0.47299999999999986, 0.365, 0.46599999999999997, 0.4650000000000001, 0.4590000000000001, 0.34099999999999997, 0.45500000000000007, 0.46499999999999986, 0.47, -0.04300000000000004, 0.4590000000000001, 0.45399999999999996, 0.46899999999999986, 0.45699999999999985, 0.45199999999999996, -0.04499999999999993, 0.43199999999999994, 0.4670000000000001, 0.4590000000000001, 0.44399999999999995, 0.46899999999999986, 0.46599999999999997, 0.46599999999999997, 0.46799999999999997, -0.031000000000000028, 0.46599999999999997, -0.031000000000000028, 0.46499999999999986, 0.46799999999999997, 0.46099999999999985, 0.44700000000000006, -0.028000000000000025, 0.45100000000000007, 0.46899999999999986, 0.45599999999999996, 0.44499999999999984, 0.4590000000000001, 0.357, 0.4179999999999999, -0.05800000000000005, 0.44300000000000006, -0.025000000000000022, 0.46499999999999986, 0.46199999999999997, 0.45399999999999996, 0.4670000000000001, 0.46599999999999997, 0.9649999999999999, 1.44], "episode_lengths": [300, 135, 20, 12, 11, 19, 9, 21, 23, 20, 17, 13, 135, 16, 11, 18, 20, 12, 8, 96, 15, 13, 17, 25, 64, 15, 300, 95, 17, 9, 10, 10, 300, 18, 29, 9, 29, 32, 11, 10, 11, 21, 151, 13, 11, 67, 10, 14, 21, 101, 14, 8, 11, 8, 13, 19, 11, 12, 68, 19, 12, 22, 13, 15, 13, 10, 15, 15, 10, 12, 14, 9, 11, 17, 9, 43, 11, 11, 13, 51, 14, 11, 10, 14, 13, 14, 10, 14, 15, 13, 22, 11, 13, 18, 10, 11, 11, 10, 10, 11, 9, 11, 10, 13, 17, 9, 16, 10, 14, 18, 13, 45, 24, 19, 18, 8, 11, 11, 15, 11, 11, 11, 19], "policy_red_0_reward": [0.485, 1.093, 1.44, 1.464, 1.467, 1.443, 1.4729999999999999, 1.4369999999999998, 1.431, 1.439, 1.4489999999999998, 1.4609999999999999, 1.0939999999999999, 1.452, 1.467, 1.4449999999999998, 1.44, 1.464, 0.976, -0.5, 1.455, 1.4609999999999999, 1.4489999999999998, 0.925, 1.308, 1.454, 0.497, 1.202, 1.4489999999999998, 1.4729999999999999, 1.47, 1.47, 0.499, 1.444, 1.413, 1.4729999999999999, 1.405, 0.897, 1.467, 1.47, 1.467, 1.4369999999999998, 1.0430000000000001, 1.4609999999999999, 1.467, 1.298, 0.97, 1.458, 0.9369999999999999, 1.189, 1.458, 1.476, 1.467, 1.476, 0.961, 1.4409999999999998, 0.965, -0.5, 1.296, 1.4409999999999998, 1.464, 1.432, 1.4609999999999999, 1.455, 1.4609999999999999, 0.968, 1.455, 1.455, 0.97, 1.464, 1.458, 1.4729999999999999, 0.967, 1.448, 1.4729999999999999, 1.37, 1.467, 1.467, 1.4609999999999999, 1.347, 1.458, 1.467, 1.47, 0.958, 1.4609999999999999, 1.458, 1.47, 1.458, 1.455, 0.958, 1.434, 1.467, 1.4609999999999999, 1.446, 1.47, 1.467, 1.467, 1.47, 0.97, 1.467, 0.973, 1.467, 1.47, 1.4609999999999999, 1.4489999999999998, 0.973, 1.452, 1.47, 1.458, 1.446, 1.4609999999999999, 1.363, 1.42, 0.943, 1.446, 0.976, 1.467, 1.467, 1.455, 1.467, 1.467, 1.467, 1.443], "policy_blue_0_reward": [0.45599999999999996, -0.5239999999999999, -1.002, -1.001, -1.001, -1.002, -1.002, -1.001, -1.002, -1.002, -1.001, -1.001, -0.5169999999999999, -1.0, -1.001, -1.0019999999999998, -1.001, -1.0, -1.0, 0.702, -1.001, -1.001, -1.002, -1.003, -1.01, -1.002, 0.45699999999999996, -0.010000000000000002, -1.005, -1.001, -1.0019999999999998, -1.001, -0.03800000000000003, -1.001, -1.001, -1.002, -1.005, -1.005, -1.002, -1.002, -1.003, -1.006, -1.019, -1.0019999999999998, -1.001, -1.011, -1.0, -1.003, -1.002, -0.512, -1.002, -1.0019999999999998, -1.0019999999999998, -1.003, -1.002, -1.003, -1.002, 0.962, -1.006, -1.0019999999999998, -1.0019999999999998, -0.501, -1.003, -1.001, -1.003, -1.002, -0.001, -1.0, -0.502, -1.002, -1.002, -1.002, -1.002, -1.004, -1.0, -1.005, -1.001, -1.0019999999999998, -1.002, -1.006, -1.003, -1.002, -1.0, -1.001, -1.002, -1.004, -1.001, -1.001, -1.003, -1.003, -1.002, -1.0, -1.002, -1.002, -1.001, -1.001, -1.001, -1.002, -1.001, -1.001, -1.004, -1.002, -1.002, -1.0, -1.0019999999999998, -1.001, -1.001, -1.001, -1.002, -1.001, -1.002, -1.006, -1.002, -1.001, -1.003, -1.001, -1.002, -1.005, -1.001, -1.0, -1.001, -0.502, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2446627520633112, "mean_inference_ms": 1.4754089600813332, "mean_action_processing_ms": 0.06289964159131112, "mean_env_wait_ms": 0.08893848115410632, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022092001224921002, "StateBufferConnector_ms": 0.00152394054381828, "ViewRequirementAgentConnector_ms": 0.03273874763550797}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000, "num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.04713205419242, "num_env_steps_trained_throughput_per_sec": 102.04713205419242, "timesteps_total": 184000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 368000, "timers": {"training_iteration_time_ms": 38949.72, "sample_time_ms": 7552.097, "learn_time_ms": 31380.077, "learn_throughput": 127.469, "synch_weights_time_ms": 17.054}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 184000, "num_agent_steps_sampled": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 5302, "training_iteration": 46, "trial_id": "d67e4_00000", "date": "2023-09-20_22-39-07", "timestamp": 1695263947, "time_this_iter_s": 39.20312714576721, "time_total_s": 1789.3421704769135, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706dd0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1789.3421704769135, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 33.31964285714286, "ram_util_percent": 48.99285714285714}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.12857142857142856, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8071428571428572, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04285714285714286, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8071428571428572, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04285714285714286, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8071428571428572, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04285714285714286, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8318776317251226, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.010892609488534315, "policy_loss": -0.01682050576976811, "vf_loss": 0.006585664215769308, "vf_explained_var": 0.807317620391647, "kl": 0.007032464281100466, "entropy": 0.5295449631909529, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 44640.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "sampler_results": {"episode_reward_max": 1.9060000000000001, "episode_reward_min": -0.14900000000000002, "episode_reward_mean": 0.5368142857142857, "episode_len_mean": 28.435714285714287, "episode_media": {}, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.031}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.965}, "policy_reward_mean": {"red_0": 1.2675214285714287, "blue_0": -0.7307071428571427}, "custom_metrics": {"red_0/door_open_done_mean": 0.12857142857142856, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8071428571428572, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04285714285714286, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8071428571428572, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04285714285714286, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8071428571428572, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04285714285714286, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4590000000000001, 0.46899999999999986, 0.4630000000000001, 1.3679999999999999, 0.43900000000000006, -0.04200000000000004, 0.3860000000000001, 0.3760000000000001, 0.956, -0.03599999999999992, 0.46399999999999997, 0.4590000000000001, -0.038000000000000034, 0.46599999999999997, 0.41200000000000014, 0.44500000000000006, 0.3720000000000001, 0.44499999999999984, 0.46099999999999985, 0.43399999999999994, 0.47699999999999987, -0.14900000000000002, 0.45199999999999996, 0.46099999999999985, 0.46399999999999997, 0.3719999999999999, 0.4750000000000001, 0.4620000000000002, 0.46099999999999985, 1.453, -0.05900000000000005, 0.472, 1.448, 0.4670000000000001, 1.4249999999999998, 0.46399999999999997, 0.46599999999999997, 0.4710000000000001, 0.44799999999999995, 0.3959999999999999, 0.43399999999999994, 1.431, 0.601, 0.45599999999999996, 1.447, 0.44500000000000006, 0.44199999999999995, -0.031000000000000028, 1.9060000000000001, -0.05600000000000005, 1.45, 1.358, 0.4670000000000001, 1.38, 1.396, 0.45599999999999996, 0.42199999999999993, 1.454, 0.44999999999999996, 0.46599999999999997, 0.42799999999999994, 0.4710000000000001, 0.44799999999999995, 0.46099999999999985, 0.3919999999999999, 0.45799999999999996, 0.45100000000000007, 0.46799999999999997, 0.43899999999999995, 0.44999999999999996, -0.121, 0.46399999999999997, 0.46399999999999997, -0.027000000000000024, 0.43999999999999995, 1.452, 0.42200000000000015, 0.46899999999999986, 0.4670000000000001, 1.449, 1.442, 0.45699999999999996, -0.04200000000000004, 0.27, 0.43399999999999994, -0.03299999999999992, 0.4580000000000002, 0.46499999999999986, 0.47, -0.041999999999999926, 0.47299999999999986, 0.46899999999999986, 0.9249999999999998, 1.424, 0.43199999999999994, 0.4630000000000001, 0.46199999999999997, 0.46899999999999986, 0.4249999999999998, -0.04500000000000004, 0.46099999999999985, -0.06600000000000006, 0.46199999999999997, 0.43399999999999994, -0.02400000000000002, 0.367, 0.45699999999999985, 0.46399999999999997, 0.44799999999999995, 0.47, 1.452, 0.4670000000000001, 0.44799999999999995, 0.4630000000000001, 0.42899999999999994, 0.32000000000000006, 0.4750000000000001, 0.47, -0.03200000000000003, 0.21899999999999986, 0.4630000000000001, 0.45599999999999996, 0.45599999999999996, 0.46399999999999997, 0.956, 0.47, 0.45199999999999996, 1.4769999999999999, 0.45999999999999996, 0.45599999999999996, 0.46799999999999997, -0.03700000000000003, 0.953, 0.4590000000000001, 0.8940000000000001, 0.46099999999999985, 0.44199999999999995, 0.9569999999999999, 0.45199999999999996, 0.43199999999999994], "episode_lengths": [13, 10, 12, 42, 20, 13, 36, 39, 300, 11, 11, 13, 12, 11, 28, 17, 38, 18, 13, 21, 7, 205, 15, 13, 12, 42, 8, 12, 12, 15, 19, 9, 16, 11, 24, 11, 11, 9, 17, 32, 21, 22, 128, 13, 17, 17, 19, 10, 30, 18, 16, 45, 11, 37, 32, 14, 22, 15, 16, 11, 23, 9, 15, 13, 34, 13, 16, 10, 19, 16, 37, 12, 11, 9, 19, 16, 25, 10, 11, 16, 19, 14, 14, 73, 21, 10, 13, 11, 10, 13, 9, 10, 24, 25, 21, 12, 12, 10, 24, 14, 13, 179, 12, 21, 8, 42, 14, 12, 16, 10, 16, 11, 17, 12, 22, 56, 8, 10, 10, 88, 12, 14, 13, 11, 14, 10, 14, 167, 13, 300, 10, 12, 300, 13, 32, 13, 19, 14, 16, 22], "policy_red_0_reward": [1.4609999999999999, 1.47, 1.464, 1.373, 1.439, 0.961, 1.392, 1.379, 0.499, -1.001, -0.501, 1.4609999999999999, 0.964, 1.467, 1.416, 1.4489999999999998, 1.384, 1.446, 1.4609999999999999, 1.4369999999999998, 1.479, 0.882, 1.455, 0.961, 1.464, 1.374, 1.476, 1.464, 1.464, 1.455, 0.943, 1.4729999999999999, 1.452, 1.467, 1.427, 1.467, 1.467, 1.4729999999999999, 1.4489999999999998, 1.403, 1.436, 1.434, 1.116, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.443, 0.97, 1.4100000000000001, 0.946, 1.452, 1.363, 1.467, 1.387, 1.4, 1.458, 0.9229999999999999, 1.455, 1.452, 1.467, 1.431, 1.4729999999999999, 1.455, 1.4609999999999999, 1.397, 1.4609999999999999, 1.452, 1.47, -0.5, 1.452, 0.884, 1.464, 1.467, 0.973, 1.443, 1.452, 1.425, 1.47, 1.467, 1.452, 1.443, -0.5, 0.958, 1.2799999999999998, 1.4369999999999998, 0.97, 1.4609999999999999, 1.467, 1.47, 0.959, 1.4729999999999999, 1.47, 1.428, 1.425, 1.4369999999999998, 1.464, 1.464, 1.47, 1.427, 0.956, 1.4609999999999999, 0.962, 1.464, 1.4369999999999998, 0.976, 1.371, 1.458, -0.5, 1.452, 1.47, 1.452, 1.467, 1.4489999999999998, 1.464, -0.503, 1.33, 1.476, 1.47, 0.97, 1.233, 1.464, 1.458, 1.4609999999999999, 1.467, 1.458, 1.47, 1.458, 0.997, 1.4609999999999999, 0.499, 1.4689999999999999, 0.964, 0.497, 1.4609999999999999, 1.4, 1.4609999999999999, 1.443, 1.458, 1.452, 1.434], "policy_blue_0_reward": [-1.002, -1.001, -1.001, -0.005, -1.0, -1.003, -1.006, -1.003, 0.45699999999999996, 0.965, 0.965, -1.0019999999999998, -1.002, -1.001, -1.0039999999999998, -1.0039999999999998, -1.0119999999999998, -1.001, -1.0, -1.003, -1.002, -1.031, -1.003, -0.5, -1.0, -1.002, -1.001, -1.0019999999999998, -1.003, -0.002, -1.002, -1.001, -0.004, -1.0, -0.002, -1.003, -1.001, -1.0019999999999998, -1.001, -1.007, -1.002, -0.003, -0.515, -1.005, -0.002, -1.0039999999999998, -1.001, -1.001, 0.496, -1.002, -0.002, -0.005, -1.0, -0.007, -0.004, -1.002, -0.501, -0.001, -1.002, -1.001, -1.003, -1.0019999999999998, -1.007, -1.0, -1.005, -1.003, -1.001, -1.002, 0.939, -1.002, -1.005, -1.0, -1.003, -1.0, -1.003, 0.0, -1.003, -1.001, -1.0, -0.003, -0.001, 0.957, -1.0, -1.01, -1.003, -1.003, -1.003, -1.002, -1.0, -1.001, -1.0, -1.001, -0.503, -0.001, -1.005, -1.001, -1.002, -1.001, -1.002, -1.001, -1.0, -1.028, -1.002, -1.003, -1.0, -1.004, -1.001, 0.964, -1.004, -1.0, 0.0, -1.0, -1.001, -1.001, 0.9319999999999999, -1.0099999999999998, -1.001, -1.0, -1.002, -1.014, -1.001, -1.002, -1.005, -1.003, -0.502, -1.0, -1.006, 0.48, -1.001, -0.04300000000000003, -1.001, -1.001, 0.45599999999999996, -1.002, -0.5059999999999999, -1.0, -1.001, -0.501, -1.0, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24484227574966627, "mean_inference_ms": 1.4752835046873012, "mean_action_processing_ms": 0.06293195940733773, "mean_env_wait_ms": 0.08895164822050583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021617412567138672, "StateBufferConnector_ms": 0.001527411597115653, "ViewRequirementAgentConnector_ms": 0.0323998076575143}}, "episode_reward_max": 1.9060000000000001, "episode_reward_min": -0.14900000000000002, "episode_reward_mean": 0.5368142857142857, "episode_len_mean": 28.435714285714287, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.031}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.965}, "policy_reward_mean": {"red_0": 1.2675214285714287, "blue_0": -0.7307071428571427}, "hist_stats": {"episode_reward": [0.4590000000000001, 0.46899999999999986, 0.4630000000000001, 1.3679999999999999, 0.43900000000000006, -0.04200000000000004, 0.3860000000000001, 0.3760000000000001, 0.956, -0.03599999999999992, 0.46399999999999997, 0.4590000000000001, -0.038000000000000034, 0.46599999999999997, 0.41200000000000014, 0.44500000000000006, 0.3720000000000001, 0.44499999999999984, 0.46099999999999985, 0.43399999999999994, 0.47699999999999987, -0.14900000000000002, 0.45199999999999996, 0.46099999999999985, 0.46399999999999997, 0.3719999999999999, 0.4750000000000001, 0.4620000000000002, 0.46099999999999985, 1.453, -0.05900000000000005, 0.472, 1.448, 0.4670000000000001, 1.4249999999999998, 0.46399999999999997, 0.46599999999999997, 0.4710000000000001, 0.44799999999999995, 0.3959999999999999, 0.43399999999999994, 1.431, 0.601, 0.45599999999999996, 1.447, 0.44500000000000006, 0.44199999999999995, -0.031000000000000028, 1.9060000000000001, -0.05600000000000005, 1.45, 1.358, 0.4670000000000001, 1.38, 1.396, 0.45599999999999996, 0.42199999999999993, 1.454, 0.44999999999999996, 0.46599999999999997, 0.42799999999999994, 0.4710000000000001, 0.44799999999999995, 0.46099999999999985, 0.3919999999999999, 0.45799999999999996, 0.45100000000000007, 0.46799999999999997, 0.43899999999999995, 0.44999999999999996, -0.121, 0.46399999999999997, 0.46399999999999997, -0.027000000000000024, 0.43999999999999995, 1.452, 0.42200000000000015, 0.46899999999999986, 0.4670000000000001, 1.449, 1.442, 0.45699999999999996, -0.04200000000000004, 0.27, 0.43399999999999994, -0.03299999999999992, 0.4580000000000002, 0.46499999999999986, 0.47, -0.041999999999999926, 0.47299999999999986, 0.46899999999999986, 0.9249999999999998, 1.424, 0.43199999999999994, 0.4630000000000001, 0.46199999999999997, 0.46899999999999986, 0.4249999999999998, -0.04500000000000004, 0.46099999999999985, -0.06600000000000006, 0.46199999999999997, 0.43399999999999994, -0.02400000000000002, 0.367, 0.45699999999999985, 0.46399999999999997, 0.44799999999999995, 0.47, 1.452, 0.4670000000000001, 0.44799999999999995, 0.4630000000000001, 0.42899999999999994, 0.32000000000000006, 0.4750000000000001, 0.47, -0.03200000000000003, 0.21899999999999986, 0.4630000000000001, 0.45599999999999996, 0.45599999999999996, 0.46399999999999997, 0.956, 0.47, 0.45199999999999996, 1.4769999999999999, 0.45999999999999996, 0.45599999999999996, 0.46799999999999997, -0.03700000000000003, 0.953, 0.4590000000000001, 0.8940000000000001, 0.46099999999999985, 0.44199999999999995, 0.9569999999999999, 0.45199999999999996, 0.43199999999999994], "episode_lengths": [13, 10, 12, 42, 20, 13, 36, 39, 300, 11, 11, 13, 12, 11, 28, 17, 38, 18, 13, 21, 7, 205, 15, 13, 12, 42, 8, 12, 12, 15, 19, 9, 16, 11, 24, 11, 11, 9, 17, 32, 21, 22, 128, 13, 17, 17, 19, 10, 30, 18, 16, 45, 11, 37, 32, 14, 22, 15, 16, 11, 23, 9, 15, 13, 34, 13, 16, 10, 19, 16, 37, 12, 11, 9, 19, 16, 25, 10, 11, 16, 19, 14, 14, 73, 21, 10, 13, 11, 10, 13, 9, 10, 24, 25, 21, 12, 12, 10, 24, 14, 13, 179, 12, 21, 8, 42, 14, 12, 16, 10, 16, 11, 17, 12, 22, 56, 8, 10, 10, 88, 12, 14, 13, 11, 14, 10, 14, 167, 13, 300, 10, 12, 300, 13, 32, 13, 19, 14, 16, 22], "policy_red_0_reward": [1.4609999999999999, 1.47, 1.464, 1.373, 1.439, 0.961, 1.392, 1.379, 0.499, -1.001, -0.501, 1.4609999999999999, 0.964, 1.467, 1.416, 1.4489999999999998, 1.384, 1.446, 1.4609999999999999, 1.4369999999999998, 1.479, 0.882, 1.455, 0.961, 1.464, 1.374, 1.476, 1.464, 1.464, 1.455, 0.943, 1.4729999999999999, 1.452, 1.467, 1.427, 1.467, 1.467, 1.4729999999999999, 1.4489999999999998, 1.403, 1.436, 1.434, 1.116, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.443, 0.97, 1.4100000000000001, 0.946, 1.452, 1.363, 1.467, 1.387, 1.4, 1.458, 0.9229999999999999, 1.455, 1.452, 1.467, 1.431, 1.4729999999999999, 1.455, 1.4609999999999999, 1.397, 1.4609999999999999, 1.452, 1.47, -0.5, 1.452, 0.884, 1.464, 1.467, 0.973, 1.443, 1.452, 1.425, 1.47, 1.467, 1.452, 1.443, -0.5, 0.958, 1.2799999999999998, 1.4369999999999998, 0.97, 1.4609999999999999, 1.467, 1.47, 0.959, 1.4729999999999999, 1.47, 1.428, 1.425, 1.4369999999999998, 1.464, 1.464, 1.47, 1.427, 0.956, 1.4609999999999999, 0.962, 1.464, 1.4369999999999998, 0.976, 1.371, 1.458, -0.5, 1.452, 1.47, 1.452, 1.467, 1.4489999999999998, 1.464, -0.503, 1.33, 1.476, 1.47, 0.97, 1.233, 1.464, 1.458, 1.4609999999999999, 1.467, 1.458, 1.47, 1.458, 0.997, 1.4609999999999999, 0.499, 1.4689999999999999, 0.964, 0.497, 1.4609999999999999, 1.4, 1.4609999999999999, 1.443, 1.458, 1.452, 1.434], "policy_blue_0_reward": [-1.002, -1.001, -1.001, -0.005, -1.0, -1.003, -1.006, -1.003, 0.45699999999999996, 0.965, 0.965, -1.0019999999999998, -1.002, -1.001, -1.0039999999999998, -1.0039999999999998, -1.0119999999999998, -1.001, -1.0, -1.003, -1.002, -1.031, -1.003, -0.5, -1.0, -1.002, -1.001, -1.0019999999999998, -1.003, -0.002, -1.002, -1.001, -0.004, -1.0, -0.002, -1.003, -1.001, -1.0019999999999998, -1.001, -1.007, -1.002, -0.003, -0.515, -1.005, -0.002, -1.0039999999999998, -1.001, -1.001, 0.496, -1.002, -0.002, -0.005, -1.0, -0.007, -0.004, -1.002, -0.501, -0.001, -1.002, -1.001, -1.003, -1.0019999999999998, -1.007, -1.0, -1.005, -1.003, -1.001, -1.002, 0.939, -1.002, -1.005, -1.0, -1.003, -1.0, -1.003, 0.0, -1.003, -1.001, -1.0, -0.003, -0.001, 0.957, -1.0, -1.01, -1.003, -1.003, -1.003, -1.002, -1.0, -1.001, -1.0, -1.001, -0.503, -0.001, -1.005, -1.001, -1.002, -1.001, -1.002, -1.001, -1.0, -1.028, -1.002, -1.003, -1.0, -1.004, -1.001, 0.964, -1.004, -1.0, 0.0, -1.0, -1.001, -1.001, 0.9319999999999999, -1.0099999999999998, -1.001, -1.0, -1.002, -1.014, -1.001, -1.002, -1.005, -1.003, -0.502, -1.0, -1.006, 0.48, -1.001, -0.04300000000000003, -1.001, -1.001, 0.45599999999999996, -1.002, -0.5059999999999999, -1.0, -1.001, -0.501, -1.0, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24484227574966627, "mean_inference_ms": 1.4752835046873012, "mean_action_processing_ms": 0.06293195940733773, "mean_env_wait_ms": 0.08895164822050583, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021617412567138672, "StateBufferConnector_ms": 0.001527411597115653, "ViewRequirementAgentConnector_ms": 0.0323998076575143}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000, "num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.4798115324202, "num_env_steps_trained_throughput_per_sec": 102.4798115324202, "timesteps_total": 188000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 376000, "timers": {"training_iteration_time_ms": 38941.727, "sample_time_ms": 7551.223, "learn_time_ms": 31372.977, "learn_throughput": 127.498, "synch_weights_time_ms": 17.029}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 188000, "num_agent_steps_sampled": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 5442, "training_iteration": 47, "trial_id": "d67e4_00000", "date": "2023-09-20_22-39-46", "timestamp": 1695263986, "time_this_iter_s": 39.038185119628906, "time_total_s": 1828.3803555965424, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706b90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1828.3803555965424, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 34.93035714285714, "ram_util_percent": 49.00178571428571}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.06666666666666667, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8833333333333333, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.025, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8833333333333333, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.025, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8833333333333333, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.025, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.216112044205268, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009778895117415231, "policy_loss": -0.01475872594868027, "vf_loss": 0.00492103790990465, "vf_explained_var": 0.8477476838976145, "kl": 0.006703575661368085, "entropy": 0.4972970265895128, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 45600.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "sampler_results": {"episode_reward_max": 1.45, "episode_reward_min": -0.30400000000000005, "episode_reward_mean": 0.4437833333333333, "episode_len_mean": 35.46666666666667, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.2831583333333332, "blue_0": -0.8393750000000001}, "custom_metrics": {"red_0/door_open_done_mean": 0.06666666666666667, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8833333333333333, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.025, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8833333333333333, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.025, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8833333333333333, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.025, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.957, 0.472, 0.47, 0.4710000000000001, 0.46599999999999997, 0.4750000000000001, 0.45699999999999985, 0.47, 0.472, 0.45100000000000007, 0.3959999999999999, 1.357, 0.44700000000000006, -0.025999999999999912, 0.46399999999999997, 0.45599999999999996, 0.4630000000000001, 0.45199999999999996, 0.2709999999999999, 0.44599999999999995, 0.45299999999999985, 0.4630000000000001, 0.4610000000000001, -0.062000000000000055, -0.15699999999999992, 0.4630000000000001, 0.44700000000000006, 0.43399999999999994, 0.848, 0.44899999999999984, 0.4590000000000001, 0.46199999999999997, 1.4409999999999998, 0.32499999999999996, 0.4650000000000001, 0.41600000000000015, 0.46099999999999985, 0.47, 0.97, 0.46499999999999986, 0.43100000000000005, 0.911, 0.45100000000000007, 0.42200000000000015, 0.42999999999999994, 0.22199999999999998, 0.3999999999999999, 0.44100000000000006, -0.02100000000000002, -0.050999999999999934, 0.94, 0.45199999999999996, 0.45399999999999996, 0.44599999999999995, 0.45599999999999996, 0.43100000000000005, 0.4630000000000001, 0.4670000000000001, 0.3250000000000002, 0.46599999999999997, 0.391, 0.4630000000000001, 0.46099999999999985, 0.472, 0.46399999999999997, 0.45199999999999996, 0.46199999999999997, 1.438, 0.4750000000000001, 0.45599999999999996, 0.45599999999999996, 0.44999999999999996, 1.2189999999999999, 0.952, 0.45999999999999996, 0.46599999999999997, 0.33099999999999996, 0.46499999999999986, 0.403, -0.09699999999999998, 1.4449999999999998, 0.46499999999999986, 0.45100000000000007, -0.03500000000000003, 0.401, -0.2520000000000001, 0.4710000000000001, 0.45399999999999996, 0.403, 0.4630000000000001, 0.46399999999999997, 0.45199999999999996, 0.474, -0.30400000000000005, -0.03300000000000003, 0.43799999999999994, 0.44300000000000006, -0.16600000000000004, 0.04100000000000015, -0.029000000000000026, 0.8019999999999999, -0.030000000000000027, 0.44999999999999996, 0.44999999999999996, 0.43199999999999994, 1.45, 0.45500000000000007, 0.45599999999999996, 0.46799999999999997, 0.46799999999999997, 0.46599999999999997, -0.038000000000000034, 0.46399999999999997, 0.41300000000000003, 0.44399999999999995, 0.9409999999999998, -0.06900000000000006, 0.46599999999999997, -0.04500000000000004, -0.030000000000000027], "episode_lengths": [300, 9, 10, 9, 11, 8, 14, 10, 9, 15, 30, 46, 17, 8, 11, 14, 12, 15, 73, 17, 15, 12, 12, 20, 208, 12, 17, 21, 206, 16, 13, 12, 19, 55, 11, 26, 12, 9, 10, 11, 22, 29, 16, 25, 22, 87, 31, 19, 7, 16, 19, 15, 14, 17, 14, 19, 12, 11, 55, 11, 35, 12, 13, 9, 12, 16, 12, 20, 8, 14, 14, 16, 87, 300, 13, 11, 53, 11, 30, 31, 18, 11, 16, 11, 30, 237, 9, 15, 31, 12, 11, 15, 8, 256, 10, 20, 18, 54, 144, 9, 217, 10, 16, 16, 22, 16, 14, 300, 10, 10, 11, 12, 12, 28, 18, 19, 22, 11, 14, 10], "policy_red_0_reward": [0.499, 1.4729999999999999, 1.47, 1.4729999999999999, 1.467, 1.476, 1.458, 1.47, 1.4729999999999999, 1.455, 1.4, 1.361, 1.4489999999999998, 0.976, 1.467, 1.4569999999999999, 1.464, 1.455, 1.279, 1.448, 1.455, 1.464, 1.464, 0.94, 0.873, 1.464, 1.4489999999999998, 1.436, 0.88, 1.452, 1.4609999999999999, 1.464, 1.443, 1.334, 1.467, 1.42, 1.464, 1.4729999999999999, -0.5, 1.467, 1.4329999999999998, 1.412, 1.452, 1.425, 1.432, 1.236, 1.4060000000000001, 1.443, 0.979, 0.952, 1.443, 1.455, 1.456, 1.446, 1.458, 1.4369999999999998, 1.463, 1.467, 1.3319999999999999, 1.466, 1.395, 1.464, 1.4609999999999999, -0.5, 1.464, 1.452, 1.464, 1.44, 1.476, 1.458, 1.458, 1.452, 1.238, 0.494, 1.4609999999999999, 1.467, 1.338, 1.467, 1.408, 0.906, 1.446, 1.467, 1.452, 0.967, 1.4060000000000001, 0.7869999999999999, 1.4729999999999999, 1.455, 1.404, 1.464, 1.467, 1.455, 1.476, 0.732, 0.97, 1.44, 1.446, 0.836, 1.064, 0.972, 0.842, 0.97, 1.452, 1.452, 1.434, 1.452, 1.458, 0.494, 1.47, 1.47, 1.467, 0.964, 1.464, -0.502, 1.446, 1.443, 0.9339999999999999, 1.467, 0.957, 0.97], "policy_blue_0_reward": [0.45799999999999996, -1.001, -1.0, -1.002, -1.001, -1.001, -1.001, -1.0, -1.001, -1.0039999999999998, -1.004, -0.004, -1.002, -1.0019999999999998, -1.003, -1.001, -1.001, -1.003, -1.008, -1.002, -1.002, -1.001, -1.003, -1.002, -1.0299999999999998, -1.001, -1.002, -1.002, -0.03200000000000002, -1.003, -1.002, -1.002, -0.002, -1.009, -1.0019999999999998, -1.0039999999999998, -1.003, -1.003, 1.47, -1.002, -1.002, -0.501, -1.001, -1.003, -1.002, -1.014, -1.006, -1.0019999999999998, -1.0, -1.003, -0.503, -1.003, -1.002, -1.0, -1.002, -1.0059999999999998, -1.0, -1.0, -1.007, -1.0, -1.004, -1.001, -1.0, 0.972, -1.0, -1.0, -1.002, -0.002, -1.001, -1.002, -1.002, -1.002, -0.01900000000000001, 0.45799999999999996, -1.001, -1.001, -1.007, -1.002, -1.005, -1.003, -0.001, -1.002, -1.001, -1.002, -1.005, -1.039, -1.002, -1.001, -1.001, -1.001, -1.003, -1.003, -1.002, -1.036, -1.003, -1.002, -1.003, -1.002, -1.023, -1.001, -0.04000000000000003, -1.0, -1.002, -1.002, -1.002, -0.002, -1.003, -0.03800000000000003, -1.002, -1.002, -1.001, -1.002, -1.0, 0.915, -1.002, -0.502, -1.003, -1.001, -1.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24536853811094075, "mean_inference_ms": 1.4766423270294382, "mean_action_processing_ms": 0.0630796268152147, "mean_env_wait_ms": 0.08905746766147296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021623075008392334, "StateBufferConnector_ms": 0.0015267729759216309, "ViewRequirementAgentConnector_ms": 0.03255277872085571}}, "episode_reward_max": 1.45, "episode_reward_min": -0.30400000000000005, "episode_reward_mean": 0.4437833333333333, "episode_len_mean": 35.46666666666667, "episodes_this_iter": 120, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.47}, "policy_reward_mean": {"red_0": 1.2831583333333332, "blue_0": -0.8393750000000001}, "hist_stats": {"episode_reward": [0.957, 0.472, 0.47, 0.4710000000000001, 0.46599999999999997, 0.4750000000000001, 0.45699999999999985, 0.47, 0.472, 0.45100000000000007, 0.3959999999999999, 1.357, 0.44700000000000006, -0.025999999999999912, 0.46399999999999997, 0.45599999999999996, 0.4630000000000001, 0.45199999999999996, 0.2709999999999999, 0.44599999999999995, 0.45299999999999985, 0.4630000000000001, 0.4610000000000001, -0.062000000000000055, -0.15699999999999992, 0.4630000000000001, 0.44700000000000006, 0.43399999999999994, 0.848, 0.44899999999999984, 0.4590000000000001, 0.46199999999999997, 1.4409999999999998, 0.32499999999999996, 0.4650000000000001, 0.41600000000000015, 0.46099999999999985, 0.47, 0.97, 0.46499999999999986, 0.43100000000000005, 0.911, 0.45100000000000007, 0.42200000000000015, 0.42999999999999994, 0.22199999999999998, 0.3999999999999999, 0.44100000000000006, -0.02100000000000002, -0.050999999999999934, 0.94, 0.45199999999999996, 0.45399999999999996, 0.44599999999999995, 0.45599999999999996, 0.43100000000000005, 0.4630000000000001, 0.4670000000000001, 0.3250000000000002, 0.46599999999999997, 0.391, 0.4630000000000001, 0.46099999999999985, 0.472, 0.46399999999999997, 0.45199999999999996, 0.46199999999999997, 1.438, 0.4750000000000001, 0.45599999999999996, 0.45599999999999996, 0.44999999999999996, 1.2189999999999999, 0.952, 0.45999999999999996, 0.46599999999999997, 0.33099999999999996, 0.46499999999999986, 0.403, -0.09699999999999998, 1.4449999999999998, 0.46499999999999986, 0.45100000000000007, -0.03500000000000003, 0.401, -0.2520000000000001, 0.4710000000000001, 0.45399999999999996, 0.403, 0.4630000000000001, 0.46399999999999997, 0.45199999999999996, 0.474, -0.30400000000000005, -0.03300000000000003, 0.43799999999999994, 0.44300000000000006, -0.16600000000000004, 0.04100000000000015, -0.029000000000000026, 0.8019999999999999, -0.030000000000000027, 0.44999999999999996, 0.44999999999999996, 0.43199999999999994, 1.45, 0.45500000000000007, 0.45599999999999996, 0.46799999999999997, 0.46799999999999997, 0.46599999999999997, -0.038000000000000034, 0.46399999999999997, 0.41300000000000003, 0.44399999999999995, 0.9409999999999998, -0.06900000000000006, 0.46599999999999997, -0.04500000000000004, -0.030000000000000027], "episode_lengths": [300, 9, 10, 9, 11, 8, 14, 10, 9, 15, 30, 46, 17, 8, 11, 14, 12, 15, 73, 17, 15, 12, 12, 20, 208, 12, 17, 21, 206, 16, 13, 12, 19, 55, 11, 26, 12, 9, 10, 11, 22, 29, 16, 25, 22, 87, 31, 19, 7, 16, 19, 15, 14, 17, 14, 19, 12, 11, 55, 11, 35, 12, 13, 9, 12, 16, 12, 20, 8, 14, 14, 16, 87, 300, 13, 11, 53, 11, 30, 31, 18, 11, 16, 11, 30, 237, 9, 15, 31, 12, 11, 15, 8, 256, 10, 20, 18, 54, 144, 9, 217, 10, 16, 16, 22, 16, 14, 300, 10, 10, 11, 12, 12, 28, 18, 19, 22, 11, 14, 10], "policy_red_0_reward": [0.499, 1.4729999999999999, 1.47, 1.4729999999999999, 1.467, 1.476, 1.458, 1.47, 1.4729999999999999, 1.455, 1.4, 1.361, 1.4489999999999998, 0.976, 1.467, 1.4569999999999999, 1.464, 1.455, 1.279, 1.448, 1.455, 1.464, 1.464, 0.94, 0.873, 1.464, 1.4489999999999998, 1.436, 0.88, 1.452, 1.4609999999999999, 1.464, 1.443, 1.334, 1.467, 1.42, 1.464, 1.4729999999999999, -0.5, 1.467, 1.4329999999999998, 1.412, 1.452, 1.425, 1.432, 1.236, 1.4060000000000001, 1.443, 0.979, 0.952, 1.443, 1.455, 1.456, 1.446, 1.458, 1.4369999999999998, 1.463, 1.467, 1.3319999999999999, 1.466, 1.395, 1.464, 1.4609999999999999, -0.5, 1.464, 1.452, 1.464, 1.44, 1.476, 1.458, 1.458, 1.452, 1.238, 0.494, 1.4609999999999999, 1.467, 1.338, 1.467, 1.408, 0.906, 1.446, 1.467, 1.452, 0.967, 1.4060000000000001, 0.7869999999999999, 1.4729999999999999, 1.455, 1.404, 1.464, 1.467, 1.455, 1.476, 0.732, 0.97, 1.44, 1.446, 0.836, 1.064, 0.972, 0.842, 0.97, 1.452, 1.452, 1.434, 1.452, 1.458, 0.494, 1.47, 1.47, 1.467, 0.964, 1.464, -0.502, 1.446, 1.443, 0.9339999999999999, 1.467, 0.957, 0.97], "policy_blue_0_reward": [0.45799999999999996, -1.001, -1.0, -1.002, -1.001, -1.001, -1.001, -1.0, -1.001, -1.0039999999999998, -1.004, -0.004, -1.002, -1.0019999999999998, -1.003, -1.001, -1.001, -1.003, -1.008, -1.002, -1.002, -1.001, -1.003, -1.002, -1.0299999999999998, -1.001, -1.002, -1.002, -0.03200000000000002, -1.003, -1.002, -1.002, -0.002, -1.009, -1.0019999999999998, -1.0039999999999998, -1.003, -1.003, 1.47, -1.002, -1.002, -0.501, -1.001, -1.003, -1.002, -1.014, -1.006, -1.0019999999999998, -1.0, -1.003, -0.503, -1.003, -1.002, -1.0, -1.002, -1.0059999999999998, -1.0, -1.0, -1.007, -1.0, -1.004, -1.001, -1.0, 0.972, -1.0, -1.0, -1.002, -0.002, -1.001, -1.002, -1.002, -1.002, -0.01900000000000001, 0.45799999999999996, -1.001, -1.001, -1.007, -1.002, -1.005, -1.003, -0.001, -1.002, -1.001, -1.002, -1.005, -1.039, -1.002, -1.001, -1.001, -1.001, -1.003, -1.003, -1.002, -1.036, -1.003, -1.002, -1.003, -1.002, -1.023, -1.001, -0.04000000000000003, -1.0, -1.002, -1.002, -1.002, -0.002, -1.003, -0.03800000000000003, -1.002, -1.002, -1.001, -1.002, -1.0, 0.915, -1.002, -0.502, -1.003, -1.001, -1.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24536853811094075, "mean_inference_ms": 1.4766423270294382, "mean_action_processing_ms": 0.0630796268152147, "mean_env_wait_ms": 0.08905746766147296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021623075008392334, "StateBufferConnector_ms": 0.0015267729759216309, "ViewRequirementAgentConnector_ms": 0.03255277872085571}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000, "num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.93993137503982, "num_env_steps_trained_throughput_per_sec": 102.93993137503982, "timesteps_total": 192000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 384000, "timers": {"training_iteration_time_ms": 38927.671, "sample_time_ms": 7549.384, "learn_time_ms": 31360.784, "learn_throughput": 127.548, "synch_weights_time_ms": 17.006}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 192000, "num_agent_steps_sampled": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 5562, "training_iteration": 48, "trial_id": "d67e4_00000", "date": "2023-09-20_22-40-25", "timestamp": 1695264025, "time_this_iter_s": 38.86305618286133, "time_total_s": 1867.2434117794037, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706a70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1867.2434117794037, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 34.52363636363636, "ram_util_percent": 48.967272727272736}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.12269938650306748, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8159509202453987, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.049079754601226995, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8159509202453987, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.049079754601226995, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8159509202453987, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.049079754601226995, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.911807068126897, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.008203279149529407, "policy_loss": -0.014469411280394221, "vf_loss": 0.008386811685098413, "vf_explained_var": 0.7892664620652795, "kl": 0.0055862925425392024, "entropy": 0.4411049793784817, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 46560.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "sampler_results": {"episode_reward_max": 1.458, "episode_reward_min": -0.21100000000000008, "episode_reward_mean": 0.5254539877300614, "episode_len_mean": 27.484662576687118, "episode_media": {}, "episodes_this_iter": 163, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.972}, "policy_reward_mean": {"red_0": 1.2729754601226995, "blue_0": -0.7475214723926379}, "custom_metrics": {"red_0/door_open_done_mean": 0.12269938650306748, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8159509202453987, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.049079754601226995, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8159509202453987, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.049079754601226995, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8159509202453987, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.049079754601226995, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.693, 0.46399999999999997, 0.46099999999999985, 1.401, 0.46599999999999997, -0.02400000000000002, 0.401, 1.448, 0.45500000000000007, 0.44899999999999984, 0.45799999999999996, 1.451, 1.4449999999999998, 0.45299999999999985, 0.43199999999999994, 0.44999999999999996, 0.45999999999999996, 0.45799999999999996, 0.43699999999999983, 0.45699999999999985, 0.43399999999999994, 0.395, 0.3860000000000001, 0.45599999999999996, 0.20500000000000007, 0.46899999999999986, 0.44700000000000006, 0.4570000000000001, -0.030000000000000027, 0.46899999999999986, 0.45500000000000007, 1.44, -0.050000000000000044, 0.43699999999999983, 0.45399999999999996, 0.43599999999999994, 0.32200000000000006, 0.45799999999999996, 0.4710000000000001, -0.028000000000000025, 0.44799999999999995, 0.45799999999999996, 0.45699999999999985, 0.46499999999999986, 0.44799999999999995, 0.399, 0.44899999999999984, 0.381, 0.7050000000000001, 0.4590000000000001, 1.442, 0.44799999999999995, -0.02400000000000002, 0.45300000000000007, 0.405, 0.4630000000000001, 0.4249999999999998, 0.33099999999999996, 0.46799999999999997, 0.45699999999999985, 0.3959999999999999, 0.46599999999999997, -0.05700000000000005, 0.4670000000000001, 0.3420000000000001, -0.04400000000000004, 0.45199999999999996, 0.4630000000000001, 0.44199999999999995, 0.44899999999999984, 0.44700000000000006, 0.4590000000000001, 0.4710000000000001, 0.46399999999999997, -0.027000000000000024, 0.248, 0.45599999999999996, 1.4529999999999998, 0.42799999999999994, 0.43500000000000005, 0.472, 0.46499999999999986, 1.233, 0.43799999999999994, 0.17399999999999993, 0.46099999999999985, -0.05100000000000004, 0.45599999999999996, 0.46599999999999997, 0.45500000000000007, 1.44, 0.4590000000000001, 0.44700000000000006, 0.9649999999999999, 0.45999999999999996, 0.46499999999999986, 0.472, 1.458, 0.46799999999999997, 1.451, 1.436, 1.431, 0.45799999999999996, 0.46099999999999985, 0.45500000000000007, 0.9590000000000001, 0.44200000000000017, 0.46399999999999997, 0.9279999999999999, 0.47299999999999986, 0.45699999999999985, 0.46099999999999985, 0.46799999999999997, 0.4590000000000001, 0.4590000000000001, 0.9189999999999999, 0.45599999999999996, -0.02100000000000002, 0.9089999999999999, 0.45199999999999996, -0.21100000000000008, 0.46699999999999997, 0.44499999999999984, 0.472, 0.46399999999999997, 0.4079999999999999, 0.901, -0.026000000000000023, 0.45500000000000007, 0.45699999999999985, 0.4630000000000001, 0.32199999999999995, 1.448, 1.282, 0.45199999999999996, 0.43999999999999995, 0.43900000000000006, 0.44399999999999995, 0.45199999999999996, 0.472, 0.9319999999999999, 1.451, 0.46499999999999986, 0.45999999999999996, 0.953, 0.46599999999999997, -0.025999999999999912, 0.42399999999999993, 0.476, 0.44700000000000006, 0.4630000000000001, 0.4630000000000001, 0.40400000000000014, 0.4630000000000001, 0.46399999999999997, 0.4670000000000001, -0.049000000000000044, 0.46399999999999997, 0.4670000000000001, 1.3530000000000002, 0.472, 0.43900000000000006, -0.040000000000000036], "episode_lengths": [256, 11, 12, 32, 11, 7, 31, 17, 15, 16, 13, 15, 17, 15, 181, 16, 13, 13, 20, 14, 22, 32, 36, 14, 93, 10, 17, 13, 10, 10, 14, 18, 16, 20, 15, 20, 57, 13, 9, 9, 16, 14, 14, 11, 16, 30, 16, 38, 93, 13, 19, 17, 8, 15, 31, 11, 24, 53, 10, 13, 34, 11, 17, 10, 49, 14, 15, 12, 19, 15, 17, 13, 9, 12, 9, 81, 13, 15, 24, 20, 9, 11, 86, 20, 104, 12, 300, 14, 11, 14, 19, 13, 16, 11, 13, 11, 9, 14, 10, 16, 20, 22, 13, 12, 14, 13, 18, 12, 23, 9, 14, 13, 10, 13, 13, 186, 14, 7, 188, 15, 61, 11, 17, 9, 11, 29, 32, 8, 14, 14, 12, 56, 17, 69, 15, 18, 19, 18, 15, 9, 22, 15, 11, 13, 300, 11, 8, 24, 8, 17, 11, 12, 30, 12, 12, 11, 16, 11, 11, 45, 9, 19, 12], "policy_red_0_reward": [0.728, 1.467, 1.464, 1.404, 1.467, 0.979, 1.405, 1.4489999999999998, 1.455, 1.452, 1.4609999999999999, 1.455, 1.4489999999999998, 1.455, 0.956, 1.452, 1.4609999999999999, 1.4609999999999999, 1.44, 1.458, 1.434, 1.404, 1.391, 1.458, 1.22, 1.47, 1.4489999999999998, 1.4609999999999999, 0.97, 1.47, 1.458, 1.446, -1.0, 1.44, 1.455, 1.44, 1.327, 1.4609999999999999, 1.4729999999999999, 0.973, 1.452, 1.458, 1.458, 1.467, -0.5, 1.4060000000000001, 1.452, 1.385, 1.22, 1.46, 1.443, -0.5, 0.976, 1.455, 1.407, 1.467, 1.428, 1.338, 1.47, 1.4609999999999999, 1.3980000000000001, 1.467, 0.945, 1.47, 1.353, 0.957, 1.455, 1.464, 1.443, 1.455, 1.4489999999999998, 1.4609999999999999, 1.4729999999999999, 1.464, 0.973, -0.501, 1.4609999999999999, 1.455, 1.428, 1.438, 1.4729999999999999, 1.467, 1.241, 1.44, 1.1869999999999998, 1.464, -0.006, 1.458, 1.467, 1.458, 1.442, 1.4609999999999999, 1.452, 1.467, 1.4609999999999999, 1.467, 1.4729999999999999, 1.458, 1.47, 1.452, 1.44, 1.434, 1.4609999999999999, 1.464, 1.458, 1.4609999999999999, 1.446, 1.464, 1.431, 1.4729999999999999, 1.458, 1.4609999999999999, 1.47, 1.4609999999999999, 1.4609999999999999, 0.9369999999999999, 1.458, 0.979, 0.9339999999999999, 1.455, 0.7959999999999999, -0.5, 1.4489999999999998, 1.4729999999999999, 1.467, 1.413, 1.404, 0.975, 1.458, 1.458, 1.464, -0.501, 1.4489999999999998, 1.291, 1.455, 1.446, 1.443, 1.446, 1.455, -0.5, 1.434, 1.455, 1.467, 1.4609999999999999, 0.5, 1.467, 0.976, 1.428, 1.476, 0.949, 1.467, 1.464, -0.5009999999999999, 1.464, 1.464, 1.467, 0.952, 1.467, 1.467, 1.363, 1.4729999999999999, 1.443, 0.964], "policy_blue_0_reward": [-0.035000000000000024, -1.003, -1.003, -0.003, -1.001, -1.003, -1.004, -0.001, -1.0, -1.003, -1.003, -0.004, -0.004, -1.002, -0.524, -1.002, -1.001, -1.003, -1.003, -1.001, -1.0, -1.009, -1.005, -1.002, -1.015, -1.001, -1.002, -1.0039999999999998, -1.0, -1.001, -1.003, -0.006, 0.95, -1.003, -1.001, -1.004, -1.005, -1.003, -1.0019999999999998, -1.001, -1.004, -1.0, -1.001, -1.002, 0.948, -1.007, -1.003, -1.004, -0.515, -1.001, -0.001, 0.948, -1.0, -1.0019999999999998, -1.002, -1.004, -1.003, -1.007, -1.002, -1.004, -1.002, -1.001, -1.002, -1.003, -1.011, -1.001, -1.003, -1.001, -1.001, -1.006, -1.002, -1.002, -1.0019999999999998, -1.0, -1.0, 0.749, -1.005, -0.002, -1.0, -1.003, -1.001, -1.002, -0.008, -1.002, -1.013, -1.003, -0.04500000000000003, -1.002, -1.001, -1.003, -0.002, -1.0019999999999998, -1.005, -0.502, -1.001, -1.002, -1.001, 0.0, -1.002, -0.001, -0.004, -0.003, -1.003, -1.003, -1.003, -0.5019999999999999, -1.0039999999999998, -1.0, -0.503, -1.0, -1.001, -1.0, -1.002, -1.002, -1.0019999999999998, -0.01800000000000001, -1.002, -1.0, -0.025000000000000015, -1.003, -1.007, 0.967, -1.004, -1.001, -1.003, -1.005, -0.503, -1.001, -1.003, -1.001, -1.001, 0.823, -0.001, -0.009000000000000001, -1.003, -1.006, -1.0039999999999998, -1.0019999999999998, -1.003, 0.972, -0.5019999999999999, -0.004, -1.002, -1.001, 0.45299999999999996, -1.001, -1.0019999999999998, -1.0039999999999998, -1.0, -0.502, -1.0039999999999998, -1.001, 0.905, -1.001, -1.0, -1.0, -1.001, -1.003, -1.0, -0.010000000000000002, -1.001, -1.0039999999999998, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24548922161822362, "mean_inference_ms": 1.4759553149194524, "mean_action_processing_ms": 0.06300578101101241, "mean_env_wait_ms": 0.08897397169699386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02151354690270921, "StateBufferConnector_ms": 0.0015478924008234878, "ViewRequirementAgentConnector_ms": 0.03254698829416849}}, "episode_reward_max": 1.458, "episode_reward_min": -0.21100000000000008, "episode_reward_mean": 0.5254539877300614, "episode_len_mean": 27.484662576687118, "episodes_this_iter": 163, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.015}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.972}, "policy_reward_mean": {"red_0": 1.2729754601226995, "blue_0": -0.7475214723926379}, "hist_stats": {"episode_reward": [0.693, 0.46399999999999997, 0.46099999999999985, 1.401, 0.46599999999999997, -0.02400000000000002, 0.401, 1.448, 0.45500000000000007, 0.44899999999999984, 0.45799999999999996, 1.451, 1.4449999999999998, 0.45299999999999985, 0.43199999999999994, 0.44999999999999996, 0.45999999999999996, 0.45799999999999996, 0.43699999999999983, 0.45699999999999985, 0.43399999999999994, 0.395, 0.3860000000000001, 0.45599999999999996, 0.20500000000000007, 0.46899999999999986, 0.44700000000000006, 0.4570000000000001, -0.030000000000000027, 0.46899999999999986, 0.45500000000000007, 1.44, -0.050000000000000044, 0.43699999999999983, 0.45399999999999996, 0.43599999999999994, 0.32200000000000006, 0.45799999999999996, 0.4710000000000001, -0.028000000000000025, 0.44799999999999995, 0.45799999999999996, 0.45699999999999985, 0.46499999999999986, 0.44799999999999995, 0.399, 0.44899999999999984, 0.381, 0.7050000000000001, 0.4590000000000001, 1.442, 0.44799999999999995, -0.02400000000000002, 0.45300000000000007, 0.405, 0.4630000000000001, 0.4249999999999998, 0.33099999999999996, 0.46799999999999997, 0.45699999999999985, 0.3959999999999999, 0.46599999999999997, -0.05700000000000005, 0.4670000000000001, 0.3420000000000001, -0.04400000000000004, 0.45199999999999996, 0.4630000000000001, 0.44199999999999995, 0.44899999999999984, 0.44700000000000006, 0.4590000000000001, 0.4710000000000001, 0.46399999999999997, -0.027000000000000024, 0.248, 0.45599999999999996, 1.4529999999999998, 0.42799999999999994, 0.43500000000000005, 0.472, 0.46499999999999986, 1.233, 0.43799999999999994, 0.17399999999999993, 0.46099999999999985, -0.05100000000000004, 0.45599999999999996, 0.46599999999999997, 0.45500000000000007, 1.44, 0.4590000000000001, 0.44700000000000006, 0.9649999999999999, 0.45999999999999996, 0.46499999999999986, 0.472, 1.458, 0.46799999999999997, 1.451, 1.436, 1.431, 0.45799999999999996, 0.46099999999999985, 0.45500000000000007, 0.9590000000000001, 0.44200000000000017, 0.46399999999999997, 0.9279999999999999, 0.47299999999999986, 0.45699999999999985, 0.46099999999999985, 0.46799999999999997, 0.4590000000000001, 0.4590000000000001, 0.9189999999999999, 0.45599999999999996, -0.02100000000000002, 0.9089999999999999, 0.45199999999999996, -0.21100000000000008, 0.46699999999999997, 0.44499999999999984, 0.472, 0.46399999999999997, 0.4079999999999999, 0.901, -0.026000000000000023, 0.45500000000000007, 0.45699999999999985, 0.4630000000000001, 0.32199999999999995, 1.448, 1.282, 0.45199999999999996, 0.43999999999999995, 0.43900000000000006, 0.44399999999999995, 0.45199999999999996, 0.472, 0.9319999999999999, 1.451, 0.46499999999999986, 0.45999999999999996, 0.953, 0.46599999999999997, -0.025999999999999912, 0.42399999999999993, 0.476, 0.44700000000000006, 0.4630000000000001, 0.4630000000000001, 0.40400000000000014, 0.4630000000000001, 0.46399999999999997, 0.4670000000000001, -0.049000000000000044, 0.46399999999999997, 0.4670000000000001, 1.3530000000000002, 0.472, 0.43900000000000006, -0.040000000000000036], "episode_lengths": [256, 11, 12, 32, 11, 7, 31, 17, 15, 16, 13, 15, 17, 15, 181, 16, 13, 13, 20, 14, 22, 32, 36, 14, 93, 10, 17, 13, 10, 10, 14, 18, 16, 20, 15, 20, 57, 13, 9, 9, 16, 14, 14, 11, 16, 30, 16, 38, 93, 13, 19, 17, 8, 15, 31, 11, 24, 53, 10, 13, 34, 11, 17, 10, 49, 14, 15, 12, 19, 15, 17, 13, 9, 12, 9, 81, 13, 15, 24, 20, 9, 11, 86, 20, 104, 12, 300, 14, 11, 14, 19, 13, 16, 11, 13, 11, 9, 14, 10, 16, 20, 22, 13, 12, 14, 13, 18, 12, 23, 9, 14, 13, 10, 13, 13, 186, 14, 7, 188, 15, 61, 11, 17, 9, 11, 29, 32, 8, 14, 14, 12, 56, 17, 69, 15, 18, 19, 18, 15, 9, 22, 15, 11, 13, 300, 11, 8, 24, 8, 17, 11, 12, 30, 12, 12, 11, 16, 11, 11, 45, 9, 19, 12], "policy_red_0_reward": [0.728, 1.467, 1.464, 1.404, 1.467, 0.979, 1.405, 1.4489999999999998, 1.455, 1.452, 1.4609999999999999, 1.455, 1.4489999999999998, 1.455, 0.956, 1.452, 1.4609999999999999, 1.4609999999999999, 1.44, 1.458, 1.434, 1.404, 1.391, 1.458, 1.22, 1.47, 1.4489999999999998, 1.4609999999999999, 0.97, 1.47, 1.458, 1.446, -1.0, 1.44, 1.455, 1.44, 1.327, 1.4609999999999999, 1.4729999999999999, 0.973, 1.452, 1.458, 1.458, 1.467, -0.5, 1.4060000000000001, 1.452, 1.385, 1.22, 1.46, 1.443, -0.5, 0.976, 1.455, 1.407, 1.467, 1.428, 1.338, 1.47, 1.4609999999999999, 1.3980000000000001, 1.467, 0.945, 1.47, 1.353, 0.957, 1.455, 1.464, 1.443, 1.455, 1.4489999999999998, 1.4609999999999999, 1.4729999999999999, 1.464, 0.973, -0.501, 1.4609999999999999, 1.455, 1.428, 1.438, 1.4729999999999999, 1.467, 1.241, 1.44, 1.1869999999999998, 1.464, -0.006, 1.458, 1.467, 1.458, 1.442, 1.4609999999999999, 1.452, 1.467, 1.4609999999999999, 1.467, 1.4729999999999999, 1.458, 1.47, 1.452, 1.44, 1.434, 1.4609999999999999, 1.464, 1.458, 1.4609999999999999, 1.446, 1.464, 1.431, 1.4729999999999999, 1.458, 1.4609999999999999, 1.47, 1.4609999999999999, 1.4609999999999999, 0.9369999999999999, 1.458, 0.979, 0.9339999999999999, 1.455, 0.7959999999999999, -0.5, 1.4489999999999998, 1.4729999999999999, 1.467, 1.413, 1.404, 0.975, 1.458, 1.458, 1.464, -0.501, 1.4489999999999998, 1.291, 1.455, 1.446, 1.443, 1.446, 1.455, -0.5, 1.434, 1.455, 1.467, 1.4609999999999999, 0.5, 1.467, 0.976, 1.428, 1.476, 0.949, 1.467, 1.464, -0.5009999999999999, 1.464, 1.464, 1.467, 0.952, 1.467, 1.467, 1.363, 1.4729999999999999, 1.443, 0.964], "policy_blue_0_reward": [-0.035000000000000024, -1.003, -1.003, -0.003, -1.001, -1.003, -1.004, -0.001, -1.0, -1.003, -1.003, -0.004, -0.004, -1.002, -0.524, -1.002, -1.001, -1.003, -1.003, -1.001, -1.0, -1.009, -1.005, -1.002, -1.015, -1.001, -1.002, -1.0039999999999998, -1.0, -1.001, -1.003, -0.006, 0.95, -1.003, -1.001, -1.004, -1.005, -1.003, -1.0019999999999998, -1.001, -1.004, -1.0, -1.001, -1.002, 0.948, -1.007, -1.003, -1.004, -0.515, -1.001, -0.001, 0.948, -1.0, -1.0019999999999998, -1.002, -1.004, -1.003, -1.007, -1.002, -1.004, -1.002, -1.001, -1.002, -1.003, -1.011, -1.001, -1.003, -1.001, -1.001, -1.006, -1.002, -1.002, -1.0019999999999998, -1.0, -1.0, 0.749, -1.005, -0.002, -1.0, -1.003, -1.001, -1.002, -0.008, -1.002, -1.013, -1.003, -0.04500000000000003, -1.002, -1.001, -1.003, -0.002, -1.0019999999999998, -1.005, -0.502, -1.001, -1.002, -1.001, 0.0, -1.002, -0.001, -0.004, -0.003, -1.003, -1.003, -1.003, -0.5019999999999999, -1.0039999999999998, -1.0, -0.503, -1.0, -1.001, -1.0, -1.002, -1.002, -1.0019999999999998, -0.01800000000000001, -1.002, -1.0, -0.025000000000000015, -1.003, -1.007, 0.967, -1.004, -1.001, -1.003, -1.005, -0.503, -1.001, -1.003, -1.001, -1.001, 0.823, -0.001, -0.009000000000000001, -1.003, -1.006, -1.0039999999999998, -1.0019999999999998, -1.003, 0.972, -0.5019999999999999, -0.004, -1.002, -1.001, 0.45299999999999996, -1.001, -1.0019999999999998, -1.0039999999999998, -1.0, -0.502, -1.0039999999999998, -1.001, 0.905, -1.001, -1.0, -1.0, -1.001, -1.003, -1.0, -0.010000000000000002, -1.001, -1.0039999999999998, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24548922161822362, "mean_inference_ms": 1.4759553149194524, "mean_action_processing_ms": 0.06300578101101241, "mean_env_wait_ms": 0.08897397169699386, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02151354690270921, "StateBufferConnector_ms": 0.0015478924008234878, "ViewRequirementAgentConnector_ms": 0.03254698829416849}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000, "num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.95219235303887, "num_env_steps_trained_throughput_per_sec": 102.95219235303887, "timesteps_total": 196000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 392000, "timers": {"training_iteration_time_ms": 38902.639, "sample_time_ms": 7543.445, "learn_time_ms": 31341.721, "learn_throughput": 127.625, "synch_weights_time_ms": 16.974}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 196000, "num_agent_steps_sampled": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 5725, "training_iteration": 49, "trial_id": "d67e4_00000", "date": "2023-09-20_22-41-04", "timestamp": 1695264064, "time_this_iter_s": 38.917683839797974, "time_total_s": 1906.1610956192017, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fdc60>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1906.1610956192017, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 34.61071428571429, "ram_util_percent": 49.00892857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.1347517730496454, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8226950354609929, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02127659574468085, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8226950354609929, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02127659574468085, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8226950354609929, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02127659574468085, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4303628776222466, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.015181391354174897, "policy_loss": -0.021766343772954617, "vf_loss": 0.005682180801522918, "vf_explained_var": 0.8561006067941587, "kl": 0.009396020250925214, "entropy": 0.4843469362705946, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 47520.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "sampler_results": {"episode_reward_max": 1.95, "episode_reward_min": -0.25, "episode_reward_mean": 0.5618085106382978, "episode_len_mean": 28.0, "episode_media": {}, "episodes_this_iter": 141, "policy_reward_min": {"red_0": -0.501, "blue_0": -1.023}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.963}, "policy_reward_mean": {"red_0": 1.3237375886524823, "blue_0": -0.7619290780141843}, "custom_metrics": {"red_0/door_open_done_mean": 0.1347517730496454, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.8226950354609929, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02127659574468085, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.8226950354609929, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02127659574468085, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.8226950354609929, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02127659574468085, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.472, 0.43000000000000016, 0.45599999999999996, 1.405, 0.42300000000000004, 0.45399999999999996, 0.4630000000000001, 1.443, 1.444, 0.41300000000000003, 0.45500000000000007, 1.454, 0.45999999999999996, 0.45599999999999996, 0.41900000000000004, 0.1499999999999999, 0.44700000000000006, 1.45, -0.03499999999999992, 0.46099999999999985, 0.10699999999999998, 1.439, 0.45599999999999996, 0.47299999999999986, 0.4670000000000001, 0.4590000000000001, 0.44999999999999996, 0.46099999999999985, 0.4570000000000001, 0.46899999999999986, 0.45199999999999996, 1.4409999999999998, -0.25, 0.46499999999999986, 0.27700000000000014, 1.434, 0.45199999999999996, 0.46899999999999986, 0.43599999999999994, 0.45699999999999985, 0.44899999999999984, 0.45500000000000007, 0.44999999999999996, 0.3759999999999999, 1.341, 1.454, 0.472, 0.4590000000000001, -0.02200000000000002, 0.966, -0.05700000000000005, 0.47, 0.45299999999999985, 0.44799999999999995, 0.32600000000000007, 0.946, 0.44399999999999995, 0.4670000000000001, -0.025000000000000022, 1.397, -0.07099999999999995, -0.039000000000000035, 0.46399999999999997, 0.32299999999999995, 0.44399999999999995, 0.4670000000000001, 0.16100000000000003, 0.4590000000000001, 0.46499999999999986, 0.9609999999999999, 0.46599999999999997, 1.447, 0.46499999999999986, 0.47299999999999986, 0.46899999999999986, 0.965, 0.45999999999999996, -0.031000000000000028, 0.46799999999999997, 0.44799999999999995, 0.40900000000000003, 0.45599999999999996, 0.385, -0.031000000000000028, 0.45399999999999996, 0.29800000000000004, 0.46799999999999997, 0.7020000000000002, 0.4630000000000001, 0.42700000000000005, 0.44799999999999995, 0.46099999999999985, -0.030000000000000027, 0.4590000000000001, 1.436, 0.9249999999999998, 0.9329999999999998, 0.46599999999999997, 0.45999999999999996, 0.46599999999999997, 0.45699999999999985, 0.46399999999999997, 0.46799999999999997, 0.4590000000000001, 1.95, 0.44499999999999984, 0.45199999999999996, 0.45799999999999996, 0.45199999999999996, 0.45699999999999985, 0.45699999999999985, 1.44, 0.44399999999999995, 0.45299999999999985, 0.46599999999999997, 0.45199999999999996, 1.5190000000000001, 0.44300000000000006, 1.864, 0.46299999999999997, 0.472, 0.44999999999999996, 0.46099999999999997, 0.45999999999999996, 0.4580000000000002, 0.4580000000000002, 1.4489999999999998, -0.09999999999999998, 0.4670000000000001, 0.46099999999999985, 0.4650000000000001, 1.451, 0.4670000000000001, 0.45299999999999985, 0.45799999999999996, -0.04600000000000004, 0.46899999999999986, 0.9079999999999999, -0.02200000000000002, 0.47299999999999986, 0.46099999999999985], "episode_lengths": [9, 23, 14, 31, 23, 15, 12, 19, 17, 27, 14, 15, 12, 14, 25, 112, 17, 15, 11, 12, 126, 20, 13, 9, 10, 13, 16, 12, 13, 10, 15, 19, 77, 11, 70, 21, 15, 10, 20, 14, 16, 15, 16, 39, 51, 15, 9, 13, 7, 11, 18, 10, 14, 17, 53, 300, 18, 10, 8, 33, 23, 12, 11, 49, 18, 11, 107, 13, 11, 13, 11, 17, 11, 9, 10, 300, 13, 10, 10, 16, 29, 14, 37, 10, 300, 63, 10, 95, 11, 23, 17, 12, 10, 13, 20, 24, 22, 11, 13, 11, 14, 11, 10, 13, 16, 17, 14, 14, 15, 14, 13, 19, 17, 15, 11, 16, 151, 18, 43, 11, 9, 16, 13, 13, 13, 13, 16, 32, 10, 12, 11, 16, 11, 15, 14, 170, 10, 29, 7, 9, 13], "policy_red_0_reward": [1.4729999999999999, 1.431, 1.458, 1.407, 1.431, 1.454, 1.464, 1.443, 1.4489999999999998, 1.4180000000000001, 1.458, 1.455, 1.464, 1.458, 1.423, 1.164, 1.4489999999999998, 1.455, 0.967, 1.464, 1.121, 1.44, 1.4609999999999999, 1.4729999999999999, 1.47, 1.4609999999999999, 1.452, 1.464, 1.4609999999999999, 1.47, 1.455, 1.443, 0.762, 1.467, 1.284, 1.4369999999999998, 1.455, 1.47, 1.44, 1.458, 1.452, 1.455, 1.452, 1.383, 1.345, 1.455, 1.4729999999999999, 1.4609999999999999, 0.979, 1.467, 0.946, 1.47, 1.458, 1.4489999999999998, 0.837, 0.486, 1.446, 1.47, 0.976, 1.401, 0.931, 0.961, 1.467, 0.83, 1.446, 1.467, -0.501, 1.4609999999999999, 1.467, 1.4609999999999999, 1.467, 1.4489999999999998, 1.467, 1.4729999999999999, 1.47, 0.5, 1.4609999999999999, 0.97, 1.47, 1.452, 1.412, 1.458, 1.387, 0.97, 0.496, 1.306, 1.47, 1.213, 1.467, 1.431, 1.4489999999999998, 1.463, 0.97, 1.4609999999999999, 1.44, 1.428, 1.434, 1.467, 1.4609999999999999, 1.467, 1.458, 1.467, 1.47, 1.4609999999999999, 1.452, 1.4489999999999998, 1.458, 1.458, 1.455, 1.458, 1.4609999999999999, 1.443, 1.448, 1.455, 1.467, 1.452, 1.0430000000000001, 1.446, 1.3679999999999999, -0.5, 1.4729999999999999, 1.452, -0.5, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.452, 0.904, 1.47, 1.464, 1.467, 1.451, 1.467, 1.455, 1.458, 0.977, 1.47, 1.413, 0.979, 1.4729999999999999, 1.4609999999999999], "policy_blue_0_reward": [-1.001, -1.001, -1.002, -0.002, -1.008, -1.0, -1.001, 0.0, -0.005, -1.005, -1.003, -0.001, -1.0039999999999998, -1.002, -1.004, -1.014, -1.002, -0.005, -1.0019999999999998, -1.003, -1.014, -0.001, -1.005, -1.0, -1.003, -1.002, -1.002, -1.003, -1.0039999999999998, -1.001, -1.003, -0.002, -1.012, -1.002, -1.007, -0.003, -1.003, -1.001, -1.0039999999999998, -1.001, -1.003, -1.0, -1.002, -1.007, -0.004, -0.001, -1.001, -1.002, -1.001, -0.501, -1.003, -1.0, -1.005, -1.001, -0.511, 0.45999999999999996, -1.002, -1.003, -1.001, -0.004, -1.002, -1.0, -1.003, -0.507, -1.002, -1.0, 0.662, -1.0019999999999998, -1.002, -0.5, -1.001, -0.002, -1.002, -1.0, -1.001, 0.46499999999999997, -1.001, -1.001, -1.002, -1.0039999999999998, -1.003, -1.002, -1.002, -1.001, -0.04200000000000003, -1.008, -1.002, -0.5109999999999999, -1.004, -1.004, -1.001, -1.002, -1.0, -1.002, -0.004, -0.503, -0.501, -1.001, -1.001, -1.001, -1.001, -1.003, -1.002, -1.002, 0.498, -1.004, -1.006, -1.0, -1.003, -1.001, -1.004, -0.003, -1.004, -1.002, -1.001, -1.0, 0.476, -1.003, 0.496, 0.963, -1.001, -1.002, 0.961, -1.001, -1.003, -1.003, -0.003, -1.004, -1.003, -1.003, -1.0019999999999998, 0.0, -1.0, -1.002, -1.0, -1.023, -1.001, -0.505, -1.001, -1.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24590620722671, "mean_inference_ms": 1.4760612442146042, "mean_action_processing_ms": 0.06308112077028183, "mean_env_wait_ms": 0.08903362377265753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02185605096478834, "StateBufferConnector_ms": 0.0015142116140812, "ViewRequirementAgentConnector_ms": 0.03259393340306924}}, "episode_reward_max": 1.95, "episode_reward_min": -0.25, "episode_reward_mean": 0.5618085106382978, "episode_len_mean": 28.0, "episodes_this_iter": 141, "policy_reward_min": {"red_0": -0.501, "blue_0": -1.023}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.963}, "policy_reward_mean": {"red_0": 1.3237375886524823, "blue_0": -0.7619290780141843}, "hist_stats": {"episode_reward": [0.472, 0.43000000000000016, 0.45599999999999996, 1.405, 0.42300000000000004, 0.45399999999999996, 0.4630000000000001, 1.443, 1.444, 0.41300000000000003, 0.45500000000000007, 1.454, 0.45999999999999996, 0.45599999999999996, 0.41900000000000004, 0.1499999999999999, 0.44700000000000006, 1.45, -0.03499999999999992, 0.46099999999999985, 0.10699999999999998, 1.439, 0.45599999999999996, 0.47299999999999986, 0.4670000000000001, 0.4590000000000001, 0.44999999999999996, 0.46099999999999985, 0.4570000000000001, 0.46899999999999986, 0.45199999999999996, 1.4409999999999998, -0.25, 0.46499999999999986, 0.27700000000000014, 1.434, 0.45199999999999996, 0.46899999999999986, 0.43599999999999994, 0.45699999999999985, 0.44899999999999984, 0.45500000000000007, 0.44999999999999996, 0.3759999999999999, 1.341, 1.454, 0.472, 0.4590000000000001, -0.02200000000000002, 0.966, -0.05700000000000005, 0.47, 0.45299999999999985, 0.44799999999999995, 0.32600000000000007, 0.946, 0.44399999999999995, 0.4670000000000001, -0.025000000000000022, 1.397, -0.07099999999999995, -0.039000000000000035, 0.46399999999999997, 0.32299999999999995, 0.44399999999999995, 0.4670000000000001, 0.16100000000000003, 0.4590000000000001, 0.46499999999999986, 0.9609999999999999, 0.46599999999999997, 1.447, 0.46499999999999986, 0.47299999999999986, 0.46899999999999986, 0.965, 0.45999999999999996, -0.031000000000000028, 0.46799999999999997, 0.44799999999999995, 0.40900000000000003, 0.45599999999999996, 0.385, -0.031000000000000028, 0.45399999999999996, 0.29800000000000004, 0.46799999999999997, 0.7020000000000002, 0.4630000000000001, 0.42700000000000005, 0.44799999999999995, 0.46099999999999985, -0.030000000000000027, 0.4590000000000001, 1.436, 0.9249999999999998, 0.9329999999999998, 0.46599999999999997, 0.45999999999999996, 0.46599999999999997, 0.45699999999999985, 0.46399999999999997, 0.46799999999999997, 0.4590000000000001, 1.95, 0.44499999999999984, 0.45199999999999996, 0.45799999999999996, 0.45199999999999996, 0.45699999999999985, 0.45699999999999985, 1.44, 0.44399999999999995, 0.45299999999999985, 0.46599999999999997, 0.45199999999999996, 1.5190000000000001, 0.44300000000000006, 1.864, 0.46299999999999997, 0.472, 0.44999999999999996, 0.46099999999999997, 0.45999999999999996, 0.4580000000000002, 0.4580000000000002, 1.4489999999999998, -0.09999999999999998, 0.4670000000000001, 0.46099999999999985, 0.4650000000000001, 1.451, 0.4670000000000001, 0.45299999999999985, 0.45799999999999996, -0.04600000000000004, 0.46899999999999986, 0.9079999999999999, -0.02200000000000002, 0.47299999999999986, 0.46099999999999985], "episode_lengths": [9, 23, 14, 31, 23, 15, 12, 19, 17, 27, 14, 15, 12, 14, 25, 112, 17, 15, 11, 12, 126, 20, 13, 9, 10, 13, 16, 12, 13, 10, 15, 19, 77, 11, 70, 21, 15, 10, 20, 14, 16, 15, 16, 39, 51, 15, 9, 13, 7, 11, 18, 10, 14, 17, 53, 300, 18, 10, 8, 33, 23, 12, 11, 49, 18, 11, 107, 13, 11, 13, 11, 17, 11, 9, 10, 300, 13, 10, 10, 16, 29, 14, 37, 10, 300, 63, 10, 95, 11, 23, 17, 12, 10, 13, 20, 24, 22, 11, 13, 11, 14, 11, 10, 13, 16, 17, 14, 14, 15, 14, 13, 19, 17, 15, 11, 16, 151, 18, 43, 11, 9, 16, 13, 13, 13, 13, 16, 32, 10, 12, 11, 16, 11, 15, 14, 170, 10, 29, 7, 9, 13], "policy_red_0_reward": [1.4729999999999999, 1.431, 1.458, 1.407, 1.431, 1.454, 1.464, 1.443, 1.4489999999999998, 1.4180000000000001, 1.458, 1.455, 1.464, 1.458, 1.423, 1.164, 1.4489999999999998, 1.455, 0.967, 1.464, 1.121, 1.44, 1.4609999999999999, 1.4729999999999999, 1.47, 1.4609999999999999, 1.452, 1.464, 1.4609999999999999, 1.47, 1.455, 1.443, 0.762, 1.467, 1.284, 1.4369999999999998, 1.455, 1.47, 1.44, 1.458, 1.452, 1.455, 1.452, 1.383, 1.345, 1.455, 1.4729999999999999, 1.4609999999999999, 0.979, 1.467, 0.946, 1.47, 1.458, 1.4489999999999998, 0.837, 0.486, 1.446, 1.47, 0.976, 1.401, 0.931, 0.961, 1.467, 0.83, 1.446, 1.467, -0.501, 1.4609999999999999, 1.467, 1.4609999999999999, 1.467, 1.4489999999999998, 1.467, 1.4729999999999999, 1.47, 0.5, 1.4609999999999999, 0.97, 1.47, 1.452, 1.412, 1.458, 1.387, 0.97, 0.496, 1.306, 1.47, 1.213, 1.467, 1.431, 1.4489999999999998, 1.463, 0.97, 1.4609999999999999, 1.44, 1.428, 1.434, 1.467, 1.4609999999999999, 1.467, 1.458, 1.467, 1.47, 1.4609999999999999, 1.452, 1.4489999999999998, 1.458, 1.458, 1.455, 1.458, 1.4609999999999999, 1.443, 1.448, 1.455, 1.467, 1.452, 1.0430000000000001, 1.446, 1.3679999999999999, -0.5, 1.4729999999999999, 1.452, -0.5, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.452, 0.904, 1.47, 1.464, 1.467, 1.451, 1.467, 1.455, 1.458, 0.977, 1.47, 1.413, 0.979, 1.4729999999999999, 1.4609999999999999], "policy_blue_0_reward": [-1.001, -1.001, -1.002, -0.002, -1.008, -1.0, -1.001, 0.0, -0.005, -1.005, -1.003, -0.001, -1.0039999999999998, -1.002, -1.004, -1.014, -1.002, -0.005, -1.0019999999999998, -1.003, -1.014, -0.001, -1.005, -1.0, -1.003, -1.002, -1.002, -1.003, -1.0039999999999998, -1.001, -1.003, -0.002, -1.012, -1.002, -1.007, -0.003, -1.003, -1.001, -1.0039999999999998, -1.001, -1.003, -1.0, -1.002, -1.007, -0.004, -0.001, -1.001, -1.002, -1.001, -0.501, -1.003, -1.0, -1.005, -1.001, -0.511, 0.45999999999999996, -1.002, -1.003, -1.001, -0.004, -1.002, -1.0, -1.003, -0.507, -1.002, -1.0, 0.662, -1.0019999999999998, -1.002, -0.5, -1.001, -0.002, -1.002, -1.0, -1.001, 0.46499999999999997, -1.001, -1.001, -1.002, -1.0039999999999998, -1.003, -1.002, -1.002, -1.001, -0.04200000000000003, -1.008, -1.002, -0.5109999999999999, -1.004, -1.004, -1.001, -1.002, -1.0, -1.002, -0.004, -0.503, -0.501, -1.001, -1.001, -1.001, -1.001, -1.003, -1.002, -1.002, 0.498, -1.004, -1.006, -1.0, -1.003, -1.001, -1.004, -0.003, -1.004, -1.002, -1.001, -1.0, 0.476, -1.003, 0.496, 0.963, -1.001, -1.002, 0.961, -1.001, -1.003, -1.003, -0.003, -1.004, -1.003, -1.003, -1.0019999999999998, 0.0, -1.0, -1.002, -1.0, -1.023, -1.001, -0.505, -1.001, -1.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24590620722671, "mean_inference_ms": 1.4760612442146042, "mean_action_processing_ms": 0.06308112077028183, "mean_env_wait_ms": 0.08903362377265753, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02185605096478834, "StateBufferConnector_ms": 0.0015142116140812, "ViewRequirementAgentConnector_ms": 0.03259393340306924}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000, "num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.05784545129215, "num_env_steps_trained_throughput_per_sec": 103.05784545129215, "timesteps_total": 200000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 400000, "timers": {"training_iteration_time_ms": 38891.888, "sample_time_ms": 7538.888, "learn_time_ms": 31335.558, "learn_throughput": 127.651, "synch_weights_time_ms": 16.941}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 200000, "num_agent_steps_sampled": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 5866, "training_iteration": 50, "trial_id": "d67e4_00000", "date": "2023-09-20_22-41-43", "timestamp": 1695264103, "time_this_iter_s": 38.81919527053833, "time_total_s": 1944.98029088974, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fecb0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1944.98029088974, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 34.56909090909092, "ram_util_percent": 49.00909090909091}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.15625, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.78125, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05625, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.78125, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.05625, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.78125, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05625, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7841444857418538, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00903928195524107, "policy_loss": -0.015569869518124809, "vf_loss": 0.008389643826133882, "vf_explained_var": 0.7730164066577951, "kl": 0.006174992893062888, "entropy": 0.44298114616734285, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 48480.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "sampler_results": {"episode_reward_max": 1.916, "episode_reward_min": -0.273, "episode_reward_mean": 0.54831875, "episode_len_mean": 23.95625, "episode_media": {}, "episodes_this_iter": 160, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.034}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.413}, "policy_reward_mean": {"red_0": 1.24571875, "blue_0": -0.6973999999999998}, "custom_metrics": {"red_0/door_open_done_mean": 0.15625, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.78125, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05625, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.78125, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.05625, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.78125, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05625, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44099999999999984, 0.44700000000000006, 0.46799999999999997, -0.030999999999999917, 0.9240000000000002, 0.44999999999999996, 0.46199999999999997, 0.45599999999999996, -0.03200000000000003, 0.40200000000000014, 0.43699999999999983, -0.02199999999999991, -0.07500000000000007, 0.46099999999999985, 0.4670000000000001, 0.46099999999999985, 0.4209999999999998, 1.446, 0.45100000000000007, -0.09999999999999998, 1.454, -0.02199999999999991, 0.46799999999999997, 0.43500000000000005, 1.45, 1.436, 1.435, 0.45100000000000007, 1.4569999999999999, -0.02300000000000002, -0.050000000000000044, 0.46899999999999986, 0.46099999999999985, -0.028000000000000025, 0.45199999999999996, 0.45199999999999996, 0.9630000000000001, 0.46599999999999997, 1.434, 0.44899999999999984, 1.916, 0.944, 0.41900000000000004, 0.45599999999999996, 0.349, 0.891, 0.3780000000000001, 0.4710000000000001, -0.030000000000000027, 0.46899999999999986, 0.4630000000000001, 0.46599999999999997, 0.2410000000000001, 0.45799999999999996, 1.4409999999999998, 0.4670000000000001, 0.45699999999999985, 1.4220000000000002, 0.45999999999999996, 1.673, 0.4750000000000001, 0.4670000000000001, 0.46599999999999997, -0.09399999999999997, 0.45599999999999996, 0.45999999999999996, 0.45999999999999996, 0.4630000000000001, 0.45299999999999985, -0.03200000000000003, -0.06300000000000006, 0.913, -0.03600000000000003, 1.451, 0.45699999999999985, 0.923, 0.46099999999999985, 0.44300000000000006, 0.43400000000000016, 0.4009999999999999, 0.43599999999999994, 0.44199999999999995, -0.14400000000000002, 1.451, 0.4630000000000001, 1.427, 0.44599999999999995, 0.42899999999999994, 0.41700000000000004, 1.396, -0.06099999999999994, 1.3800000000000001, 0.542, -0.04400000000000004, 0.44399999999999995, 0.46799999999999997, 1.415, 0.46599999999999997, -0.19500000000000006, 0.4690000000000001, -0.03500000000000003, -0.03700000000000003, 0.42399999999999993, 0.45399999999999996, 1.447, 1.4529999999999998, 1.435, 0.45500000000000007, 0.46199999999999997, 0.45799999999999996, 0.45399999999999996, 0.41700000000000004, 0.45999999999999996, 0.9430000000000001, 0.44700000000000006, -0.030000000000000027, -0.02400000000000002, -0.273, 0.45999999999999996, 0.44399999999999995, 1.447, 0.46399999999999997, 0.476, 0.45500000000000007, 0.45999999999999996, 0.46599999999999997, 0.45500000000000007, 1.441, 0.3959999999999999, 0.4670000000000001, -0.03500000000000003, 0.40900000000000003, 0.46199999999999997, 0.45799999999999996, 1.451, 0.4630000000000001, 0.355, 0.46199999999999997, 0.45799999999999996, 0.46399999999999997, 1.448, 0.397, 0.45999999999999996, 0.45099999999999996, 0.46599999999999997, 0.43599999999999994, 0.9449999999999998, 0.46799999999999997, 0.46499999999999986, -0.04600000000000004, 0.46899999999999986, -0.028999999999999915, 0.45299999999999985, 0.43900000000000006, 0.45999999999999996, 1.4409999999999998, 0.45199999999999996, 0.4079999999999999, 0.46199999999999997, 0.43900000000000006], "episode_lengths": [19, 16, 10, 10, 23, 15, 12, 14, 10, 30, 20, 7, 180, 12, 11, 12, 24, 17, 15, 31, 15, 7, 10, 20, 16, 20, 21, 16, 14, 7, 15, 10, 13, 9, 15, 15, 12, 11, 20, 16, 27, 300, 26, 14, 47, 34, 40, 9, 10, 10, 12, 11, 83, 13, 19, 11, 13, 25, 12, 104, 8, 11, 11, 29, 14, 12, 13, 12, 15, 10, 176, 28, 12, 16, 14, 25, 13, 18, 21, 175, 20, 19, 45, 15, 12, 23, 18, 22, 26, 33, 19, 37, 144, 14, 17, 10, 27, 11, 60, 10, 11, 12, 23, 14, 17, 15, 21, 15, 12, 14, 15, 26, 13, 19, 17, 10, 8, 87, 13, 18, 17, 12, 8, 14, 13, 11, 14, 19, 32, 11, 11, 29, 12, 14, 15, 11, 46, 12, 13, 11, 17, 33, 13, 15, 11, 21, 18, 10, 11, 14, 9, 9, 15, 19, 13, 19, 16, 29, 12, 19], "policy_red_0_reward": [1.443, 1.452, 1.47, 0.97, 1.429, 1.455, 1.464, 1.458, 0.97, 1.405, 1.44, -1.0, 0.958, 1.464, 1.467, 1.464, 1.428, 1.4489999999999998, 1.455, 0.907, 1.455, -1.0, 1.47, 1.44, 1.452, 1.44, 1.4369999999999998, 1.452, 1.458, 0.979, 0.953, 1.47, 1.4609999999999999, 0.973, 1.454, 1.454, 1.464, 1.467, 1.44, 1.452, 1.419, 0.496, 1.4220000000000002, 1.458, -0.505, 1.397, 1.38, 1.4729999999999999, 0.97, 1.47, 1.464, 1.467, 1.249, 1.4609999999999999, 1.443, 1.467, 1.4609999999999999, 1.425, 1.464, 1.1869999999999998, 1.476, 1.467, 1.467, 0.911, 1.458, 1.464, 1.4609999999999999, 1.464, 1.455, 0.97, 0.971, -0.5, 0.964, 1.452, 1.458, 1.424, 1.4609999999999999, 1.446, 1.4369999999999998, -0.541, 1.44, 1.443, 0.865, 1.455, 1.464, 1.431, 1.446, -0.501, 1.421, 1.401, 0.943, 1.389, 1.062, 0.956, 1.4489999999999998, 1.47, 1.4180000000000001, 1.467, 0.8109999999999999, 1.47, 0.967, 0.964, 1.4300000000000002, 1.458, 1.4489999999999998, 1.455, 1.4369999999999998, 1.455, 1.464, 1.458, 1.455, -0.5, 1.4609999999999999, 1.443, 1.4489999999999998, 0.97, 0.976, 0.738, 1.4609999999999999, 1.446, 1.4489999999999998, 1.464, 1.476, 1.458, 1.4609999999999999, 1.467, 1.458, 1.443, 1.404, 1.467, -1.0, 1.413, 1.464, 1.458, 1.455, 1.467, 1.361, 1.464, 1.4609999999999999, 1.467, 1.4489999999999998, 1.399, 1.4609999999999999, -0.5, 1.467, 1.4369999999999998, 1.446, 1.47, 1.467, 0.956, 1.4729999999999999, 0.973, 1.455, 1.443, 1.4609999999999999, 1.443, 1.452, 1.411, 1.464, 1.443], "policy_blue_0_reward": [-1.002, -1.005, -1.0019999999999998, -1.001, -0.5049999999999999, -1.005, -1.002, -1.002, -1.002, -1.003, -1.003, 0.978, -1.033, -1.003, -1.0, -1.003, -1.007, -0.003, -1.0039999999999998, -1.007, -0.001, 0.978, -1.0019999999999998, -1.005, -0.002, -0.004, -0.002, -1.001, -0.001, -1.002, -1.003, -1.001, -1.0, -1.001, -1.002, -1.002, -0.5009999999999999, -1.001, -0.006, -1.003, 0.497, 0.44799999999999995, -1.003, -1.0019999999999998, 0.854, -0.506, -1.002, -1.002, -1.0, -1.001, -1.001, -1.001, -1.008, -1.003, -0.002, -1.0, -1.004, -0.003, -1.0039999999999998, 0.486, -1.001, -1.0, -1.001, -1.005, -1.002, -1.0039999999999998, -1.001, -1.001, -1.002, -1.002, -1.034, 1.413, -1.0, -0.001, -1.001, -0.501, -1.0, -1.003, -1.003, 0.942, -1.004, -1.001, -1.009, -0.004, -1.001, -0.004, -1.0, 0.9299999999999999, -1.004, -0.005, -1.0039999999999998, -0.009000000000000001, -0.52, -1.0, -1.005, -1.0019999999999998, -0.003, -1.001, -1.006, -1.001, -1.002, -1.001, -1.006, -1.004, -0.002, -0.002, -0.002, -1.0, -1.002, -1.0, -1.001, 0.917, -1.001, -0.5, -1.002, -1.0, -1.0, -1.011, -1.001, -1.002, -0.002, -1.0, -1.0, -1.003, -1.001, -1.001, -1.003, -0.002, -1.008, -1.0, 0.965, -1.004, -1.002, -1.0, -0.004, -1.004, -1.006, -1.002, -1.003, -1.003, -0.001, -1.002, -1.001, 0.951, -1.001, -1.001, -0.501, -1.002, -1.002, -1.002, -1.004, -1.0019999999999998, -1.002, -1.004, -1.001, -0.002, -1.0, -1.003, -1.002, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2459698016634993, "mean_inference_ms": 1.4759416764498072, "mean_action_processing_ms": 0.06305542860093769, "mean_env_wait_ms": 0.08899021343555902, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02204202115535736, "StateBufferConnector_ms": 0.0015053153038024902, "ViewRequirementAgentConnector_ms": 0.032618939876556396}}, "episode_reward_max": 1.916, "episode_reward_min": -0.273, "episode_reward_mean": 0.54831875, "episode_len_mean": 23.95625, "episodes_this_iter": 160, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.034}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.413}, "policy_reward_mean": {"red_0": 1.24571875, "blue_0": -0.6973999999999998}, "hist_stats": {"episode_reward": [0.44099999999999984, 0.44700000000000006, 0.46799999999999997, -0.030999999999999917, 0.9240000000000002, 0.44999999999999996, 0.46199999999999997, 0.45599999999999996, -0.03200000000000003, 0.40200000000000014, 0.43699999999999983, -0.02199999999999991, -0.07500000000000007, 0.46099999999999985, 0.4670000000000001, 0.46099999999999985, 0.4209999999999998, 1.446, 0.45100000000000007, -0.09999999999999998, 1.454, -0.02199999999999991, 0.46799999999999997, 0.43500000000000005, 1.45, 1.436, 1.435, 0.45100000000000007, 1.4569999999999999, -0.02300000000000002, -0.050000000000000044, 0.46899999999999986, 0.46099999999999985, -0.028000000000000025, 0.45199999999999996, 0.45199999999999996, 0.9630000000000001, 0.46599999999999997, 1.434, 0.44899999999999984, 1.916, 0.944, 0.41900000000000004, 0.45599999999999996, 0.349, 0.891, 0.3780000000000001, 0.4710000000000001, -0.030000000000000027, 0.46899999999999986, 0.4630000000000001, 0.46599999999999997, 0.2410000000000001, 0.45799999999999996, 1.4409999999999998, 0.4670000000000001, 0.45699999999999985, 1.4220000000000002, 0.45999999999999996, 1.673, 0.4750000000000001, 0.4670000000000001, 0.46599999999999997, -0.09399999999999997, 0.45599999999999996, 0.45999999999999996, 0.45999999999999996, 0.4630000000000001, 0.45299999999999985, -0.03200000000000003, -0.06300000000000006, 0.913, -0.03600000000000003, 1.451, 0.45699999999999985, 0.923, 0.46099999999999985, 0.44300000000000006, 0.43400000000000016, 0.4009999999999999, 0.43599999999999994, 0.44199999999999995, -0.14400000000000002, 1.451, 0.4630000000000001, 1.427, 0.44599999999999995, 0.42899999999999994, 0.41700000000000004, 1.396, -0.06099999999999994, 1.3800000000000001, 0.542, -0.04400000000000004, 0.44399999999999995, 0.46799999999999997, 1.415, 0.46599999999999997, -0.19500000000000006, 0.4690000000000001, -0.03500000000000003, -0.03700000000000003, 0.42399999999999993, 0.45399999999999996, 1.447, 1.4529999999999998, 1.435, 0.45500000000000007, 0.46199999999999997, 0.45799999999999996, 0.45399999999999996, 0.41700000000000004, 0.45999999999999996, 0.9430000000000001, 0.44700000000000006, -0.030000000000000027, -0.02400000000000002, -0.273, 0.45999999999999996, 0.44399999999999995, 1.447, 0.46399999999999997, 0.476, 0.45500000000000007, 0.45999999999999996, 0.46599999999999997, 0.45500000000000007, 1.441, 0.3959999999999999, 0.4670000000000001, -0.03500000000000003, 0.40900000000000003, 0.46199999999999997, 0.45799999999999996, 1.451, 0.4630000000000001, 0.355, 0.46199999999999997, 0.45799999999999996, 0.46399999999999997, 1.448, 0.397, 0.45999999999999996, 0.45099999999999996, 0.46599999999999997, 0.43599999999999994, 0.9449999999999998, 0.46799999999999997, 0.46499999999999986, -0.04600000000000004, 0.46899999999999986, -0.028999999999999915, 0.45299999999999985, 0.43900000000000006, 0.45999999999999996, 1.4409999999999998, 0.45199999999999996, 0.4079999999999999, 0.46199999999999997, 0.43900000000000006], "episode_lengths": [19, 16, 10, 10, 23, 15, 12, 14, 10, 30, 20, 7, 180, 12, 11, 12, 24, 17, 15, 31, 15, 7, 10, 20, 16, 20, 21, 16, 14, 7, 15, 10, 13, 9, 15, 15, 12, 11, 20, 16, 27, 300, 26, 14, 47, 34, 40, 9, 10, 10, 12, 11, 83, 13, 19, 11, 13, 25, 12, 104, 8, 11, 11, 29, 14, 12, 13, 12, 15, 10, 176, 28, 12, 16, 14, 25, 13, 18, 21, 175, 20, 19, 45, 15, 12, 23, 18, 22, 26, 33, 19, 37, 144, 14, 17, 10, 27, 11, 60, 10, 11, 12, 23, 14, 17, 15, 21, 15, 12, 14, 15, 26, 13, 19, 17, 10, 8, 87, 13, 18, 17, 12, 8, 14, 13, 11, 14, 19, 32, 11, 11, 29, 12, 14, 15, 11, 46, 12, 13, 11, 17, 33, 13, 15, 11, 21, 18, 10, 11, 14, 9, 9, 15, 19, 13, 19, 16, 29, 12, 19], "policy_red_0_reward": [1.443, 1.452, 1.47, 0.97, 1.429, 1.455, 1.464, 1.458, 0.97, 1.405, 1.44, -1.0, 0.958, 1.464, 1.467, 1.464, 1.428, 1.4489999999999998, 1.455, 0.907, 1.455, -1.0, 1.47, 1.44, 1.452, 1.44, 1.4369999999999998, 1.452, 1.458, 0.979, 0.953, 1.47, 1.4609999999999999, 0.973, 1.454, 1.454, 1.464, 1.467, 1.44, 1.452, 1.419, 0.496, 1.4220000000000002, 1.458, -0.505, 1.397, 1.38, 1.4729999999999999, 0.97, 1.47, 1.464, 1.467, 1.249, 1.4609999999999999, 1.443, 1.467, 1.4609999999999999, 1.425, 1.464, 1.1869999999999998, 1.476, 1.467, 1.467, 0.911, 1.458, 1.464, 1.4609999999999999, 1.464, 1.455, 0.97, 0.971, -0.5, 0.964, 1.452, 1.458, 1.424, 1.4609999999999999, 1.446, 1.4369999999999998, -0.541, 1.44, 1.443, 0.865, 1.455, 1.464, 1.431, 1.446, -0.501, 1.421, 1.401, 0.943, 1.389, 1.062, 0.956, 1.4489999999999998, 1.47, 1.4180000000000001, 1.467, 0.8109999999999999, 1.47, 0.967, 0.964, 1.4300000000000002, 1.458, 1.4489999999999998, 1.455, 1.4369999999999998, 1.455, 1.464, 1.458, 1.455, -0.5, 1.4609999999999999, 1.443, 1.4489999999999998, 0.97, 0.976, 0.738, 1.4609999999999999, 1.446, 1.4489999999999998, 1.464, 1.476, 1.458, 1.4609999999999999, 1.467, 1.458, 1.443, 1.404, 1.467, -1.0, 1.413, 1.464, 1.458, 1.455, 1.467, 1.361, 1.464, 1.4609999999999999, 1.467, 1.4489999999999998, 1.399, 1.4609999999999999, -0.5, 1.467, 1.4369999999999998, 1.446, 1.47, 1.467, 0.956, 1.4729999999999999, 0.973, 1.455, 1.443, 1.4609999999999999, 1.443, 1.452, 1.411, 1.464, 1.443], "policy_blue_0_reward": [-1.002, -1.005, -1.0019999999999998, -1.001, -0.5049999999999999, -1.005, -1.002, -1.002, -1.002, -1.003, -1.003, 0.978, -1.033, -1.003, -1.0, -1.003, -1.007, -0.003, -1.0039999999999998, -1.007, -0.001, 0.978, -1.0019999999999998, -1.005, -0.002, -0.004, -0.002, -1.001, -0.001, -1.002, -1.003, -1.001, -1.0, -1.001, -1.002, -1.002, -0.5009999999999999, -1.001, -0.006, -1.003, 0.497, 0.44799999999999995, -1.003, -1.0019999999999998, 0.854, -0.506, -1.002, -1.002, -1.0, -1.001, -1.001, -1.001, -1.008, -1.003, -0.002, -1.0, -1.004, -0.003, -1.0039999999999998, 0.486, -1.001, -1.0, -1.001, -1.005, -1.002, -1.0039999999999998, -1.001, -1.001, -1.002, -1.002, -1.034, 1.413, -1.0, -0.001, -1.001, -0.501, -1.0, -1.003, -1.003, 0.942, -1.004, -1.001, -1.009, -0.004, -1.001, -0.004, -1.0, 0.9299999999999999, -1.004, -0.005, -1.0039999999999998, -0.009000000000000001, -0.52, -1.0, -1.005, -1.0019999999999998, -0.003, -1.001, -1.006, -1.001, -1.002, -1.001, -1.006, -1.004, -0.002, -0.002, -0.002, -1.0, -1.002, -1.0, -1.001, 0.917, -1.001, -0.5, -1.002, -1.0, -1.0, -1.011, -1.001, -1.002, -0.002, -1.0, -1.0, -1.003, -1.001, -1.001, -1.003, -0.002, -1.008, -1.0, 0.965, -1.004, -1.002, -1.0, -0.004, -1.004, -1.006, -1.002, -1.003, -1.003, -0.001, -1.002, -1.001, 0.951, -1.001, -1.001, -0.501, -1.002, -1.002, -1.002, -1.004, -1.0019999999999998, -1.002, -1.004, -1.001, -0.002, -1.0, -1.003, -1.002, -1.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2459698016634993, "mean_inference_ms": 1.4759416764498072, "mean_action_processing_ms": 0.06305542860093769, "mean_env_wait_ms": 0.08899021343555902, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.02204202115535736, "StateBufferConnector_ms": 0.0015053153038024902, "ViewRequirementAgentConnector_ms": 0.032618939876556396}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000, "num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.6765234696955, "num_env_steps_trained_throughput_per_sec": 102.6765234696955, "timesteps_total": 204000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 408000, "timers": {"training_iteration_time_ms": 38895.426, "sample_time_ms": 7544.934, "learn_time_ms": 31333.069, "learn_throughput": 127.661, "synch_weights_time_ms": 16.923}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 204000, "num_agent_steps_sampled": 408000, "num_agent_steps_trained": 408000}, "done": false, "episodes_total": 6026, "training_iteration": 51, "trial_id": "d67e4_00000", "date": "2023-09-20_22-42-23", "timestamp": 1695264143, "time_this_iter_s": 38.9639778137207, "time_total_s": 1983.9442687034607, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a47070a0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 1983.9442687034607, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 33.78035714285714, "ram_util_percent": 49.05714285714286}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.18902439024390244, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7621951219512195, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.036585365853658534, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7621951219512195, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.006097560975609756, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.036585365853658534, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7621951219512195, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.036585365853658534, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0419025882457693, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011517035120778018, "policy_loss": -0.017944654420474156, "vf_loss": 0.007086875982107207, "vf_explained_var": 0.8337690755104025, "kl": 0.007343226778314937, "entropy": 0.4202711837987105, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 49440.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "sampler_results": {"episode_reward_max": 1.9409999999999998, "episode_reward_min": -0.645, "episode_reward_mean": 0.5767987804878049, "episode_len_mean": 25.628048780487806, "episode_media": {}, "episodes_this_iter": 164, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.029}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.177}, "policy_reward_mean": {"red_0": 1.2696524390243904, "blue_0": -0.6928536585365853}, "custom_metrics": {"red_0/door_open_done_mean": 0.18902439024390244, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7621951219512195, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.036585365853658534, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7621951219512195, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.006097560975609756, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.036585365853658534, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7621951219512195, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.036585365853658534, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4570000000000001, -0.06900000000000006, 0.8860000000000001, 0.46399999999999997, 1.451, 0.44799999999999995, 0.42300000000000004, 0.47, -0.03200000000000003, 0.43699999999999983, 0.45999999999999996, -0.027000000000000024, 0.45799999999999996, 1.1600000000000001, 0.4670000000000001, 1.42, 1.896, 0.47, 0.44099999999999984, 0.351, -0.031000000000000028, 0.952, -0.040000000000000036, 0.47, 0.43499999999999994, 1.319, 0.3999999999999999, 0.381, 0.46099999999999985, 0.45100000000000007, 1.424, 0.4590000000000001, 0.4650000000000001, -0.05399999999999994, 1.452, 0.45100000000000007, 1.455, 1.455, -0.04900000000000004, 0.4710000000000001, 0.45999999999999996, 0.46399999999999997, 0.43999999999999995, 0.4580000000000002, 0.45399999999999996, 1.4529999999999998, 1.416, 1.326, 0.46899999999999986, 0.46199999999999997, 0.12, 0.46399999999999997, 0.46199999999999997, 0.46899999999999986, 0.45199999999999996, -0.031000000000000028, 0.45699999999999985, 0.44199999999999995, 0.47, 0.42200000000000015, 0.4650000000000001, 1.454, -0.09299999999999986, 1.421, 1.438, 0.403, 1.4449999999999998, -0.645, 1.9409999999999998, 0.46399999999999997, 0.4630000000000001, 0.9630000000000001, 0.899, 0.45199999999999996, 0.050999999999999934, 0.43900000000000006, 0.45799999999999996, 0.45699999999999985, 0.4620000000000002, 0.46399999999999997, 0.4630000000000001, 0.4540000000000002, 0.44700000000000006, 0.45399999999999996, 1.459, -0.02499999999999991, 0.45999999999999996, 0.4590000000000001, 0.4650000000000001, -0.030000000000000027, -0.07200000000000006, 0.46899999999999986, 0.472, 0.944, 0.46799999999999997, -0.05800000000000005, 0.4570000000000001, 1.3519999999999999, 1.447, -0.03300000000000003, 0.06999999999999995, 0.47299999999999986, 0.45599999999999996, 1.927, -0.031000000000000028, 0.3860000000000001, 0.45500000000000007, 0.42700000000000005, 1.46, 0.46199999999999997, 1.436, 0.42100000000000026, 0.478, 0.44499999999999984, 0.45500000000000007, 0.46199999999999997, -0.038000000000000034, 1.405, 1.411, 0.46499999999999986, 0.9339999999999999, 0.9670000000000001, 0.4630000000000001, 0.46499999999999986, 0.43799999999999994, 1.4449999999999998, 0.32299999999999995, 0.43500000000000005, 1.4369999999999998, -0.03500000000000003, 0.4540000000000002, 0.45799999999999996, 0.43999999999999995, 1.347, 0.40600000000000014, 1.3940000000000001, -0.04299999999999993, -0.039000000000000035, -0.040000000000000036, 0.21399999999999997, 0.3900000000000001, 1.43, 0.3580000000000001, -0.04299999999999993, 0.39800000000000013, -0.02400000000000002, 0.4500000000000002, 0.46799999999999997, -0.07600000000000007, 0.931, 0.43199999999999994, 0.389, 0.31699999999999995, 1.424, 0.45500000000000007, 1.6749999999999998, -0.04400000000000004, 0.47299999999999986, 0.46399999999999997, 0.46499999999999986, -0.03700000000000003, 0.45299999999999985, -0.03599999999999992, 0.45500000000000007], "episode_lengths": [13, 22, 35, 11, 16, 17, 24, 10, 10, 20, 13, 9, 13, 108, 11, 26, 33, 10, 19, 48, 10, 15, 13, 10, 20, 57, 32, 39, 12, 15, 24, 13, 11, 15, 15, 16, 15, 14, 300, 9, 13, 11, 19, 13, 14, 15, 26, 53, 10, 12, 281, 11, 12, 10, 14, 10, 14, 18, 10, 25, 11, 15, 28, 25, 20, 31, 18, 205, 19, 12, 12, 12, 32, 15, 141, 19, 13, 14, 12, 12, 12, 14, 17, 15, 13, 8, 13, 13, 11, 10, 24, 10, 9, 18, 10, 18, 14, 47, 17, 11, 138, 9, 14, 23, 10, 37, 14, 23, 13, 12, 20, 25, 7, 17, 13, 12, 12, 29, 27, 11, 21, 11, 12, 11, 20, 18, 56, 21, 19, 11, 14, 13, 19, 47, 29, 33, 14, 13, 12, 90, 35, 22, 39, 13, 31, 8, 15, 10, 24, 23, 22, 35, 56, 23, 14, 102, 14, 9, 11, 11, 12, 15, 11, 14], "policy_red_0_reward": [1.4609999999999999, 0.9339999999999999, 1.395, 1.467, 1.452, 1.4489999999999998, 1.428, 1.47, 0.97, 1.44, 1.4609999999999999, 0.973, 1.4609999999999999, 1.1749999999999998, 1.467, 1.4220000000000002, 1.4, 1.47, 1.442, 1.3559999999999999, 0.97, 1.455, 0.96, 1.47, -0.501, 1.3279999999999998, 1.4020000000000001, 1.3820000000000001, 0.961, 1.455, 1.427, 1.4609999999999999, 1.467, 0.95, 1.455, 1.452, 1.455, 1.458, -0.005, 1.4729999999999999, 1.4609999999999999, 1.467, 1.443, 1.46, 1.458, 1.455, 1.4220000000000002, 1.338, 1.47, 1.464, -0.502, 1.467, 1.464, 1.47, 1.458, 0.97, 1.458, 1.446, 1.47, 1.425, 1.467, 1.455, 0.914, 1.424, 1.44, 1.407, 1.446, 0.384, 1.443, 1.464, 1.464, 1.463, 1.404, 1.455, 1.073, 1.443, 1.4609999999999999, 1.458, 1.464, 1.464, 1.464, 1.458, 1.4489999999999998, 1.455, 1.4609999999999999, 0.976, 1.4609999999999999, 1.4609999999999999, 1.467, 0.97, 0.9279999999999999, 1.47, 1.4729999999999999, 1.446, 1.47, 0.945, 1.458, 1.357, 1.4489999999999998, 0.967, -0.502, 1.4729999999999999, 1.458, 1.4300000000000002, 0.97, 1.388, 1.458, -0.501, 1.4609999999999999, 1.464, 1.44, 1.425, 1.479, 1.4489999999999998, 1.4609999999999999, 1.464, 0.964, 1.412, 1.419, 1.467, 1.4369999999999998, 1.467, 1.464, 1.467, 1.44, 1.446, 1.33, 1.4369999999999998, 1.443, 0.967, 1.458, 1.4609999999999999, -0.5, 1.357, 1.413, 1.401, 0.958, 0.961, 0.963, -0.502, 1.395, 1.434, 1.3639999999999999, 0.96, 1.403, 0.976, 1.455, 1.47, 0.9279999999999999, 1.431, 1.434, 1.393, 1.329, 1.429, 1.458, 0.498, 0.958, 1.4729999999999999, 1.467, 1.467, 0.964, 1.455, 0.967, 1.458], "policy_blue_0_reward": [-1.0039999999999998, -1.003, -0.5089999999999999, -1.003, -0.001, -1.001, -1.005, -1.0, -1.002, -1.003, -1.001, -1.0, -1.003, -0.015000000000000006, -1.0, -0.002, 0.496, -1.0, -1.001, -1.005, -1.001, -0.503, -1.0, -1.0, 0.9359999999999999, -0.009000000000000001, -1.002, -1.001, -0.5, -1.004, -0.003, -1.002, -1.0019999999999998, -1.0039999999999998, -0.003, -1.001, 0.0, -0.003, -0.04400000000000003, -1.0019999999999998, -1.001, -1.003, -1.003, -1.0019999999999998, -1.004, -0.002, -0.006, -0.012000000000000004, -1.001, -1.002, 0.622, -1.003, -1.002, -1.001, -1.006, -1.001, -1.001, -1.004, -1.0, -1.003, -1.0019999999999998, -0.001, -1.007, -0.003, -0.002, -1.004, -0.001, -1.029, 0.498, -1.0, -1.001, -0.5, -0.505, -1.003, -1.022, -1.004, -1.003, -1.001, -1.0019999999999998, -1.0, -1.001, -1.0039999999999998, -1.002, -1.001, -0.002, -1.001, -1.001, -1.002, -1.0019999999999998, -1.0, -1.0, -1.001, -1.001, -0.502, -1.002, -1.003, -1.001, -0.005, -0.002, -1.0, 0.572, -1.0, -1.002, 0.497, -1.001, -1.002, -1.003, 0.928, -0.001, -1.002, -0.004, -1.0039999999999998, -1.001, -1.004, -1.006, -1.002, -1.002, -0.007, -0.008, -1.002, -0.503, -0.5, -1.001, -1.002, -1.002, -0.001, -1.007, -1.002, -0.006, -1.002, -1.0039999999999998, -1.003, 0.94, -0.010000000000000002, -1.007, -0.007, -1.001, -1.0, -1.003, 0.716, -1.005, -0.004, -1.006, -1.003, -1.005, -1.0, -1.005, -1.002, -1.004, -0.5, -1.002, -1.004, -1.012, -0.005, -1.003, 1.177, -1.002, -1.0, -1.003, -1.002, -1.001, -1.002, -1.003, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24596158935227472, "mean_inference_ms": 1.4756556735817457, "mean_action_processing_ms": 0.06307539993740029, "mean_env_wait_ms": 0.08894674323207948, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021817117202572706, "StateBufferConnector_ms": 0.0014933871059882931, "ViewRequirementAgentConnector_ms": 0.03235238354380538}}, "episode_reward_max": 1.9409999999999998, "episode_reward_min": -0.645, "episode_reward_mean": 0.5767987804878049, "episode_len_mean": 25.628048780487806, "episodes_this_iter": 164, "policy_reward_min": {"red_0": -0.502, "blue_0": -1.029}, "policy_reward_max": {"red_0": 1.479, "blue_0": 1.177}, "policy_reward_mean": {"red_0": 1.2696524390243904, "blue_0": -0.6928536585365853}, "hist_stats": {"episode_reward": [0.4570000000000001, -0.06900000000000006, 0.8860000000000001, 0.46399999999999997, 1.451, 0.44799999999999995, 0.42300000000000004, 0.47, -0.03200000000000003, 0.43699999999999983, 0.45999999999999996, -0.027000000000000024, 0.45799999999999996, 1.1600000000000001, 0.4670000000000001, 1.42, 1.896, 0.47, 0.44099999999999984, 0.351, -0.031000000000000028, 0.952, -0.040000000000000036, 0.47, 0.43499999999999994, 1.319, 0.3999999999999999, 0.381, 0.46099999999999985, 0.45100000000000007, 1.424, 0.4590000000000001, 0.4650000000000001, -0.05399999999999994, 1.452, 0.45100000000000007, 1.455, 1.455, -0.04900000000000004, 0.4710000000000001, 0.45999999999999996, 0.46399999999999997, 0.43999999999999995, 0.4580000000000002, 0.45399999999999996, 1.4529999999999998, 1.416, 1.326, 0.46899999999999986, 0.46199999999999997, 0.12, 0.46399999999999997, 0.46199999999999997, 0.46899999999999986, 0.45199999999999996, -0.031000000000000028, 0.45699999999999985, 0.44199999999999995, 0.47, 0.42200000000000015, 0.4650000000000001, 1.454, -0.09299999999999986, 1.421, 1.438, 0.403, 1.4449999999999998, -0.645, 1.9409999999999998, 0.46399999999999997, 0.4630000000000001, 0.9630000000000001, 0.899, 0.45199999999999996, 0.050999999999999934, 0.43900000000000006, 0.45799999999999996, 0.45699999999999985, 0.4620000000000002, 0.46399999999999997, 0.4630000000000001, 0.4540000000000002, 0.44700000000000006, 0.45399999999999996, 1.459, -0.02499999999999991, 0.45999999999999996, 0.4590000000000001, 0.4650000000000001, -0.030000000000000027, -0.07200000000000006, 0.46899999999999986, 0.472, 0.944, 0.46799999999999997, -0.05800000000000005, 0.4570000000000001, 1.3519999999999999, 1.447, -0.03300000000000003, 0.06999999999999995, 0.47299999999999986, 0.45599999999999996, 1.927, -0.031000000000000028, 0.3860000000000001, 0.45500000000000007, 0.42700000000000005, 1.46, 0.46199999999999997, 1.436, 0.42100000000000026, 0.478, 0.44499999999999984, 0.45500000000000007, 0.46199999999999997, -0.038000000000000034, 1.405, 1.411, 0.46499999999999986, 0.9339999999999999, 0.9670000000000001, 0.4630000000000001, 0.46499999999999986, 0.43799999999999994, 1.4449999999999998, 0.32299999999999995, 0.43500000000000005, 1.4369999999999998, -0.03500000000000003, 0.4540000000000002, 0.45799999999999996, 0.43999999999999995, 1.347, 0.40600000000000014, 1.3940000000000001, -0.04299999999999993, -0.039000000000000035, -0.040000000000000036, 0.21399999999999997, 0.3900000000000001, 1.43, 0.3580000000000001, -0.04299999999999993, 0.39800000000000013, -0.02400000000000002, 0.4500000000000002, 0.46799999999999997, -0.07600000000000007, 0.931, 0.43199999999999994, 0.389, 0.31699999999999995, 1.424, 0.45500000000000007, 1.6749999999999998, -0.04400000000000004, 0.47299999999999986, 0.46399999999999997, 0.46499999999999986, -0.03700000000000003, 0.45299999999999985, -0.03599999999999992, 0.45500000000000007], "episode_lengths": [13, 22, 35, 11, 16, 17, 24, 10, 10, 20, 13, 9, 13, 108, 11, 26, 33, 10, 19, 48, 10, 15, 13, 10, 20, 57, 32, 39, 12, 15, 24, 13, 11, 15, 15, 16, 15, 14, 300, 9, 13, 11, 19, 13, 14, 15, 26, 53, 10, 12, 281, 11, 12, 10, 14, 10, 14, 18, 10, 25, 11, 15, 28, 25, 20, 31, 18, 205, 19, 12, 12, 12, 32, 15, 141, 19, 13, 14, 12, 12, 12, 14, 17, 15, 13, 8, 13, 13, 11, 10, 24, 10, 9, 18, 10, 18, 14, 47, 17, 11, 138, 9, 14, 23, 10, 37, 14, 23, 13, 12, 20, 25, 7, 17, 13, 12, 12, 29, 27, 11, 21, 11, 12, 11, 20, 18, 56, 21, 19, 11, 14, 13, 19, 47, 29, 33, 14, 13, 12, 90, 35, 22, 39, 13, 31, 8, 15, 10, 24, 23, 22, 35, 56, 23, 14, 102, 14, 9, 11, 11, 12, 15, 11, 14], "policy_red_0_reward": [1.4609999999999999, 0.9339999999999999, 1.395, 1.467, 1.452, 1.4489999999999998, 1.428, 1.47, 0.97, 1.44, 1.4609999999999999, 0.973, 1.4609999999999999, 1.1749999999999998, 1.467, 1.4220000000000002, 1.4, 1.47, 1.442, 1.3559999999999999, 0.97, 1.455, 0.96, 1.47, -0.501, 1.3279999999999998, 1.4020000000000001, 1.3820000000000001, 0.961, 1.455, 1.427, 1.4609999999999999, 1.467, 0.95, 1.455, 1.452, 1.455, 1.458, -0.005, 1.4729999999999999, 1.4609999999999999, 1.467, 1.443, 1.46, 1.458, 1.455, 1.4220000000000002, 1.338, 1.47, 1.464, -0.502, 1.467, 1.464, 1.47, 1.458, 0.97, 1.458, 1.446, 1.47, 1.425, 1.467, 1.455, 0.914, 1.424, 1.44, 1.407, 1.446, 0.384, 1.443, 1.464, 1.464, 1.463, 1.404, 1.455, 1.073, 1.443, 1.4609999999999999, 1.458, 1.464, 1.464, 1.464, 1.458, 1.4489999999999998, 1.455, 1.4609999999999999, 0.976, 1.4609999999999999, 1.4609999999999999, 1.467, 0.97, 0.9279999999999999, 1.47, 1.4729999999999999, 1.446, 1.47, 0.945, 1.458, 1.357, 1.4489999999999998, 0.967, -0.502, 1.4729999999999999, 1.458, 1.4300000000000002, 0.97, 1.388, 1.458, -0.501, 1.4609999999999999, 1.464, 1.44, 1.425, 1.479, 1.4489999999999998, 1.4609999999999999, 1.464, 0.964, 1.412, 1.419, 1.467, 1.4369999999999998, 1.467, 1.464, 1.467, 1.44, 1.446, 1.33, 1.4369999999999998, 1.443, 0.967, 1.458, 1.4609999999999999, -0.5, 1.357, 1.413, 1.401, 0.958, 0.961, 0.963, -0.502, 1.395, 1.434, 1.3639999999999999, 0.96, 1.403, 0.976, 1.455, 1.47, 0.9279999999999999, 1.431, 1.434, 1.393, 1.329, 1.429, 1.458, 0.498, 0.958, 1.4729999999999999, 1.467, 1.467, 0.964, 1.455, 0.967, 1.458], "policy_blue_0_reward": [-1.0039999999999998, -1.003, -0.5089999999999999, -1.003, -0.001, -1.001, -1.005, -1.0, -1.002, -1.003, -1.001, -1.0, -1.003, -0.015000000000000006, -1.0, -0.002, 0.496, -1.0, -1.001, -1.005, -1.001, -0.503, -1.0, -1.0, 0.9359999999999999, -0.009000000000000001, -1.002, -1.001, -0.5, -1.004, -0.003, -1.002, -1.0019999999999998, -1.0039999999999998, -0.003, -1.001, 0.0, -0.003, -0.04400000000000003, -1.0019999999999998, -1.001, -1.003, -1.003, -1.0019999999999998, -1.004, -0.002, -0.006, -0.012000000000000004, -1.001, -1.002, 0.622, -1.003, -1.002, -1.001, -1.006, -1.001, -1.001, -1.004, -1.0, -1.003, -1.0019999999999998, -0.001, -1.007, -0.003, -0.002, -1.004, -0.001, -1.029, 0.498, -1.0, -1.001, -0.5, -0.505, -1.003, -1.022, -1.004, -1.003, -1.001, -1.0019999999999998, -1.0, -1.001, -1.0039999999999998, -1.002, -1.001, -0.002, -1.001, -1.001, -1.002, -1.0019999999999998, -1.0, -1.0, -1.001, -1.001, -0.502, -1.002, -1.003, -1.001, -0.005, -0.002, -1.0, 0.572, -1.0, -1.002, 0.497, -1.001, -1.002, -1.003, 0.928, -0.001, -1.002, -0.004, -1.0039999999999998, -1.001, -1.004, -1.006, -1.002, -1.002, -0.007, -0.008, -1.002, -0.503, -0.5, -1.001, -1.002, -1.002, -0.001, -1.007, -1.002, -0.006, -1.002, -1.0039999999999998, -1.003, 0.94, -0.010000000000000002, -1.007, -0.007, -1.001, -1.0, -1.003, 0.716, -1.005, -0.004, -1.006, -1.003, -1.005, -1.0, -1.005, -1.002, -1.004, -0.5, -1.002, -1.004, -1.012, -0.005, -1.003, 1.177, -1.002, -1.0, -1.003, -1.002, -1.001, -1.002, -1.003, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24596158935227472, "mean_inference_ms": 1.4756556735817457, "mean_action_processing_ms": 0.06307539993740029, "mean_env_wait_ms": 0.08894674323207948, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021817117202572706, "StateBufferConnector_ms": 0.0014933871059882931, "ViewRequirementAgentConnector_ms": 0.03235238354380538}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000, "num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.80022882299812, "num_env_steps_trained_throughput_per_sec": 102.80022882299812, "timesteps_total": 208000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 416000, "timers": {"training_iteration_time_ms": 38894.26, "sample_time_ms": 7543.582, "learn_time_ms": 31333.274, "learn_throughput": 127.66, "synch_weights_time_ms": 16.905}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 208000, "num_agent_steps_sampled": 416000, "num_agent_steps_trained": 416000}, "done": false, "episodes_total": 6190, "training_iteration": 52, "trial_id": "d67e4_00000", "date": "2023-09-20_22-43-02", "timestamp": 1695264182, "time_this_iter_s": 38.91716504096985, "time_total_s": 2022.8614337444305, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4707f40>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2022.8614337444305, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 35.02727272727274, "ram_util_percent": 49.178181818181805}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2597402597402597, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6948051948051948, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03896103896103896, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6948051948051948, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03896103896103896, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6948051948051948, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03896103896103896, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.132608573635419, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.005629109894289286, "policy_loss": -0.011599814181681722, "vf_loss": 0.006716203779797069, "vf_explained_var": 0.8207457713782788, "kl": 0.0068102680432847295, "entropy": 0.45201801223059496, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 50400.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "sampler_results": {"episode_reward_max": 1.95, "episode_reward_min": -0.45199999999999996, "episode_reward_mean": 0.6759285714285714, "episode_len_mean": 23.396103896103895, "episode_media": {}, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.969}, "policy_reward_mean": {"red_0": 1.3197402597402599, "blue_0": -0.6438116883116882}, "custom_metrics": {"red_0/door_open_done_mean": 0.2597402597402597, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6948051948051948, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03896103896103896, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6948051948051948, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03896103896103896, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6948051948051948, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03896103896103896, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4660000000000002, 1.4369999999999998, 0.43900000000000006, 0.45599999999999996, 1.435, 0.45500000000000007, 0.44799999999999995, -0.45199999999999996, 1.3439999999999999, 0.42100000000000004, 0.45599999999999996, -0.026000000000000023, 1.4529999999999998, 1.46, 1.4409999999999998, 0.7650000000000001, 1.4529999999999998, 1.4220000000000002, 0.46099999999999985, 1.436, 0.45399999999999996, 0.45099999999999996, 0.45799999999999996, 0.45699999999999985, 0.3959999999999999, 1.442, 0.46599999999999997, 0.44399999999999995, 0.474, 0.4630000000000001, 0.903, 0.45699999999999985, 0.4630000000000001, -0.03700000000000003, 0.47299999999999986, 0.3460000000000001, 0.44199999999999995, 0.474, 0.46899999999999986, 1.458, 0.45199999999999996, -0.041000000000000036, 0.47, 0.44300000000000006, 0.472, 1.416, 1.438, 0.45999999999999996, 0.46499999999999986, 0.4670000000000001, 0.46599999999999997, 0.41800000000000015, 0.9119999999999999, 0.44700000000000006, 0.46899999999999986, 0.44999999999999996, -0.02100000000000002, 0.46599999999999997, -0.3670000000000001, 0.46499999999999986, 0.43599999999999994, 1.44, 1.442, 0.3420000000000001, 1.266, 1.4449999999999998, -0.037000000000000026, 0.43900000000000006, 0.469, -0.07199999999999995, 0.46599999999999997, 0.45699999999999985, 0.4580000000000002, 1.459, 0.4670000000000001, 1.393, -0.10899999999999999, 0.4630000000000001, 0.46899999999999986, 0.46899999999999986, 0.42100000000000004, 0.44599999999999995, 0.4590000000000001, 0.43799999999999994, 0.4540000000000002, 0.45299999999999985, 0.4670000000000001, 0.393, 1.432, 1.449, 1.451, 0.45999999999999996, 0.44899999999999984, -0.04399999999999993, 0.44499999999999984, 0.45799999999999996, 1.454, 0.377, 1.242, 0.45399999999999996, 0.4590000000000001, 0.4580000000000002, 0.44499999999999984, 0.44499999999999984, 0.01200000000000001, 0.40700000000000003, 0.9670000000000001, 0.4630000000000001, 0.4500000000000002, 1.447, 0.46499999999999986, 1.46, 1.454, 0.46499999999999997, 1.892, 0.44399999999999995, 1.452, 0.4610000000000001, 0.46399999999999997, 0.46499999999999986, 1.442, 0.45599999999999996, 0.4630000000000001, 0.45199999999999996, 0.4630000000000001, 1.3880000000000001, 0.45999999999999996, 0.44399999999999995, 0.47, 1.37, 0.45999999999999996, 0.44999999999999996, 1.4449999999999998, 1.4489999999999998, 1.45, 0.45999999999999996, 0.42100000000000004, 0.45100000000000007, 0.43799999999999994, 0.43999999999999995, 1.4489999999999998, -0.049000000000000044, 0.43599999999999994, 1.95, 0.4630000000000001, 0.46599999999999997, 0.4700000000000002, 0.46399999999999997, 1.455, 0.40700000000000003, 1.45, 1.454, -0.025000000000000022, 0.46599999999999997], "episode_lengths": [11, 21, 20, 14, 21, 14, 17, 142, 51, 25, 14, 8, 15, 13, 18, 76, 15, 25, 13, 20, 14, 16, 14, 13, 32, 19, 11, 17, 8, 12, 31, 14, 12, 12, 9, 49, 18, 8, 10, 14, 15, 13, 10, 19, 9, 27, 19, 13, 11, 11, 11, 26, 28, 17, 10, 15, 7, 11, 276, 11, 20, 19, 19, 49, 73, 18, 300, 20, 10, 23, 11, 14, 13, 13, 10, 33, 34, 11, 10, 10, 25, 17, 13, 20, 15, 15, 11, 33, 21, 16, 16, 13, 16, 14, 18, 13, 15, 39, 81, 15, 13, 13, 18, 18, 153, 30, 11, 12, 16, 17, 11, 13, 15, 11, 35, 17, 16, 12, 12, 11, 18, 14, 12, 16, 12, 36, 13, 18, 10, 41, 13, 15, 17, 17, 16, 13, 26, 15, 20, 20, 16, 16, 20, 16, 12, 11, 9, 11, 14, 31, 16, 15, 8, 11], "policy_red_0_reward": [1.467, 1.4369999999999998, 1.44, 1.458, 1.4369999999999998, 1.458, 1.4489999999999998, -1.003, 1.346, 1.425, 1.458, 0.975, 1.455, 1.4609999999999999, 1.446, 1.27, 1.455, 1.425, 1.4609999999999999, 1.44, 1.458, -0.5, 1.458, 1.4609999999999999, 1.401, 1.443, 1.467, 1.4489999999999998, 1.476, 1.464, 1.407, 1.458, 1.464, 0.964, 1.4729999999999999, 1.3519999999999999, 1.446, 1.476, 1.47, 1.458, 1.455, 0.961, 1.47, 1.443, 1.4729999999999999, 1.419, 1.443, 1.4609999999999999, 1.467, 1.467, 1.467, 1.4220000000000002, 1.416, 1.4489999999999998, 1.47, 1.455, 0.979, 1.467, 0.6699999999999999, 1.467, 1.44, 1.443, 1.443, 1.3519999999999999, 1.2799999999999998, 1.446, -0.003, 1.44, -0.5, 0.931, 1.467, 1.458, 1.4609999999999999, 1.4609999999999999, 1.47, 1.397, 0.897, 1.467, 1.47, 1.47, 1.425, 1.4489999999999998, 1.4609999999999999, 1.44, 1.455, 1.455, 1.467, 1.401, 1.4369999999999998, 1.452, 1.452, 1.4609999999999999, 1.452, 0.958, 1.446, 1.4609999999999999, 1.455, 1.381, 1.2530000000000001, 1.455, 1.4609999999999999, 1.4609999999999999, 1.446, 1.446, 1.033, -0.5, 1.467, 1.464, 1.452, 1.4489999999999998, 1.467, 1.4609999999999999, 1.455, -0.5, 1.395, 1.4489999999999998, 1.452, 1.464, 1.464, 1.467, 1.4449999999999998, 1.458, 1.464, 1.452, 1.464, 1.392, 1.4609999999999999, 1.446, 1.47, 1.377, 1.4609999999999999, 1.455, 1.4489999999999998, 1.4489999999999998, 1.452, 1.4609999999999999, 1.4220000000000002, 1.455, -0.5, 1.44, 1.452, 0.952, 1.44, 1.452, 1.464, 1.467, 1.4729999999999999, 1.467, 1.458, 1.407, 1.452, 1.455, 0.976, 1.467], "policy_blue_0_reward": [-1.001, 0.0, -1.001, -1.002, -0.002, -1.003, -1.001, 0.551, -0.002, -1.004, -1.002, -1.001, -0.002, -0.001, -0.005, -0.505, -0.002, -0.003, -1.0, -0.004, -1.004, 0.951, -1.0, -1.004, -1.005, -0.001, -1.001, -1.005, -1.002, -1.001, -0.504, -1.001, -1.001, -1.001, -1.0, -1.006, -1.004, -1.002, -1.001, 0.0, -1.003, -1.002, -1.0, -1.0, -1.001, -0.003, -0.005, -1.001, -1.002, -1.0, -1.001, -1.004, -0.504, -1.002, -1.001, -1.005, -1.0, -1.001, -1.037, -1.002, -1.004, -0.003, -0.001, -1.01, -0.014000000000000005, -0.001, -0.03400000000000002, -1.001, 0.969, -1.003, -1.001, -1.001, -1.003, -0.002, -1.003, -0.004, -1.006, -1.0039999999999998, -1.001, -1.001, -1.004, -1.003, -1.002, -1.002, -1.001, -1.002, -1.0, -1.008, -0.005, -0.003, -0.001, -1.001, -1.003, -1.0019999999999998, -1.001, -1.003, -0.001, -1.004, -0.011000000000000003, -1.001, -1.002, -1.003, -1.001, -1.001, -1.021, 0.907, -0.5, -1.001, -1.0019999999999998, -0.002, -1.002, -0.001, -0.001, 0.965, 0.497, -1.005, 0.0, -1.003, -1.0, -1.002, -0.003, -1.002, -1.001, -1.0, -1.001, -0.004, -1.001, -1.002, -1.0, -0.007, -1.001, -1.005, -0.004, 0.0, -0.002, -1.001, -1.001, -1.0039999999999998, 0.938, -1.0, -0.003, -1.001, -1.004, 0.498, -1.001, -1.001, -1.003, -1.003, -0.003, -1.0, -0.002, -0.001, -1.001, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24619594193882863, "mean_inference_ms": 1.4761022189628334, "mean_action_processing_ms": 0.06304841037425966, "mean_env_wait_ms": 0.08895250427900721, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01929588132090383, "StateBufferConnector_ms": 0.0014832267513522853, "ViewRequirementAgentConnector_ms": 0.03154811921057763}}, "episode_reward_max": 1.95, "episode_reward_min": -0.45199999999999996, "episode_reward_mean": 0.6759285714285714, "episode_len_mean": 23.396103896103895, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.969}, "policy_reward_mean": {"red_0": 1.3197402597402599, "blue_0": -0.6438116883116882}, "hist_stats": {"episode_reward": [0.4660000000000002, 1.4369999999999998, 0.43900000000000006, 0.45599999999999996, 1.435, 0.45500000000000007, 0.44799999999999995, -0.45199999999999996, 1.3439999999999999, 0.42100000000000004, 0.45599999999999996, -0.026000000000000023, 1.4529999999999998, 1.46, 1.4409999999999998, 0.7650000000000001, 1.4529999999999998, 1.4220000000000002, 0.46099999999999985, 1.436, 0.45399999999999996, 0.45099999999999996, 0.45799999999999996, 0.45699999999999985, 0.3959999999999999, 1.442, 0.46599999999999997, 0.44399999999999995, 0.474, 0.4630000000000001, 0.903, 0.45699999999999985, 0.4630000000000001, -0.03700000000000003, 0.47299999999999986, 0.3460000000000001, 0.44199999999999995, 0.474, 0.46899999999999986, 1.458, 0.45199999999999996, -0.041000000000000036, 0.47, 0.44300000000000006, 0.472, 1.416, 1.438, 0.45999999999999996, 0.46499999999999986, 0.4670000000000001, 0.46599999999999997, 0.41800000000000015, 0.9119999999999999, 0.44700000000000006, 0.46899999999999986, 0.44999999999999996, -0.02100000000000002, 0.46599999999999997, -0.3670000000000001, 0.46499999999999986, 0.43599999999999994, 1.44, 1.442, 0.3420000000000001, 1.266, 1.4449999999999998, -0.037000000000000026, 0.43900000000000006, 0.469, -0.07199999999999995, 0.46599999999999997, 0.45699999999999985, 0.4580000000000002, 1.459, 0.4670000000000001, 1.393, -0.10899999999999999, 0.4630000000000001, 0.46899999999999986, 0.46899999999999986, 0.42100000000000004, 0.44599999999999995, 0.4590000000000001, 0.43799999999999994, 0.4540000000000002, 0.45299999999999985, 0.4670000000000001, 0.393, 1.432, 1.449, 1.451, 0.45999999999999996, 0.44899999999999984, -0.04399999999999993, 0.44499999999999984, 0.45799999999999996, 1.454, 0.377, 1.242, 0.45399999999999996, 0.4590000000000001, 0.4580000000000002, 0.44499999999999984, 0.44499999999999984, 0.01200000000000001, 0.40700000000000003, 0.9670000000000001, 0.4630000000000001, 0.4500000000000002, 1.447, 0.46499999999999986, 1.46, 1.454, 0.46499999999999997, 1.892, 0.44399999999999995, 1.452, 0.4610000000000001, 0.46399999999999997, 0.46499999999999986, 1.442, 0.45599999999999996, 0.4630000000000001, 0.45199999999999996, 0.4630000000000001, 1.3880000000000001, 0.45999999999999996, 0.44399999999999995, 0.47, 1.37, 0.45999999999999996, 0.44999999999999996, 1.4449999999999998, 1.4489999999999998, 1.45, 0.45999999999999996, 0.42100000000000004, 0.45100000000000007, 0.43799999999999994, 0.43999999999999995, 1.4489999999999998, -0.049000000000000044, 0.43599999999999994, 1.95, 0.4630000000000001, 0.46599999999999997, 0.4700000000000002, 0.46399999999999997, 1.455, 0.40700000000000003, 1.45, 1.454, -0.025000000000000022, 0.46599999999999997], "episode_lengths": [11, 21, 20, 14, 21, 14, 17, 142, 51, 25, 14, 8, 15, 13, 18, 76, 15, 25, 13, 20, 14, 16, 14, 13, 32, 19, 11, 17, 8, 12, 31, 14, 12, 12, 9, 49, 18, 8, 10, 14, 15, 13, 10, 19, 9, 27, 19, 13, 11, 11, 11, 26, 28, 17, 10, 15, 7, 11, 276, 11, 20, 19, 19, 49, 73, 18, 300, 20, 10, 23, 11, 14, 13, 13, 10, 33, 34, 11, 10, 10, 25, 17, 13, 20, 15, 15, 11, 33, 21, 16, 16, 13, 16, 14, 18, 13, 15, 39, 81, 15, 13, 13, 18, 18, 153, 30, 11, 12, 16, 17, 11, 13, 15, 11, 35, 17, 16, 12, 12, 11, 18, 14, 12, 16, 12, 36, 13, 18, 10, 41, 13, 15, 17, 17, 16, 13, 26, 15, 20, 20, 16, 16, 20, 16, 12, 11, 9, 11, 14, 31, 16, 15, 8, 11], "policy_red_0_reward": [1.467, 1.4369999999999998, 1.44, 1.458, 1.4369999999999998, 1.458, 1.4489999999999998, -1.003, 1.346, 1.425, 1.458, 0.975, 1.455, 1.4609999999999999, 1.446, 1.27, 1.455, 1.425, 1.4609999999999999, 1.44, 1.458, -0.5, 1.458, 1.4609999999999999, 1.401, 1.443, 1.467, 1.4489999999999998, 1.476, 1.464, 1.407, 1.458, 1.464, 0.964, 1.4729999999999999, 1.3519999999999999, 1.446, 1.476, 1.47, 1.458, 1.455, 0.961, 1.47, 1.443, 1.4729999999999999, 1.419, 1.443, 1.4609999999999999, 1.467, 1.467, 1.467, 1.4220000000000002, 1.416, 1.4489999999999998, 1.47, 1.455, 0.979, 1.467, 0.6699999999999999, 1.467, 1.44, 1.443, 1.443, 1.3519999999999999, 1.2799999999999998, 1.446, -0.003, 1.44, -0.5, 0.931, 1.467, 1.458, 1.4609999999999999, 1.4609999999999999, 1.47, 1.397, 0.897, 1.467, 1.47, 1.47, 1.425, 1.4489999999999998, 1.4609999999999999, 1.44, 1.455, 1.455, 1.467, 1.401, 1.4369999999999998, 1.452, 1.452, 1.4609999999999999, 1.452, 0.958, 1.446, 1.4609999999999999, 1.455, 1.381, 1.2530000000000001, 1.455, 1.4609999999999999, 1.4609999999999999, 1.446, 1.446, 1.033, -0.5, 1.467, 1.464, 1.452, 1.4489999999999998, 1.467, 1.4609999999999999, 1.455, -0.5, 1.395, 1.4489999999999998, 1.452, 1.464, 1.464, 1.467, 1.4449999999999998, 1.458, 1.464, 1.452, 1.464, 1.392, 1.4609999999999999, 1.446, 1.47, 1.377, 1.4609999999999999, 1.455, 1.4489999999999998, 1.4489999999999998, 1.452, 1.4609999999999999, 1.4220000000000002, 1.455, -0.5, 1.44, 1.452, 0.952, 1.44, 1.452, 1.464, 1.467, 1.4729999999999999, 1.467, 1.458, 1.407, 1.452, 1.455, 0.976, 1.467], "policy_blue_0_reward": [-1.001, 0.0, -1.001, -1.002, -0.002, -1.003, -1.001, 0.551, -0.002, -1.004, -1.002, -1.001, -0.002, -0.001, -0.005, -0.505, -0.002, -0.003, -1.0, -0.004, -1.004, 0.951, -1.0, -1.004, -1.005, -0.001, -1.001, -1.005, -1.002, -1.001, -0.504, -1.001, -1.001, -1.001, -1.0, -1.006, -1.004, -1.002, -1.001, 0.0, -1.003, -1.002, -1.0, -1.0, -1.001, -0.003, -0.005, -1.001, -1.002, -1.0, -1.001, -1.004, -0.504, -1.002, -1.001, -1.005, -1.0, -1.001, -1.037, -1.002, -1.004, -0.003, -0.001, -1.01, -0.014000000000000005, -0.001, -0.03400000000000002, -1.001, 0.969, -1.003, -1.001, -1.001, -1.003, -0.002, -1.003, -0.004, -1.006, -1.0039999999999998, -1.001, -1.001, -1.004, -1.003, -1.002, -1.002, -1.001, -1.002, -1.0, -1.008, -0.005, -0.003, -0.001, -1.001, -1.003, -1.0019999999999998, -1.001, -1.003, -0.001, -1.004, -0.011000000000000003, -1.001, -1.002, -1.003, -1.001, -1.001, -1.021, 0.907, -0.5, -1.001, -1.0019999999999998, -0.002, -1.002, -0.001, -0.001, 0.965, 0.497, -1.005, 0.0, -1.003, -1.0, -1.002, -0.003, -1.002, -1.001, -1.0, -1.001, -0.004, -1.001, -1.002, -1.0, -0.007, -1.001, -1.005, -0.004, 0.0, -0.002, -1.001, -1.001, -1.0039999999999998, 0.938, -1.0, -0.003, -1.001, -1.004, 0.498, -1.001, -1.001, -1.003, -1.003, -0.003, -1.0, -0.002, -0.001, -1.001, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24619594193882863, "mean_inference_ms": 1.4761022189628334, "mean_action_processing_ms": 0.06304841037425966, "mean_env_wait_ms": 0.08895250427900721, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01929588132090383, "StateBufferConnector_ms": 0.0014832267513522853, "ViewRequirementAgentConnector_ms": 0.03154811921057763}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000, "num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 101.33535409506555, "num_env_steps_trained_throughput_per_sec": 101.33535409506555, "timesteps_total": 212000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 424000, "timers": {"training_iteration_time_ms": 38962.968, "sample_time_ms": 7553.677, "learn_time_ms": 31391.556, "learn_throughput": 127.423, "synch_weights_time_ms": 17.229}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 212000, "num_agent_steps_sampled": 424000, "num_agent_steps_trained": 424000}, "done": false, "episodes_total": 6344, "training_iteration": 53, "trial_id": "d67e4_00000", "date": "2023-09-20_22-43-42", "timestamp": 1695264222, "time_this_iter_s": 39.480132818222046, "time_total_s": 2062.3415665626526, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d088d30>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2062.3415665626526, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 36.112280701754386, "ram_util_percent": 49.26315789473685}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2342857142857143, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7257142857142858, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7257142857142858, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7257142857142858, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0445241427669925, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009983577059028904, "policy_loss": -0.016701803164566324, "vf_loss": 0.00779613094321879, "vf_explained_var": 0.802102359260122, "kl": 0.0072416338135316005, "entropy": 0.4385747228749096, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 51360.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "sampler_results": {"episode_reward_max": 1.903, "episode_reward_min": -0.7079999999999999, "episode_reward_mean": 0.6320342857142857, "episode_len_mean": 24.222857142857144, "episode_media": {}, "episodes_this_iter": 175, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.964}, "policy_reward_mean": {"red_0": 1.2956171428571428, "blue_0": -0.6635828571428571}, "custom_metrics": {"red_0/door_open_done_mean": 0.2342857142857143, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7257142857142858, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7257142857142858, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7257142857142858, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.264, 1.446, 0.4620000000000002, 0.43699999999999983, 0.45999999999999996, -0.16200000000000003, 0.45699999999999985, 0.3900000000000001, -0.049000000000000044, 1.362, 0.45500000000000007, 1.447, 0.43199999999999994, 0.44999999999999996, 0.45399999999999996, 0.4710000000000001, 0.4670000000000001, -0.05600000000000005, 0.46499999999999986, 0.44499999999999984, 0.46399999999999997, 1.452, 1.419, 1.455, 0.43099999999999994, 0.478, 0.44300000000000006, 1.324, 0.41700000000000004, 0.46799999999999997, 0.46599999999999997, 0.45399999999999996, 0.45100000000000007, 0.42999999999999994, 0.44399999999999995, -0.040000000000000036, 0.4590000000000001, 0.44099999999999984, 0.45699999999999985, 1.429, 1.4409999999999998, 0.44599999999999995, 0.44199999999999995, 1.4529999999999998, 0.45299999999999985, 0.45599999999999996, 0.45299999999999985, 0.4670000000000001, 0.45299999999999985, 0.46599999999999997, 0.472, 0.4289999999999998, 1.383, 1.3519999999999999, 0.45999999999999996, -0.10899999999999999, 0.42599999999999993, 1.564, 0.405, 0.4710000000000001, 0.43000000000000016, -0.025000000000000022, 0.4460000000000002, 0.46599999999999997, 1.333, -0.04400000000000004, 0.46199999999999997, 0.4580000000000002, 0.45300000000000007, 0.45699999999999985, -0.03300000000000003, -0.02100000000000002, 1.44, 0.46399999999999997, 0.4710000000000001, 0.45199999999999996, 0.43499999999999994, 0.4670000000000001, 0.9220000000000002, 0.4670000000000001, 1.347, 0.45500000000000007, 0.44899999999999984, 0.44999999999999996, 0.46099999999999985, -0.041000000000000036, -0.7079999999999999, 1.455, 1.4289999999999998, 0.45500000000000007, 0.45999999999999996, 1.416, 1.371, 0.4750000000000001, 0.44199999999999995, 1.1480000000000001, 0.41500000000000004, 0.46799999999999997, 0.8740000000000001, 0.46599999999999997, 0.472, 0.46099999999999985, 0.45100000000000007, 0.4630000000000001, 1.455, 0.44799999999999995, 0.45999999999999996, -0.03300000000000003, 0.44599999999999995, 1.399, 1.865, 0.46799999999999997, 0.3620000000000001, 0.44700000000000006, 0.14400000000000013, 0.4119999999999999, 0.44499999999999984, 0.4710000000000001, 0.45999999999999996, -0.04600000000000004, 1.4569999999999999, 0.4540000000000002, 0.9550000000000001, 0.45799999999999996, 0.2430000000000001, 0.45500000000000007, 0.46799999999999997, 1.397, 1.426, -0.04400000000000004, 0.31299999999999994, 0.43900000000000006, 1.453, 1.819, 1.4200000000000002, 1.43, 0.4650000000000001, 0.4750000000000001, 0.964, 0.45999999999999996, -0.025000000000000022, 0.43900000000000006, 1.4529999999999998, 1.4409999999999998, 1.2040000000000002, 0.45799999999999996, 0.46599999999999997, 0.45300000000000007, 1.455, 0.46199999999999997, 0.46599999999999997, 1.4329999999999998, 1.4449999999999998, 0.46799999999999997, -0.02300000000000002, 1.903, 0.44799999999999995, 0.4580000000000002, 0.46899999999999986, 0.42399999999999993, 1.4529999999999998, 0.44499999999999984, 0.40500000000000025, 0.389, -0.04500000000000004, 0.44799999999999995, 0.46799999999999997, 1.4280000000000002, 0.45100000000000007, 0.4630000000000001, 0.4590000000000001, 1.4580000000000002, -0.10599999999999998, 0.46399999999999997, -0.03700000000000003], "episode_lengths": [75, 17, 11, 20, 13, 52, 13, 36, 14, 42, 14, 17, 22, 15, 15, 9, 11, 18, 11, 17, 12, 15, 25, 14, 22, 7, 19, 56, 25, 10, 11, 15, 15, 22, 18, 12, 13, 19, 14, 23, 19, 17, 19, 15, 15, 14, 15, 11, 15, 10, 9, 22, 37, 48, 13, 35, 24, 132, 29, 9, 22, 8, 16, 11, 53, 14, 12, 13, 15, 14, 11, 7, 19, 11, 9, 15, 21, 11, 25, 11, 208, 15, 15, 16, 13, 13, 226, 14, 22, 15, 13, 27, 41, 8, 19, 110, 27, 10, 40, 11, 9, 12, 16, 12, 14, 17, 13, 10, 17, 31, 43, 10, 202, 16, 113, 27, 17, 9, 13, 14, 14, 14, 14, 13, 80, 13, 10, 34, 24, 13, 60, 19, 15, 57, 25, 22, 11, 8, 11, 13, 8, 20, 15, 18, 95, 13, 11, 15, 14, 12, 11, 21, 18, 10, 7, 31, 17, 13, 10, 25, 15, 18, 31, 35, 13, 17, 10, 23, 15, 12, 13, 13, 34, 11, 12], "policy_red_0_reward": [1.274, 1.4489999999999998, 1.467, 1.44, 1.4609999999999999, -1.0, 1.4609999999999999, 1.392, 0.954, 1.374, 1.458, 1.4489999999999998, 1.434, 1.455, 1.455, 1.4729999999999999, 1.467, 0.946, 1.467, 1.4489999999999998, 1.464, 1.455, 1.424, 1.458, -0.5, 1.479, 1.443, 1.3319999999999999, 1.425, 1.47, 1.467, 1.455, 1.455, 1.434, 1.446, 0.963, 1.4609999999999999, 1.443, 1.458, 1.431, 1.443, 1.4489999999999998, 1.443, 1.455, 1.455, 1.458, 1.455, 1.467, 1.455, 1.47, 1.4729999999999999, 1.434, 1.389, 1.3559999999999999, 1.4609999999999999, 0.894, -0.5, 1.0859999999999999, -0.5, 1.4729999999999999, 1.434, 0.976, 1.452, 1.467, 1.337, -1.0, 1.464, 1.4609999999999999, 1.455, 1.458, 0.967, 0.979, 1.443, -0.5, 1.4729999999999999, 1.455, -0.5, 1.467, 1.424, 1.467, 0.874, 1.455, 1.455, 1.452, 1.4609999999999999, 0.961, 0.31900000000000006, 1.458, 1.4329999999999998, 1.455, 1.4609999999999999, 1.419, 1.377, 1.476, 1.443, 1.169, 1.419, 1.47, 1.3780000000000001, 1.467, 1.4729999999999999, 1.464, 1.452, 1.464, 1.458, 1.4489999999999998, 1.4609999999999999, 0.97, 1.4489999999999998, 1.407, 1.371, 1.47, 0.893, 1.452, 1.1560000000000001, 1.416, 1.4489999999999998, 1.4729999999999999, 1.4609999999999999, 0.955, 1.458, 1.458, 1.458, 1.4609999999999999, 1.2570000000000001, 1.4609999999999999, 1.47, 1.3980000000000001, 1.428, 0.961, 1.319, 1.443, 1.455, 1.327, 1.424, 1.434, 1.467, 1.476, 1.467, 1.4609999999999999, 0.976, 1.44, 1.455, 1.446, 1.215, 1.4609999999999999, 1.467, 1.455, 1.4569999999999999, 1.464, 1.467, 1.4369999999999998, 1.446, 1.47, 0.979, 1.407, 1.4489999999999998, 1.4609999999999999, 1.47, 1.425, 1.455, 1.446, 1.4060000000000001, 1.3940000000000001, 0.956, 1.4489999999999998, 1.47, 1.431, 1.455, 1.464, 1.4609999999999999, 1.4609999999999999, 0.896, 1.467, 0.964], "policy_blue_0_reward": [-1.01, -0.003, -1.005, -1.003, -1.001, 0.838, -1.004, -1.002, -1.003, -0.012000000000000004, -1.003, -0.002, -1.002, -1.005, -1.001, -1.0019999999999998, -1.0, -1.002, -1.002, -1.004, -1.0, -0.003, -0.005, -0.003, 0.9309999999999999, -1.001, -1.0, -0.008, -1.008, -1.0019999999999998, -1.001, -1.001, -1.0039999999999998, -1.004, -1.002, -1.003, -1.002, -1.002, -1.001, -0.002, -0.002, -1.003, -1.001, -0.002, -1.002, -1.002, -1.002, -1.0, -1.002, -1.004, -1.001, -1.005, -0.006, -0.004, -1.001, -1.003, 0.9259999999999999, 0.478, 0.905, -1.0019999999999998, -1.0039999999999998, -1.001, -1.0059999999999998, -1.001, -0.004, 0.956, -1.002, -1.003, -1.0019999999999998, -1.001, -1.0, -1.0, -0.003, 0.964, -1.002, -1.003, 0.9349999999999999, -1.0, -0.502, -1.0, 0.473, -1.0, -1.006, -1.002, -1.0, -1.002, -1.027, -0.003, -0.004, -1.0, -1.001, -0.003, -0.006, -1.001, -1.001, -0.02100000000000001, -1.004, -1.002, -0.504, -1.001, -1.001, -1.003, -1.001, -1.001, -0.003, -1.001, -1.001, -1.003, -1.003, -0.008, 0.494, -1.002, -0.5309999999999999, -1.005, -1.012, -1.004, -1.004, -1.002, -1.001, -1.001, -0.001, -1.0039999999999998, -0.503, -1.003, -1.0139999999999998, -1.0059999999999998, -1.002, -0.001, -0.002, -1.005, -1.006, -1.004, -0.002, 0.492, -0.004, -0.004, -1.0019999999999998, -1.001, -0.5029999999999999, -1.001, -1.001, -1.001, -0.002, -0.005, -0.011000000000000003, -1.003, -1.001, -1.0019999999999998, -0.002, -1.002, -1.001, -0.004, -0.001, -1.002, -1.002, 0.496, -1.001, -1.003, -1.001, -1.001, -0.002, -1.001, -1.001, -1.005, -1.001, -1.001, -1.0019999999999998, -0.003, -1.004, -1.001, -1.002, -0.003, -1.002, -1.003, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.246330248036062, "mean_inference_ms": 1.4754627832404916, "mean_action_processing_ms": 0.06307277498934792, "mean_env_wait_ms": 0.08896184539799966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01948676790509905, "StateBufferConnector_ms": 0.0014887537275041854, "ViewRequirementAgentConnector_ms": 0.03140538079398019}}, "episode_reward_max": 1.903, "episode_reward_min": -0.7079999999999999, "episode_reward_mean": 0.6320342857142857, "episode_len_mean": 24.222857142857144, "episodes_this_iter": 175, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.964}, "policy_reward_mean": {"red_0": 1.2956171428571428, "blue_0": -0.6635828571428571}, "hist_stats": {"episode_reward": [0.264, 1.446, 0.4620000000000002, 0.43699999999999983, 0.45999999999999996, -0.16200000000000003, 0.45699999999999985, 0.3900000000000001, -0.049000000000000044, 1.362, 0.45500000000000007, 1.447, 0.43199999999999994, 0.44999999999999996, 0.45399999999999996, 0.4710000000000001, 0.4670000000000001, -0.05600000000000005, 0.46499999999999986, 0.44499999999999984, 0.46399999999999997, 1.452, 1.419, 1.455, 0.43099999999999994, 0.478, 0.44300000000000006, 1.324, 0.41700000000000004, 0.46799999999999997, 0.46599999999999997, 0.45399999999999996, 0.45100000000000007, 0.42999999999999994, 0.44399999999999995, -0.040000000000000036, 0.4590000000000001, 0.44099999999999984, 0.45699999999999985, 1.429, 1.4409999999999998, 0.44599999999999995, 0.44199999999999995, 1.4529999999999998, 0.45299999999999985, 0.45599999999999996, 0.45299999999999985, 0.4670000000000001, 0.45299999999999985, 0.46599999999999997, 0.472, 0.4289999999999998, 1.383, 1.3519999999999999, 0.45999999999999996, -0.10899999999999999, 0.42599999999999993, 1.564, 0.405, 0.4710000000000001, 0.43000000000000016, -0.025000000000000022, 0.4460000000000002, 0.46599999999999997, 1.333, -0.04400000000000004, 0.46199999999999997, 0.4580000000000002, 0.45300000000000007, 0.45699999999999985, -0.03300000000000003, -0.02100000000000002, 1.44, 0.46399999999999997, 0.4710000000000001, 0.45199999999999996, 0.43499999999999994, 0.4670000000000001, 0.9220000000000002, 0.4670000000000001, 1.347, 0.45500000000000007, 0.44899999999999984, 0.44999999999999996, 0.46099999999999985, -0.041000000000000036, -0.7079999999999999, 1.455, 1.4289999999999998, 0.45500000000000007, 0.45999999999999996, 1.416, 1.371, 0.4750000000000001, 0.44199999999999995, 1.1480000000000001, 0.41500000000000004, 0.46799999999999997, 0.8740000000000001, 0.46599999999999997, 0.472, 0.46099999999999985, 0.45100000000000007, 0.4630000000000001, 1.455, 0.44799999999999995, 0.45999999999999996, -0.03300000000000003, 0.44599999999999995, 1.399, 1.865, 0.46799999999999997, 0.3620000000000001, 0.44700000000000006, 0.14400000000000013, 0.4119999999999999, 0.44499999999999984, 0.4710000000000001, 0.45999999999999996, -0.04600000000000004, 1.4569999999999999, 0.4540000000000002, 0.9550000000000001, 0.45799999999999996, 0.2430000000000001, 0.45500000000000007, 0.46799999999999997, 1.397, 1.426, -0.04400000000000004, 0.31299999999999994, 0.43900000000000006, 1.453, 1.819, 1.4200000000000002, 1.43, 0.4650000000000001, 0.4750000000000001, 0.964, 0.45999999999999996, -0.025000000000000022, 0.43900000000000006, 1.4529999999999998, 1.4409999999999998, 1.2040000000000002, 0.45799999999999996, 0.46599999999999997, 0.45300000000000007, 1.455, 0.46199999999999997, 0.46599999999999997, 1.4329999999999998, 1.4449999999999998, 0.46799999999999997, -0.02300000000000002, 1.903, 0.44799999999999995, 0.4580000000000002, 0.46899999999999986, 0.42399999999999993, 1.4529999999999998, 0.44499999999999984, 0.40500000000000025, 0.389, -0.04500000000000004, 0.44799999999999995, 0.46799999999999997, 1.4280000000000002, 0.45100000000000007, 0.4630000000000001, 0.4590000000000001, 1.4580000000000002, -0.10599999999999998, 0.46399999999999997, -0.03700000000000003], "episode_lengths": [75, 17, 11, 20, 13, 52, 13, 36, 14, 42, 14, 17, 22, 15, 15, 9, 11, 18, 11, 17, 12, 15, 25, 14, 22, 7, 19, 56, 25, 10, 11, 15, 15, 22, 18, 12, 13, 19, 14, 23, 19, 17, 19, 15, 15, 14, 15, 11, 15, 10, 9, 22, 37, 48, 13, 35, 24, 132, 29, 9, 22, 8, 16, 11, 53, 14, 12, 13, 15, 14, 11, 7, 19, 11, 9, 15, 21, 11, 25, 11, 208, 15, 15, 16, 13, 13, 226, 14, 22, 15, 13, 27, 41, 8, 19, 110, 27, 10, 40, 11, 9, 12, 16, 12, 14, 17, 13, 10, 17, 31, 43, 10, 202, 16, 113, 27, 17, 9, 13, 14, 14, 14, 14, 13, 80, 13, 10, 34, 24, 13, 60, 19, 15, 57, 25, 22, 11, 8, 11, 13, 8, 20, 15, 18, 95, 13, 11, 15, 14, 12, 11, 21, 18, 10, 7, 31, 17, 13, 10, 25, 15, 18, 31, 35, 13, 17, 10, 23, 15, 12, 13, 13, 34, 11, 12], "policy_red_0_reward": [1.274, 1.4489999999999998, 1.467, 1.44, 1.4609999999999999, -1.0, 1.4609999999999999, 1.392, 0.954, 1.374, 1.458, 1.4489999999999998, 1.434, 1.455, 1.455, 1.4729999999999999, 1.467, 0.946, 1.467, 1.4489999999999998, 1.464, 1.455, 1.424, 1.458, -0.5, 1.479, 1.443, 1.3319999999999999, 1.425, 1.47, 1.467, 1.455, 1.455, 1.434, 1.446, 0.963, 1.4609999999999999, 1.443, 1.458, 1.431, 1.443, 1.4489999999999998, 1.443, 1.455, 1.455, 1.458, 1.455, 1.467, 1.455, 1.47, 1.4729999999999999, 1.434, 1.389, 1.3559999999999999, 1.4609999999999999, 0.894, -0.5, 1.0859999999999999, -0.5, 1.4729999999999999, 1.434, 0.976, 1.452, 1.467, 1.337, -1.0, 1.464, 1.4609999999999999, 1.455, 1.458, 0.967, 0.979, 1.443, -0.5, 1.4729999999999999, 1.455, -0.5, 1.467, 1.424, 1.467, 0.874, 1.455, 1.455, 1.452, 1.4609999999999999, 0.961, 0.31900000000000006, 1.458, 1.4329999999999998, 1.455, 1.4609999999999999, 1.419, 1.377, 1.476, 1.443, 1.169, 1.419, 1.47, 1.3780000000000001, 1.467, 1.4729999999999999, 1.464, 1.452, 1.464, 1.458, 1.4489999999999998, 1.4609999999999999, 0.97, 1.4489999999999998, 1.407, 1.371, 1.47, 0.893, 1.452, 1.1560000000000001, 1.416, 1.4489999999999998, 1.4729999999999999, 1.4609999999999999, 0.955, 1.458, 1.458, 1.458, 1.4609999999999999, 1.2570000000000001, 1.4609999999999999, 1.47, 1.3980000000000001, 1.428, 0.961, 1.319, 1.443, 1.455, 1.327, 1.424, 1.434, 1.467, 1.476, 1.467, 1.4609999999999999, 0.976, 1.44, 1.455, 1.446, 1.215, 1.4609999999999999, 1.467, 1.455, 1.4569999999999999, 1.464, 1.467, 1.4369999999999998, 1.446, 1.47, 0.979, 1.407, 1.4489999999999998, 1.4609999999999999, 1.47, 1.425, 1.455, 1.446, 1.4060000000000001, 1.3940000000000001, 0.956, 1.4489999999999998, 1.47, 1.431, 1.455, 1.464, 1.4609999999999999, 1.4609999999999999, 0.896, 1.467, 0.964], "policy_blue_0_reward": [-1.01, -0.003, -1.005, -1.003, -1.001, 0.838, -1.004, -1.002, -1.003, -0.012000000000000004, -1.003, -0.002, -1.002, -1.005, -1.001, -1.0019999999999998, -1.0, -1.002, -1.002, -1.004, -1.0, -0.003, -0.005, -0.003, 0.9309999999999999, -1.001, -1.0, -0.008, -1.008, -1.0019999999999998, -1.001, -1.001, -1.0039999999999998, -1.004, -1.002, -1.003, -1.002, -1.002, -1.001, -0.002, -0.002, -1.003, -1.001, -0.002, -1.002, -1.002, -1.002, -1.0, -1.002, -1.004, -1.001, -1.005, -0.006, -0.004, -1.001, -1.003, 0.9259999999999999, 0.478, 0.905, -1.0019999999999998, -1.0039999999999998, -1.001, -1.0059999999999998, -1.001, -0.004, 0.956, -1.002, -1.003, -1.0019999999999998, -1.001, -1.0, -1.0, -0.003, 0.964, -1.002, -1.003, 0.9349999999999999, -1.0, -0.502, -1.0, 0.473, -1.0, -1.006, -1.002, -1.0, -1.002, -1.027, -0.003, -0.004, -1.0, -1.001, -0.003, -0.006, -1.001, -1.001, -0.02100000000000001, -1.004, -1.002, -0.504, -1.001, -1.001, -1.003, -1.001, -1.001, -0.003, -1.001, -1.001, -1.003, -1.003, -0.008, 0.494, -1.002, -0.5309999999999999, -1.005, -1.012, -1.004, -1.004, -1.002, -1.001, -1.001, -0.001, -1.0039999999999998, -0.503, -1.003, -1.0139999999999998, -1.0059999999999998, -1.002, -0.001, -0.002, -1.005, -1.006, -1.004, -0.002, 0.492, -0.004, -0.004, -1.0019999999999998, -1.001, -0.5029999999999999, -1.001, -1.001, -1.001, -0.002, -0.005, -0.011000000000000003, -1.003, -1.001, -1.0019999999999998, -0.002, -1.002, -1.001, -0.004, -0.001, -1.002, -1.002, 0.496, -1.001, -1.003, -1.001, -1.001, -0.002, -1.001, -1.001, -1.005, -1.001, -1.001, -1.0019999999999998, -0.003, -1.004, -1.001, -1.002, -0.003, -1.002, -1.003, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.246330248036062, "mean_inference_ms": 1.4754627832404916, "mean_action_processing_ms": 0.06307277498934792, "mean_env_wait_ms": 0.08896184539799966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01948676790509905, "StateBufferConnector_ms": 0.0014887537275041854, "ViewRequirementAgentConnector_ms": 0.03140538079398019}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000, "num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.98216539677937, "num_env_steps_trained_throughput_per_sec": 102.98216539677937, "timesteps_total": 216000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 432000, "timers": {"training_iteration_time_ms": 38964.067, "sample_time_ms": 7555.395, "learn_time_ms": 31390.985, "learn_throughput": 127.425, "synch_weights_time_ms": 17.185}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 216000, "num_agent_steps_sampled": 432000, "num_agent_steps_trained": 432000}, "done": false, "episodes_total": 6519, "training_iteration": 54, "trial_id": "d67e4_00000", "date": "2023-09-20_22-44-21", "timestamp": 1695264261, "time_this_iter_s": 38.84867811203003, "time_total_s": 2101.1902446746826, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706680>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2101.1902446746826, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 33.625, "ram_util_percent": 49.208928571428565}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.23563218390804597, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.735632183908046, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.028735632183908046, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.735632183908046, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.028735632183908046, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.735632183908046, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.028735632183908046, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.2648377678667506, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.01665317708539078, "policy_loss": -0.025286136527574853, "vf_loss": 0.007013363415414157, "vf_explained_var": 0.8143443576991558, "kl": 0.01234696658885691, "entropy": 0.4298569511001309, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 52320.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "sampler_results": {"episode_reward_max": 1.9409999999999998, "episode_reward_min": -0.667, "episode_reward_mean": 0.6227816091954024, "episode_len_mean": 23.902298850574713, "episode_media": {}, "episodes_this_iter": 174, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.095}, "policy_reward_mean": {"red_0": 1.3248965517241378, "blue_0": -0.7021149425287355}, "custom_metrics": {"red_0/door_open_done_mean": 0.23563218390804597, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.735632183908046, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.028735632183908046, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.735632183908046, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.028735632183908046, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.735632183908046, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.028735632183908046, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.3940000000000001, 1.8359999999999999, 0.46499999999999986, -0.03400000000000003, 0.45199999999999996, 0.4630000000000001, 0.4670000000000001, 0.45999999999999996, 0.4630000000000001, 0.4670000000000001, 0.469, 0.44900000000000007, 0.45699999999999985, 0.45300000000000007, 0.46499999999999986, 0.3900000000000001, 0.45399999999999996, 0.46199999999999997, 1.447, 0.44300000000000006, 1.4449999999999998, 0.4540000000000002, 0.4630000000000001, 0.45500000000000007, 0.584, -0.039999999999999925, 1.455, 0.4249999999999998, 1.416, 0.47, 0.47, 0.4580000000000002, -0.05399999999999994, 0.45199999999999996, 0.44899999999999984, 1.451, 0.3780000000000001, 0.45999999999999996, 0.44399999999999995, 0.45500000000000007, -0.07899999999999996, 0.45999999999999996, 1.405, 1.407, -0.06700000000000006, 0.43900000000000006, 0.4590000000000001, 1.4249999999999998, -0.09899999999999998, 1.447, 1.419, 0.46199999999999997, 0.44499999999999984, 0.47, 0.45999999999999996, 0.43100000000000005, 0.47299999999999986, 0.4740000000000002, 1.454, 0.43799999999999994, 1.459, 0.46099999999999985, 0.44300000000000006, 0.45599999999999996, 0.4670000000000001, 0.45399999999999996, 0.45799999999999996, 0.46899999999999986, 0.246, 0.4620000000000002, 0.46099999999999985, 0.45699999999999985, 0.44799999999999995, 0.44999999999999996, 0.46799999999999997, 0.405, 0.45299999999999985, 1.46, 1.4489999999999998, 1.274, 0.4500000000000002, -0.02200000000000002, 0.44599999999999995, 0.42700000000000005, -0.04799999999999993, 0.46499999999999986, 0.46199999999999997, 0.4650000000000001, 0.44799999999999995, -0.10099999999999998, 1.455, 1.44, 0.45699999999999985, 1.4329999999999998, -0.43900000000000006, 1.459, 1.9409999999999998, 0.44199999999999995, 0.45399999999999996, 0.46499999999999986, 1.432, -0.02200000000000002, 0.43199999999999994, 0.45999999999999996, 0.46399999999999997, 0.45999999999999996, 0.45799999999999996, 0.45100000000000007, 1.447, 0.45799999999999996, 1.451, 0.45599999999999996, 0.45599999999999996, 0.45499999999999996, 0.46499999999999986, 1.323, 1.4609999999999999, -0.11399999999999999, -0.667, -0.05700000000000005, 0.41700000000000004, 0.44099999999999984, 0.45999999999999996, 0.4540000000000002, 0.45599999999999996, 1.353, 0.46599999999999997, 1.454, 0.47299999999999986, 0.44999999999999996, 0.45599999999999996, 0.45599999999999996, 0.45500000000000007, 0.45999999999999996, 1.417, 0.4650000000000001, 0.44300000000000006, -0.2510000000000001, 0.45399999999999996, 0.9339999999999999, 1.458, -0.19399999999999995, 0.45100000000000007, 0.45100000000000007, 0.44499999999999984, 1.209, -0.08299999999999985, 0.46899999999999986, 0.472, 0.403, 0.44099999999999984, 1.436, -0.08100000000000007, 1.435, 0.4630000000000001, 1.4249999999999998, 1.444, 0.46899999999999986, 0.46599999999999997, 0.45599999999999996, 1.4580000000000002, 0.47, 1.45, -0.09599999999999997, 1.4489999999999998, 0.40900000000000003, 0.41999999999999993, 0.45999999999999996, 0.44900000000000007, -0.04499999999999993, 0.46499999999999986, 1.4529999999999998, 0.41700000000000004, 1.454], "episode_lengths": [35, 52, 11, 11, 14, 12, 10, 13, 12, 11, 10, 16, 13, 15, 11, 31, 15, 12, 16, 18, 17, 14, 12, 14, 129, 13, 15, 24, 26, 10, 10, 13, 17, 16, 16, 15, 39, 13, 18, 14, 24, 12, 30, 30, 21, 19, 13, 24, 31, 17, 26, 12, 17, 10, 12, 22, 9, 8, 15, 20, 13, 13, 18, 14, 11, 14, 13, 10, 80, 12, 13, 14, 17, 16, 10, 30, 14, 13, 17, 71, 16, 7, 17, 23, 15, 11, 12, 11, 17, 32, 15, 19, 14, 21, 298, 13, 19, 19, 14, 11, 21, 7, 22, 13, 12, 12, 13, 16, 17, 13, 16, 14, 14, 14, 11, 58, 13, 37, 206, 19, 26, 19, 12, 14, 14, 48, 11, 15, 9, 16, 13, 14, 14, 12, 26, 11, 19, 240, 14, 21, 14, 220, 14, 16, 17, 93, 26, 10, 9, 31, 19, 21, 24, 21, 11, 24, 18, 10, 11, 14, 13, 10, 16, 30, 17, 29, 24, 13, 16, 14, 11, 15, 26, 14], "policy_red_0_reward": [1.395, 1.3439999999999999, 1.467, 0.967, 1.458, 1.464, 1.47, 1.4609999999999999, 1.464, 1.467, -0.5, 1.452, 1.4609999999999999, 1.455, 1.467, 1.3940000000000001, 1.455, 1.464, 1.452, 1.446, 1.4489999999999998, 1.458, 1.464, 1.458, -0.511, -1.0, 1.455, 1.428, 1.4220000000000002, 1.47, 1.47, 1.4609999999999999, 0.949, 1.452, 1.452, 1.455, 1.3820000000000001, 1.4609999999999999, 1.446, 1.458, 0.9279999999999999, 1.464, 1.4100000000000001, 1.4100000000000001, 0.9369999999999999, 1.443, 1.4609999999999999, 1.427, 0.907, 1.4489999999999998, 1.4220000000000002, 1.464, 1.448, 1.47, 1.464, 1.434, 1.4729999999999999, 1.476, 1.455, 1.44, 1.4609999999999999, 1.4609999999999999, 1.446, 1.458, 1.467, 1.458, 1.4609999999999999, 1.47, 1.256, 1.464, 1.4609999999999999, 1.458, 1.4489999999999998, 1.452, 1.47, 1.4100000000000001, 1.458, 1.4609999999999999, 1.4489999999999998, 1.2850000000000001, 1.452, 0.979, 1.448, 1.431, 0.955, 1.467, 1.464, 1.467, 1.4489999999999998, 0.904, 1.455, 1.443, 1.458, 1.436, 0.6, 1.4609999999999999, 1.443, 1.443, 1.458, 1.467, 1.4369999999999998, 0.979, 1.4329999999999998, 1.4609999999999999, 1.464, 1.464, 1.46, 1.452, 1.4489999999999998, 1.4609999999999999, 1.452, 1.458, 1.458, -0.5, 1.467, 1.326, 1.4609999999999999, 0.889, 0.367, 0.943, 1.4220000000000002, 1.443, 1.464, 1.458, 1.458, 1.3559999999999999, 1.467, 1.455, 1.4729999999999999, 1.452, 1.4609999999999999, 1.458, 1.458, 1.464, 1.4220000000000002, 1.467, 1.443, 0.7799999999999999, 1.458, 1.4369999999999998, 1.458, 0.8400000000000001, 1.458, 1.452, 1.4489999999999998, 1.221, -1.001, 1.47, 1.4729999999999999, 1.407, 1.443, 1.4369999999999998, 0.9259999999999999, 1.4369999999999998, 1.467, 1.428, 1.4449999999999998, 1.47, 1.467, 1.458, 1.4609999999999999, 1.47, 1.452, 0.91, 1.4489999999999998, 1.413, 1.424, 1.4609999999999999, 1.452, 0.957, 1.467, 1.455, 1.4220000000000002, 1.458], "policy_blue_0_reward": [-0.001, 0.492, -1.002, -1.001, -1.006, -1.001, -1.003, -1.001, -1.001, -1.0, 0.969, -1.003, -1.004, -1.0019999999999998, -1.002, -1.004, -1.001, -1.002, -0.005, -1.003, -0.004, -1.0039999999999998, -1.001, -1.003, 1.095, 0.96, 0.0, -1.003, -0.006, -1.0, -1.0, -1.003, -1.003, -1.0, -1.003, -0.004, -1.004, -1.001, -1.002, -1.003, -1.007, -1.0039999999999998, -0.005, -0.003, -1.004, -1.004, -1.002, -0.002, -1.006, -0.002, -0.003, -1.002, -1.003, -1.0, -1.0039999999999998, -1.003, -1.0, -1.0019999999999998, -0.001, -1.002, -0.002, -1.0, -1.003, -1.002, -1.0, -1.004, -1.003, -1.001, -1.01, -1.0019999999999998, -1.0, -1.001, -1.001, -1.002, -1.0019999999999998, -1.005, -1.005, -0.001, 0.0, -0.011000000000000003, -1.0019999999999998, -1.001, -1.002, -1.004, -1.003, -1.002, -1.002, -1.0019999999999998, -1.001, -1.005, 0.0, -0.003, -1.001, -0.003, -1.039, -0.002, 0.498, -1.001, -1.004, -1.002, -0.005, -1.001, -1.001, -1.001, -1.0, -1.004, -1.002, -1.001, -0.002, -1.003, -0.001, -1.002, -1.002, 0.955, -1.002, -0.003, 0.0, -1.003, -1.034, -1.0, -1.005, -1.002, -1.0039999999999998, -1.0039999999999998, -1.002, -0.003, -1.001, -0.001, -1.0, -1.002, -1.005, -1.002, -1.003, -1.0039999999999998, -0.005, -1.0019999999999998, -1.0, -1.031, -1.004, -0.503, 0.0, -1.034, -1.007, -1.001, -1.004, -0.012000000000000004, 0.918, -1.001, -1.001, -1.004, -1.002, -0.001, -1.007, -0.002, -1.0039999999999998, -0.003, -0.001, -1.001, -1.001, -1.002, -0.003, -1.0, -0.002, -1.006, 0.0, -1.004, -1.004, -1.001, -1.003, -1.0019999999999998, -1.002, -0.002, -1.005, -0.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24648435571253963, "mean_inference_ms": 1.4764282284575547, "mean_action_processing_ms": 0.0631238438652848, "mean_env_wait_ms": 0.08897420261567769, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019272990610407686, "StateBufferConnector_ms": 0.001451133311479941, "ViewRequirementAgentConnector_ms": 0.03114472860577463}}, "episode_reward_max": 1.9409999999999998, "episode_reward_min": -0.667, "episode_reward_mean": 0.6227816091954024, "episode_len_mean": 23.902298850574713, "episodes_this_iter": 174, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.039}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.095}, "policy_reward_mean": {"red_0": 1.3248965517241378, "blue_0": -0.7021149425287355}, "hist_stats": {"episode_reward": [1.3940000000000001, 1.8359999999999999, 0.46499999999999986, -0.03400000000000003, 0.45199999999999996, 0.4630000000000001, 0.4670000000000001, 0.45999999999999996, 0.4630000000000001, 0.4670000000000001, 0.469, 0.44900000000000007, 0.45699999999999985, 0.45300000000000007, 0.46499999999999986, 0.3900000000000001, 0.45399999999999996, 0.46199999999999997, 1.447, 0.44300000000000006, 1.4449999999999998, 0.4540000000000002, 0.4630000000000001, 0.45500000000000007, 0.584, -0.039999999999999925, 1.455, 0.4249999999999998, 1.416, 0.47, 0.47, 0.4580000000000002, -0.05399999999999994, 0.45199999999999996, 0.44899999999999984, 1.451, 0.3780000000000001, 0.45999999999999996, 0.44399999999999995, 0.45500000000000007, -0.07899999999999996, 0.45999999999999996, 1.405, 1.407, -0.06700000000000006, 0.43900000000000006, 0.4590000000000001, 1.4249999999999998, -0.09899999999999998, 1.447, 1.419, 0.46199999999999997, 0.44499999999999984, 0.47, 0.45999999999999996, 0.43100000000000005, 0.47299999999999986, 0.4740000000000002, 1.454, 0.43799999999999994, 1.459, 0.46099999999999985, 0.44300000000000006, 0.45599999999999996, 0.4670000000000001, 0.45399999999999996, 0.45799999999999996, 0.46899999999999986, 0.246, 0.4620000000000002, 0.46099999999999985, 0.45699999999999985, 0.44799999999999995, 0.44999999999999996, 0.46799999999999997, 0.405, 0.45299999999999985, 1.46, 1.4489999999999998, 1.274, 0.4500000000000002, -0.02200000000000002, 0.44599999999999995, 0.42700000000000005, -0.04799999999999993, 0.46499999999999986, 0.46199999999999997, 0.4650000000000001, 0.44799999999999995, -0.10099999999999998, 1.455, 1.44, 0.45699999999999985, 1.4329999999999998, -0.43900000000000006, 1.459, 1.9409999999999998, 0.44199999999999995, 0.45399999999999996, 0.46499999999999986, 1.432, -0.02200000000000002, 0.43199999999999994, 0.45999999999999996, 0.46399999999999997, 0.45999999999999996, 0.45799999999999996, 0.45100000000000007, 1.447, 0.45799999999999996, 1.451, 0.45599999999999996, 0.45599999999999996, 0.45499999999999996, 0.46499999999999986, 1.323, 1.4609999999999999, -0.11399999999999999, -0.667, -0.05700000000000005, 0.41700000000000004, 0.44099999999999984, 0.45999999999999996, 0.4540000000000002, 0.45599999999999996, 1.353, 0.46599999999999997, 1.454, 0.47299999999999986, 0.44999999999999996, 0.45599999999999996, 0.45599999999999996, 0.45500000000000007, 0.45999999999999996, 1.417, 0.4650000000000001, 0.44300000000000006, -0.2510000000000001, 0.45399999999999996, 0.9339999999999999, 1.458, -0.19399999999999995, 0.45100000000000007, 0.45100000000000007, 0.44499999999999984, 1.209, -0.08299999999999985, 0.46899999999999986, 0.472, 0.403, 0.44099999999999984, 1.436, -0.08100000000000007, 1.435, 0.4630000000000001, 1.4249999999999998, 1.444, 0.46899999999999986, 0.46599999999999997, 0.45599999999999996, 1.4580000000000002, 0.47, 1.45, -0.09599999999999997, 1.4489999999999998, 0.40900000000000003, 0.41999999999999993, 0.45999999999999996, 0.44900000000000007, -0.04499999999999993, 0.46499999999999986, 1.4529999999999998, 0.41700000000000004, 1.454], "episode_lengths": [35, 52, 11, 11, 14, 12, 10, 13, 12, 11, 10, 16, 13, 15, 11, 31, 15, 12, 16, 18, 17, 14, 12, 14, 129, 13, 15, 24, 26, 10, 10, 13, 17, 16, 16, 15, 39, 13, 18, 14, 24, 12, 30, 30, 21, 19, 13, 24, 31, 17, 26, 12, 17, 10, 12, 22, 9, 8, 15, 20, 13, 13, 18, 14, 11, 14, 13, 10, 80, 12, 13, 14, 17, 16, 10, 30, 14, 13, 17, 71, 16, 7, 17, 23, 15, 11, 12, 11, 17, 32, 15, 19, 14, 21, 298, 13, 19, 19, 14, 11, 21, 7, 22, 13, 12, 12, 13, 16, 17, 13, 16, 14, 14, 14, 11, 58, 13, 37, 206, 19, 26, 19, 12, 14, 14, 48, 11, 15, 9, 16, 13, 14, 14, 12, 26, 11, 19, 240, 14, 21, 14, 220, 14, 16, 17, 93, 26, 10, 9, 31, 19, 21, 24, 21, 11, 24, 18, 10, 11, 14, 13, 10, 16, 30, 17, 29, 24, 13, 16, 14, 11, 15, 26, 14], "policy_red_0_reward": [1.395, 1.3439999999999999, 1.467, 0.967, 1.458, 1.464, 1.47, 1.4609999999999999, 1.464, 1.467, -0.5, 1.452, 1.4609999999999999, 1.455, 1.467, 1.3940000000000001, 1.455, 1.464, 1.452, 1.446, 1.4489999999999998, 1.458, 1.464, 1.458, -0.511, -1.0, 1.455, 1.428, 1.4220000000000002, 1.47, 1.47, 1.4609999999999999, 0.949, 1.452, 1.452, 1.455, 1.3820000000000001, 1.4609999999999999, 1.446, 1.458, 0.9279999999999999, 1.464, 1.4100000000000001, 1.4100000000000001, 0.9369999999999999, 1.443, 1.4609999999999999, 1.427, 0.907, 1.4489999999999998, 1.4220000000000002, 1.464, 1.448, 1.47, 1.464, 1.434, 1.4729999999999999, 1.476, 1.455, 1.44, 1.4609999999999999, 1.4609999999999999, 1.446, 1.458, 1.467, 1.458, 1.4609999999999999, 1.47, 1.256, 1.464, 1.4609999999999999, 1.458, 1.4489999999999998, 1.452, 1.47, 1.4100000000000001, 1.458, 1.4609999999999999, 1.4489999999999998, 1.2850000000000001, 1.452, 0.979, 1.448, 1.431, 0.955, 1.467, 1.464, 1.467, 1.4489999999999998, 0.904, 1.455, 1.443, 1.458, 1.436, 0.6, 1.4609999999999999, 1.443, 1.443, 1.458, 1.467, 1.4369999999999998, 0.979, 1.4329999999999998, 1.4609999999999999, 1.464, 1.464, 1.46, 1.452, 1.4489999999999998, 1.4609999999999999, 1.452, 1.458, 1.458, -0.5, 1.467, 1.326, 1.4609999999999999, 0.889, 0.367, 0.943, 1.4220000000000002, 1.443, 1.464, 1.458, 1.458, 1.3559999999999999, 1.467, 1.455, 1.4729999999999999, 1.452, 1.4609999999999999, 1.458, 1.458, 1.464, 1.4220000000000002, 1.467, 1.443, 0.7799999999999999, 1.458, 1.4369999999999998, 1.458, 0.8400000000000001, 1.458, 1.452, 1.4489999999999998, 1.221, -1.001, 1.47, 1.4729999999999999, 1.407, 1.443, 1.4369999999999998, 0.9259999999999999, 1.4369999999999998, 1.467, 1.428, 1.4449999999999998, 1.47, 1.467, 1.458, 1.4609999999999999, 1.47, 1.452, 0.91, 1.4489999999999998, 1.413, 1.424, 1.4609999999999999, 1.452, 0.957, 1.467, 1.455, 1.4220000000000002, 1.458], "policy_blue_0_reward": [-0.001, 0.492, -1.002, -1.001, -1.006, -1.001, -1.003, -1.001, -1.001, -1.0, 0.969, -1.003, -1.004, -1.0019999999999998, -1.002, -1.004, -1.001, -1.002, -0.005, -1.003, -0.004, -1.0039999999999998, -1.001, -1.003, 1.095, 0.96, 0.0, -1.003, -0.006, -1.0, -1.0, -1.003, -1.003, -1.0, -1.003, -0.004, -1.004, -1.001, -1.002, -1.003, -1.007, -1.0039999999999998, -0.005, -0.003, -1.004, -1.004, -1.002, -0.002, -1.006, -0.002, -0.003, -1.002, -1.003, -1.0, -1.0039999999999998, -1.003, -1.0, -1.0019999999999998, -0.001, -1.002, -0.002, -1.0, -1.003, -1.002, -1.0, -1.004, -1.003, -1.001, -1.01, -1.0019999999999998, -1.0, -1.001, -1.001, -1.002, -1.0019999999999998, -1.005, -1.005, -0.001, 0.0, -0.011000000000000003, -1.0019999999999998, -1.001, -1.002, -1.004, -1.003, -1.002, -1.002, -1.0019999999999998, -1.001, -1.005, 0.0, -0.003, -1.001, -0.003, -1.039, -0.002, 0.498, -1.001, -1.004, -1.002, -0.005, -1.001, -1.001, -1.001, -1.0, -1.004, -1.002, -1.001, -0.002, -1.003, -0.001, -1.002, -1.002, 0.955, -1.002, -0.003, 0.0, -1.003, -1.034, -1.0, -1.005, -1.002, -1.0039999999999998, -1.0039999999999998, -1.002, -0.003, -1.001, -0.001, -1.0, -1.002, -1.005, -1.002, -1.003, -1.0039999999999998, -0.005, -1.0019999999999998, -1.0, -1.031, -1.004, -0.503, 0.0, -1.034, -1.007, -1.001, -1.004, -0.012000000000000004, 0.918, -1.001, -1.001, -1.004, -1.002, -0.001, -1.007, -0.002, -1.0039999999999998, -0.003, -0.001, -1.001, -1.001, -1.002, -0.003, -1.0, -0.002, -1.006, 0.0, -1.004, -1.004, -1.001, -1.003, -1.0019999999999998, -1.002, -0.002, -1.005, -0.004]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24648435571253963, "mean_inference_ms": 1.4764282284575547, "mean_action_processing_ms": 0.0631238438652848, "mean_env_wait_ms": 0.08897420261567769, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019272990610407686, "StateBufferConnector_ms": 0.001451133311479941, "ViewRequirementAgentConnector_ms": 0.03114472860577463}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000, "num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.97644876014779, "num_env_steps_trained_throughput_per_sec": 102.97644876014779, "timesteps_total": 220000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 440000, "timers": {"training_iteration_time_ms": 38977.939, "sample_time_ms": 7557.634, "learn_time_ms": 31402.629, "learn_throughput": 127.378, "synch_weights_time_ms": 17.173}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 220000, "num_agent_steps_sampled": 440000, "num_agent_steps_trained": 440000}, "done": false, "episodes_total": 6693, "training_iteration": 55, "trial_id": "d67e4_00000", "date": "2023-09-20_22-45-00", "timestamp": 1695264300, "time_this_iter_s": 38.8510320186615, "time_total_s": 2140.041276693344, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a46fe200>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2140.041276693344, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 34.6, "ram_util_percent": 49.274545454545475}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2033898305084746, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7627118644067796, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03389830508474576, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7627118644067796, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03389830508474576, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7627118644067796, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03389830508474576, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9652501826484998, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007494371337331055, "policy_loss": -0.013306956702338842, "vf_loss": 0.006803312619013013, "vf_explained_var": 0.8012078033139308, "kl": 0.006238240610824394, "entropy": 0.3962797053468724, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 53280.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "sampler_results": {"episode_reward_max": 1.9290000000000003, "episode_reward_min": -0.124, "episode_reward_mean": 0.6169265536723164, "episode_len_mean": 21.135593220338983, "episode_media": {}, "episodes_this_iter": 177, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.0119999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.973}, "policy_reward_mean": {"red_0": 1.3253898305084748, "blue_0": -0.7084632768361581}, "custom_metrics": {"red_0/door_open_done_mean": 0.2033898305084746, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7627118644067796, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03389830508474576, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7627118644067796, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03389830508474576, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7627118644067796, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03389830508474576, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.41700000000000004, 0.4630000000000001, 0.46199999999999997, 1.384, 1.4409999999999998, 0.46099999999999985, -0.10799999999999987, 0.473, 0.46399999999999997, 0.387, 0.4670000000000001, 0.46199999999999997, 0.44399999999999995, 0.44999999999999996, 0.4630000000000001, -0.05400000000000005, 0.4289999999999998, -0.03500000000000003, 0.46199999999999997, 1.387, 0.46599999999999997, 0.4670000000000001, 0.46599999999999997, -0.03700000000000003, 0.33000000000000007, 0.45399999999999996, 0.29899999999999993, 0.44200000000000017, 1.4369999999999998, 0.4670000000000001, 0.46499999999999986, 1.2469999999999999, 0.41400000000000015, 0.45299999999999985, 0.46599999999999997, 0.44799999999999995, 1.2149999999999999, 0.45500000000000007, 0.46899999999999986, 0.45799999999999996, 0.46399999999999997, 0.4590000000000001, 0.46399999999999997, 0.45999999999999996, -0.03799999999999992, 1.395, 0.46599999999999997, 0.472, 1.44, 0.46099999999999985, -0.122, 0.43599999999999994, 0.45199999999999996, 1.335, 0.4670000000000001, 0.45599999999999996, 0.46399999999999997, 0.45799999999999996, 0.46199999999999997, 0.44999999999999996, 0.44199999999999995, 0.44899999999999984, 0.45599999999999996, 0.4750000000000001, 0.44999999999999996, -0.02300000000000002, 0.909, 0.4590000000000001, 0.46599999999999997, 0.28300000000000014, 0.44999999999999996, 1.451, 0.45999999999999996, 0.45699999999999985, 0.45699999999999985, 1.443, 0.4630000000000001, 0.42900000000000005, 0.45100000000000007, 0.47299999999999986, 0.46399999999999997, -0.08099999999999996, 0.44700000000000006, 1.448, 0.476, -0.09999999999999998, 1.4140000000000001, 0.4650000000000001, 0.45799999999999996, 1.417, 0.44999999999999996, 1.396, 0.4660000000000002, 0.44700000000000006, 1.456, -0.124, 0.472, 1.4, 0.43399999999999994, 0.46599999999999997, 0.3460000000000001, 0.46499999999999986, 1.451, -0.026999999999999913, 0.46399999999999997, 1.4180000000000001, 1.266, 0.35599999999999987, 0.403, 0.43500000000000005, -0.050000000000000044, 0.46899999999999986, 0.44799999999999995, 0.44199999999999995, 1.4460000000000002, 0.4590000000000001, 0.45199999999999996, -0.031000000000000028, 1.4220000000000002, 0.471, 0.45299999999999985, 0.46599999999999997, 0.9249999999999998, 0.45999999999999996, 0.938, 0.4630000000000001, -0.031000000000000028, 1.444, 0.46599999999999997, 0.933, 0.44199999999999995, 1.9290000000000003, 0.2559999999999999, 0.46599999999999997, 0.45699999999999985, 0.44499999999999984, -0.04400000000000004, 1.4120000000000001, 0.4610000000000001, 1.445, 0.46599999999999997, 1.412, 0.4540000000000002, 0.42999999999999994, 0.871, 1.379, 0.4590000000000001, 0.4670000000000001, 1.427, 0.46499999999999986, 0.42700000000000005, 0.44399999999999995, 1.452, 1.829, 1.417, 0.403, 0.46799999999999997, 0.44700000000000006, 0.4249999999999998, 0.46899999999999986, 0.47, 0.40600000000000014, 0.46399999999999997, 0.43399999999999994, 0.954, 0.46399999999999997, 1.43, 1.3679999999999999, 1.446, -0.018000000000000016, 0.473, 0.4630000000000001, 0.46399999999999997, 0.4650000000000001, 0.46399999999999997, 1.412, 0.2629999999999999], "episode_lengths": [26, 11, 12, 37, 18, 13, 34, 9, 12, 36, 11, 12, 18, 15, 12, 16, 22, 11, 12, 36, 11, 11, 11, 12, 52, 15, 64, 19, 20, 11, 11, 81, 27, 15, 11, 17, 87, 14, 10, 13, 11, 13, 12, 13, 12, 33, 11, 9, 19, 12, 38, 20, 15, 53, 11, 14, 11, 13, 12, 16, 18, 15, 14, 8, 16, 7, 29, 13, 11, 68, 16, 15, 13, 14, 14, 18, 12, 23, 16, 9, 11, 26, 17, 16, 8, 32, 26, 11, 13, 26, 16, 33, 11, 17, 14, 39, 9, 32, 21, 11, 50, 11, 16, 8, 11, 26, 73, 46, 31, 21, 16, 10, 17, 18, 17, 13, 16, 10, 25, 9, 15, 11, 24, 13, 20, 12, 10, 17, 11, 21, 19, 23, 237, 11, 14, 17, 14, 27, 12, 17, 11, 27, 14, 22, 42, 38, 13, 11, 23, 11, 23, 18, 15, 55, 27, 31, 10, 17, 24, 10, 10, 29, 11, 21, 15, 12, 22, 42, 17, 6, 9, 11, 11, 11, 11, 27, 74], "policy_red_0_reward": [1.4220000000000002, 1.467, 1.464, 1.389, 1.446, 1.4609999999999999, 0.898, -0.5, 1.464, 1.391, 1.467, 1.464, 1.446, 1.455, 1.464, 0.949, 1.434, -1.0, 1.464, 1.392, 1.467, 1.467, 1.467, 0.964, 1.339, 1.455, 1.308, 1.443, 1.44, 1.467, 1.467, 1.2570000000000001, 1.417, 1.455, 1.467, 1.4489999999999998, 1.237, 1.458, 1.47, 1.4609999999999999, 1.467, 1.4609999999999999, 1.464, 1.4609999999999999, 0.964, 1.4, 1.467, 1.4729999999999999, 1.443, 1.464, 0.884, 1.44, 1.455, 1.341, 1.467, 1.458, 1.467, 1.4609999999999999, 1.464, 1.452, 1.444, 1.455, 1.458, 1.476, 1.452, 0.979, 1.413, 1.4609999999999999, 1.467, 1.295, 1.452, 1.455, 1.4609999999999999, 1.458, 1.458, 1.446, 1.464, 1.431, 1.452, 1.4729999999999999, 1.467, 0.922, 1.4489999999999998, 1.452, 1.476, 0.902, 1.4220000000000002, 1.467, 1.4609999999999999, 1.4220000000000002, 1.452, 1.401, 1.467, 1.4489999999999998, 1.458, 0.883, 1.4729999999999999, 1.403, 1.4369999999999998, 1.467, 1.35, 1.467, 1.452, 0.976, 1.467, 1.4220000000000002, 1.273, 1.362, 1.407, 1.436, 0.952, 1.47, 1.4489999999999998, 1.446, 1.4489999999999998, 1.4609999999999999, 1.452, 0.969, 1.425, -0.5, 1.455, 1.467, 1.428, 1.4609999999999999, 1.44, 1.464, 0.97, 1.447, 1.467, 1.4369999999999998, 1.443, 1.431, -0.501, 1.467, 1.458, 1.4489999999999998, 0.958, 1.419, 1.464, 1.4489999999999998, 1.467, 1.419, 1.458, 1.434, 1.374, 1.3860000000000001, 1.4609999999999999, 1.467, 1.431, 1.467, 1.429, 1.446, 1.455, 1.335, 1.419, 0.907, 1.47, 1.4489999999999998, 1.428, 1.47, 1.47, 1.412, 1.467, 1.4369999999999998, 1.455, -0.5, 1.434, 1.374, 1.4489999999999998, 0.982, -0.5, 1.466, 1.467, 1.467, 1.467, 1.419, 1.2730000000000001], "policy_blue_0_reward": [-1.005, -1.004, -1.002, -0.005, -0.005, -1.0, -1.0059999999999998, 0.973, -1.0, -1.004, -1.0, -1.002, -1.002, -1.005, -1.001, -1.003, -1.005, 0.965, -1.002, -0.005, -1.001, -1.0, -1.001, -1.001, -1.009, -1.001, -1.009, -1.001, -0.003, -1.0, -1.002, -0.010000000000000002, -1.003, -1.002, -1.001, -1.001, -0.022000000000000013, -1.003, -1.001, -1.003, -1.003, -1.002, -1.0, -1.001, -1.0019999999999998, -0.005, -1.001, -1.001, -0.003, -1.003, -1.006, -1.004, -1.003, -0.006, -1.0, -1.002, -1.003, -1.003, -1.002, -1.002, -1.002, -1.006, -1.002, -1.001, -1.002, -1.002, -0.504, -1.002, -1.001, -1.0119999999999998, -1.002, -0.004, -1.001, -1.001, -1.001, -0.003, -1.001, -1.002, -1.001, -1.0, -1.003, -1.003, -1.0019999999999998, -0.004, -1.0, -1.002, -0.008, -1.0019999999999998, -1.003, -0.005, -1.002, -0.005, -1.001, -1.0019999999999998, -0.002, -1.007, -1.001, -0.003, -1.003, -1.001, -1.004, -1.002, -0.001, -1.003, -1.003, -0.004, -0.007, -1.006, -1.004, -1.001, -1.002, -1.001, -1.001, -1.004, -0.003, -1.002, -1.0, -1.0, -0.003, 0.971, -1.002, -1.001, -0.503, -1.001, -0.502, -1.001, -1.001, -0.003, -1.001, -0.5039999999999999, -1.001, 0.498, 0.7569999999999999, -1.001, -1.001, -1.004, -1.002, -0.007, -1.003, -0.004, -1.001, -0.007, -1.0039999999999998, -1.004, -0.503, -0.007, -1.002, -1.0, -0.004, -1.002, -1.002, -1.002, -0.003, 0.494, -0.002, -0.504, -1.002, -1.002, -1.003, -1.001, -1.0, -1.0059999999999998, -1.003, -1.003, -0.501, 0.964, -0.004, -0.006, -0.003, -1.0, 0.973, -1.003, -1.003, -1.0019999999999998, -1.003, -0.007, -1.01]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24660711660902007, "mean_inference_ms": 1.4759672967709536, "mean_action_processing_ms": 0.06309134370040959, "mean_env_wait_ms": 0.08896986724650344, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019455494853736318, "StateBufferConnector_ms": 0.0014879609231894973, "ViewRequirementAgentConnector_ms": 0.03146121730912203}}, "episode_reward_max": 1.9290000000000003, "episode_reward_min": -0.124, "episode_reward_mean": 0.6169265536723164, "episode_len_mean": 21.135593220338983, "episodes_this_iter": 177, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.0119999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.973}, "policy_reward_mean": {"red_0": 1.3253898305084748, "blue_0": -0.7084632768361581}, "hist_stats": {"episode_reward": [0.41700000000000004, 0.4630000000000001, 0.46199999999999997, 1.384, 1.4409999999999998, 0.46099999999999985, -0.10799999999999987, 0.473, 0.46399999999999997, 0.387, 0.4670000000000001, 0.46199999999999997, 0.44399999999999995, 0.44999999999999996, 0.4630000000000001, -0.05400000000000005, 0.4289999999999998, -0.03500000000000003, 0.46199999999999997, 1.387, 0.46599999999999997, 0.4670000000000001, 0.46599999999999997, -0.03700000000000003, 0.33000000000000007, 0.45399999999999996, 0.29899999999999993, 0.44200000000000017, 1.4369999999999998, 0.4670000000000001, 0.46499999999999986, 1.2469999999999999, 0.41400000000000015, 0.45299999999999985, 0.46599999999999997, 0.44799999999999995, 1.2149999999999999, 0.45500000000000007, 0.46899999999999986, 0.45799999999999996, 0.46399999999999997, 0.4590000000000001, 0.46399999999999997, 0.45999999999999996, -0.03799999999999992, 1.395, 0.46599999999999997, 0.472, 1.44, 0.46099999999999985, -0.122, 0.43599999999999994, 0.45199999999999996, 1.335, 0.4670000000000001, 0.45599999999999996, 0.46399999999999997, 0.45799999999999996, 0.46199999999999997, 0.44999999999999996, 0.44199999999999995, 0.44899999999999984, 0.45599999999999996, 0.4750000000000001, 0.44999999999999996, -0.02300000000000002, 0.909, 0.4590000000000001, 0.46599999999999997, 0.28300000000000014, 0.44999999999999996, 1.451, 0.45999999999999996, 0.45699999999999985, 0.45699999999999985, 1.443, 0.4630000000000001, 0.42900000000000005, 0.45100000000000007, 0.47299999999999986, 0.46399999999999997, -0.08099999999999996, 0.44700000000000006, 1.448, 0.476, -0.09999999999999998, 1.4140000000000001, 0.4650000000000001, 0.45799999999999996, 1.417, 0.44999999999999996, 1.396, 0.4660000000000002, 0.44700000000000006, 1.456, -0.124, 0.472, 1.4, 0.43399999999999994, 0.46599999999999997, 0.3460000000000001, 0.46499999999999986, 1.451, -0.026999999999999913, 0.46399999999999997, 1.4180000000000001, 1.266, 0.35599999999999987, 0.403, 0.43500000000000005, -0.050000000000000044, 0.46899999999999986, 0.44799999999999995, 0.44199999999999995, 1.4460000000000002, 0.4590000000000001, 0.45199999999999996, -0.031000000000000028, 1.4220000000000002, 0.471, 0.45299999999999985, 0.46599999999999997, 0.9249999999999998, 0.45999999999999996, 0.938, 0.4630000000000001, -0.031000000000000028, 1.444, 0.46599999999999997, 0.933, 0.44199999999999995, 1.9290000000000003, 0.2559999999999999, 0.46599999999999997, 0.45699999999999985, 0.44499999999999984, -0.04400000000000004, 1.4120000000000001, 0.4610000000000001, 1.445, 0.46599999999999997, 1.412, 0.4540000000000002, 0.42999999999999994, 0.871, 1.379, 0.4590000000000001, 0.4670000000000001, 1.427, 0.46499999999999986, 0.42700000000000005, 0.44399999999999995, 1.452, 1.829, 1.417, 0.403, 0.46799999999999997, 0.44700000000000006, 0.4249999999999998, 0.46899999999999986, 0.47, 0.40600000000000014, 0.46399999999999997, 0.43399999999999994, 0.954, 0.46399999999999997, 1.43, 1.3679999999999999, 1.446, -0.018000000000000016, 0.473, 0.4630000000000001, 0.46399999999999997, 0.4650000000000001, 0.46399999999999997, 1.412, 0.2629999999999999], "episode_lengths": [26, 11, 12, 37, 18, 13, 34, 9, 12, 36, 11, 12, 18, 15, 12, 16, 22, 11, 12, 36, 11, 11, 11, 12, 52, 15, 64, 19, 20, 11, 11, 81, 27, 15, 11, 17, 87, 14, 10, 13, 11, 13, 12, 13, 12, 33, 11, 9, 19, 12, 38, 20, 15, 53, 11, 14, 11, 13, 12, 16, 18, 15, 14, 8, 16, 7, 29, 13, 11, 68, 16, 15, 13, 14, 14, 18, 12, 23, 16, 9, 11, 26, 17, 16, 8, 32, 26, 11, 13, 26, 16, 33, 11, 17, 14, 39, 9, 32, 21, 11, 50, 11, 16, 8, 11, 26, 73, 46, 31, 21, 16, 10, 17, 18, 17, 13, 16, 10, 25, 9, 15, 11, 24, 13, 20, 12, 10, 17, 11, 21, 19, 23, 237, 11, 14, 17, 14, 27, 12, 17, 11, 27, 14, 22, 42, 38, 13, 11, 23, 11, 23, 18, 15, 55, 27, 31, 10, 17, 24, 10, 10, 29, 11, 21, 15, 12, 22, 42, 17, 6, 9, 11, 11, 11, 11, 27, 74], "policy_red_0_reward": [1.4220000000000002, 1.467, 1.464, 1.389, 1.446, 1.4609999999999999, 0.898, -0.5, 1.464, 1.391, 1.467, 1.464, 1.446, 1.455, 1.464, 0.949, 1.434, -1.0, 1.464, 1.392, 1.467, 1.467, 1.467, 0.964, 1.339, 1.455, 1.308, 1.443, 1.44, 1.467, 1.467, 1.2570000000000001, 1.417, 1.455, 1.467, 1.4489999999999998, 1.237, 1.458, 1.47, 1.4609999999999999, 1.467, 1.4609999999999999, 1.464, 1.4609999999999999, 0.964, 1.4, 1.467, 1.4729999999999999, 1.443, 1.464, 0.884, 1.44, 1.455, 1.341, 1.467, 1.458, 1.467, 1.4609999999999999, 1.464, 1.452, 1.444, 1.455, 1.458, 1.476, 1.452, 0.979, 1.413, 1.4609999999999999, 1.467, 1.295, 1.452, 1.455, 1.4609999999999999, 1.458, 1.458, 1.446, 1.464, 1.431, 1.452, 1.4729999999999999, 1.467, 0.922, 1.4489999999999998, 1.452, 1.476, 0.902, 1.4220000000000002, 1.467, 1.4609999999999999, 1.4220000000000002, 1.452, 1.401, 1.467, 1.4489999999999998, 1.458, 0.883, 1.4729999999999999, 1.403, 1.4369999999999998, 1.467, 1.35, 1.467, 1.452, 0.976, 1.467, 1.4220000000000002, 1.273, 1.362, 1.407, 1.436, 0.952, 1.47, 1.4489999999999998, 1.446, 1.4489999999999998, 1.4609999999999999, 1.452, 0.969, 1.425, -0.5, 1.455, 1.467, 1.428, 1.4609999999999999, 1.44, 1.464, 0.97, 1.447, 1.467, 1.4369999999999998, 1.443, 1.431, -0.501, 1.467, 1.458, 1.4489999999999998, 0.958, 1.419, 1.464, 1.4489999999999998, 1.467, 1.419, 1.458, 1.434, 1.374, 1.3860000000000001, 1.4609999999999999, 1.467, 1.431, 1.467, 1.429, 1.446, 1.455, 1.335, 1.419, 0.907, 1.47, 1.4489999999999998, 1.428, 1.47, 1.47, 1.412, 1.467, 1.4369999999999998, 1.455, -0.5, 1.434, 1.374, 1.4489999999999998, 0.982, -0.5, 1.466, 1.467, 1.467, 1.467, 1.419, 1.2730000000000001], "policy_blue_0_reward": [-1.005, -1.004, -1.002, -0.005, -0.005, -1.0, -1.0059999999999998, 0.973, -1.0, -1.004, -1.0, -1.002, -1.002, -1.005, -1.001, -1.003, -1.005, 0.965, -1.002, -0.005, -1.001, -1.0, -1.001, -1.001, -1.009, -1.001, -1.009, -1.001, -0.003, -1.0, -1.002, -0.010000000000000002, -1.003, -1.002, -1.001, -1.001, -0.022000000000000013, -1.003, -1.001, -1.003, -1.003, -1.002, -1.0, -1.001, -1.0019999999999998, -0.005, -1.001, -1.001, -0.003, -1.003, -1.006, -1.004, -1.003, -0.006, -1.0, -1.002, -1.003, -1.003, -1.002, -1.002, -1.002, -1.006, -1.002, -1.001, -1.002, -1.002, -0.504, -1.002, -1.001, -1.0119999999999998, -1.002, -0.004, -1.001, -1.001, -1.001, -0.003, -1.001, -1.002, -1.001, -1.0, -1.003, -1.003, -1.0019999999999998, -0.004, -1.0, -1.002, -0.008, -1.0019999999999998, -1.003, -0.005, -1.002, -0.005, -1.001, -1.0019999999999998, -0.002, -1.007, -1.001, -0.003, -1.003, -1.001, -1.004, -1.002, -0.001, -1.003, -1.003, -0.004, -0.007, -1.006, -1.004, -1.001, -1.002, -1.001, -1.001, -1.004, -0.003, -1.002, -1.0, -1.0, -0.003, 0.971, -1.002, -1.001, -0.503, -1.001, -0.502, -1.001, -1.001, -0.003, -1.001, -0.5039999999999999, -1.001, 0.498, 0.7569999999999999, -1.001, -1.001, -1.004, -1.002, -0.007, -1.003, -0.004, -1.001, -0.007, -1.0039999999999998, -1.004, -0.503, -0.007, -1.002, -1.0, -0.004, -1.002, -1.002, -1.002, -0.003, 0.494, -0.002, -0.504, -1.002, -1.002, -1.003, -1.001, -1.0, -1.0059999999999998, -1.003, -1.003, -0.501, 0.964, -0.004, -0.006, -0.003, -1.0, 0.973, -1.003, -1.003, -1.0019999999999998, -1.003, -0.007, -1.01]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24660711660902007, "mean_inference_ms": 1.4759672967709536, "mean_action_processing_ms": 0.06309134370040959, "mean_env_wait_ms": 0.08896986724650344, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019455494853736318, "StateBufferConnector_ms": 0.0014879609231894973, "ViewRequirementAgentConnector_ms": 0.03146121730912203}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000, "num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.96891014172893, "num_env_steps_trained_throughput_per_sec": 102.96891014172893, "timesteps_total": 224000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 448000, "timers": {"training_iteration_time_ms": 38942.849, "sample_time_ms": 7556.365, "learn_time_ms": 31368.812, "learn_throughput": 127.515, "synch_weights_time_ms": 17.163}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 224000, "num_agent_steps_sampled": 448000, "num_agent_steps_trained": 448000}, "done": false, "episodes_total": 6870, "training_iteration": 56, "trial_id": "d67e4_00000", "date": "2023-09-20_22-45-39", "timestamp": 1695264339, "time_this_iter_s": 38.853878021240234, "time_total_s": 2178.8951547145844, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706a70>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2178.8951547145844, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 34.583928571428565, "ram_util_percent": 49.253571428571426}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.21818181818181817, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7090909090909091, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06666666666666667, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7090909090909091, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.06666666666666667, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7090909090909091, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06666666666666667, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.802345977537334, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.006607698996109927, "policy_loss": -0.01364238510262415, "vf_loss": 0.008999793494028078, "vf_explained_var": 0.7437792238468925, "kl": 0.0065188008924570665, "entropy": 0.39867043402045965, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 54240.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.3790000000000001, "episode_reward_mean": 0.6512848484848485, "episode_len_mean": 24.727272727272727, "episode_media": {}, "episodes_this_iter": 165, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.976}, "policy_reward_mean": {"red_0": 1.257878787878788, "blue_0": -0.6065939393939394}, "custom_metrics": {"red_0/door_open_done_mean": 0.21818181818181817, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7090909090909091, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.06666666666666667, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7090909090909091, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.06666666666666667, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7090909090909091, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.06666666666666667, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.44399999999999995, -0.031000000000000028, 1.4020000000000001, 0.05499999999999994, 0.7720000000000002, 0.4580000000000002, 0.46199999999999997, 0.43699999999999983, -0.05700000000000005, 1.451, 0.4630000000000001, 0.9470000000000001, 0.46599999999999997, 0.902, 0.4630000000000001, 0.44099999999999984, 0.45100000000000007, -0.08099999999999996, 0.4670000000000001, 1.423, 0.46199999999999997, 0.44599999999999995, -0.05699999999999994, 0.4460000000000002, -0.09899999999999998, -0.030999999999999917, 0.4610000000000001, 0.966, 0.371, 0.4590000000000001, 1.42, 0.42100000000000004, 0.476, 1.432, 1.447, 0.45599999999999996, 0.46099999999999985, 0.43400000000000016, 0.3500000000000001, 0.46599999999999997, 0.851, 0.44599999999999995, 0.4500000000000002, 0.46399999999999997, 0.46399999999999997, 0.8900000000000001, 0.41000000000000014, 0.46799999999999997, 0.43500000000000005, 0.43199999999999994, 1.413, 0.43999999999999995, 0.46499999999999997, 0.45999999999999996, -0.05600000000000005, 0.45100000000000007, 0.45199999999999996, 0.43900000000000006, 0.47, 0.17800000000000016, 1.447, 0.44099999999999984, 0.4670000000000001, 1.4529999999999998, 0.45199999999999996, 1.451, 0.7170000000000001, 0.4540000000000002, 1.444, 0.30000000000000004, 1.4, 0.47299999999999986, 1.449, 0.4630000000000001, 1.448, 0.46499999999999986, 0.4540000000000002, 0.44499999999999984, 1.439, 1.3780000000000001, 1.345, 1.438, 0.46799999999999997, 0.478, 1.436, 0.45799999999999996, 0.9489999999999998, -0.02200000000000002, 0.46799999999999997, 0.44300000000000006, 0.45199999999999996, 1.366, 0.41500000000000004, 1.4460000000000002, 0.9339999999999999, 0.6199999999999999, 0.45599999999999996, 0.46399999999999997, -0.04500000000000004, 1.4220000000000002, 1.454, 0.42999999999999994, 0.942, 0.44999999999999996, -0.03199999999999992, 1.362, -0.18700000000000006, 0.43599999999999994, 1.429, 0.45699999999999996, 1.9529999999999998, 0.4630000000000001, 0.43699999999999983, 0.45999999999999996, 0.45999999999999996, 0.966, 0.43399999999999994, 0.46599999999999997, 0.46399999999999997, 0.45500000000000007, 0.4590000000000001, 0.45599999999999996, 0.46199999999999997, 0.32399999999999984, 0.471, 0.46399999999999997, -0.02100000000000002, 1.959, 0.44399999999999995, 0.44499999999999984, 0.45199999999999996, 0.45599999999999996, 0.46199999999999997, 0.474, 0.42399999999999993, 1.458, 0.46199999999999997, 0.45799999999999996, 0.46399999999999997, 1.4289999999999998, 0.4590000000000001, 1.404, 0.47299999999999986, 0.46199999999999997, 1.447, -0.3790000000000001, 1.427, 1.439, 0.45699999999999985, 0.472, 0.4670000000000001, 1.389, 0.4630000000000001, 0.45100000000000007, 0.45299999999999985, 0.44499999999999984, 0.46099999999999997, 1.455, 0.46599999999999997, 0.46099999999999985, 0.4670000000000001, 0.46799999999999997, 0.4590000000000001, 0.9630000000000001, 0.4570000000000001], "episode_lengths": [18, 10, 30, 140, 72, 13, 12, 19, 18, 16, 11, 17, 11, 187, 12, 18, 15, 26, 11, 24, 12, 17, 16, 17, 32, 10, 12, 11, 40, 13, 26, 26, 8, 180, 17, 13, 13, 21, 47, 11, 47, 300, 16, 12, 11, 33, 28, 10, 20, 22, 27, 19, 11, 13, 18, 15, 15, 19, 10, 101, 17, 19, 10, 15, 15, 16, 91, 14, 17, 64, 31, 9, 16, 12, 16, 11, 15, 18, 20, 33, 50, 20, 10, 7, 21, 13, 16, 7, 10, 18, 15, 41, 27, 17, 21, 120, 14, 12, 14, 25, 15, 22, 19, 15, 10, 44, 59, 20, 22, 14, 15, 12, 20, 13, 13, 11, 21, 11, 11, 14, 13, 14, 12, 56, 9, 12, 7, 13, 17, 17, 15, 14, 12, 8, 25, 13, 12, 13, 11, 22, 13, 30, 9, 12, 16, 120, 23, 19, 14, 9, 11, 35, 11, 15, 15, 17, 12, 15, 11, 12, 11, 10, 13, 12, 13], "policy_red_0_reward": [1.446, 0.97, 1.4100000000000001, -0.5, 1.282, 1.4609999999999999, 1.464, 1.443, 0.946, 1.452, 1.467, 1.4489999999999998, 1.467, 0.924, 1.464, 1.446, 1.454, 0.922, 1.467, 1.428, 1.464, 1.4489999999999998, 0.946, 1.4489999999999998, 0.904, -1.0, 1.464, 1.467, -0.502, 1.4609999999999999, 1.421, 1.4220000000000002, -0.5, 0.96, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 1.4369999999999998, 1.3559999999999999, 1.467, 1.359, 0.491, 1.452, 1.464, 1.467, 1.393, 1.416, 1.47, 1.44, 1.434, 1.4180000000000001, 1.443, -0.5, 1.4609999999999999, 0.946, 1.455, 1.455, 1.443, 1.47, 1.197, 1.4489999999999998, 1.443, 1.47, 1.455, 1.455, 1.452, 1.226, 1.456, 1.4489999999999998, 1.308, 1.407, 1.4729999999999999, 1.451, 1.464, 1.452, 1.467, 1.455, 1.446, 1.44, 1.385, 1.35, 1.44, 1.47, 1.479, 1.4369999999999998, 1.4609999999999999, 1.452, 0.979, 1.47, 1.446, 1.455, 1.373, 1.419, 1.4489999999999998, 1.4369999999999998, 1.14, 1.458, 1.464, 0.958, 1.425, 1.455, 1.434, 1.443, 1.455, 0.97, 1.3679999999999999, -1.001, 1.44, 1.434, -0.5, 1.455, 1.464, 1.44, 1.46, 1.4609999999999999, 1.467, 1.4369999999999998, 1.467, 1.467, 1.458, 1.46, 1.458, 1.464, 1.3319999999999999, -0.5, 1.464, 0.979, 1.4609999999999999, 1.4489999999999998, 1.448, 1.455, 1.458, 1.463, -0.5, 1.425, 1.4609999999999999, -0.5, 1.4609999999999999, 1.467, 1.434, 1.4609999999999999, 1.4100000000000001, 1.4729999999999999, 1.464, 1.451, 0.6389999999999999, 1.431, 1.443, 1.458, 1.4729999999999999, 1.467, 1.395, 1.467, 1.455, 1.455, 1.4489999999999998, -0.5, 1.455, 1.467, 1.464, 1.467, 1.47, 1.4609999999999999, 1.464, 1.4609999999999999], "policy_blue_0_reward": [-1.002, -1.001, -0.008, 0.5549999999999999, -0.5099999999999999, -1.003, -1.002, -1.006, -1.003, -0.001, -1.0039999999999998, -0.502, -1.001, -0.022000000000000013, -1.001, -1.005, -1.003, -1.003, -1.0, -0.005, -1.002, -1.003, -1.003, -1.003, -1.003, 0.969, -1.003, -0.501, 0.873, -1.002, -0.001, -1.001, 0.976, 0.472, -0.002, -1.005, -1.0, -1.003, -1.006, -1.001, -0.508, -0.04500000000000003, -1.0019999999999998, -1.0, -1.003, -0.503, -1.006, -1.0019999999999998, -1.005, -1.002, -0.005, -1.003, 0.965, -1.001, -1.002, -1.0039999999999998, -1.003, -1.004, -1.0, -1.019, -0.002, -1.002, -1.003, -0.002, -1.003, -0.001, -0.5089999999999999, -1.0019999999999998, -0.005, -1.008, -0.007, -1.0, -0.002, -1.001, -0.004, -1.002, -1.001, -1.001, -0.001, -0.007, -0.005, -0.002, -1.002, -1.001, -0.001, -1.003, -0.503, -1.001, -1.002, -1.003, -1.003, -0.007, -1.004, -0.003, -0.503, -0.52, -1.002, -1.0, -1.003, -0.003, -0.001, -1.004, -0.501, -1.005, -1.0019999999999998, -0.006, 0.814, -1.004, -0.005, 0.957, 0.498, -1.001, -1.003, -1.0, -1.001, -0.501, -1.003, -1.001, -1.003, -1.003, -1.001, -1.002, -1.002, -1.008, 0.971, -1.0, -1.0, 0.498, -1.005, -1.003, -1.003, -1.002, -1.001, 0.974, -1.001, -0.003, 0.962, -1.003, -1.003, -0.005, -1.002, -0.006, -1.0, -1.002, -0.004, -1.018, -0.004, -0.004, -1.001, -1.001, -1.0, -0.006, -1.0039999999999998, -1.004, -1.002, -1.004, 0.961, 0.0, -1.001, -1.003, -1.0, -1.002, -1.0019999999999998, -0.501, -1.0039999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2464425248168647, "mean_inference_ms": 1.475245159056337, "mean_action_processing_ms": 0.06300332208511471, "mean_env_wait_ms": 0.08888081672328242, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019491658066258286, "StateBufferConnector_ms": 0.0014487179842862215, "ViewRequirementAgentConnector_ms": 0.03131078951286547}}, "episode_reward_max": 1.959, "episode_reward_min": -0.3790000000000001, "episode_reward_mean": 0.6512848484848485, "episode_len_mean": 24.727272727272727, "episodes_this_iter": 165, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.019}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.976}, "policy_reward_mean": {"red_0": 1.257878787878788, "blue_0": -0.6065939393939394}, "hist_stats": {"episode_reward": [0.44399999999999995, -0.031000000000000028, 1.4020000000000001, 0.05499999999999994, 0.7720000000000002, 0.4580000000000002, 0.46199999999999997, 0.43699999999999983, -0.05700000000000005, 1.451, 0.4630000000000001, 0.9470000000000001, 0.46599999999999997, 0.902, 0.4630000000000001, 0.44099999999999984, 0.45100000000000007, -0.08099999999999996, 0.4670000000000001, 1.423, 0.46199999999999997, 0.44599999999999995, -0.05699999999999994, 0.4460000000000002, -0.09899999999999998, -0.030999999999999917, 0.4610000000000001, 0.966, 0.371, 0.4590000000000001, 1.42, 0.42100000000000004, 0.476, 1.432, 1.447, 0.45599999999999996, 0.46099999999999985, 0.43400000000000016, 0.3500000000000001, 0.46599999999999997, 0.851, 0.44599999999999995, 0.4500000000000002, 0.46399999999999997, 0.46399999999999997, 0.8900000000000001, 0.41000000000000014, 0.46799999999999997, 0.43500000000000005, 0.43199999999999994, 1.413, 0.43999999999999995, 0.46499999999999997, 0.45999999999999996, -0.05600000000000005, 0.45100000000000007, 0.45199999999999996, 0.43900000000000006, 0.47, 0.17800000000000016, 1.447, 0.44099999999999984, 0.4670000000000001, 1.4529999999999998, 0.45199999999999996, 1.451, 0.7170000000000001, 0.4540000000000002, 1.444, 0.30000000000000004, 1.4, 0.47299999999999986, 1.449, 0.4630000000000001, 1.448, 0.46499999999999986, 0.4540000000000002, 0.44499999999999984, 1.439, 1.3780000000000001, 1.345, 1.438, 0.46799999999999997, 0.478, 1.436, 0.45799999999999996, 0.9489999999999998, -0.02200000000000002, 0.46799999999999997, 0.44300000000000006, 0.45199999999999996, 1.366, 0.41500000000000004, 1.4460000000000002, 0.9339999999999999, 0.6199999999999999, 0.45599999999999996, 0.46399999999999997, -0.04500000000000004, 1.4220000000000002, 1.454, 0.42999999999999994, 0.942, 0.44999999999999996, -0.03199999999999992, 1.362, -0.18700000000000006, 0.43599999999999994, 1.429, 0.45699999999999996, 1.9529999999999998, 0.4630000000000001, 0.43699999999999983, 0.45999999999999996, 0.45999999999999996, 0.966, 0.43399999999999994, 0.46599999999999997, 0.46399999999999997, 0.45500000000000007, 0.4590000000000001, 0.45599999999999996, 0.46199999999999997, 0.32399999999999984, 0.471, 0.46399999999999997, -0.02100000000000002, 1.959, 0.44399999999999995, 0.44499999999999984, 0.45199999999999996, 0.45599999999999996, 0.46199999999999997, 0.474, 0.42399999999999993, 1.458, 0.46199999999999997, 0.45799999999999996, 0.46399999999999997, 1.4289999999999998, 0.4590000000000001, 1.404, 0.47299999999999986, 0.46199999999999997, 1.447, -0.3790000000000001, 1.427, 1.439, 0.45699999999999985, 0.472, 0.4670000000000001, 1.389, 0.4630000000000001, 0.45100000000000007, 0.45299999999999985, 0.44499999999999984, 0.46099999999999997, 1.455, 0.46599999999999997, 0.46099999999999985, 0.4670000000000001, 0.46799999999999997, 0.4590000000000001, 0.9630000000000001, 0.4570000000000001], "episode_lengths": [18, 10, 30, 140, 72, 13, 12, 19, 18, 16, 11, 17, 11, 187, 12, 18, 15, 26, 11, 24, 12, 17, 16, 17, 32, 10, 12, 11, 40, 13, 26, 26, 8, 180, 17, 13, 13, 21, 47, 11, 47, 300, 16, 12, 11, 33, 28, 10, 20, 22, 27, 19, 11, 13, 18, 15, 15, 19, 10, 101, 17, 19, 10, 15, 15, 16, 91, 14, 17, 64, 31, 9, 16, 12, 16, 11, 15, 18, 20, 33, 50, 20, 10, 7, 21, 13, 16, 7, 10, 18, 15, 41, 27, 17, 21, 120, 14, 12, 14, 25, 15, 22, 19, 15, 10, 44, 59, 20, 22, 14, 15, 12, 20, 13, 13, 11, 21, 11, 11, 14, 13, 14, 12, 56, 9, 12, 7, 13, 17, 17, 15, 14, 12, 8, 25, 13, 12, 13, 11, 22, 13, 30, 9, 12, 16, 120, 23, 19, 14, 9, 11, 35, 11, 15, 15, 17, 12, 15, 11, 12, 11, 10, 13, 12, 13], "policy_red_0_reward": [1.446, 0.97, 1.4100000000000001, -0.5, 1.282, 1.4609999999999999, 1.464, 1.443, 0.946, 1.452, 1.467, 1.4489999999999998, 1.467, 0.924, 1.464, 1.446, 1.454, 0.922, 1.467, 1.428, 1.464, 1.4489999999999998, 0.946, 1.4489999999999998, 0.904, -1.0, 1.464, 1.467, -0.502, 1.4609999999999999, 1.421, 1.4220000000000002, -0.5, 0.96, 1.4489999999999998, 1.4609999999999999, 1.4609999999999999, 1.4369999999999998, 1.3559999999999999, 1.467, 1.359, 0.491, 1.452, 1.464, 1.467, 1.393, 1.416, 1.47, 1.44, 1.434, 1.4180000000000001, 1.443, -0.5, 1.4609999999999999, 0.946, 1.455, 1.455, 1.443, 1.47, 1.197, 1.4489999999999998, 1.443, 1.47, 1.455, 1.455, 1.452, 1.226, 1.456, 1.4489999999999998, 1.308, 1.407, 1.4729999999999999, 1.451, 1.464, 1.452, 1.467, 1.455, 1.446, 1.44, 1.385, 1.35, 1.44, 1.47, 1.479, 1.4369999999999998, 1.4609999999999999, 1.452, 0.979, 1.47, 1.446, 1.455, 1.373, 1.419, 1.4489999999999998, 1.4369999999999998, 1.14, 1.458, 1.464, 0.958, 1.425, 1.455, 1.434, 1.443, 1.455, 0.97, 1.3679999999999999, -1.001, 1.44, 1.434, -0.5, 1.455, 1.464, 1.44, 1.46, 1.4609999999999999, 1.467, 1.4369999999999998, 1.467, 1.467, 1.458, 1.46, 1.458, 1.464, 1.3319999999999999, -0.5, 1.464, 0.979, 1.4609999999999999, 1.4489999999999998, 1.448, 1.455, 1.458, 1.463, -0.5, 1.425, 1.4609999999999999, -0.5, 1.4609999999999999, 1.467, 1.434, 1.4609999999999999, 1.4100000000000001, 1.4729999999999999, 1.464, 1.451, 0.6389999999999999, 1.431, 1.443, 1.458, 1.4729999999999999, 1.467, 1.395, 1.467, 1.455, 1.455, 1.4489999999999998, -0.5, 1.455, 1.467, 1.464, 1.467, 1.47, 1.4609999999999999, 1.464, 1.4609999999999999], "policy_blue_0_reward": [-1.002, -1.001, -0.008, 0.5549999999999999, -0.5099999999999999, -1.003, -1.002, -1.006, -1.003, -0.001, -1.0039999999999998, -0.502, -1.001, -0.022000000000000013, -1.001, -1.005, -1.003, -1.003, -1.0, -0.005, -1.002, -1.003, -1.003, -1.003, -1.003, 0.969, -1.003, -0.501, 0.873, -1.002, -0.001, -1.001, 0.976, 0.472, -0.002, -1.005, -1.0, -1.003, -1.006, -1.001, -0.508, -0.04500000000000003, -1.0019999999999998, -1.0, -1.003, -0.503, -1.006, -1.0019999999999998, -1.005, -1.002, -0.005, -1.003, 0.965, -1.001, -1.002, -1.0039999999999998, -1.003, -1.004, -1.0, -1.019, -0.002, -1.002, -1.003, -0.002, -1.003, -0.001, -0.5089999999999999, -1.0019999999999998, -0.005, -1.008, -0.007, -1.0, -0.002, -1.001, -0.004, -1.002, -1.001, -1.001, -0.001, -0.007, -0.005, -0.002, -1.002, -1.001, -0.001, -1.003, -0.503, -1.001, -1.002, -1.003, -1.003, -0.007, -1.004, -0.003, -0.503, -0.52, -1.002, -1.0, -1.003, -0.003, -0.001, -1.004, -0.501, -1.005, -1.0019999999999998, -0.006, 0.814, -1.004, -0.005, 0.957, 0.498, -1.001, -1.003, -1.0, -1.001, -0.501, -1.003, -1.001, -1.003, -1.003, -1.001, -1.002, -1.002, -1.008, 0.971, -1.0, -1.0, 0.498, -1.005, -1.003, -1.003, -1.002, -1.001, 0.974, -1.001, -0.003, 0.962, -1.003, -1.003, -0.005, -1.002, -0.006, -1.0, -1.002, -0.004, -1.018, -0.004, -0.004, -1.001, -1.001, -1.0, -0.006, -1.0039999999999998, -1.004, -1.002, -1.004, 0.961, 0.0, -1.001, -1.003, -1.0, -1.002, -1.0019999999999998, -0.501, -1.0039999999999998]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2464425248168647, "mean_inference_ms": 1.475245159056337, "mean_action_processing_ms": 0.06300332208511471, "mean_env_wait_ms": 0.08888081672328242, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019491658066258286, "StateBufferConnector_ms": 0.0014487179842862215, "ViewRequirementAgentConnector_ms": 0.03131078951286547}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000, "num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.9191973240249, "num_env_steps_trained_throughput_per_sec": 102.9191973240249, "timesteps_total": 228000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 456000, "timers": {"training_iteration_time_ms": 38926.185, "sample_time_ms": 7558.806, "learn_time_ms": 31349.674, "learn_throughput": 127.593, "synch_weights_time_ms": 17.199}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 228000, "num_agent_steps_sampled": 456000, "num_agent_steps_trained": 456000}, "done": false, "episodes_total": 7035, "training_iteration": 57, "trial_id": "d67e4_00000", "date": "2023-09-20_22-46-18", "timestamp": 1695264378, "time_this_iter_s": 38.872252225875854, "time_total_s": 2217.76740694046, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687ad40>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2217.76740694046, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 33.51607142857143, "ram_util_percent": 49.32857142857143}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.24691358024691357, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7160493827160493, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.030864197530864196, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7160493827160493, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.030864197530864196, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7160493827160493, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.030864197530864196, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8556624713664254, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009068825190358136, "policy_loss": -0.014706041163784296, "vf_loss": 0.0061854417264839865, "vf_explained_var": 0.8131050452589988, "kl": 0.006555487448107063, "entropy": 0.4054744576724867, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 55200.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "sampler_results": {"episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.42600000000000005, "episode_reward_mean": 0.6796604938271605, "episode_len_mean": 24.987654320987655, "episode_media": {}, "episodes_this_iter": 162, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.974}, "policy_reward_mean": {"red_0": 1.326635802469136, "blue_0": -0.6469753086419753}, "custom_metrics": {"red_0/door_open_done_mean": 0.24691358024691357, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7160493827160493, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.030864197530864196, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7160493827160493, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.030864197530864196, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7160493827160493, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.030864197530864196, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.4119999999999999, 0.45199999999999996, 0.46799999999999997, 1.434, 0.45199999999999996, 0.46899999999999986, 0.9199999999999999, 1.939, 1.4569999999999999, 0.45599999999999996, 1.931, 0.45599999999999996, 0.4590000000000001, 0.913, 1.4369999999999998, 1.375, 0.4750000000000001, 0.45299999999999985, 0.46399999999999997, 1.441, 0.45199999999999996, 0.45799999999999996, 0.96, 0.46499999999999986, 0.3719999999999999, 1.45, 0.46899999999999986, 0.4119999999999999, 0.32899999999999996, 1.424, -0.08699999999999997, 1.423, 0.46399999999999997, 0.45699999999999985, 0.46399999999999997, 1.454, 0.4620000000000002, 1.447, 0.4590000000000001, 0.44999999999999996, 0.43999999999999995, 0.472, -0.04300000000000004, 0.45999999999999996, 0.1180000000000001, 1.4489999999999998, 1.365, 0.46399999999999997, 0.46099999999999985, 0.46399999999999997, 0.23199999999999998, 1.371, 1.447, 0.46599999999999997, 0.41800000000000015, 0.45500000000000007, 0.44300000000000006, 0.4630000000000001, 1.935, 0.46199999999999997, 1.447, 1.379, 0.46199999999999997, 0.42100000000000004, 0.45100000000000007, 0.43199999999999994, 1.955, 0.46199999999999997, 1.4369999999999998, 0.4650000000000001, 1.433, 1.4080000000000001, 0.42200000000000015, 0.45299999999999985, 1.9180000000000001, 0.44899999999999995, -0.05800000000000005, 1.434, 0.45100000000000007, 0.4670000000000001, 0.4670000000000001, 1.424, 0.44700000000000006, 0.4590000000000001, 0.45599999999999996, 0.45399999999999996, 0.45399999999999996, 0.44700000000000006, 0.45599999999999996, 0.44399999999999995, 1.452, 1.442, 0.46899999999999986, 0.46599999999999997, 0.4690000000000001, 0.43100000000000005, 0.4650000000000001, 0.44300000000000006, 0.45699999999999985, 0.46599999999999997, 1.4060000000000001, 0.47299999999999986, -0.04500000000000004, 1.429, 0.45500000000000007, 0.46899999999999986, 0.472, 0.45699999999999985, 0.45500000000000007, 1.453, 0.46099999999999985, 0.28000000000000025, 1.439, 0.43399999999999994, 1.409, 0.4590000000000001, 0.964, 1.9609999999999999, 0.027000000000000135, 0.45599999999999996, 1.452, 0.45799999999999996, -0.10199999999999998, -0.05500000000000005, 1.4020000000000001, 0.47, 0.43100000000000005, 0.45799999999999996, 0.21399999999999997, 0.3599999999999999, 0.45599999999999996, 0.4540000000000002, 0.45999999999999996, 0.4540000000000002, 0.9279999999999999, -0.10399999999999998, 0.45999999999999996, 0.44499999999999984, -0.026000000000000023, -0.42600000000000005, 0.44599999999999995, 1.435, 0.4750000000000001, 0.4590000000000001, 0.4570000000000001, 0.32000000000000006, 1.413, -0.10799999999999987, 0.46899999999999986, 0.3620000000000001, 0.44799999999999995, 0.46899999999999986, 0.45100000000000007, 0.45500000000000007, 0.45599999999999996, 1.37, 1.45, -0.03400000000000003, 0.4710000000000001, 0.4610000000000001, 0.46499999999999986, 0.4670000000000001], "episode_lengths": [28, 16, 10, 20, 15, 10, 26, 20, 14, 14, 22, 14, 13, 28, 20, 40, 8, 15, 12, 19, 15, 13, 12, 11, 41, 16, 10, 24, 55, 24, 28, 25, 12, 14, 12, 15, 12, 17, 13, 16, 19, 9, 14, 13, 121, 16, 42, 11, 12, 12, 86, 40, 17, 11, 26, 14, 18, 12, 20, 12, 17, 39, 12, 25, 16, 21, 15, 12, 20, 11, 21, 29, 26, 15, 26, 17, 18, 22, 16, 11, 11, 24, 17, 13, 14, 14, 15, 17, 14, 18, 15, 19, 10, 11, 10, 22, 11, 18, 14, 11, 30, 9, 15, 23, 15, 10, 9, 14, 14, 15, 12, 68, 20, 21, 29, 13, 11, 13, 152, 14, 15, 13, 33, 18, 31, 9, 21, 14, 90, 203, 14, 14, 13, 14, 23, 32, 13, 18, 8, 275, 17, 21, 8, 13, 14, 56, 28, 35, 10, 44, 300, 10, 15, 14, 14, 41, 16, 11, 9, 12, 11, 10], "policy_red_0_reward": [1.416, 1.452, 1.47, 1.44, 1.455, 1.47, 1.4220000000000002, 1.44, 1.458, 1.458, 1.434, 1.458, 1.4609999999999999, 1.416, 1.44, 1.38, 1.476, 1.455, 1.464, 1.443, 1.455, 1.4609999999999999, 1.464, 1.467, 1.377, 1.452, 1.47, 1.4169999999999998, 1.334, 1.428, 0.916, 1.425, 1.464, 1.458, 1.464, 1.455, 1.464, 1.4489999999999998, 1.4609999999999999, 1.452, 1.443, 1.4729999999999999, 0.958, 1.4609999999999999, 1.135, 1.452, 1.374, 1.467, 1.464, 1.464, 1.242, 1.38, 1.4489999999999998, 1.467, 1.4220000000000002, 1.458, 1.446, 1.464, 1.44, 1.464, 1.4489999999999998, 1.383, 1.464, 1.425, 1.452, 1.4369999999999998, 1.455, 1.464, 1.44, 1.467, 1.4369999999999998, 1.413, 1.4220000000000002, 1.455, 1.4220000000000002, -0.5, 0.946, 1.434, 1.452, 1.467, 1.467, 1.427, 1.4489999999999998, 1.4609999999999999, 1.458, 1.4569999999999999, 1.455, 1.4489999999999998, 1.458, 1.446, 1.4529999999999998, 1.443, 1.47, 1.467, 1.47, 1.434, 1.467, 1.446, 1.458, -0.5, 1.4100000000000001, 1.4729999999999999, -1.0, 1.431, 1.455, 1.47, 1.4729999999999999, 1.458, 1.458, 1.455, 1.464, 1.296, 1.44, 1.4369999999999998, 1.413, 1.4609999999999999, 1.467, 1.4609999999999999, 1.0419999999999998, 1.458, 1.455, 1.4609999999999999, 0.901, 0.946, 1.407, 1.4729999999999999, 1.4369999999999998, 1.458, 0.725, 0.887, 1.458, 1.458, 1.4609999999999999, 1.458, 1.431, 0.9, 1.4609999999999999, 1.446, -1.0, 0.11399999999999999, 1.4489999999999998, 1.4369999999999998, 1.476, 1.4609999999999999, 1.458, 1.3319999999999999, 1.416, -1.0, 1.47, 1.3679999999999999, 0.5, 1.47, 1.455, 1.458, 1.458, 1.3719999999999999, 1.452, 0.967, 1.4729999999999999, 1.464, 1.467, 1.47], "policy_blue_0_reward": [-1.004, -1.0, -1.0019999999999998, -0.006, -1.003, -1.001, -0.502, 0.499, -0.001, -1.002, 0.497, -1.0019999999999998, -1.002, -0.503, -0.003, -0.005, -1.001, -1.002, -1.0, -0.002, -1.003, -1.003, -0.5039999999999999, -1.002, -1.005, -0.002, -1.001, -1.005, -1.005, -0.004, -1.003, -0.002, -1.0, -1.001, -1.0, -0.001, -1.0019999999999998, -0.002, -1.002, -1.002, -1.003, -1.001, -1.001, -1.001, -1.017, -0.003, -0.009000000000000001, -1.003, -1.003, -1.0, -1.01, -0.009000000000000001, -0.002, -1.001, -1.004, -1.003, -1.003, -1.001, 0.495, -1.002, -0.002, -0.004, -1.002, -1.004, -1.001, -1.005, 0.5, -1.002, -0.003, -1.0019999999999998, -0.004, -0.005, -1.0, -1.002, 0.496, 0.949, -1.004, 0.0, -1.001, -1.0, -1.0, -0.003, -1.002, -1.0019999999999998, -1.002, -1.003, -1.001, -1.002, -1.002, -1.002, -0.001, -0.001, -1.001, -1.001, -1.001, -1.003, -1.0019999999999998, -1.003, -1.001, 0.966, -0.004, -1.0, 0.955, -0.002, -1.0, -1.001, -1.001, -1.001, -1.003, -0.002, -1.003, -1.0159999999999998, -0.001, -1.003, -0.004, -1.002, -0.503, 0.5, -1.015, -1.002, -0.003, -1.003, -1.003, -1.001, -0.005, -1.003, -1.006, -1.0, -0.511, -0.527, -1.002, -1.0039999999999998, -1.001, -1.0039999999999998, -0.503, -1.004, -1.001, -1.001, 0.974, -0.54, -1.003, -0.002, -1.001, -1.002, -1.001, -1.0119999999999998, -0.003, 0.892, -1.001, -1.006, -0.05200000000000004, -1.001, -1.004, -1.003, -1.0019999999999998, -0.002, -0.002, -1.001, -1.002, -1.003, -1.002, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24688916679266432, "mean_inference_ms": 1.4762246169730209, "mean_action_processing_ms": 0.06310578342445927, "mean_env_wait_ms": 0.08899848145725722, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019532221334951895, "StateBufferConnector_ms": 0.0014593571792414159, "ViewRequirementAgentConnector_ms": 0.03153644962075316}}, "episode_reward_max": 1.9609999999999999, "episode_reward_min": -0.42600000000000005, "episode_reward_mean": 0.6796604938271605, "episode_len_mean": 24.987654320987655, "episodes_this_iter": 162, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.017}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.974}, "policy_reward_mean": {"red_0": 1.326635802469136, "blue_0": -0.6469753086419753}, "hist_stats": {"episode_reward": [0.4119999999999999, 0.45199999999999996, 0.46799999999999997, 1.434, 0.45199999999999996, 0.46899999999999986, 0.9199999999999999, 1.939, 1.4569999999999999, 0.45599999999999996, 1.931, 0.45599999999999996, 0.4590000000000001, 0.913, 1.4369999999999998, 1.375, 0.4750000000000001, 0.45299999999999985, 0.46399999999999997, 1.441, 0.45199999999999996, 0.45799999999999996, 0.96, 0.46499999999999986, 0.3719999999999999, 1.45, 0.46899999999999986, 0.4119999999999999, 0.32899999999999996, 1.424, -0.08699999999999997, 1.423, 0.46399999999999997, 0.45699999999999985, 0.46399999999999997, 1.454, 0.4620000000000002, 1.447, 0.4590000000000001, 0.44999999999999996, 0.43999999999999995, 0.472, -0.04300000000000004, 0.45999999999999996, 0.1180000000000001, 1.4489999999999998, 1.365, 0.46399999999999997, 0.46099999999999985, 0.46399999999999997, 0.23199999999999998, 1.371, 1.447, 0.46599999999999997, 0.41800000000000015, 0.45500000000000007, 0.44300000000000006, 0.4630000000000001, 1.935, 0.46199999999999997, 1.447, 1.379, 0.46199999999999997, 0.42100000000000004, 0.45100000000000007, 0.43199999999999994, 1.955, 0.46199999999999997, 1.4369999999999998, 0.4650000000000001, 1.433, 1.4080000000000001, 0.42200000000000015, 0.45299999999999985, 1.9180000000000001, 0.44899999999999995, -0.05800000000000005, 1.434, 0.45100000000000007, 0.4670000000000001, 0.4670000000000001, 1.424, 0.44700000000000006, 0.4590000000000001, 0.45599999999999996, 0.45399999999999996, 0.45399999999999996, 0.44700000000000006, 0.45599999999999996, 0.44399999999999995, 1.452, 1.442, 0.46899999999999986, 0.46599999999999997, 0.4690000000000001, 0.43100000000000005, 0.4650000000000001, 0.44300000000000006, 0.45699999999999985, 0.46599999999999997, 1.4060000000000001, 0.47299999999999986, -0.04500000000000004, 1.429, 0.45500000000000007, 0.46899999999999986, 0.472, 0.45699999999999985, 0.45500000000000007, 1.453, 0.46099999999999985, 0.28000000000000025, 1.439, 0.43399999999999994, 1.409, 0.4590000000000001, 0.964, 1.9609999999999999, 0.027000000000000135, 0.45599999999999996, 1.452, 0.45799999999999996, -0.10199999999999998, -0.05500000000000005, 1.4020000000000001, 0.47, 0.43100000000000005, 0.45799999999999996, 0.21399999999999997, 0.3599999999999999, 0.45599999999999996, 0.4540000000000002, 0.45999999999999996, 0.4540000000000002, 0.9279999999999999, -0.10399999999999998, 0.45999999999999996, 0.44499999999999984, -0.026000000000000023, -0.42600000000000005, 0.44599999999999995, 1.435, 0.4750000000000001, 0.4590000000000001, 0.4570000000000001, 0.32000000000000006, 1.413, -0.10799999999999987, 0.46899999999999986, 0.3620000000000001, 0.44799999999999995, 0.46899999999999986, 0.45100000000000007, 0.45500000000000007, 0.45599999999999996, 1.37, 1.45, -0.03400000000000003, 0.4710000000000001, 0.4610000000000001, 0.46499999999999986, 0.4670000000000001], "episode_lengths": [28, 16, 10, 20, 15, 10, 26, 20, 14, 14, 22, 14, 13, 28, 20, 40, 8, 15, 12, 19, 15, 13, 12, 11, 41, 16, 10, 24, 55, 24, 28, 25, 12, 14, 12, 15, 12, 17, 13, 16, 19, 9, 14, 13, 121, 16, 42, 11, 12, 12, 86, 40, 17, 11, 26, 14, 18, 12, 20, 12, 17, 39, 12, 25, 16, 21, 15, 12, 20, 11, 21, 29, 26, 15, 26, 17, 18, 22, 16, 11, 11, 24, 17, 13, 14, 14, 15, 17, 14, 18, 15, 19, 10, 11, 10, 22, 11, 18, 14, 11, 30, 9, 15, 23, 15, 10, 9, 14, 14, 15, 12, 68, 20, 21, 29, 13, 11, 13, 152, 14, 15, 13, 33, 18, 31, 9, 21, 14, 90, 203, 14, 14, 13, 14, 23, 32, 13, 18, 8, 275, 17, 21, 8, 13, 14, 56, 28, 35, 10, 44, 300, 10, 15, 14, 14, 41, 16, 11, 9, 12, 11, 10], "policy_red_0_reward": [1.416, 1.452, 1.47, 1.44, 1.455, 1.47, 1.4220000000000002, 1.44, 1.458, 1.458, 1.434, 1.458, 1.4609999999999999, 1.416, 1.44, 1.38, 1.476, 1.455, 1.464, 1.443, 1.455, 1.4609999999999999, 1.464, 1.467, 1.377, 1.452, 1.47, 1.4169999999999998, 1.334, 1.428, 0.916, 1.425, 1.464, 1.458, 1.464, 1.455, 1.464, 1.4489999999999998, 1.4609999999999999, 1.452, 1.443, 1.4729999999999999, 0.958, 1.4609999999999999, 1.135, 1.452, 1.374, 1.467, 1.464, 1.464, 1.242, 1.38, 1.4489999999999998, 1.467, 1.4220000000000002, 1.458, 1.446, 1.464, 1.44, 1.464, 1.4489999999999998, 1.383, 1.464, 1.425, 1.452, 1.4369999999999998, 1.455, 1.464, 1.44, 1.467, 1.4369999999999998, 1.413, 1.4220000000000002, 1.455, 1.4220000000000002, -0.5, 0.946, 1.434, 1.452, 1.467, 1.467, 1.427, 1.4489999999999998, 1.4609999999999999, 1.458, 1.4569999999999999, 1.455, 1.4489999999999998, 1.458, 1.446, 1.4529999999999998, 1.443, 1.47, 1.467, 1.47, 1.434, 1.467, 1.446, 1.458, -0.5, 1.4100000000000001, 1.4729999999999999, -1.0, 1.431, 1.455, 1.47, 1.4729999999999999, 1.458, 1.458, 1.455, 1.464, 1.296, 1.44, 1.4369999999999998, 1.413, 1.4609999999999999, 1.467, 1.4609999999999999, 1.0419999999999998, 1.458, 1.455, 1.4609999999999999, 0.901, 0.946, 1.407, 1.4729999999999999, 1.4369999999999998, 1.458, 0.725, 0.887, 1.458, 1.458, 1.4609999999999999, 1.458, 1.431, 0.9, 1.4609999999999999, 1.446, -1.0, 0.11399999999999999, 1.4489999999999998, 1.4369999999999998, 1.476, 1.4609999999999999, 1.458, 1.3319999999999999, 1.416, -1.0, 1.47, 1.3679999999999999, 0.5, 1.47, 1.455, 1.458, 1.458, 1.3719999999999999, 1.452, 0.967, 1.4729999999999999, 1.464, 1.467, 1.47], "policy_blue_0_reward": [-1.004, -1.0, -1.0019999999999998, -0.006, -1.003, -1.001, -0.502, 0.499, -0.001, -1.002, 0.497, -1.0019999999999998, -1.002, -0.503, -0.003, -0.005, -1.001, -1.002, -1.0, -0.002, -1.003, -1.003, -0.5039999999999999, -1.002, -1.005, -0.002, -1.001, -1.005, -1.005, -0.004, -1.003, -0.002, -1.0, -1.001, -1.0, -0.001, -1.0019999999999998, -0.002, -1.002, -1.002, -1.003, -1.001, -1.001, -1.001, -1.017, -0.003, -0.009000000000000001, -1.003, -1.003, -1.0, -1.01, -0.009000000000000001, -0.002, -1.001, -1.004, -1.003, -1.003, -1.001, 0.495, -1.002, -0.002, -0.004, -1.002, -1.004, -1.001, -1.005, 0.5, -1.002, -0.003, -1.0019999999999998, -0.004, -0.005, -1.0, -1.002, 0.496, 0.949, -1.004, 0.0, -1.001, -1.0, -1.0, -0.003, -1.002, -1.0019999999999998, -1.002, -1.003, -1.001, -1.002, -1.002, -1.002, -0.001, -0.001, -1.001, -1.001, -1.001, -1.003, -1.0019999999999998, -1.003, -1.001, 0.966, -0.004, -1.0, 0.955, -0.002, -1.0, -1.001, -1.001, -1.001, -1.003, -0.002, -1.003, -1.0159999999999998, -0.001, -1.003, -0.004, -1.002, -0.503, 0.5, -1.015, -1.002, -0.003, -1.003, -1.003, -1.001, -0.005, -1.003, -1.006, -1.0, -0.511, -0.527, -1.002, -1.0039999999999998, -1.001, -1.0039999999999998, -0.503, -1.004, -1.001, -1.001, 0.974, -0.54, -1.003, -0.002, -1.001, -1.002, -1.001, -1.0119999999999998, -0.003, 0.892, -1.001, -1.006, -0.05200000000000004, -1.001, -1.004, -1.003, -1.0019999999999998, -0.002, -0.002, -1.001, -1.002, -1.003, -1.002, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24688916679266432, "mean_inference_ms": 1.4762246169730209, "mean_action_processing_ms": 0.06310578342445927, "mean_env_wait_ms": 0.08899848145725722, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019532221334951895, "StateBufferConnector_ms": 0.0014593571792414159, "ViewRequirementAgentConnector_ms": 0.03153644962075316}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000, "num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.80042220117399, "num_env_steps_trained_throughput_per_sec": 102.80042220117399, "timesteps_total": 232000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 464000, "timers": {"training_iteration_time_ms": 38931.458, "sample_time_ms": 7560.766, "learn_time_ms": 31353.041, "learn_throughput": 127.579, "synch_weights_time_ms": 17.145}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 232000, "num_agent_steps_sampled": 464000, "num_agent_steps_trained": 464000}, "done": false, "episodes_total": 7197, "training_iteration": 58, "trial_id": "d67e4_00000", "date": "2023-09-20_22-46-58", "timestamp": 1695264418, "time_this_iter_s": 38.91716384887695, "time_total_s": 2256.684570789337, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a6879ea0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2256.684570789337, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 34.912727272727274, "ram_util_percent": 49.38545454545456}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2471264367816092, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6724137931034483, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07471264367816093, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6724137931034483, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.07471264367816093, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6724137931034483, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07471264367816093, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0288712474207085, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.007829122852732932, "policy_loss": -0.015802560111963734, "vf_loss": 0.010212378526557587, "vf_explained_var": 0.7037118141228954, "kl": 0.0073406454614295975, "entropy": 0.43604214846466977, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 56160.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "sampler_results": {"episode_reward_max": 1.943, "episode_reward_min": -0.45499999999999996, "episode_reward_mean": 0.6634770114942529, "episode_len_mean": 21.54597701149425, "episode_media": {}, "episodes_this_iter": 174, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.0179999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.299}, "policy_reward_mean": {"red_0": 1.2490172413793104, "blue_0": -0.5855402298850574}, "custom_metrics": {"red_0/door_open_done_mean": 0.2471264367816092, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6724137931034483, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07471264367816093, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6724137931034483, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.07471264367816093, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6724137931034483, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07471264367816093, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.799, 0.472, 0.44099999999999984, 0.46599999999999997, 0.4660000000000002, 0.44899999999999995, 1.3250000000000002, 0.46499999999999986, 1.4529999999999998, -0.05900000000000005, 0.46099999999999985, 0.46199999999999997, 0.46399999999999997, -0.038000000000000034, 0.45599999999999996, 0.41000000000000014, 0.43999999999999995, 1.458, 0.43699999999999983, 0.46499999999999986, 0.6059999999999999, 1.4569999999999999, 0.46499999999999986, 0.46599999999999997, 0.45599999999999996, 0.9339999999999999, 0.46899999999999986, 0.44899999999999984, -0.45499999999999996, 1.438, 1.4409999999999998, 1.458, 1.439, 0.4580000000000002, -0.039000000000000035, 0.46199999999999997, -0.029999999999999916, 0.44599999999999995, 0.44399999999999995, 0.348, 0.45099999999999996, -0.03599999999999992, 0.4159999999999999, 0.46599999999999997, 0.4630000000000001, 0.45699999999999985, 0.46099999999999985, 0.47, 0.45500000000000007, 0.9489999999999998, 1.431, 1.4409999999999998, 0.47299999999999986, 0.45699999999999985, 0.9609999999999999, 0.44700000000000006, -0.02299999999999991, -0.025000000000000022, 1.432, 0.45299999999999985, 1.432, 1.439, 1.4409999999999998, 0.46599999999999997, 1.425, -0.02300000000000002, 0.45699999999999985, 0.4590000000000001, 0.44999999999999996, 1.4529999999999998, 1.456, 0.4630000000000001, 1.44, 1.4609999999999999, 1.458, 0.46099999999999985, 1.421, 1.943, 1.448, 0.4670000000000001, 0.46599999999999997, 0.4670000000000001, 0.46699999999999997, 0.46099999999999985, 1.4489999999999998, 0.399, 0.46899999999999986, 1.46, 0.47, 0.43799999999999994, 1.4409999999999998, 0.44999999999999996, 0.4590000000000001, 0.46199999999999997, 0.46399999999999997, 0.46199999999999997, 1.4369999999999998, 0.4590000000000001, 0.45500000000000007, 0.46599999999999997, 0.4710000000000001, 0.46799999999999997, 1.454, 0.46199999999999997, 0.47, 0.4580000000000002, 0.45599999999999996, 0.44700000000000006, 0.44599999999999995, 0.46399999999999997, 0.4590000000000001, 0.47299999999999986, 0.45999999999999996, 0.4750000000000001, 0.46399999999999997, 0.46399999999999997, 0.44399999999999995, -0.05700000000000005, 0.44799999999999995, 1.935, 0.476, 1.46, 1.373, 0.46899999999999986, 0.42799999999999994, 0.29899999999999993, 0.393, 0.952, 0.4610000000000001, 1.458, 0.8799999999999998, 0.46199999999999997, 0.44499999999999984, -0.41000000000000003, 1.439, 0.46399999999999997, 0.46899999999999986, 0.4750000000000001, 0.44300000000000006, 1.434, 1.389, 1.454, 1.446, 0.45100000000000007, 0.45999999999999996, 1.381, 0.45500000000000007, 0.45299999999999985, 0.45399999999999996, 0.45299999999999985, -0.03500000000000003, 0.46899999999999986, 1.443, 0.44500000000000006, 0.4570000000000001, 0.44599999999999995, 0.44300000000000006, -0.08699999999999997, 0.45500000000000007, 0.264, 0.45199999999999996, 0.4540000000000002, 0.4660000000000002, 0.45599999999999996, -0.06800000000000006, 1.384, 1.44, 0.472, 0.349, 0.47, 0.45100000000000007, -0.040999999999999925, 0.26900000000000013, 1.443], "episode_lengths": [64, 9, 19, 11, 11, 17, 56, 11, 15, 18, 13, 11, 11, 12, 14, 29, 19, 14, 20, 11, 126, 14, 11, 11, 14, 21, 10, 16, 143, 20, 19, 14, 19, 13, 12, 12, 9, 300, 18, 48, 16, 11, 27, 11, 11, 14, 13, 9, 14, 16, 23, 19, 9, 14, 13, 17, 7, 8, 22, 15, 22, 20, 19, 11, 23, 7, 13, 13, 16, 15, 14, 12, 19, 13, 13, 12, 26, 19, 16, 10, 11, 11, 10, 12, 16, 32, 10, 13, 10, 20, 19, 16, 13, 12, 12, 11, 20, 12, 14, 11, 9, 10, 15, 12, 10, 13, 14, 17, 18, 11, 13, 9, 13, 8, 11, 11, 18, 16, 16, 20, 8, 13, 40, 10, 23, 65, 34, 15, 12, 13, 168, 12, 18, 118, 19, 11, 10, 8, 18, 21, 35, 15, 17, 15, 13, 37, 15, 14, 15, 15, 11, 10, 18, 18, 13, 17, 19, 27, 15, 74, 16, 14, 11, 14, 20, 36, 18, 8, 48, 10, 16, 13, 72, 18], "policy_red_0_reward": [-0.5, 1.4729999999999999, 1.443, 1.467, 1.467, -0.5, 1.3319999999999999, 1.467, 1.455, 0.946, 1.4609999999999999, 1.467, 1.467, 0.964, 1.458, 1.413, 1.443, 1.458, 1.44, 1.467, 1.1219999999999999, 1.458, 1.467, 1.467, 1.458, 1.4369999999999998, 1.47, 1.452, 0.563, 1.439, 1.443, 1.458, 1.443, 1.4609999999999999, 0.964, 1.464, -1.0, 0.484, 1.446, -0.5, -0.5, 0.966, 1.419, 1.467, 1.467, 1.458, 1.4609999999999999, 1.4729999999999999, 1.458, 1.452, 1.431, 1.443, 1.4729999999999999, 1.458, 1.4609999999999999, 1.4489999999999998, 0.979, 0.976, 1.434, 1.455, 1.434, 1.44, 1.443, 1.467, 1.431, -1.0, 1.4609999999999999, 1.4609999999999999, 1.452, 1.455, 1.458, 1.464, 1.443, 1.4609999999999999, 1.4609999999999999, 1.464, 1.4220000000000002, 1.443, 1.452, 1.47, 1.467, 1.467, -0.501, 1.463, 1.452, 1.404, 1.47, 1.4609999999999999, 1.47, -0.5, 1.443, 1.452, 1.4609999999999999, 1.464, 1.464, 1.467, 1.44, 1.464, 1.4569999999999999, 1.467, 1.4729999999999999, 1.47, 1.455, 1.464, 1.47, 1.4609999999999999, 1.458, 1.4489999999999998, 1.446, 1.467, 1.4609999999999999, 1.4729999999999999, 1.4609999999999999, 1.476, 1.467, -0.5, 1.446, 0.945, 1.451, 1.439, 1.476, 1.4609999999999999, 1.379, 1.47, 1.431, 1.3039999999999998, -0.5, 1.455, 1.464, 1.4609999999999999, 0.9009999999999998, 1.464, 1.446, -1.039, 1.443, 1.467, 1.47, 1.476, 1.446, 1.4369999999999998, 1.3940000000000001, 1.455, 1.4489999999999998, 1.455, 1.4609999999999999, 1.389, 1.455, 1.458, 1.455, 1.455, 0.967, 1.47, 1.446, 1.446, 1.4609999999999999, 1.4489999999999998, 1.443, -1.0, 1.455, -0.504, 1.452, 1.458, 1.467, 1.458, 0.9369999999999999, 1.392, 1.446, 1.476, 1.354, 1.47, 1.452, 0.961, 1.279, 1.446], "policy_blue_0_reward": [1.299, -1.001, -1.002, -1.001, -1.001, 0.949, -0.007, -1.002, -0.002, -1.005, -1.0, -1.005, -1.003, -1.002, -1.002, -1.003, -1.003, 0.0, -1.003, -1.002, -0.516, -0.001, -1.002, -1.001, -1.002, -0.503, -1.001, -1.003, -1.0179999999999998, -0.001, -0.002, 0.0, -0.004, -1.003, -1.003, -1.002, 0.97, -0.03800000000000003, -1.002, 0.848, 0.951, -1.0019999999999998, -1.003, -1.001, -1.0039999999999998, -1.001, -1.0, -1.003, -1.003, -0.503, 0.0, -0.002, -1.0, -1.001, -0.5, -1.002, -1.0019999999999998, -1.001, -0.002, -1.002, -0.002, -0.001, -0.002, -1.001, -0.006, 0.977, -1.004, -1.002, -1.002, -0.002, -0.002, -1.001, -0.003, 0.0, -0.003, -1.003, -0.001, 0.5, -0.004, -1.003, -1.001, -1.0, 0.968, -1.002, -0.003, -1.005, -1.001, -0.001, -1.0, 0.938, -0.002, -1.002, -1.002, -1.002, -1.0, -1.005, -0.003, -1.005, -1.002, -1.001, -1.002, -1.002, -0.001, -1.002, -1.0, -1.003, -1.002, -1.002, -1.0, -1.003, -1.002, -1.0, -1.001, -1.001, -1.003, 0.964, -1.002, -1.002, -1.003, 0.496, -1.0, -0.001, -0.006, -1.001, -1.003, -1.005, 0.893, -0.503, -1.003, -0.003, -0.02100000000000001, -1.002, -1.001, 0.629, -0.004, -1.003, -1.001, -1.001, -1.003, -0.003, -0.005, -0.001, -0.003, -1.004, -1.001, -0.008, -1.0, -1.005, -1.001, -1.002, -1.002, -1.001, -0.003, -1.001, -1.0039999999999998, -1.003, -1.0, 0.913, -1.0, 0.768, -1.0, -1.0039999999999998, -1.001, -1.002, -1.005, -0.008, -0.006, -1.0039999999999998, -1.005, -1.0, -1.001, -1.0019999999999998, -1.01, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2464179459793588, "mean_inference_ms": 1.4745166791877802, "mean_action_processing_ms": 0.0629225619765505, "mean_env_wait_ms": 0.08880696111652452, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019164674583522754, "StateBufferConnector_ms": 0.0014871016316030216, "ViewRequirementAgentConnector_ms": 0.031242699458681304}}, "episode_reward_max": 1.943, "episode_reward_min": -0.45499999999999996, "episode_reward_mean": 0.6634770114942529, "episode_len_mean": 21.54597701149425, "episodes_this_iter": 174, "policy_reward_min": {"red_0": -1.039, "blue_0": -1.0179999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.299}, "policy_reward_mean": {"red_0": 1.2490172413793104, "blue_0": -0.5855402298850574}, "hist_stats": {"episode_reward": [0.799, 0.472, 0.44099999999999984, 0.46599999999999997, 0.4660000000000002, 0.44899999999999995, 1.3250000000000002, 0.46499999999999986, 1.4529999999999998, -0.05900000000000005, 0.46099999999999985, 0.46199999999999997, 0.46399999999999997, -0.038000000000000034, 0.45599999999999996, 0.41000000000000014, 0.43999999999999995, 1.458, 0.43699999999999983, 0.46499999999999986, 0.6059999999999999, 1.4569999999999999, 0.46499999999999986, 0.46599999999999997, 0.45599999999999996, 0.9339999999999999, 0.46899999999999986, 0.44899999999999984, -0.45499999999999996, 1.438, 1.4409999999999998, 1.458, 1.439, 0.4580000000000002, -0.039000000000000035, 0.46199999999999997, -0.029999999999999916, 0.44599999999999995, 0.44399999999999995, 0.348, 0.45099999999999996, -0.03599999999999992, 0.4159999999999999, 0.46599999999999997, 0.4630000000000001, 0.45699999999999985, 0.46099999999999985, 0.47, 0.45500000000000007, 0.9489999999999998, 1.431, 1.4409999999999998, 0.47299999999999986, 0.45699999999999985, 0.9609999999999999, 0.44700000000000006, -0.02299999999999991, -0.025000000000000022, 1.432, 0.45299999999999985, 1.432, 1.439, 1.4409999999999998, 0.46599999999999997, 1.425, -0.02300000000000002, 0.45699999999999985, 0.4590000000000001, 0.44999999999999996, 1.4529999999999998, 1.456, 0.4630000000000001, 1.44, 1.4609999999999999, 1.458, 0.46099999999999985, 1.421, 1.943, 1.448, 0.4670000000000001, 0.46599999999999997, 0.4670000000000001, 0.46699999999999997, 0.46099999999999985, 1.4489999999999998, 0.399, 0.46899999999999986, 1.46, 0.47, 0.43799999999999994, 1.4409999999999998, 0.44999999999999996, 0.4590000000000001, 0.46199999999999997, 0.46399999999999997, 0.46199999999999997, 1.4369999999999998, 0.4590000000000001, 0.45500000000000007, 0.46599999999999997, 0.4710000000000001, 0.46799999999999997, 1.454, 0.46199999999999997, 0.47, 0.4580000000000002, 0.45599999999999996, 0.44700000000000006, 0.44599999999999995, 0.46399999999999997, 0.4590000000000001, 0.47299999999999986, 0.45999999999999996, 0.4750000000000001, 0.46399999999999997, 0.46399999999999997, 0.44399999999999995, -0.05700000000000005, 0.44799999999999995, 1.935, 0.476, 1.46, 1.373, 0.46899999999999986, 0.42799999999999994, 0.29899999999999993, 0.393, 0.952, 0.4610000000000001, 1.458, 0.8799999999999998, 0.46199999999999997, 0.44499999999999984, -0.41000000000000003, 1.439, 0.46399999999999997, 0.46899999999999986, 0.4750000000000001, 0.44300000000000006, 1.434, 1.389, 1.454, 1.446, 0.45100000000000007, 0.45999999999999996, 1.381, 0.45500000000000007, 0.45299999999999985, 0.45399999999999996, 0.45299999999999985, -0.03500000000000003, 0.46899999999999986, 1.443, 0.44500000000000006, 0.4570000000000001, 0.44599999999999995, 0.44300000000000006, -0.08699999999999997, 0.45500000000000007, 0.264, 0.45199999999999996, 0.4540000000000002, 0.4660000000000002, 0.45599999999999996, -0.06800000000000006, 1.384, 1.44, 0.472, 0.349, 0.47, 0.45100000000000007, -0.040999999999999925, 0.26900000000000013, 1.443], "episode_lengths": [64, 9, 19, 11, 11, 17, 56, 11, 15, 18, 13, 11, 11, 12, 14, 29, 19, 14, 20, 11, 126, 14, 11, 11, 14, 21, 10, 16, 143, 20, 19, 14, 19, 13, 12, 12, 9, 300, 18, 48, 16, 11, 27, 11, 11, 14, 13, 9, 14, 16, 23, 19, 9, 14, 13, 17, 7, 8, 22, 15, 22, 20, 19, 11, 23, 7, 13, 13, 16, 15, 14, 12, 19, 13, 13, 12, 26, 19, 16, 10, 11, 11, 10, 12, 16, 32, 10, 13, 10, 20, 19, 16, 13, 12, 12, 11, 20, 12, 14, 11, 9, 10, 15, 12, 10, 13, 14, 17, 18, 11, 13, 9, 13, 8, 11, 11, 18, 16, 16, 20, 8, 13, 40, 10, 23, 65, 34, 15, 12, 13, 168, 12, 18, 118, 19, 11, 10, 8, 18, 21, 35, 15, 17, 15, 13, 37, 15, 14, 15, 15, 11, 10, 18, 18, 13, 17, 19, 27, 15, 74, 16, 14, 11, 14, 20, 36, 18, 8, 48, 10, 16, 13, 72, 18], "policy_red_0_reward": [-0.5, 1.4729999999999999, 1.443, 1.467, 1.467, -0.5, 1.3319999999999999, 1.467, 1.455, 0.946, 1.4609999999999999, 1.467, 1.467, 0.964, 1.458, 1.413, 1.443, 1.458, 1.44, 1.467, 1.1219999999999999, 1.458, 1.467, 1.467, 1.458, 1.4369999999999998, 1.47, 1.452, 0.563, 1.439, 1.443, 1.458, 1.443, 1.4609999999999999, 0.964, 1.464, -1.0, 0.484, 1.446, -0.5, -0.5, 0.966, 1.419, 1.467, 1.467, 1.458, 1.4609999999999999, 1.4729999999999999, 1.458, 1.452, 1.431, 1.443, 1.4729999999999999, 1.458, 1.4609999999999999, 1.4489999999999998, 0.979, 0.976, 1.434, 1.455, 1.434, 1.44, 1.443, 1.467, 1.431, -1.0, 1.4609999999999999, 1.4609999999999999, 1.452, 1.455, 1.458, 1.464, 1.443, 1.4609999999999999, 1.4609999999999999, 1.464, 1.4220000000000002, 1.443, 1.452, 1.47, 1.467, 1.467, -0.501, 1.463, 1.452, 1.404, 1.47, 1.4609999999999999, 1.47, -0.5, 1.443, 1.452, 1.4609999999999999, 1.464, 1.464, 1.467, 1.44, 1.464, 1.4569999999999999, 1.467, 1.4729999999999999, 1.47, 1.455, 1.464, 1.47, 1.4609999999999999, 1.458, 1.4489999999999998, 1.446, 1.467, 1.4609999999999999, 1.4729999999999999, 1.4609999999999999, 1.476, 1.467, -0.5, 1.446, 0.945, 1.451, 1.439, 1.476, 1.4609999999999999, 1.379, 1.47, 1.431, 1.3039999999999998, -0.5, 1.455, 1.464, 1.4609999999999999, 0.9009999999999998, 1.464, 1.446, -1.039, 1.443, 1.467, 1.47, 1.476, 1.446, 1.4369999999999998, 1.3940000000000001, 1.455, 1.4489999999999998, 1.455, 1.4609999999999999, 1.389, 1.455, 1.458, 1.455, 1.455, 0.967, 1.47, 1.446, 1.446, 1.4609999999999999, 1.4489999999999998, 1.443, -1.0, 1.455, -0.504, 1.452, 1.458, 1.467, 1.458, 0.9369999999999999, 1.392, 1.446, 1.476, 1.354, 1.47, 1.452, 0.961, 1.279, 1.446], "policy_blue_0_reward": [1.299, -1.001, -1.002, -1.001, -1.001, 0.949, -0.007, -1.002, -0.002, -1.005, -1.0, -1.005, -1.003, -1.002, -1.002, -1.003, -1.003, 0.0, -1.003, -1.002, -0.516, -0.001, -1.002, -1.001, -1.002, -0.503, -1.001, -1.003, -1.0179999999999998, -0.001, -0.002, 0.0, -0.004, -1.003, -1.003, -1.002, 0.97, -0.03800000000000003, -1.002, 0.848, 0.951, -1.0019999999999998, -1.003, -1.001, -1.0039999999999998, -1.001, -1.0, -1.003, -1.003, -0.503, 0.0, -0.002, -1.0, -1.001, -0.5, -1.002, -1.0019999999999998, -1.001, -0.002, -1.002, -0.002, -0.001, -0.002, -1.001, -0.006, 0.977, -1.004, -1.002, -1.002, -0.002, -0.002, -1.001, -0.003, 0.0, -0.003, -1.003, -0.001, 0.5, -0.004, -1.003, -1.001, -1.0, 0.968, -1.002, -0.003, -1.005, -1.001, -0.001, -1.0, 0.938, -0.002, -1.002, -1.002, -1.002, -1.0, -1.005, -0.003, -1.005, -1.002, -1.001, -1.002, -1.002, -0.001, -1.002, -1.0, -1.003, -1.002, -1.002, -1.0, -1.003, -1.002, -1.0, -1.001, -1.001, -1.003, 0.964, -1.002, -1.002, -1.003, 0.496, -1.0, -0.001, -0.006, -1.001, -1.003, -1.005, 0.893, -0.503, -1.003, -0.003, -0.02100000000000001, -1.002, -1.001, 0.629, -0.004, -1.003, -1.001, -1.001, -1.003, -0.003, -0.005, -0.001, -0.003, -1.004, -1.001, -0.008, -1.0, -1.005, -1.001, -1.002, -1.002, -1.001, -0.003, -1.001, -1.0039999999999998, -1.003, -1.0, 0.913, -1.0, 0.768, -1.0, -1.0039999999999998, -1.001, -1.002, -1.005, -0.008, -0.006, -1.0039999999999998, -1.005, -1.0, -1.001, -1.0019999999999998, -1.01, -0.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2464179459793588, "mean_inference_ms": 1.4745166791877802, "mean_action_processing_ms": 0.0629225619765505, "mean_env_wait_ms": 0.08880696111652452, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019164674583522754, "StateBufferConnector_ms": 0.0014871016316030216, "ViewRequirementAgentConnector_ms": 0.031242699458681304}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000, "num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.79691631112823, "num_env_steps_trained_throughput_per_sec": 102.79691631112823, "timesteps_total": 236000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 472000, "timers": {"training_iteration_time_ms": 38937.327, "sample_time_ms": 7561.244, "learn_time_ms": 31358.433, "learn_throughput": 127.557, "synch_weights_time_ms": 17.145}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 236000, "num_agent_steps_sampled": 472000, "num_agent_steps_trained": 472000}, "done": false, "episodes_total": 7371, "training_iteration": 59, "trial_id": "d67e4_00000", "date": "2023-09-20_22-47-37", "timestamp": 1695264457, "time_this_iter_s": 38.91881608963013, "time_total_s": 2295.6033868789673, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d095750>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2295.6033868789673, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 33.426785714285714, "ram_util_percent": 49.40178571428571}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2571428571428571, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6857142857142857, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03571428571428571, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6857142857142857, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03571428571428571, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6857142857142857, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03571428571428571, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.4663493540138006, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.013518831772429015, "policy_loss": -0.021065953894382497, "vf_loss": 0.006179813109459549, "vf_explained_var": 0.7829758688186605, "kl": 0.01094312422790545, "entropy": 0.46719045070931314, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 57120.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "sampler_results": {"episode_reward_max": 1.954, "episode_reward_min": -0.20899999999999996, "episode_reward_mean": 0.6503857142857143, "episode_len_mean": 26.35, "episode_media": {}, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.966}, "policy_reward_mean": {"red_0": 1.2820285714285713, "blue_0": -0.6316428571428571}, "custom_metrics": {"red_0/door_open_done_mean": 0.2571428571428571, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6857142857142857, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.03571428571428571, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6857142857142857, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.03571428571428571, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6857142857142857, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.03571428571428571, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.05500000000000004, 1.4369999999999998, 0.46499999999999986, 0.46199999999999997, 0.43500000000000005, 0.45399999999999996, -0.10499999999999998, 1.349, 1.408, 0.472, 0.32499999999999996, -0.09299999999999997, 0.45199999999999996, 0.44900000000000007, 0.4610000000000001, 0.46199999999999997, 1.3399999999999999, 0.45999999999999996, -0.11599999999999999, 0.377, 1.4409999999999998, 0.45399999999999996, 1.447, 0.4710000000000001, 0.45699999999999985, -0.051999999999999935, 0.942, 0.96, 0.4590000000000001, 0.44599999999999995, 0.42999999999999994, 0.45199999999999996, 1.954, 0.45199999999999996, 0.45799999999999996, 0.4610000000000001, 1.454, 0.42700000000000005, 1.444, -0.08399999999999996, -0.07799999999999996, 1.0700000000000003, 0.4620000000000002, 0.46899999999999986, 1.455, 1.45, 1.4529999999999998, 1.258, 0.41900000000000004, 1.448, 0.46899999999999986, 1.46, 0.45999999999999996, 1.46, 0.47, 0.44300000000000006, 0.45500000000000007, 1.4609999999999999, 1.4569999999999999, 1.439, 0.21999999999999997, 0.4670000000000001, 0.47299999999999986, 1.431, 0.46399999999999997, 0.4710000000000001, 1.4, -0.031000000000000028, 0.42300000000000004, 0.968, 0.42999999999999994, 1.393, 1.439, 0.964, 0.45999999999999996, 1.455, -0.03399999999999992, 0.44899999999999984, -0.20899999999999996, 0.45599999999999996, 0.46099999999999985, 0.46199999999999997, 1.459, 0.4630000000000001, 0.41800000000000015, 0.4630000000000001, 1.419, -0.06700000000000005, 0.45799999999999996, 0.472, -0.135, 0.43900000000000006, 0.46899999999999986, 0.46499999999999986, 0.45500000000000007, 0.3500000000000001, 1.4060000000000001, 0.43199999999999994, 0.46799999999999997, 0.46899999999999986, 0.46499999999999986, 0.476, 1.4020000000000001, 0.46399999999999997, 0.41500000000000004, 0.4630000000000001, -0.03399999999999992, -0.09199999999999997, 0.4670000000000001, 1.4220000000000002, 0.43900000000000006, -0.050000000000000044, 1.951, 0.4710000000000001, 0.46199999999999997, 1.451, -0.02100000000000002, 0.45500000000000007, 0.43100000000000005, 0.45100000000000007, 0.45799999999999996, 1.947, -0.06699999999999995, 0.45399999999999996, 0.476, 0.41400000000000015, -0.041000000000000036, 1.3519999999999999, 0.44700000000000006, 0.47, 1.251, 0.45599999999999996, 1.455, 0.45699999999999985, -0.04700000000000004, 0.42900000000000005, 0.45299999999999985, 0.45999999999999996, 0.46499999999999986, 0.47], "episode_lengths": [300, 20, 11, 12, 21, 15, 33, 48, 30, 9, 55, 29, 15, 16, 12, 12, 51, 13, 37, 38, 19, 15, 17, 9, 14, 17, 19, 300, 13, 17, 22, 15, 15, 15, 13, 12, 15, 23, 17, 28, 25, 136, 12, 10, 14, 16, 15, 75, 26, 17, 10, 13, 13, 13, 10, 18, 14, 13, 14, 20, 89, 11, 9, 22, 12, 9, 31, 9, 25, 10, 22, 34, 19, 12, 13, 15, 10, 16, 66, 14, 12, 12, 13, 11, 25, 12, 26, 300, 14, 9, 42, 19, 10, 11, 15, 48, 29, 21, 10, 10, 11, 8, 32, 12, 28, 12, 11, 26, 11, 25, 19, 15, 16, 9, 12, 16, 7, 15, 22, 16, 13, 17, 20, 15, 8, 27, 13, 47, 17, 10, 77, 14, 15, 14, 15, 23, 15, 12, 11, 10], "policy_red_0_reward": [-0.015000000000000006, 1.44, 1.467, 1.464, 1.4369999999999998, 1.455, 0.9, 1.3559999999999999, 1.4100000000000001, 1.4729999999999999, -0.5, 0.91, 1.455, 1.452, 1.464, 1.464, 1.345, 1.46, 0.888, -0.5, 1.443, 1.455, 1.4489999999999998, 1.4729999999999999, 1.4569999999999999, -1.001, 1.443, 0.493, 1.4609999999999999, 1.448, 1.434, 1.455, 1.455, 1.455, 1.4609999999999999, 1.464, 1.455, 1.431, 1.448, -1.0, 0.924, 1.088, 1.464, 1.47, 1.458, 1.452, 1.455, 1.2690000000000001, 1.4220000000000002, 1.4489999999999998, 1.47, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.47, 1.446, 1.458, 1.4609999999999999, 1.458, 1.44, 1.233, 1.467, 1.4729999999999999, 1.4329999999999998, 1.464, 1.4729999999999999, 1.407, 0.972, 1.425, 1.47, 1.434, 1.3980000000000001, 1.443, 1.464, 1.4609999999999999, 1.455, 0.968, 1.452, 0.802, 1.458, 1.464, 1.464, 1.4609999999999999, 1.467, 1.423, 1.464, 1.4220000000000002, -0.013000000000000005, 1.458, 1.4729999999999999, 0.869, 1.4409999999999998, 1.47, 1.467, 1.455, 1.3559999999999999, 1.411, 1.4369999999999998, 1.47, 1.47, 1.467, 1.476, 1.404, 1.464, 1.416, 1.464, -1.0, 0.909, 1.467, 1.425, 1.443, 0.955, 1.452, 1.4729999999999999, 1.464, 1.452, 0.979, 1.455, 1.432, 1.452, 1.4609999999999999, 1.4489999999999998, 0.939, 1.455, 1.476, 1.419, 0.961, 1.359, 1.4489999999999998, 1.47, 1.263, 1.458, 1.455, 1.458, 0.954, 1.431, 1.455, 1.464, 1.467, 1.47], "policy_blue_0_reward": [-0.04000000000000003, -0.003, -1.002, -1.002, -1.0019999999999998, -1.001, -1.005, -0.007, -0.002, -1.001, 0.825, -1.003, -1.003, -1.003, -1.003, -1.002, -0.005, -1.0, -1.004, 0.877, -0.002, -1.001, -0.002, -1.002, -1.0, 0.949, -0.501, 0.46699999999999997, -1.002, -1.002, -1.004, -1.003, 0.499, -1.003, -1.003, -1.003, -0.001, -1.004, -0.004, 0.916, -1.002, -0.01800000000000001, -1.0019999999999998, -1.001, -0.003, -0.002, -0.002, -0.011000000000000003, -1.003, -0.001, -1.001, -0.001, -1.001, -0.001, -1.0, -1.003, -1.003, 0.0, -0.001, -0.001, -1.013, -1.0, -1.0, -0.002, -1.0, -1.0019999999999998, -0.007, -1.003, -1.002, -0.5019999999999999, -1.004, -0.005, -0.004, -0.5, -1.001, 0.0, -1.0019999999999998, -1.003, -1.011, -1.0019999999999998, -1.003, -1.002, -0.002, -1.004, -1.005, -1.001, -0.003, -0.05400000000000004, -1.0, -1.001, -1.004, -1.002, -1.001, -1.002, -1.0, -1.006, -0.005, -1.005, -1.002, -1.001, -1.002, -1.0, -0.002, -1.0, -1.001, -1.001, 0.966, -1.001, -1.0, -0.003, -1.004, -1.005, 0.499, -1.002, -1.002, -0.001, -1.0, -1.0, -1.001, -1.001, -1.003, 0.498, -1.0059999999999998, -1.001, -1.0, -1.005, -1.002, -0.007, -1.002, -1.0, -0.012000000000000004, -1.002, 0.0, -1.001, -1.001, -1.002, -1.002, -1.0039999999999998, -1.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24696041510304054, "mean_inference_ms": 1.4755342554838753, "mean_action_processing_ms": 0.06304701337022078, "mean_env_wait_ms": 0.0889261700089006, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018964920725141252, "StateBufferConnector_ms": 0.0014910527638026647, "ViewRequirementAgentConnector_ms": 0.031225340706961497}}, "episode_reward_max": 1.954, "episode_reward_min": -0.20899999999999996, "episode_reward_mean": 0.6503857142857143, "episode_len_mean": 26.35, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.966}, "policy_reward_mean": {"red_0": 1.2820285714285713, "blue_0": -0.6316428571428571}, "hist_stats": {"episode_reward": [-0.05500000000000004, 1.4369999999999998, 0.46499999999999986, 0.46199999999999997, 0.43500000000000005, 0.45399999999999996, -0.10499999999999998, 1.349, 1.408, 0.472, 0.32499999999999996, -0.09299999999999997, 0.45199999999999996, 0.44900000000000007, 0.4610000000000001, 0.46199999999999997, 1.3399999999999999, 0.45999999999999996, -0.11599999999999999, 0.377, 1.4409999999999998, 0.45399999999999996, 1.447, 0.4710000000000001, 0.45699999999999985, -0.051999999999999935, 0.942, 0.96, 0.4590000000000001, 0.44599999999999995, 0.42999999999999994, 0.45199999999999996, 1.954, 0.45199999999999996, 0.45799999999999996, 0.4610000000000001, 1.454, 0.42700000000000005, 1.444, -0.08399999999999996, -0.07799999999999996, 1.0700000000000003, 0.4620000000000002, 0.46899999999999986, 1.455, 1.45, 1.4529999999999998, 1.258, 0.41900000000000004, 1.448, 0.46899999999999986, 1.46, 0.45999999999999996, 1.46, 0.47, 0.44300000000000006, 0.45500000000000007, 1.4609999999999999, 1.4569999999999999, 1.439, 0.21999999999999997, 0.4670000000000001, 0.47299999999999986, 1.431, 0.46399999999999997, 0.4710000000000001, 1.4, -0.031000000000000028, 0.42300000000000004, 0.968, 0.42999999999999994, 1.393, 1.439, 0.964, 0.45999999999999996, 1.455, -0.03399999999999992, 0.44899999999999984, -0.20899999999999996, 0.45599999999999996, 0.46099999999999985, 0.46199999999999997, 1.459, 0.4630000000000001, 0.41800000000000015, 0.4630000000000001, 1.419, -0.06700000000000005, 0.45799999999999996, 0.472, -0.135, 0.43900000000000006, 0.46899999999999986, 0.46499999999999986, 0.45500000000000007, 0.3500000000000001, 1.4060000000000001, 0.43199999999999994, 0.46799999999999997, 0.46899999999999986, 0.46499999999999986, 0.476, 1.4020000000000001, 0.46399999999999997, 0.41500000000000004, 0.4630000000000001, -0.03399999999999992, -0.09199999999999997, 0.4670000000000001, 1.4220000000000002, 0.43900000000000006, -0.050000000000000044, 1.951, 0.4710000000000001, 0.46199999999999997, 1.451, -0.02100000000000002, 0.45500000000000007, 0.43100000000000005, 0.45100000000000007, 0.45799999999999996, 1.947, -0.06699999999999995, 0.45399999999999996, 0.476, 0.41400000000000015, -0.041000000000000036, 1.3519999999999999, 0.44700000000000006, 0.47, 1.251, 0.45599999999999996, 1.455, 0.45699999999999985, -0.04700000000000004, 0.42900000000000005, 0.45299999999999985, 0.45999999999999996, 0.46499999999999986, 0.47], "episode_lengths": [300, 20, 11, 12, 21, 15, 33, 48, 30, 9, 55, 29, 15, 16, 12, 12, 51, 13, 37, 38, 19, 15, 17, 9, 14, 17, 19, 300, 13, 17, 22, 15, 15, 15, 13, 12, 15, 23, 17, 28, 25, 136, 12, 10, 14, 16, 15, 75, 26, 17, 10, 13, 13, 13, 10, 18, 14, 13, 14, 20, 89, 11, 9, 22, 12, 9, 31, 9, 25, 10, 22, 34, 19, 12, 13, 15, 10, 16, 66, 14, 12, 12, 13, 11, 25, 12, 26, 300, 14, 9, 42, 19, 10, 11, 15, 48, 29, 21, 10, 10, 11, 8, 32, 12, 28, 12, 11, 26, 11, 25, 19, 15, 16, 9, 12, 16, 7, 15, 22, 16, 13, 17, 20, 15, 8, 27, 13, 47, 17, 10, 77, 14, 15, 14, 15, 23, 15, 12, 11, 10], "policy_red_0_reward": [-0.015000000000000006, 1.44, 1.467, 1.464, 1.4369999999999998, 1.455, 0.9, 1.3559999999999999, 1.4100000000000001, 1.4729999999999999, -0.5, 0.91, 1.455, 1.452, 1.464, 1.464, 1.345, 1.46, 0.888, -0.5, 1.443, 1.455, 1.4489999999999998, 1.4729999999999999, 1.4569999999999999, -1.001, 1.443, 0.493, 1.4609999999999999, 1.448, 1.434, 1.455, 1.455, 1.455, 1.4609999999999999, 1.464, 1.455, 1.431, 1.448, -1.0, 0.924, 1.088, 1.464, 1.47, 1.458, 1.452, 1.455, 1.2690000000000001, 1.4220000000000002, 1.4489999999999998, 1.47, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.47, 1.446, 1.458, 1.4609999999999999, 1.458, 1.44, 1.233, 1.467, 1.4729999999999999, 1.4329999999999998, 1.464, 1.4729999999999999, 1.407, 0.972, 1.425, 1.47, 1.434, 1.3980000000000001, 1.443, 1.464, 1.4609999999999999, 1.455, 0.968, 1.452, 0.802, 1.458, 1.464, 1.464, 1.4609999999999999, 1.467, 1.423, 1.464, 1.4220000000000002, -0.013000000000000005, 1.458, 1.4729999999999999, 0.869, 1.4409999999999998, 1.47, 1.467, 1.455, 1.3559999999999999, 1.411, 1.4369999999999998, 1.47, 1.47, 1.467, 1.476, 1.404, 1.464, 1.416, 1.464, -1.0, 0.909, 1.467, 1.425, 1.443, 0.955, 1.452, 1.4729999999999999, 1.464, 1.452, 0.979, 1.455, 1.432, 1.452, 1.4609999999999999, 1.4489999999999998, 0.939, 1.455, 1.476, 1.419, 0.961, 1.359, 1.4489999999999998, 1.47, 1.263, 1.458, 1.455, 1.458, 0.954, 1.431, 1.455, 1.464, 1.467, 1.47], "policy_blue_0_reward": [-0.04000000000000003, -0.003, -1.002, -1.002, -1.0019999999999998, -1.001, -1.005, -0.007, -0.002, -1.001, 0.825, -1.003, -1.003, -1.003, -1.003, -1.002, -0.005, -1.0, -1.004, 0.877, -0.002, -1.001, -0.002, -1.002, -1.0, 0.949, -0.501, 0.46699999999999997, -1.002, -1.002, -1.004, -1.003, 0.499, -1.003, -1.003, -1.003, -0.001, -1.004, -0.004, 0.916, -1.002, -0.01800000000000001, -1.0019999999999998, -1.001, -0.003, -0.002, -0.002, -0.011000000000000003, -1.003, -0.001, -1.001, -0.001, -1.001, -0.001, -1.0, -1.003, -1.003, 0.0, -0.001, -0.001, -1.013, -1.0, -1.0, -0.002, -1.0, -1.0019999999999998, -0.007, -1.003, -1.002, -0.5019999999999999, -1.004, -0.005, -0.004, -0.5, -1.001, 0.0, -1.0019999999999998, -1.003, -1.011, -1.0019999999999998, -1.003, -1.002, -0.002, -1.004, -1.005, -1.001, -0.003, -0.05400000000000004, -1.0, -1.001, -1.004, -1.002, -1.001, -1.002, -1.0, -1.006, -0.005, -1.005, -1.002, -1.001, -1.002, -1.0, -0.002, -1.0, -1.001, -1.001, 0.966, -1.001, -1.0, -0.003, -1.004, -1.005, 0.499, -1.002, -1.002, -0.001, -1.0, -1.0, -1.001, -1.001, -1.003, 0.498, -1.0059999999999998, -1.001, -1.0, -1.005, -1.002, -0.007, -1.002, -1.0, -0.012000000000000004, -1.002, 0.0, -1.001, -1.001, -1.002, -1.002, -1.0039999999999998, -1.002, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24696041510304054, "mean_inference_ms": 1.4755342554838753, "mean_action_processing_ms": 0.06304701337022078, "mean_env_wait_ms": 0.0889261700089006, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.018964920725141252, "StateBufferConnector_ms": 0.0014910527638026647, "ViewRequirementAgentConnector_ms": 0.031225340706961497}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000, "num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.65045043339597, "num_env_steps_trained_throughput_per_sec": 102.65045043339597, "timesteps_total": 240000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 480000, "timers": {"training_iteration_time_ms": 38952.731, "sample_time_ms": 7560.787, "learn_time_ms": 31374.246, "learn_throughput": 127.493, "synch_weights_time_ms": 17.192}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 240000, "num_agent_steps_sampled": 480000, "num_agent_steps_trained": 480000}, "done": false, "episodes_total": 7511, "training_iteration": 60, "trial_id": "d67e4_00000", "date": "2023-09-20_22-48-16", "timestamp": 1695264496, "time_this_iter_s": 38.97322487831116, "time_total_s": 2334.5766117572784, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d0888b0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2334.5766117572784, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 33.8375, "ram_util_percent": 49.482142857142854}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.3, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6571428571428571, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02142857142857143, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6571428571428571, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.007142857142857143, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.02142857142857143, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6571428571428571, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02142857142857143, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1896676742161314, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011511542182233825, "policy_loss": -0.016932541439746273, "vf_loss": 0.005066183906941054, "vf_explained_var": 0.847650614567101, "kl": 0.007346609018339393, "entropy": 0.41806736181800563, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 58080.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "sampler_results": {"episode_reward_max": 1.959, "episode_reward_min": -0.30699999999999994, "episode_reward_mean": 0.7275571428571428, "episode_len_mean": 32.4, "episode_media": {}, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -0.503, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.967}, "policy_reward_mean": {"red_0": 1.3259999999999998, "blue_0": -0.598442857142857}, "custom_metrics": {"red_0/door_open_done_mean": 0.3, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6571428571428571, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02142857142857143, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6571428571428571, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.007142857142857143, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 1, "blue_0/eliminated_opponents_done_mean": 0.02142857142857143, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6571428571428571, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02142857142857143, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46599999999999997, 1.446, 0.44799999999999995, 0.4159999999999999, 0.45999999999999996, 1.443, 0.359, 1.4529999999999998, 0.40700000000000003, 0.42200000000000015, 0.45500000000000007, 0.45999999999999996, 0.44900000000000007, 0.46599999999999997, 1.4420000000000002, 0.45399999999999996, -0.046000000000000034, 0.4650000000000001, 0.4590000000000001, 0.46399999999999997, 0.9219999999999999, 0.4620000000000002, 1.45, -0.038999999999999924, 1.4569999999999999, 0.45399999999999996, 0.45299999999999996, 1.409, 0.4630000000000001, 0.4630000000000001, 0.18699999999999983, 1.4580000000000002, 1.436, 0.389, 0.45699999999999985, 1.422, 1.438, 1.451, -0.03200000000000003, 0.46599999999999997, 0.44099999999999984, 1.4529999999999998, 1.458, 1.459, 0.41700000000000004, 0.7650000000000001, 0.45599999999999996, 0.45699999999999985, 0.45599999999999996, 0.4710000000000001, 0.45699999999999985, 1.4329999999999998, 0.3769999999999998, -0.28800000000000003, 1.434, 0.45500000000000007, 0.43399999999999994, 0.46699999999999997, 0.27300000000000013, 0.46599999999999997, 0.45500000000000007, 0.46199999999999997, 1.45, 1.45, 1.456, 0.46399999999999997, 0.3820000000000001, 0.46399999999999997, 0.46499999999999986, 1.438, 1.4500000000000002, -0.28300000000000003, 0.6099999999999999, 1.444, 0.44099999999999984, 0.46399999999999997, 0.9550000000000001, 0.12400000000000011, 1.459, 0.4630000000000001, 0.46599999999999997, 0.35599999999999987, 0.46399999999999997, 1.4420000000000002, 0.4159999999999999, 0.45399999999999996, 0.4670000000000001, -0.03600000000000003, -0.04500000000000003, 0.45599999999999996, 0.42900000000000005, 0.45999999999999996, 0.4590000000000001, 0.4710000000000001, 1.049, 1.4609999999999999, -0.122, 1.451, 0.46099999999999985, 1.959, 0.43900000000000006, 0.45399999999999996, 1.838, 1.061, 0.41300000000000003, 0.46099999999999985, 1.444, 1.36, 0.45999999999999996, 1.9300000000000002, 0.46899999999999986, 1.4449999999999998, 0.44599999999999995, 0.46499999999999986, 0.2749999999999999, 0.41300000000000003, 0.9670000000000001, 1.435, 0.44999999999999996, 0.45100000000000007, 0.44799999999999995, 0.383, 0.45199999999999996, 0.4670000000000001, 0.44099999999999984, 1.947, -0.30699999999999994, 0.4630000000000001, 0.46899999999999986, 0.46599999999999997, 0.4670000000000001, 0.46499999999999986, 1.4329999999999998, 1.4409999999999998, 1.4460000000000002, -0.061000000000000054, 1.4100000000000001, 1.421, 1.447, 0.45799999999999996], "episode_lengths": [11, 17, 17, 25, 13, 18, 44, 15, 27, 25, 14, 13, 16, 11, 18, 15, 300, 11, 13, 11, 24, 11, 16, 12, 13, 14, 15, 28, 12, 12, 96, 13, 21, 35, 14, 24, 20, 16, 10, 11, 19, 15, 13, 13, 26, 75, 14, 14, 14, 9, 14, 20, 198, 250, 21, 14, 21, 11, 68, 11, 14, 11, 16, 16, 14, 12, 37, 11, 11, 20, 16, 87, 123, 18, 18, 12, 14, 114, 13, 11, 11, 45, 11, 18, 26, 14, 11, 12, 300, 14, 23, 13, 13, 9, 294, 13, 197, 16, 13, 13, 19, 14, 51, 140, 26, 13, 18, 42, 12, 23, 10, 18, 17, 11, 67, 28, 10, 21, 15, 15, 16, 36, 15, 11, 19, 17, 96, 11, 10, 11, 11, 11, 21, 18, 16, 19, 28, 25, 17, 13], "policy_red_0_reward": [1.467, 1.4489999999999998, 1.4489999999999998, 1.4220000000000002, 1.4609999999999999, 1.446, -0.503, 1.455, 1.413, 1.424, 1.458, 1.4609999999999999, 1.452, 1.467, 1.4449999999999998, 1.455, -0.003, 1.467, 1.4609999999999999, 1.467, 1.428, 1.467, 1.452, 0.964, 1.4609999999999999, 1.4569999999999999, -0.5, 1.416, 1.464, 1.464, 1.2069999999999999, 1.4609999999999999, 1.4369999999999998, 1.395, 1.458, 1.428, 1.44, 1.452, 0.97, 1.467, 1.443, 1.455, 1.4609999999999999, 1.4609999999999999, 1.4220000000000002, 1.275, 1.458, 1.458, 1.458, 1.4729999999999999, 1.458, 1.438, 0.9029999999999999, 0.749, 1.4369999999999998, 1.458, 1.434, -0.5, 0.785, 1.467, 1.458, 1.467, 1.452, 1.451, 1.458, 1.464, 1.388, 1.467, 1.467, 1.44, 1.452, 0.734, 1.1280000000000001, 1.446, 1.446, 1.464, 1.458, 1.137, 1.4609999999999999, 1.467, 1.467, 1.362, 1.467, 1.446, 1.421, 1.458, 1.467, 0.964, -0.004, 1.458, 1.431, 1.4609999999999999, 1.4609999999999999, 1.4729999999999999, 0.47, 1.4609999999999999, 0.909, 1.452, 1.4609999999999999, 1.4609999999999999, 1.443, 1.458, 1.346, 1.08, 1.421, 1.4609999999999999, 1.446, 1.371, 1.464, 1.431, 1.47, 1.446, 1.4489999999999998, 1.467, 1.2839999999999998, 1.415, 1.47, 1.4369999999999998, 1.454, 1.455, 1.4489999999999998, 1.392, 1.454, 1.467, 1.443, 1.4489999999999998, 0.709, 1.467, 1.47, 1.467, 1.467, 1.467, 1.4369999999999998, 1.446, 1.452, 0.942, 1.4140000000000001, 1.425, 1.4489999999999998, 1.4609999999999999], "policy_blue_0_reward": [-1.001, -0.003, -1.001, -1.006, -1.001, -0.003, 0.862, -0.002, -1.006, -1.002, -1.003, -1.001, -1.003, -1.001, -0.003, -1.001, -0.04300000000000003, -1.0019999999999998, -1.002, -1.003, -0.506, -1.005, -0.002, -1.003, -0.004, -1.003, 0.953, -0.007, -1.001, -1.001, -1.02, -0.003, -0.001, -1.006, -1.001, -0.006, -0.002, -0.001, -1.002, -1.001, -1.002, -0.002, -0.003, -0.002, -1.005, -0.51, -1.0019999999999998, -1.001, -1.002, -1.002, -1.001, -0.005, -0.526, -1.037, -0.003, -1.003, -1.0, 0.967, -0.512, -1.001, -1.003, -1.005, -0.002, -0.001, -0.002, -1.0, -1.0059999999999998, -1.003, -1.002, -0.002, -0.002, -1.017, -0.518, -0.002, -1.005, -1.0, -0.503, -1.013, -0.002, -1.0039999999999998, -1.001, -1.006, -1.003, -0.004, -1.005, -1.004, -1.0, -1.0, -0.04100000000000003, -1.002, -1.002, -1.001, -1.0019999999999998, -1.002, 0.579, 0.0, -1.031, -0.001, -1.0, 0.498, -1.004, -1.004, 0.492, -0.01900000000000001, -1.008, -1.0, -0.002, -0.011000000000000003, -1.004, 0.499, -1.001, -0.001, -1.003, -1.002, -1.009, -1.002, -0.503, -0.002, -1.004, -1.004, -1.001, -1.009, -1.002, -1.0, -1.002, 0.498, -1.0159999999999998, -1.004, -1.001, -1.001, -1.0, -1.002, -0.004, -0.005, -0.006, -1.003, -0.004, -0.004, -0.002, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24710194610213984, "mean_inference_ms": 1.4760478376875317, "mean_action_processing_ms": 0.06305829067491861, "mean_env_wait_ms": 0.08892704730082536, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01941493579319545, "StateBufferConnector_ms": 0.0014444759913853236, "ViewRequirementAgentConnector_ms": 0.03112043653215681}}, "episode_reward_max": 1.959, "episode_reward_min": -0.30699999999999994, "episode_reward_mean": 0.7275571428571428, "episode_len_mean": 32.4, "episodes_this_iter": 140, "policy_reward_min": {"red_0": -0.503, "blue_0": -1.037}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.967}, "policy_reward_mean": {"red_0": 1.3259999999999998, "blue_0": -0.598442857142857}, "hist_stats": {"episode_reward": [0.46599999999999997, 1.446, 0.44799999999999995, 0.4159999999999999, 0.45999999999999996, 1.443, 0.359, 1.4529999999999998, 0.40700000000000003, 0.42200000000000015, 0.45500000000000007, 0.45999999999999996, 0.44900000000000007, 0.46599999999999997, 1.4420000000000002, 0.45399999999999996, -0.046000000000000034, 0.4650000000000001, 0.4590000000000001, 0.46399999999999997, 0.9219999999999999, 0.4620000000000002, 1.45, -0.038999999999999924, 1.4569999999999999, 0.45399999999999996, 0.45299999999999996, 1.409, 0.4630000000000001, 0.4630000000000001, 0.18699999999999983, 1.4580000000000002, 1.436, 0.389, 0.45699999999999985, 1.422, 1.438, 1.451, -0.03200000000000003, 0.46599999999999997, 0.44099999999999984, 1.4529999999999998, 1.458, 1.459, 0.41700000000000004, 0.7650000000000001, 0.45599999999999996, 0.45699999999999985, 0.45599999999999996, 0.4710000000000001, 0.45699999999999985, 1.4329999999999998, 0.3769999999999998, -0.28800000000000003, 1.434, 0.45500000000000007, 0.43399999999999994, 0.46699999999999997, 0.27300000000000013, 0.46599999999999997, 0.45500000000000007, 0.46199999999999997, 1.45, 1.45, 1.456, 0.46399999999999997, 0.3820000000000001, 0.46399999999999997, 0.46499999999999986, 1.438, 1.4500000000000002, -0.28300000000000003, 0.6099999999999999, 1.444, 0.44099999999999984, 0.46399999999999997, 0.9550000000000001, 0.12400000000000011, 1.459, 0.4630000000000001, 0.46599999999999997, 0.35599999999999987, 0.46399999999999997, 1.4420000000000002, 0.4159999999999999, 0.45399999999999996, 0.4670000000000001, -0.03600000000000003, -0.04500000000000003, 0.45599999999999996, 0.42900000000000005, 0.45999999999999996, 0.4590000000000001, 0.4710000000000001, 1.049, 1.4609999999999999, -0.122, 1.451, 0.46099999999999985, 1.959, 0.43900000000000006, 0.45399999999999996, 1.838, 1.061, 0.41300000000000003, 0.46099999999999985, 1.444, 1.36, 0.45999999999999996, 1.9300000000000002, 0.46899999999999986, 1.4449999999999998, 0.44599999999999995, 0.46499999999999986, 0.2749999999999999, 0.41300000000000003, 0.9670000000000001, 1.435, 0.44999999999999996, 0.45100000000000007, 0.44799999999999995, 0.383, 0.45199999999999996, 0.4670000000000001, 0.44099999999999984, 1.947, -0.30699999999999994, 0.4630000000000001, 0.46899999999999986, 0.46599999999999997, 0.4670000000000001, 0.46499999999999986, 1.4329999999999998, 1.4409999999999998, 1.4460000000000002, -0.061000000000000054, 1.4100000000000001, 1.421, 1.447, 0.45799999999999996], "episode_lengths": [11, 17, 17, 25, 13, 18, 44, 15, 27, 25, 14, 13, 16, 11, 18, 15, 300, 11, 13, 11, 24, 11, 16, 12, 13, 14, 15, 28, 12, 12, 96, 13, 21, 35, 14, 24, 20, 16, 10, 11, 19, 15, 13, 13, 26, 75, 14, 14, 14, 9, 14, 20, 198, 250, 21, 14, 21, 11, 68, 11, 14, 11, 16, 16, 14, 12, 37, 11, 11, 20, 16, 87, 123, 18, 18, 12, 14, 114, 13, 11, 11, 45, 11, 18, 26, 14, 11, 12, 300, 14, 23, 13, 13, 9, 294, 13, 197, 16, 13, 13, 19, 14, 51, 140, 26, 13, 18, 42, 12, 23, 10, 18, 17, 11, 67, 28, 10, 21, 15, 15, 16, 36, 15, 11, 19, 17, 96, 11, 10, 11, 11, 11, 21, 18, 16, 19, 28, 25, 17, 13], "policy_red_0_reward": [1.467, 1.4489999999999998, 1.4489999999999998, 1.4220000000000002, 1.4609999999999999, 1.446, -0.503, 1.455, 1.413, 1.424, 1.458, 1.4609999999999999, 1.452, 1.467, 1.4449999999999998, 1.455, -0.003, 1.467, 1.4609999999999999, 1.467, 1.428, 1.467, 1.452, 0.964, 1.4609999999999999, 1.4569999999999999, -0.5, 1.416, 1.464, 1.464, 1.2069999999999999, 1.4609999999999999, 1.4369999999999998, 1.395, 1.458, 1.428, 1.44, 1.452, 0.97, 1.467, 1.443, 1.455, 1.4609999999999999, 1.4609999999999999, 1.4220000000000002, 1.275, 1.458, 1.458, 1.458, 1.4729999999999999, 1.458, 1.438, 0.9029999999999999, 0.749, 1.4369999999999998, 1.458, 1.434, -0.5, 0.785, 1.467, 1.458, 1.467, 1.452, 1.451, 1.458, 1.464, 1.388, 1.467, 1.467, 1.44, 1.452, 0.734, 1.1280000000000001, 1.446, 1.446, 1.464, 1.458, 1.137, 1.4609999999999999, 1.467, 1.467, 1.362, 1.467, 1.446, 1.421, 1.458, 1.467, 0.964, -0.004, 1.458, 1.431, 1.4609999999999999, 1.4609999999999999, 1.4729999999999999, 0.47, 1.4609999999999999, 0.909, 1.452, 1.4609999999999999, 1.4609999999999999, 1.443, 1.458, 1.346, 1.08, 1.421, 1.4609999999999999, 1.446, 1.371, 1.464, 1.431, 1.47, 1.446, 1.4489999999999998, 1.467, 1.2839999999999998, 1.415, 1.47, 1.4369999999999998, 1.454, 1.455, 1.4489999999999998, 1.392, 1.454, 1.467, 1.443, 1.4489999999999998, 0.709, 1.467, 1.47, 1.467, 1.467, 1.467, 1.4369999999999998, 1.446, 1.452, 0.942, 1.4140000000000001, 1.425, 1.4489999999999998, 1.4609999999999999], "policy_blue_0_reward": [-1.001, -0.003, -1.001, -1.006, -1.001, -0.003, 0.862, -0.002, -1.006, -1.002, -1.003, -1.001, -1.003, -1.001, -0.003, -1.001, -0.04300000000000003, -1.0019999999999998, -1.002, -1.003, -0.506, -1.005, -0.002, -1.003, -0.004, -1.003, 0.953, -0.007, -1.001, -1.001, -1.02, -0.003, -0.001, -1.006, -1.001, -0.006, -0.002, -0.001, -1.002, -1.001, -1.002, -0.002, -0.003, -0.002, -1.005, -0.51, -1.0019999999999998, -1.001, -1.002, -1.002, -1.001, -0.005, -0.526, -1.037, -0.003, -1.003, -1.0, 0.967, -0.512, -1.001, -1.003, -1.005, -0.002, -0.001, -0.002, -1.0, -1.0059999999999998, -1.003, -1.002, -0.002, -0.002, -1.017, -0.518, -0.002, -1.005, -1.0, -0.503, -1.013, -0.002, -1.0039999999999998, -1.001, -1.006, -1.003, -0.004, -1.005, -1.004, -1.0, -1.0, -0.04100000000000003, -1.002, -1.002, -1.001, -1.0019999999999998, -1.002, 0.579, 0.0, -1.031, -0.001, -1.0, 0.498, -1.004, -1.004, 0.492, -0.01900000000000001, -1.008, -1.0, -0.002, -0.011000000000000003, -1.004, 0.499, -1.001, -0.001, -1.003, -1.002, -1.009, -1.002, -0.503, -0.002, -1.004, -1.004, -1.001, -1.009, -1.002, -1.0, -1.002, 0.498, -1.0159999999999998, -1.004, -1.001, -1.001, -1.0, -1.002, -0.004, -0.005, -0.006, -1.003, -0.004, -0.004, -0.002, -1.003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24710194610213984, "mean_inference_ms": 1.4760478376875317, "mean_action_processing_ms": 0.06305829067491861, "mean_env_wait_ms": 0.08892704730082536, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.01941493579319545, "StateBufferConnector_ms": 0.0014444759913853236, "ViewRequirementAgentConnector_ms": 0.03112043653215681}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000, "num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.58524262565018, "num_env_steps_trained_throughput_per_sec": 102.58524262565018, "timesteps_total": 244000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 488000, "timers": {"training_iteration_time_ms": 38956.198, "sample_time_ms": 7555.963, "learn_time_ms": 31382.524, "learn_throughput": 127.459, "synch_weights_time_ms": 17.204}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 244000, "num_agent_steps_sampled": 488000, "num_agent_steps_trained": 488000}, "done": false, "episodes_total": 7651, "training_iteration": 61, "trial_id": "d67e4_00000", "date": "2023-09-20_22-48-55", "timestamp": 1695264535, "time_this_iter_s": 38.99818205833435, "time_total_s": 2373.574793815613, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4706b90>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2373.574793815613, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 38.13214285714285, "ram_util_percent": 49.528571428571425}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2641509433962264, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.710691823899371, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.018867924528301886, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.710691823899371, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.018867924528301886, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.710691823899371, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.018867924528301886, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.3322211060673, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.011138973236423528, "policy_loss": -0.01660095422436522, "vf_loss": 0.004820082934384118, "vf_explained_var": 0.8320203201224406, "kl": 0.007672647494925422, "entropy": 0.4007516918393473, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 59040.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "sampler_results": {"episode_reward_max": 1.954, "episode_reward_min": -0.30499999999999994, "episode_reward_mean": 0.6894716981132076, "episode_len_mean": 23.87421383647799, "episode_media": {}, "episodes_this_iter": 159, "policy_reward_min": {"red_0": -0.5099999999999999, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.958}, "policy_reward_mean": {"red_0": 1.350949685534591, "blue_0": -0.6614779874213835}, "custom_metrics": {"red_0/door_open_done_mean": 0.2641509433962264, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.710691823899371, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.018867924528301886, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.710691823899371, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.018867924528301886, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.710691823899371, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.018867924528301886, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.268, 1.448, 1.4409999999999998, 1.451, 0.45300000000000007, 0.4630000000000001, 0.9359999999999999, 0.41800000000000015, 0.46799999999999997, 0.47299999999999986, -0.038000000000000034, 0.46799999999999997, 1.4449999999999998, 1.444, 0.45100000000000007, -0.06300000000000006, 0.42300000000000004, 0.46599999999999997, 0.44300000000000006, 0.45100000000000007, 1.4540000000000002, 0.46799999999999997, 0.46399999999999997, 0.387, 0.371, 0.44399999999999995, 1.423, 0.4670000000000001, 0.43900000000000006, 1.3820000000000001, 0.46599999999999997, -0.09099999999999997, -0.30499999999999994, 1.446, 1.442, 1.935, 1.458, 0.45799999999999996, 0.46399999999999997, 0.44899999999999984, 1.431, 0.45599999999999996, 0.41000000000000014, 0.45999999999999996, 0.47299999999999986, 0.2469999999999999, -0.02400000000000002, 0.45299999999999985, 1.455, 1.946, 0.44300000000000006, 0.43100000000000005, 0.4079999999999999, 0.4630000000000001, 0.45399999999999996, -0.07500000000000007, 0.45399999999999996, 1.451, 0.45799999999999996, 0.44300000000000006, 0.45999999999999996, 1.4449999999999998, 0.46599999999999997, 0.46199999999999997, 0.44099999999999984, 1.45, 0.46099999999999985, 0.43399999999999994, 0.4590000000000001, 0.44399999999999995, 0.43000000000000016, 1.455, 0.4590000000000001, 0.47, 0.45999999999999996, 0.40600000000000014, 1.46, 0.46599999999999997, 0.45199999999999996, 0.4289999999999998, 1.446, 0.355, 0.45699999999999985, 0.9670000000000001, 0.45399999999999996, 0.46899999999999986, 1.454, 0.47299999999999986, 0.45799999999999996, 0.46399999999999997, 0.47, -0.031000000000000028, 0.46499999999999986, 1.85, 0.46599999999999997, 1.4300000000000002, 0.33499999999999996, 0.43100000000000005, 0.44999999999999996, 0.46199999999999997, 0.44099999999999984, 0.97, 0.46799999999999997, 0.4570000000000001, 0.46899999999999986, 0.4670000000000001, -0.04400000000000004, 0.4670000000000001, 0.45699999999999985, 1.8890000000000002, 0.45599999999999996, 0.2549999999999998, 0.46599999999999997, 1.451, -0.07999999999999996, -0.038000000000000034, 0.45699999999999985, 0.4590000000000001, 0.44399999999999995, 1.455, 1.3820000000000001, 0.45299999999999985, -0.03400000000000003, 1.4569999999999999, 0.46799999999999997, 0.4670000000000001, 0.40100000000000013, 0.4590000000000001, 0.45599999999999996, 0.4630000000000001, 0.395, 0.46799999999999997, 0.472, 1.455, 1.4369999999999998, 1.451, 1.954, 0.45599999999999996, 0.4790000000000001, 0.45599999999999996, 0.44499999999999984, 0.44499999999999984, -0.04999999999999993, 1.404, 1.458, 0.45799999999999996, 1.455, 0.46899999999999986, 0.46499999999999986, 1.447, 0.44799999999999995, 1.412, 1.46, 1.383, 1.451, 0.45500000000000007, 1.371, 0.46899999999999986, 0.45500000000000007], "episode_lengths": [233, 16, 19, 16, 14, 12, 21, 25, 10, 9, 12, 10, 16, 18, 15, 20, 25, 11, 18, 16, 15, 10, 12, 32, 39, 18, 24, 11, 19, 34, 11, 29, 96, 17, 19, 19, 13, 13, 11, 16, 22, 14, 28, 13, 9, 75, 8, 15, 15, 18, 18, 21, 29, 12, 14, 178, 15, 16, 13, 17, 13, 17, 11, 12, 19, 16, 12, 21, 13, 18, 23, 14, 13, 10, 13, 187, 13, 11, 15, 21, 17, 44, 14, 11, 15, 10, 15, 9, 14, 12, 10, 10, 11, 48, 11, 23, 53, 176, 15, 12, 19, 10, 10, 13, 10, 10, 14, 11, 14, 36, 14, 300, 11, 15, 23, 12, 13, 13, 18, 15, 38, 15, 11, 14, 10, 11, 28, 13, 14, 12, 34, 10, 9, 15, 20, 16, 15, 14, 7, 14, 18, 17, 16, 31, 14, 14, 15, 10, 11, 17, 17, 27, 13, 34, 14, 15, 41, 10, 15], "policy_red_0_reward": [0.266, 1.452, 1.443, 1.452, 1.458, 1.464, 1.4369999999999998, 1.425, 1.47, 1.4729999999999999, 0.962, 1.47, 1.452, 1.446, 1.455, 0.938, 1.425, 1.467, 1.446, 1.452, 1.455, 1.47, 1.464, 1.393, 1.377, 1.446, 1.427, 1.467, 1.443, 1.395, 1.467, 0.913, 0.703, 1.4489999999999998, 1.443, 1.442, 1.4609999999999999, 1.4609999999999999, 1.467, 1.452, 1.434, 1.458, 1.415, 1.4609999999999999, 1.4729999999999999, 1.2610000000000001, 0.976, 1.455, 1.455, 1.446, 1.4449999999999998, 1.4369999999999998, 1.413, 1.464, 1.458, 0.952, 1.455, 1.452, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.4489999999999998, 1.467, 1.464, 1.443, 1.452, 1.464, 1.4369999999999998, 1.4609999999999999, 1.446, 1.431, 1.458, 1.4609999999999999, 1.47, 1.4609999999999999, 0.9390000000000001, 1.4609999999999999, 1.467, 1.455, 1.4329999999999998, 1.4489999999999998, 1.3599999999999999, 1.458, 1.467, 1.455, 1.47, 1.455, 1.4729999999999999, 1.458, 1.464, 1.47, 0.97, 1.467, 1.3559999999999999, 1.467, 1.431, 1.341, 0.95, 1.455, 1.464, 1.443, 1.47, 1.47, 1.4609999999999999, 1.47, 1.47, 0.958, 1.467, 1.458, 1.392, 1.458, 0.2929999999999998, 1.467, 1.455, 0.922, 0.964, 1.4609999999999999, 1.4609999999999999, 1.446, 1.455, 1.385, 1.455, 0.967, 1.458, 1.47, 1.467, -0.5099999999999999, 1.4609999999999999, 1.458, 1.464, 1.3980000000000001, 1.47, 1.4729999999999999, 1.455, 1.438, 1.452, 1.455, -0.5, 1.479, 1.458, 1.446, 1.4489999999999998, 0.952, 1.407, 1.458, -0.5, 1.455, 1.47, 1.467, 1.4489999999999998, 1.4489999999999998, 1.417, 1.4609999999999999, 1.387, 1.458, 1.455, 1.374, 1.47, 1.455], "policy_blue_0_reward": [-0.534, -0.004, -0.002, -0.001, -1.005, -1.001, -0.501, -1.007, -1.002, -1.0, -1.0, -1.002, -0.007, -0.002, -1.004, -1.001, -1.002, -1.001, -1.003, -1.001, -0.001, -1.002, -1.0, -1.0059999999999998, -1.006, -1.002, -0.004, -1.0, -1.004, -0.013000000000000005, -1.001, -1.004, -1.0079999999999998, -0.003, -0.001, 0.493, -0.003, -1.003, -1.003, -1.003, -0.003, -1.002, -1.005, -1.001, -1.0, -1.014, -1.0, -1.002, 0.0, 0.5, -1.002, -1.006, -1.005, -1.001, -1.004, -1.027, -1.001, -0.001, -1.003, -1.006, -1.001, -0.004, -1.001, -1.002, -1.002, -0.002, -1.003, -1.003, -1.002, -1.002, -1.001, -0.003, -1.002, -1.0, -1.001, -0.5329999999999999, -0.001, -1.001, -1.003, -1.004, -0.003, -1.005, -1.001, -0.5, -1.001, -1.001, -0.001, -1.0, -1.0, -1.0, -1.0, -1.001, -1.002, 0.494, -1.001, -0.001, -1.006, -0.519, -1.005, -1.002, -1.002, -0.5, -1.0019999999999998, -1.0039999999999998, -1.001, -1.003, -1.002, -1.0, -1.001, 0.497, -1.002, -0.03800000000000003, -1.001, -0.004, -1.002, -1.002, -1.004, -1.002, -1.002, 0.0, -0.003, -1.002, -1.001, -0.001, -1.002, -1.0, 0.911, -1.002, -1.002, -1.001, -1.003, -1.002, -1.001, 0.0, -0.001, -0.001, 0.499, 0.956, -1.0, -1.002, -1.001, -1.004, -1.0019999999999998, -0.003, 0.0, 0.958, 0.0, -1.001, -1.002, -0.002, -1.001, -0.005, -0.001, -0.004, -0.007, -1.0, -0.003, -1.001, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24726769843701998, "mean_inference_ms": 1.4767572954236021, "mean_action_processing_ms": 0.06309247060371997, "mean_env_wait_ms": 0.08894432474604817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022556047019718577, "StateBufferConnector_ms": 0.001523929571955459, "ViewRequirementAgentConnector_ms": 0.032997806117219745}}, "episode_reward_max": 1.954, "episode_reward_min": -0.30499999999999994, "episode_reward_mean": 0.6894716981132076, "episode_len_mean": 23.87421383647799, "episodes_this_iter": 159, "policy_reward_min": {"red_0": -0.5099999999999999, "blue_0": -1.027}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.958}, "policy_reward_mean": {"red_0": 1.350949685534591, "blue_0": -0.6614779874213835}, "hist_stats": {"episode_reward": [-0.268, 1.448, 1.4409999999999998, 1.451, 0.45300000000000007, 0.4630000000000001, 0.9359999999999999, 0.41800000000000015, 0.46799999999999997, 0.47299999999999986, -0.038000000000000034, 0.46799999999999997, 1.4449999999999998, 1.444, 0.45100000000000007, -0.06300000000000006, 0.42300000000000004, 0.46599999999999997, 0.44300000000000006, 0.45100000000000007, 1.4540000000000002, 0.46799999999999997, 0.46399999999999997, 0.387, 0.371, 0.44399999999999995, 1.423, 0.4670000000000001, 0.43900000000000006, 1.3820000000000001, 0.46599999999999997, -0.09099999999999997, -0.30499999999999994, 1.446, 1.442, 1.935, 1.458, 0.45799999999999996, 0.46399999999999997, 0.44899999999999984, 1.431, 0.45599999999999996, 0.41000000000000014, 0.45999999999999996, 0.47299999999999986, 0.2469999999999999, -0.02400000000000002, 0.45299999999999985, 1.455, 1.946, 0.44300000000000006, 0.43100000000000005, 0.4079999999999999, 0.4630000000000001, 0.45399999999999996, -0.07500000000000007, 0.45399999999999996, 1.451, 0.45799999999999996, 0.44300000000000006, 0.45999999999999996, 1.4449999999999998, 0.46599999999999997, 0.46199999999999997, 0.44099999999999984, 1.45, 0.46099999999999985, 0.43399999999999994, 0.4590000000000001, 0.44399999999999995, 0.43000000000000016, 1.455, 0.4590000000000001, 0.47, 0.45999999999999996, 0.40600000000000014, 1.46, 0.46599999999999997, 0.45199999999999996, 0.4289999999999998, 1.446, 0.355, 0.45699999999999985, 0.9670000000000001, 0.45399999999999996, 0.46899999999999986, 1.454, 0.47299999999999986, 0.45799999999999996, 0.46399999999999997, 0.47, -0.031000000000000028, 0.46499999999999986, 1.85, 0.46599999999999997, 1.4300000000000002, 0.33499999999999996, 0.43100000000000005, 0.44999999999999996, 0.46199999999999997, 0.44099999999999984, 0.97, 0.46799999999999997, 0.4570000000000001, 0.46899999999999986, 0.4670000000000001, -0.04400000000000004, 0.4670000000000001, 0.45699999999999985, 1.8890000000000002, 0.45599999999999996, 0.2549999999999998, 0.46599999999999997, 1.451, -0.07999999999999996, -0.038000000000000034, 0.45699999999999985, 0.4590000000000001, 0.44399999999999995, 1.455, 1.3820000000000001, 0.45299999999999985, -0.03400000000000003, 1.4569999999999999, 0.46799999999999997, 0.4670000000000001, 0.40100000000000013, 0.4590000000000001, 0.45599999999999996, 0.4630000000000001, 0.395, 0.46799999999999997, 0.472, 1.455, 1.4369999999999998, 1.451, 1.954, 0.45599999999999996, 0.4790000000000001, 0.45599999999999996, 0.44499999999999984, 0.44499999999999984, -0.04999999999999993, 1.404, 1.458, 0.45799999999999996, 1.455, 0.46899999999999986, 0.46499999999999986, 1.447, 0.44799999999999995, 1.412, 1.46, 1.383, 1.451, 0.45500000000000007, 1.371, 0.46899999999999986, 0.45500000000000007], "episode_lengths": [233, 16, 19, 16, 14, 12, 21, 25, 10, 9, 12, 10, 16, 18, 15, 20, 25, 11, 18, 16, 15, 10, 12, 32, 39, 18, 24, 11, 19, 34, 11, 29, 96, 17, 19, 19, 13, 13, 11, 16, 22, 14, 28, 13, 9, 75, 8, 15, 15, 18, 18, 21, 29, 12, 14, 178, 15, 16, 13, 17, 13, 17, 11, 12, 19, 16, 12, 21, 13, 18, 23, 14, 13, 10, 13, 187, 13, 11, 15, 21, 17, 44, 14, 11, 15, 10, 15, 9, 14, 12, 10, 10, 11, 48, 11, 23, 53, 176, 15, 12, 19, 10, 10, 13, 10, 10, 14, 11, 14, 36, 14, 300, 11, 15, 23, 12, 13, 13, 18, 15, 38, 15, 11, 14, 10, 11, 28, 13, 14, 12, 34, 10, 9, 15, 20, 16, 15, 14, 7, 14, 18, 17, 16, 31, 14, 14, 15, 10, 11, 17, 17, 27, 13, 34, 14, 15, 41, 10, 15], "policy_red_0_reward": [0.266, 1.452, 1.443, 1.452, 1.458, 1.464, 1.4369999999999998, 1.425, 1.47, 1.4729999999999999, 0.962, 1.47, 1.452, 1.446, 1.455, 0.938, 1.425, 1.467, 1.446, 1.452, 1.455, 1.47, 1.464, 1.393, 1.377, 1.446, 1.427, 1.467, 1.443, 1.395, 1.467, 0.913, 0.703, 1.4489999999999998, 1.443, 1.442, 1.4609999999999999, 1.4609999999999999, 1.467, 1.452, 1.434, 1.458, 1.415, 1.4609999999999999, 1.4729999999999999, 1.2610000000000001, 0.976, 1.455, 1.455, 1.446, 1.4449999999999998, 1.4369999999999998, 1.413, 1.464, 1.458, 0.952, 1.455, 1.452, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.4489999999999998, 1.467, 1.464, 1.443, 1.452, 1.464, 1.4369999999999998, 1.4609999999999999, 1.446, 1.431, 1.458, 1.4609999999999999, 1.47, 1.4609999999999999, 0.9390000000000001, 1.4609999999999999, 1.467, 1.455, 1.4329999999999998, 1.4489999999999998, 1.3599999999999999, 1.458, 1.467, 1.455, 1.47, 1.455, 1.4729999999999999, 1.458, 1.464, 1.47, 0.97, 1.467, 1.3559999999999999, 1.467, 1.431, 1.341, 0.95, 1.455, 1.464, 1.443, 1.47, 1.47, 1.4609999999999999, 1.47, 1.47, 0.958, 1.467, 1.458, 1.392, 1.458, 0.2929999999999998, 1.467, 1.455, 0.922, 0.964, 1.4609999999999999, 1.4609999999999999, 1.446, 1.455, 1.385, 1.455, 0.967, 1.458, 1.47, 1.467, -0.5099999999999999, 1.4609999999999999, 1.458, 1.464, 1.3980000000000001, 1.47, 1.4729999999999999, 1.455, 1.438, 1.452, 1.455, -0.5, 1.479, 1.458, 1.446, 1.4489999999999998, 0.952, 1.407, 1.458, -0.5, 1.455, 1.47, 1.467, 1.4489999999999998, 1.4489999999999998, 1.417, 1.4609999999999999, 1.387, 1.458, 1.455, 1.374, 1.47, 1.455], "policy_blue_0_reward": [-0.534, -0.004, -0.002, -0.001, -1.005, -1.001, -0.501, -1.007, -1.002, -1.0, -1.0, -1.002, -0.007, -0.002, -1.004, -1.001, -1.002, -1.001, -1.003, -1.001, -0.001, -1.002, -1.0, -1.0059999999999998, -1.006, -1.002, -0.004, -1.0, -1.004, -0.013000000000000005, -1.001, -1.004, -1.0079999999999998, -0.003, -0.001, 0.493, -0.003, -1.003, -1.003, -1.003, -0.003, -1.002, -1.005, -1.001, -1.0, -1.014, -1.0, -1.002, 0.0, 0.5, -1.002, -1.006, -1.005, -1.001, -1.004, -1.027, -1.001, -0.001, -1.003, -1.006, -1.001, -0.004, -1.001, -1.002, -1.002, -0.002, -1.003, -1.003, -1.002, -1.002, -1.001, -0.003, -1.002, -1.0, -1.001, -0.5329999999999999, -0.001, -1.001, -1.003, -1.004, -0.003, -1.005, -1.001, -0.5, -1.001, -1.001, -0.001, -1.0, -1.0, -1.0, -1.0, -1.001, -1.002, 0.494, -1.001, -0.001, -1.006, -0.519, -1.005, -1.002, -1.002, -0.5, -1.0019999999999998, -1.0039999999999998, -1.001, -1.003, -1.002, -1.0, -1.001, 0.497, -1.002, -0.03800000000000003, -1.001, -0.004, -1.002, -1.002, -1.004, -1.002, -1.002, 0.0, -0.003, -1.002, -1.001, -0.001, -1.002, -1.0, 0.911, -1.002, -1.002, -1.001, -1.003, -1.002, -1.001, 0.0, -0.001, -0.001, 0.499, 0.956, -1.0, -1.002, -1.001, -1.004, -1.0019999999999998, -0.003, 0.0, 0.958, 0.0, -1.001, -1.002, -0.002, -1.001, -0.005, -0.001, -0.004, -0.007, -1.0, -0.003, -1.001, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24726769843701998, "mean_inference_ms": 1.4767572954236021, "mean_action_processing_ms": 0.06309247060371997, "mean_env_wait_ms": 0.08894432474604817, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022556047019718577, "StateBufferConnector_ms": 0.001523929571955459, "ViewRequirementAgentConnector_ms": 0.032997806117219745}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000, "num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.29740102643514, "num_env_steps_trained_throughput_per_sec": 102.29740102643514, "timesteps_total": 248000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 496000, "timers": {"training_iteration_time_ms": 38975.324, "sample_time_ms": 7578.242, "learn_time_ms": 31379.434, "learn_throughput": 127.472, "synch_weights_time_ms": 17.139}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 248000, "num_agent_steps_sampled": 496000, "num_agent_steps_trained": 496000}, "done": false, "episodes_total": 7810, "training_iteration": 62, "trial_id": "d67e4_00000", "date": "2023-09-20_22-49-35", "timestamp": 1695264575, "time_this_iter_s": 39.10833787918091, "time_total_s": 2412.6831316947937, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687bbe0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2412.6831316947937, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 35.5875, "ram_util_percent": 49.755357142857136}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.18253968253968253, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7142857142857143, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07142857142857142, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7142857142857143, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.07142857142857142, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7142857142857143, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07142857142857142, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.820306706863145, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009891746935682021, "policy_loss": -0.01627035584533587, "vf_loss": 0.0071176680241478605, "vf_explained_var": 0.7764541067183017, "kl": 0.007360310880448782, "entropy": 0.4923654501326382, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60000.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "sampler_results": {"episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.5050000000000001, "episode_reward_mean": 0.5687063492063491, "episode_len_mean": 32.357142857142854, "episode_media": {}, "episodes_this_iter": 126, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.028}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.3319999999999999}, "policy_reward_mean": {"red_0": 1.2108253968253972, "blue_0": -0.6421190476190476}, "custom_metrics": {"red_0/door_open_done_mean": 0.18253968253968253, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.7142857142857143, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.07142857142857142, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.7142857142857143, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.07142857142857142, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.7142857142857143, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.07142857142857142, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.21099999999999997, -0.5050000000000001, -0.13000000000000012, 1.454, 0.44799999999999995, -0.06000000000000005, 0.44199999999999995, 1.2570000000000001, 0.44700000000000006, 0.46199999999999997, 0.45300000000000007, 0.44499999999999984, 0.45699999999999985, -0.04000000000000003, 0.4159999999999999, 0.45999999999999996, 0.45500000000000007, 0.46699999999999997, 0.45699999999999985, 0.45999999999999996, 0.46399999999999997, 0.4620000000000002, 1.448, 1.453, 0.4540000000000002, -0.501, 0.476, 0.45999999999999996, -0.06000000000000005, 0.46599999999999997, 1.444, 0.4590000000000001, 0.44899999999999984, 0.45299999999999985, 0.45500000000000007, -0.04700000000000004, 0.44899999999999984, 0.46099999999999985, 0.45699999999999985, 0.43100000000000005, 0.45100000000000007, 0.4610000000000001, -0.040000000000000036, -0.02199999999999991, 0.45100000000000007, 0.4580000000000002, 0.4750000000000001, 0.43500000000000005, 0.45999999999999996, -0.05500000000000004, 0.9470000000000001, 1.443, 1.4489999999999998, 0.278, 1.442, 1.459, 0.44099999999999984, 1.4220000000000002, 0.45699999999999985, 1.4489999999999998, 0.46099999999999985, 0.44799999999999995, 0.42100000000000004, 0.45299999999999985, 0.42399999999999993, 0.9259999999999999, 0.46399999999999997, 0.4650000000000001, 0.44999999999999996, 0.46399999999999997, 0.4630000000000001, 1.033, -0.02100000000000002, -0.04599999999999993, 1.266, 0.46599999999999997, 0.44700000000000006, 1.456, 0.30899999999999994, 0.45999999999999996, -0.038000000000000034, 0.4630000000000001, 0.45999999999999996, 0.46599999999999997, 0.45699999999999985, 0.476, 0.46099999999999985, 0.4590000000000001, 0.46099999999999985, 0.44799999999999995, 1.452, 1.456, 0.45599999999999996, 1.454, 1.447, 0.44599999999999995, 0.40800000000000003, 0.45199999999999996, 0.44899999999999984, 0.45500000000000007, 0.45199999999999996, 0.45699999999999985, 0.45199999999999996, 1.454, 0.4620000000000002, 0.44999999999999996, 0.45500000000000007, -0.02199999999999991, -0.03400000000000003, 1.4420000000000002, 0.46599999999999997, 0.8140000000000001, 1.4609999999999999, -0.03200000000000003, 0.4620000000000002, 0.46599999999999997, 0.44599999999999995, 0.46099999999999985, 0.46499999999999986, 0.9040000000000001, 1.452, 0.43100000000000005, 0.45999999999999996, 0.45999999999999996, 0.4670000000000001, 1.459], "episode_lengths": [240, 159, 201, 15, 16, 19, 18, 77, 17, 12, 15, 17, 13, 300, 27, 13, 14, 300, 14, 13, 11, 12, 17, 15, 13, 157, 8, 12, 19, 11, 17, 13, 16, 15, 14, 14, 17, 12, 14, 21, 16, 12, 12, 7, 16, 13, 8, 21, 13, 300, 17, 19, 16, 67, 18, 13, 19, 25, 14, 17, 13, 16, 25, 15, 24, 300, 12, 11, 16, 12, 12, 148, 7, 15, 71, 11, 17, 14, 61, 13, 12, 12, 13, 11, 13, 8, 12, 13, 13, 16, 16, 14, 14, 15, 17, 17, 30, 15, 16, 14, 15, 13, 15, 15, 11, 16, 14, 7, 10, 18, 11, 54, 13, 10, 12, 11, 18, 12, 11, 30, 15, 22, 13, 13, 10, 13], "policy_red_0_reward": [-0.5429999999999999, -1.003, 0.8969999999999999, 1.455, 1.451, 0.943, 1.446, 1.2690000000000001, 1.4489999999999998, 1.464, 1.455, 1.4489999999999998, 1.4609999999999999, -0.002, 1.4180000000000001, 1.4609999999999999, 1.458, 0.5, 1.458, 1.4609999999999999, 1.467, 1.464, 1.4489999999999998, 1.455, 1.4609999999999999, 0.527, 1.476, 1.464, 0.943, -0.5, 1.4489999999999998, 1.4609999999999999, 1.452, 1.455, 1.458, 0.955, 1.4489999999999998, 1.464, 1.458, 1.4369999999999998, 1.452, 1.464, 0.962, 0.979, 1.452, 1.4609999999999999, 1.476, 1.4369999999999998, 1.4609999999999999, -0.006, 1.4489999999999998, 1.443, 1.452, -0.5099999999999999, 1.446, 1.4609999999999999, 1.443, 1.425, 1.458, 1.4489999999999998, 1.4609999999999999, 1.452, 1.425, 1.455, -0.5, 0.46699999999999997, 1.464, 1.467, 1.452, 1.464, 1.464, 1.0550000000000002, 0.979, 0.955, 1.275, 1.467, 1.4489999999999998, 1.458, 1.313, 1.4609999999999999, 0.964, 1.464, 1.4609999999999999, 1.467, 1.4609999999999999, 1.476, 1.464, 1.4609999999999999, 1.4609999999999999, 1.452, 1.452, 1.458, 1.458, 1.455, 1.4489999999999998, 1.4489999999999998, -0.5, 1.454, 1.452, 1.458, 1.455, 1.4609999999999999, 1.455, 1.455, 1.467, 1.452, 1.458, 0.979, 0.969, 1.446, -0.501, -0.5179999999999999, 1.4609999999999999, 0.968, 1.464, 1.467, -0.5, 1.464, 1.467, 1.4100000000000001, 1.455, 1.4329999999999998, 1.4609999999999999, 1.4609999999999999, 1.47, 1.4609999999999999], "policy_blue_0_reward": [0.7539999999999999, 0.4979999999999999, -1.027, -0.001, -1.003, -1.003, -1.004, -0.012000000000000004, -1.002, -1.002, -1.0019999999999998, -1.004, -1.004, -0.03800000000000003, -1.002, -1.001, -1.003, -0.03300000000000002, -1.001, -1.001, -1.003, -1.0019999999999998, -0.001, -0.002, -1.007, -1.028, -1.0, -1.004, -1.003, 0.966, -0.005, -1.002, -1.003, -1.002, -1.003, -1.002, -1.0, -1.003, -1.001, -1.0059999999999998, -1.001, -1.003, -1.002, -1.001, -1.001, -1.003, -1.001, -1.002, -1.001, -0.04900000000000004, -0.502, 0.0, -0.003, 0.7879999999999999, -0.004, -0.002, -1.002, -0.003, -1.001, 0.0, -1.0, -1.004, -1.004, -1.002, 0.9239999999999999, 0.45899999999999996, -1.0, -1.0019999999999998, -1.002, -1.0, -1.001, -0.022000000000000013, -1.0, -1.001, -0.009000000000000001, -1.001, -1.002, -0.002, -1.004, -1.001, -1.002, -1.001, -1.001, -1.001, -1.004, -1.0, -1.003, -1.002, -1.0, -1.004, 0.0, -0.002, -1.0019999999999998, -0.001, -0.002, -1.003, 0.908, -1.002, -1.003, -1.003, -1.003, -1.004, -1.003, -0.001, -1.005, -1.002, -1.003, -1.001, -1.003, -0.004, 0.967, 1.3319999999999999, 0.0, -1.0, -1.0019999999999998, -1.001, 0.946, -1.003, -1.002, -0.5059999999999999, -0.003, -1.002, -1.001, -1.001, -1.003, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24698149745315195, "mean_inference_ms": 1.4742549196154768, "mean_action_processing_ms": 0.06293833384951146, "mean_env_wait_ms": 0.0887994915389718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021928075760129898, "StateBufferConnector_ms": 0.0015196346101306734, "ViewRequirementAgentConnector_ms": 0.03270223027183896}}, "episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.5050000000000001, "episode_reward_mean": 0.5687063492063491, "episode_len_mean": 32.357142857142854, "episodes_this_iter": 126, "policy_reward_min": {"red_0": -1.003, "blue_0": -1.028}, "policy_reward_max": {"red_0": 1.476, "blue_0": 1.3319999999999999}, "policy_reward_mean": {"red_0": 1.2108253968253972, "blue_0": -0.6421190476190476}, "hist_stats": {"episode_reward": [0.21099999999999997, -0.5050000000000001, -0.13000000000000012, 1.454, 0.44799999999999995, -0.06000000000000005, 0.44199999999999995, 1.2570000000000001, 0.44700000000000006, 0.46199999999999997, 0.45300000000000007, 0.44499999999999984, 0.45699999999999985, -0.04000000000000003, 0.4159999999999999, 0.45999999999999996, 0.45500000000000007, 0.46699999999999997, 0.45699999999999985, 0.45999999999999996, 0.46399999999999997, 0.4620000000000002, 1.448, 1.453, 0.4540000000000002, -0.501, 0.476, 0.45999999999999996, -0.06000000000000005, 0.46599999999999997, 1.444, 0.4590000000000001, 0.44899999999999984, 0.45299999999999985, 0.45500000000000007, -0.04700000000000004, 0.44899999999999984, 0.46099999999999985, 0.45699999999999985, 0.43100000000000005, 0.45100000000000007, 0.4610000000000001, -0.040000000000000036, -0.02199999999999991, 0.45100000000000007, 0.4580000000000002, 0.4750000000000001, 0.43500000000000005, 0.45999999999999996, -0.05500000000000004, 0.9470000000000001, 1.443, 1.4489999999999998, 0.278, 1.442, 1.459, 0.44099999999999984, 1.4220000000000002, 0.45699999999999985, 1.4489999999999998, 0.46099999999999985, 0.44799999999999995, 0.42100000000000004, 0.45299999999999985, 0.42399999999999993, 0.9259999999999999, 0.46399999999999997, 0.4650000000000001, 0.44999999999999996, 0.46399999999999997, 0.4630000000000001, 1.033, -0.02100000000000002, -0.04599999999999993, 1.266, 0.46599999999999997, 0.44700000000000006, 1.456, 0.30899999999999994, 0.45999999999999996, -0.038000000000000034, 0.4630000000000001, 0.45999999999999996, 0.46599999999999997, 0.45699999999999985, 0.476, 0.46099999999999985, 0.4590000000000001, 0.46099999999999985, 0.44799999999999995, 1.452, 1.456, 0.45599999999999996, 1.454, 1.447, 0.44599999999999995, 0.40800000000000003, 0.45199999999999996, 0.44899999999999984, 0.45500000000000007, 0.45199999999999996, 0.45699999999999985, 0.45199999999999996, 1.454, 0.4620000000000002, 0.44999999999999996, 0.45500000000000007, -0.02199999999999991, -0.03400000000000003, 1.4420000000000002, 0.46599999999999997, 0.8140000000000001, 1.4609999999999999, -0.03200000000000003, 0.4620000000000002, 0.46599999999999997, 0.44599999999999995, 0.46099999999999985, 0.46499999999999986, 0.9040000000000001, 1.452, 0.43100000000000005, 0.45999999999999996, 0.45999999999999996, 0.4670000000000001, 1.459], "episode_lengths": [240, 159, 201, 15, 16, 19, 18, 77, 17, 12, 15, 17, 13, 300, 27, 13, 14, 300, 14, 13, 11, 12, 17, 15, 13, 157, 8, 12, 19, 11, 17, 13, 16, 15, 14, 14, 17, 12, 14, 21, 16, 12, 12, 7, 16, 13, 8, 21, 13, 300, 17, 19, 16, 67, 18, 13, 19, 25, 14, 17, 13, 16, 25, 15, 24, 300, 12, 11, 16, 12, 12, 148, 7, 15, 71, 11, 17, 14, 61, 13, 12, 12, 13, 11, 13, 8, 12, 13, 13, 16, 16, 14, 14, 15, 17, 17, 30, 15, 16, 14, 15, 13, 15, 15, 11, 16, 14, 7, 10, 18, 11, 54, 13, 10, 12, 11, 18, 12, 11, 30, 15, 22, 13, 13, 10, 13], "policy_red_0_reward": [-0.5429999999999999, -1.003, 0.8969999999999999, 1.455, 1.451, 0.943, 1.446, 1.2690000000000001, 1.4489999999999998, 1.464, 1.455, 1.4489999999999998, 1.4609999999999999, -0.002, 1.4180000000000001, 1.4609999999999999, 1.458, 0.5, 1.458, 1.4609999999999999, 1.467, 1.464, 1.4489999999999998, 1.455, 1.4609999999999999, 0.527, 1.476, 1.464, 0.943, -0.5, 1.4489999999999998, 1.4609999999999999, 1.452, 1.455, 1.458, 0.955, 1.4489999999999998, 1.464, 1.458, 1.4369999999999998, 1.452, 1.464, 0.962, 0.979, 1.452, 1.4609999999999999, 1.476, 1.4369999999999998, 1.4609999999999999, -0.006, 1.4489999999999998, 1.443, 1.452, -0.5099999999999999, 1.446, 1.4609999999999999, 1.443, 1.425, 1.458, 1.4489999999999998, 1.4609999999999999, 1.452, 1.425, 1.455, -0.5, 0.46699999999999997, 1.464, 1.467, 1.452, 1.464, 1.464, 1.0550000000000002, 0.979, 0.955, 1.275, 1.467, 1.4489999999999998, 1.458, 1.313, 1.4609999999999999, 0.964, 1.464, 1.4609999999999999, 1.467, 1.4609999999999999, 1.476, 1.464, 1.4609999999999999, 1.4609999999999999, 1.452, 1.452, 1.458, 1.458, 1.455, 1.4489999999999998, 1.4489999999999998, -0.5, 1.454, 1.452, 1.458, 1.455, 1.4609999999999999, 1.455, 1.455, 1.467, 1.452, 1.458, 0.979, 0.969, 1.446, -0.501, -0.5179999999999999, 1.4609999999999999, 0.968, 1.464, 1.467, -0.5, 1.464, 1.467, 1.4100000000000001, 1.455, 1.4329999999999998, 1.4609999999999999, 1.4609999999999999, 1.47, 1.4609999999999999], "policy_blue_0_reward": [0.7539999999999999, 0.4979999999999999, -1.027, -0.001, -1.003, -1.003, -1.004, -0.012000000000000004, -1.002, -1.002, -1.0019999999999998, -1.004, -1.004, -0.03800000000000003, -1.002, -1.001, -1.003, -0.03300000000000002, -1.001, -1.001, -1.003, -1.0019999999999998, -0.001, -0.002, -1.007, -1.028, -1.0, -1.004, -1.003, 0.966, -0.005, -1.002, -1.003, -1.002, -1.003, -1.002, -1.0, -1.003, -1.001, -1.0059999999999998, -1.001, -1.003, -1.002, -1.001, -1.001, -1.003, -1.001, -1.002, -1.001, -0.04900000000000004, -0.502, 0.0, -0.003, 0.7879999999999999, -0.004, -0.002, -1.002, -0.003, -1.001, 0.0, -1.0, -1.004, -1.004, -1.002, 0.9239999999999999, 0.45899999999999996, -1.0, -1.0019999999999998, -1.002, -1.0, -1.001, -0.022000000000000013, -1.0, -1.001, -0.009000000000000001, -1.001, -1.002, -0.002, -1.004, -1.001, -1.002, -1.001, -1.001, -1.001, -1.004, -1.0, -1.003, -1.002, -1.0, -1.004, 0.0, -0.002, -1.0019999999999998, -0.001, -0.002, -1.003, 0.908, -1.002, -1.003, -1.003, -1.003, -1.004, -1.003, -0.001, -1.005, -1.002, -1.003, -1.001, -1.003, -0.004, 0.967, 1.3319999999999999, 0.0, -1.0, -1.0019999999999998, -1.001, 0.946, -1.003, -1.002, -0.5059999999999999, -0.003, -1.002, -1.001, -1.001, -1.003, -0.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24698149745315195, "mean_inference_ms": 1.4742549196154768, "mean_action_processing_ms": 0.06293833384951146, "mean_env_wait_ms": 0.0887994915389718, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021928075760129898, "StateBufferConnector_ms": 0.0015196346101306734, "ViewRequirementAgentConnector_ms": 0.03270223027183896}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000, "num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.66769423199305, "num_env_steps_trained_throughput_per_sec": 102.66769423199305, "timesteps_total": 252000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 504000, "timers": {"training_iteration_time_ms": 38924.099, "sample_time_ms": 7581.435, "learn_time_ms": 31325.389, "learn_throughput": 127.692, "synch_weights_time_ms": 16.772}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 252000, "num_agent_steps_sampled": 504000, "num_agent_steps_trained": 504000}, "done": false, "episodes_total": 7936, "training_iteration": 63, "trial_id": "d67e4_00000", "date": "2023-09-20_22-50-14", "timestamp": 1695264614, "time_this_iter_s": 38.96627688407898, "time_total_s": 2451.6494085788727, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d08ac20>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2451.6494085788727, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 37.04, "ram_util_percent": 50.05636363636363}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.24561403508771928, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6929824561403509, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02631578947368421, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6929824561403509, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02631578947368421, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6929824561403509, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02631578947368421, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.203415310258667, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009792179556097836, "policy_loss": -0.015386983183755849, "vf_loss": 0.004615088835635106, "vf_explained_var": 0.8305035184447964, "kl": 0.008228650588337248, "entropy": 0.41563362701175116, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 60960.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "sampler_results": {"episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.20300000000000007, "episode_reward_mean": 0.6595350877192984, "episode_len_mean": 33.96491228070175, "episode_media": {}, "episodes_this_iter": 114, "policy_reward_min": {"red_0": -0.503, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.972}, "policy_reward_mean": {"red_0": 1.3132105263157894, "blue_0": -0.6536754385964912}, "custom_metrics": {"red_0/door_open_done_mean": 0.24561403508771928, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6929824561403509, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.02631578947368421, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6929824561403509, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.02631578947368421, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6929824561403509, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.02631578947368421, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46399999999999997, 0.45999999999999996, 0.4670000000000001, 0.4590000000000001, 1.455, 0.42299999999999993, 1.384, 0.47, 0.14900000000000002, 1.455, 1.401, 1.4609999999999999, 0.45599999999999996, 0.45799999999999996, 0.42600000000000016, 1.444, 0.4630000000000001, 0.43399999999999994, 0.13200000000000012, 0.4630000000000001, 0.42999999999999994, 1.267, 0.44399999999999995, 0.472, 0.46799999999999997, 0.45599999999999996, 0.20700000000000007, 1.4329999999999998, 0.35199999999999987, 1.45, 0.4630000000000001, 1.4220000000000002, 0.46499999999999986, 0.45500000000000007, 0.45999999999999996, 0.44499999999999984, -0.039000000000000035, 0.47299999999999986, 0.9359999999999999, 0.46899999999999986, 1.439, 1.448, 0.46399999999999997, 0.4610000000000001, 0.46499999999999986, 0.4209999999999998, 1.4140000000000001, 1.451, 0.9630000000000001, 1.443, 1.46, 0.45699999999999985, -0.20300000000000007, 1.21, 0.41999999999999993, 0.5069999999999999, 0.46399999999999997, 0.46399999999999997, 0.46799999999999997, 0.43400000000000016, 0.47, 0.45299999999999985, 0.4670000000000001, 0.46499999999999986, -0.027000000000000024, 0.45100000000000007, 0.47, 0.46499999999999986, 0.9650000000000001, 0.45699999999999985, 0.46099999999999985, 1.371, 0.347, 0.4710000000000001, 0.46499999999999986, 0.46099999999999985, 0.46399999999999997, 0.46099999999999985, 1.426, -0.062000000000000055, -0.10699999999999998, 1.451, 1.435, 0.45299999999999985, 1.4529999999999998, -0.09999999999999998, 0.43999999999999995, 0.43300000000000005, 1.4449999999999998, 0.4590000000000001, 0.45399999999999996, 0.46899999999999986, 0.45500000000000007, 0.46599999999999997, 0.45599999999999996, 0.4029999999999999, 0.45999999999999996, 0.4710000000000001, 0.45999999999999996, 0.08099999999999996, 0.45699999999999985, 1.448, 0.46499999999999986, 0.46499999999999986, 1.4569999999999999, 0.43900000000000006, -0.06799999999999995, 0.45399999999999996, 0.4670000000000001, 1.448, 1.426, 1.44, 0.43900000000000006, 0.31000000000000005], "episode_lengths": [12, 13, 11, 13, 15, 300, 33, 10, 111, 15, 32, 13, 14, 13, 22, 18, 12, 20, 110, 12, 300, 73, 18, 9, 10, 14, 93, 21, 47, 16, 12, 25, 11, 14, 13, 18, 11, 9, 20, 10, 19, 17, 12, 12, 11, 24, 27, 16, 12, 17, 13, 14, 65, 90, 24, 149, 12, 11, 10, 19, 10, 14, 11, 11, 9, 15, 10, 11, 11, 14, 12, 40, 48, 9, 11, 13, 12, 13, 24, 19, 34, 16, 21, 15, 15, 31, 20, 20, 18, 13, 15, 10, 14, 11, 14, 300, 13, 9, 13, 286, 14, 17, 11, 11, 14, 20, 21, 300, 10, 17, 24, 19, 20, 52], "policy_red_0_reward": [1.464, 1.4609999999999999, 1.467, 1.4609999999999999, 1.455, 0.484, 1.389, 1.47, -0.503, 1.455, 1.403, 1.4609999999999999, 1.458, 1.4609999999999999, 1.4289999999999998, 1.446, 1.464, 1.439, 1.154, 1.464, 0.478, 1.2799999999999998, 1.446, -0.5, 1.47, 1.458, 1.217, 1.4369999999999998, 1.359, 1.452, 1.464, 1.425, 1.467, 1.458, 1.4609999999999999, 1.4449999999999998, 0.964, 1.4729999999999999, 1.44, 1.47, 1.443, 1.4489999999999998, 1.464, 1.463, 1.467, 1.4249999999999998, 1.419, 1.452, 1.464, 1.4489999999999998, 1.4609999999999999, 1.458, 0.8049999999999999, 1.224, -0.502, 1.031, 1.464, 1.467, 1.47, 1.442, 1.47, 1.458, 1.467, 1.466, 0.973, 1.455, 1.47, 1.467, 1.467, 1.458, 1.464, 1.377, 1.354, 1.4729999999999999, 1.467, 1.4609999999999999, 1.464, 1.4609999999999999, 1.428, 0.943, 0.897, 1.452, 1.436, 1.455, 1.455, 0.907, 1.44, 1.435, 1.446, 1.4609999999999999, 1.454, 1.47, 1.458, 1.467, 1.458, 0.46399999999999997, 1.4609999999999999, 1.4729999999999999, 1.4609999999999999, 0.6299999999999999, 1.458, 1.4489999999999998, 1.467, 1.467, 1.458, 1.44, 0.9369999999999999, 0.5, 1.47, 1.4489999999999998, 1.428, 1.443, 1.44, 1.3159999999999998], "policy_blue_0_reward": [-1.0, -1.001, -1.0, -1.002, 0.0, -0.06100000000000005, -0.005, -1.0, 0.652, 0.0, -0.002, 0.0, -1.002, -1.003, -1.003, -0.002, -1.001, -1.005, -1.022, -1.001, -0.048000000000000036, -0.013000000000000005, -1.002, 0.972, -1.002, -1.002, -1.0099999999999998, -0.004, -1.007, -0.002, -1.001, -0.003, -1.002, -1.003, -1.001, -1.0, -1.003, -1.0, -0.504, -1.001, -0.004, -0.001, -1.0, -1.0019999999999998, -1.002, -1.004, -0.005, -0.001, -0.501, -0.006, -0.001, -1.001, -1.008, -0.014000000000000005, 0.9219999999999999, -0.524, -1.0, -1.003, -1.002, -1.0079999999999998, -1.0, -1.005, -1.0, -1.001, -1.0, -1.004, -1.0, -1.002, -0.5019999999999999, -1.001, -1.003, -0.006, -1.007, -1.002, -1.002, -1.0, -1.0, -1.0, -0.002, -1.005, -1.004, -0.001, -0.001, -1.002, -0.002, -1.007, -1.0, -1.0019999999999998, -0.001, -1.002, -1.0, -1.001, -1.003, -1.001, -1.002, -0.06100000000000005, -1.001, -1.002, -1.001, -0.549, -1.001, -0.001, -1.002, -1.002, -0.001, -1.001, -1.005, -0.046000000000000034, -1.003, -0.001, -0.002, -0.003, -1.001, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24697076862293718, "mean_inference_ms": 1.4754298582808185, "mean_action_processing_ms": 0.0630344381067435, "mean_env_wait_ms": 0.08881013631094112, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022090004201520953, "StateBufferConnector_ms": 0.0015069518172950076, "ViewRequirementAgentConnector_ms": 0.03269461163303308}}, "episode_reward_max": 1.4609999999999999, "episode_reward_min": -0.20300000000000007, "episode_reward_mean": 0.6595350877192984, "episode_len_mean": 33.96491228070175, "episodes_this_iter": 114, "policy_reward_min": {"red_0": -0.503, "blue_0": -1.022}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.972}, "policy_reward_mean": {"red_0": 1.3132105263157894, "blue_0": -0.6536754385964912}, "hist_stats": {"episode_reward": [0.46399999999999997, 0.45999999999999996, 0.4670000000000001, 0.4590000000000001, 1.455, 0.42299999999999993, 1.384, 0.47, 0.14900000000000002, 1.455, 1.401, 1.4609999999999999, 0.45599999999999996, 0.45799999999999996, 0.42600000000000016, 1.444, 0.4630000000000001, 0.43399999999999994, 0.13200000000000012, 0.4630000000000001, 0.42999999999999994, 1.267, 0.44399999999999995, 0.472, 0.46799999999999997, 0.45599999999999996, 0.20700000000000007, 1.4329999999999998, 0.35199999999999987, 1.45, 0.4630000000000001, 1.4220000000000002, 0.46499999999999986, 0.45500000000000007, 0.45999999999999996, 0.44499999999999984, -0.039000000000000035, 0.47299999999999986, 0.9359999999999999, 0.46899999999999986, 1.439, 1.448, 0.46399999999999997, 0.4610000000000001, 0.46499999999999986, 0.4209999999999998, 1.4140000000000001, 1.451, 0.9630000000000001, 1.443, 1.46, 0.45699999999999985, -0.20300000000000007, 1.21, 0.41999999999999993, 0.5069999999999999, 0.46399999999999997, 0.46399999999999997, 0.46799999999999997, 0.43400000000000016, 0.47, 0.45299999999999985, 0.4670000000000001, 0.46499999999999986, -0.027000000000000024, 0.45100000000000007, 0.47, 0.46499999999999986, 0.9650000000000001, 0.45699999999999985, 0.46099999999999985, 1.371, 0.347, 0.4710000000000001, 0.46499999999999986, 0.46099999999999985, 0.46399999999999997, 0.46099999999999985, 1.426, -0.062000000000000055, -0.10699999999999998, 1.451, 1.435, 0.45299999999999985, 1.4529999999999998, -0.09999999999999998, 0.43999999999999995, 0.43300000000000005, 1.4449999999999998, 0.4590000000000001, 0.45399999999999996, 0.46899999999999986, 0.45500000000000007, 0.46599999999999997, 0.45599999999999996, 0.4029999999999999, 0.45999999999999996, 0.4710000000000001, 0.45999999999999996, 0.08099999999999996, 0.45699999999999985, 1.448, 0.46499999999999986, 0.46499999999999986, 1.4569999999999999, 0.43900000000000006, -0.06799999999999995, 0.45399999999999996, 0.4670000000000001, 1.448, 1.426, 1.44, 0.43900000000000006, 0.31000000000000005], "episode_lengths": [12, 13, 11, 13, 15, 300, 33, 10, 111, 15, 32, 13, 14, 13, 22, 18, 12, 20, 110, 12, 300, 73, 18, 9, 10, 14, 93, 21, 47, 16, 12, 25, 11, 14, 13, 18, 11, 9, 20, 10, 19, 17, 12, 12, 11, 24, 27, 16, 12, 17, 13, 14, 65, 90, 24, 149, 12, 11, 10, 19, 10, 14, 11, 11, 9, 15, 10, 11, 11, 14, 12, 40, 48, 9, 11, 13, 12, 13, 24, 19, 34, 16, 21, 15, 15, 31, 20, 20, 18, 13, 15, 10, 14, 11, 14, 300, 13, 9, 13, 286, 14, 17, 11, 11, 14, 20, 21, 300, 10, 17, 24, 19, 20, 52], "policy_red_0_reward": [1.464, 1.4609999999999999, 1.467, 1.4609999999999999, 1.455, 0.484, 1.389, 1.47, -0.503, 1.455, 1.403, 1.4609999999999999, 1.458, 1.4609999999999999, 1.4289999999999998, 1.446, 1.464, 1.439, 1.154, 1.464, 0.478, 1.2799999999999998, 1.446, -0.5, 1.47, 1.458, 1.217, 1.4369999999999998, 1.359, 1.452, 1.464, 1.425, 1.467, 1.458, 1.4609999999999999, 1.4449999999999998, 0.964, 1.4729999999999999, 1.44, 1.47, 1.443, 1.4489999999999998, 1.464, 1.463, 1.467, 1.4249999999999998, 1.419, 1.452, 1.464, 1.4489999999999998, 1.4609999999999999, 1.458, 0.8049999999999999, 1.224, -0.502, 1.031, 1.464, 1.467, 1.47, 1.442, 1.47, 1.458, 1.467, 1.466, 0.973, 1.455, 1.47, 1.467, 1.467, 1.458, 1.464, 1.377, 1.354, 1.4729999999999999, 1.467, 1.4609999999999999, 1.464, 1.4609999999999999, 1.428, 0.943, 0.897, 1.452, 1.436, 1.455, 1.455, 0.907, 1.44, 1.435, 1.446, 1.4609999999999999, 1.454, 1.47, 1.458, 1.467, 1.458, 0.46399999999999997, 1.4609999999999999, 1.4729999999999999, 1.4609999999999999, 0.6299999999999999, 1.458, 1.4489999999999998, 1.467, 1.467, 1.458, 1.44, 0.9369999999999999, 0.5, 1.47, 1.4489999999999998, 1.428, 1.443, 1.44, 1.3159999999999998], "policy_blue_0_reward": [-1.0, -1.001, -1.0, -1.002, 0.0, -0.06100000000000005, -0.005, -1.0, 0.652, 0.0, -0.002, 0.0, -1.002, -1.003, -1.003, -0.002, -1.001, -1.005, -1.022, -1.001, -0.048000000000000036, -0.013000000000000005, -1.002, 0.972, -1.002, -1.002, -1.0099999999999998, -0.004, -1.007, -0.002, -1.001, -0.003, -1.002, -1.003, -1.001, -1.0, -1.003, -1.0, -0.504, -1.001, -0.004, -0.001, -1.0, -1.0019999999999998, -1.002, -1.004, -0.005, -0.001, -0.501, -0.006, -0.001, -1.001, -1.008, -0.014000000000000005, 0.9219999999999999, -0.524, -1.0, -1.003, -1.002, -1.0079999999999998, -1.0, -1.005, -1.0, -1.001, -1.0, -1.004, -1.0, -1.002, -0.5019999999999999, -1.001, -1.003, -0.006, -1.007, -1.002, -1.002, -1.0, -1.0, -1.0, -0.002, -1.005, -1.004, -0.001, -0.001, -1.002, -0.002, -1.007, -1.0, -1.0019999999999998, -0.001, -1.002, -1.0, -1.001, -1.003, -1.001, -1.002, -0.06100000000000005, -1.001, -1.002, -1.001, -0.549, -1.001, -0.001, -1.002, -1.002, -0.001, -1.001, -1.005, -0.046000000000000034, -1.003, -0.001, -0.002, -0.003, -1.001, -1.006]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24697076862293718, "mean_inference_ms": 1.4754298582808185, "mean_action_processing_ms": 0.0630344381067435, "mean_env_wait_ms": 0.08881013631094112, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022090004201520953, "StateBufferConnector_ms": 0.0015069518172950076, "ViewRequirementAgentConnector_ms": 0.03269461163303308}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000, "num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.04152594962427, "num_env_steps_trained_throughput_per_sec": 103.04152594962427, "timesteps_total": 256000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 512000, "timers": {"training_iteration_time_ms": 38921.861, "sample_time_ms": 7577.114, "learn_time_ms": 31327.434, "learn_throughput": 127.684, "synch_weights_time_ms": 16.806}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 256000, "num_agent_steps_sampled": 512000, "num_agent_steps_trained": 512000}, "done": false, "episodes_total": 8050, "training_iteration": 64, "trial_id": "d67e4_00000", "date": "2023-09-20_22-50-53", "timestamp": 1695264653, "time_this_iter_s": 38.824543952941895, "time_total_s": 2490.4739525318146, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a4707640>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2490.4739525318146, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 34.994642857142864, "ram_util_percent": 50.18392857142857}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.22794117647058823, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6838235294117647, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.051470588235294115, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6838235294117647, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.051470588235294115, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6838235294117647, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.051470588235294115, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1205525561546286, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.005845983759718365, "policy_loss": -0.010903185723873322, "vf_loss": 0.006344073614309309, "vf_explained_var": 0.8076667959491411, "kl": 0.005141524237583669, "entropy": 0.4285207219421864, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 61920.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "sampler_results": {"episode_reward_max": 1.953, "episode_reward_min": -0.22599999999999998, "episode_reward_mean": 0.6537499999999999, "episode_len_mean": 30.154411764705884, "episode_media": {}, "episodes_this_iter": 136, "policy_reward_min": {"red_0": -0.506, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.968}, "policy_reward_mean": {"red_0": 1.2614117647058822, "blue_0": -0.6076617647058823}, "custom_metrics": {"red_0/door_open_done_mean": 0.22794117647058823, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6838235294117647, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.051470588235294115, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6838235294117647, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.051470588235294115, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6838235294117647, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.051470588235294115, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.362, 0.45299999999999985, 0.46499999999999986, 0.44199999999999995, 1.444, 0.45699999999999985, 0.45699999999999985, 0.42700000000000005, 0.46699999999999997, 0.4590000000000001, 0.956, 0.46399999999999997, 0.45399999999999996, -0.05800000000000005, 0.45799999999999996, 1.458, 0.45299999999999985, 0.46899999999999986, 0.43699999999999983, 0.45799999999999996, 1.443, 0.387, 0.45699999999999985, 0.4590000000000001, -0.03300000000000003, 0.45100000000000007, 0.45999999999999996, 0.44799999999999995, 0.45999999999999996, 1.452, 1.436, 1.953, 0.45799999999999996, 0.45399999999999996, 1.4609999999999999, 1.452, 0.46099999999999985, 0.46599999999999997, 0.47, 0.46899999999999986, -0.22199999999999998, 0.4630000000000001, 1.451, 0.46499999999999986, 0.45999999999999996, 0.45299999999999985, 0.45799999999999996, 1.492, 0.44799999999999995, 0.472, 0.472, -0.17200000000000004, 0.46099999999999985, 1.46, 0.46399999999999997, 0.46499999999999986, -0.04300000000000004, 0.40700000000000003, 0.4670000000000001, 0.46499999999999986, 0.44899999999999984, 0.45999999999999996, 1.4420000000000002, 0.45699999999999985, 1.4329999999999998, 1.448, 0.45599999999999996, 0.401, 0.46899999999999986, 0.45599999999999996, 0.9630000000000001, 0.45799999999999996, 0.46599999999999997, 0.45799999999999996, 0.45199999999999996, 1.4609999999999999, 0.43999999999999995, 0.46599999999999997, -0.03200000000000003, 0.4660000000000002, -0.06899999999999995, 0.30200000000000005, 0.44899999999999995, -0.05100000000000004, 0.46799999999999997, 0.45399999999999996, 0.46199999999999997, 0.45699999999999985, 0.44900000000000007, 0.46499999999999986, 0.4670000000000001, -0.22599999999999998, 1.455, 0.46899999999999986, 0.47, -0.02200000000000002, 0.45799999999999996, 0.45699999999999985, 0.44599999999999995, 1.3219999999999998, 1.4529999999999998, 1.443, 0.45699999999999985, 0.46599999999999997, 0.46899999999999986, 0.45599999999999996, 0.4590000000000001, 1.454, 0.379, 1.4369999999999998, 0.44200000000000017, 1.366, 1.455, 0.8340000000000001, 0.4630000000000001, 0.4650000000000001, 1.922, 1.459, 0.4660000000000002, 0.45799999999999996, 0.381, 0.45599999999999996, 0.43199999999999994, 1.46, 0.46599999999999997, 1.369, 0.365, 0.45999999999999996, 1.435, 1.448, 1.45, 0.43699999999999994, 0.45399999999999996, 0.46799999999999997, 0.956, -0.11300000000000009], "episode_lengths": [43, 15, 11, 17, 18, 14, 14, 22, 11, 13, 14, 11, 14, 18, 14, 14, 15, 10, 20, 14, 18, 36, 14, 13, 11, 16, 13, 16, 12, 15, 21, 15, 13, 15, 13, 15, 13, 11, 10, 10, 70, 12, 16, 11, 13, 15, 14, 162, 300, 9, 9, 53, 12, 13, 12, 11, 14, 28, 11, 11, 16, 13, 18, 14, 21, 16, 14, 30, 10, 14, 12, 13, 11, 14, 15, 13, 19, 11, 9, 11, 21, 62, 300, 300, 10, 15, 12, 14, 16, 11, 10, 72, 15, 10, 9, 7, 13, 14, 17, 204, 15, 18, 14, 11, 10, 14, 13, 15, 37, 20, 18, 42, 15, 53, 12, 10, 24, 13, 10, 13, 36, 14, 21, 13, 11, 40, 41, 13, 20, 17, 16, 300, 14, 10, 14, 300], "policy_red_0_reward": [1.371, 1.455, 1.467, 1.4489999999999998, 1.446, 1.458, 1.458, 1.4329999999999998, -0.5, 1.4609999999999999, 1.458, 1.467, 1.458, 0.946, 1.458, 1.458, 1.455, 1.47, 1.44, 1.458, 1.446, 1.392, 1.458, 1.4609999999999999, 0.967, 1.452, 1.4609999999999999, 1.452, 1.464, 1.455, 1.4369999999999998, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 1.467, 1.47, 1.47, 0.786, 1.464, 1.452, 1.467, 1.4609999999999999, 1.455, 1.458, 1.012, 0.497, 1.4729999999999999, 1.4729999999999999, 0.841, 1.464, 1.4609999999999999, 1.464, 1.467, 0.958, 1.413, 1.467, 1.467, 1.452, 1.4609999999999999, 1.446, 1.458, 1.4369999999999998, 1.452, 1.458, -0.503, 1.47, 1.458, 1.464, 1.4609999999999999, 1.467, 1.458, 1.455, 1.4609999999999999, 1.443, 1.467, 0.971, 1.467, 0.9329999999999999, -0.506, -0.001, -0.002, -0.5, 1.455, -0.5, 1.458, 1.452, 1.467, 1.47, 0.784, 1.455, 1.47, 1.4729999999999999, 0.979, 1.4609999999999999, 1.458, 1.447, 0.8489999999999999, 1.455, 1.446, 1.458, 1.467, 1.47, 1.458, 1.4609999999999999, 1.455, -0.503, 1.44, 1.446, 1.373, 1.455, 1.3399999999999999, 1.464, 1.47, 1.426, 1.4609999999999999, 1.47, 1.4609999999999999, 1.3860000000000001, 1.458, -0.502, 1.4609999999999999, 1.467, 1.373, 1.376, 1.4609999999999999, 1.438, 1.4489999999999998, 1.452, 0.484, 1.458, 1.47, 1.458, -0.08100000000000006], "policy_blue_0_reward": [-0.009000000000000001, -1.002, -1.002, -1.007, -0.002, -1.001, -1.001, -1.006, 0.967, -1.002, -0.5019999999999999, -1.003, -1.004, -1.004, -1.0, 0.0, -1.002, -1.001, -1.003, -1.0, -0.003, -1.005, -1.001, -1.002, -1.0, -1.001, -1.001, -1.004, -1.0039999999999998, -0.003, -0.001, 0.498, -1.003, -1.001, 0.0, -0.003, -1.0, -1.001, -1.0, -1.001, -1.008, -1.001, -0.001, -1.002, -1.001, -1.002, -1.0, 0.48, -0.04900000000000004, -1.001, -1.001, -1.013, -1.003, -0.001, -1.0, -1.002, -1.001, -1.006, -1.0, -1.002, -1.003, -1.001, -0.004, -1.001, -0.004, -0.004, -1.002, 0.904, -1.001, -1.002, -0.501, -1.003, -1.001, -1.0, -1.003, 0.0, -1.003, -1.001, -1.003, -1.001, -1.0019999999999998, 0.808, 0.44999999999999996, -0.04900000000000004, 0.968, -1.001, 0.962, -1.001, -1.003, -1.002, -1.003, -1.01, 0.0, -1.001, -1.003, -1.001, -1.003, -1.001, -1.001, 0.473, -0.002, -0.003, -1.001, -1.001, -1.001, -1.002, -1.002, -0.001, 0.882, -0.003, -1.0039999999999998, -0.007, 0.0, -0.5059999999999999, -1.001, -1.005, 0.496, -0.002, -1.0039999999999998, -1.003, -1.005, -1.0019999999999998, 0.9339999999999999, -0.001, -1.001, -0.004, -1.011, -1.001, -0.003, -0.001, -0.002, -0.047000000000000035, -1.004, -1.002, -0.502, -0.03200000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24778091357892015, "mean_inference_ms": 1.4783000557119346, "mean_action_processing_ms": 0.06326607176009162, "mean_env_wait_ms": 0.08904800795048558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022031454478993136, "StateBufferConnector_ms": 0.0014950247371897979, "ViewRequirementAgentConnector_ms": 0.032672198379740995}}, "episode_reward_max": 1.953, "episode_reward_min": -0.22599999999999998, "episode_reward_mean": 0.6537499999999999, "episode_len_mean": 30.154411764705884, "episodes_this_iter": 136, "policy_reward_min": {"red_0": -0.506, "blue_0": -1.013}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.968}, "policy_reward_mean": {"red_0": 1.2614117647058822, "blue_0": -0.6076617647058823}, "hist_stats": {"episode_reward": [1.362, 0.45299999999999985, 0.46499999999999986, 0.44199999999999995, 1.444, 0.45699999999999985, 0.45699999999999985, 0.42700000000000005, 0.46699999999999997, 0.4590000000000001, 0.956, 0.46399999999999997, 0.45399999999999996, -0.05800000000000005, 0.45799999999999996, 1.458, 0.45299999999999985, 0.46899999999999986, 0.43699999999999983, 0.45799999999999996, 1.443, 0.387, 0.45699999999999985, 0.4590000000000001, -0.03300000000000003, 0.45100000000000007, 0.45999999999999996, 0.44799999999999995, 0.45999999999999996, 1.452, 1.436, 1.953, 0.45799999999999996, 0.45399999999999996, 1.4609999999999999, 1.452, 0.46099999999999985, 0.46599999999999997, 0.47, 0.46899999999999986, -0.22199999999999998, 0.4630000000000001, 1.451, 0.46499999999999986, 0.45999999999999996, 0.45299999999999985, 0.45799999999999996, 1.492, 0.44799999999999995, 0.472, 0.472, -0.17200000000000004, 0.46099999999999985, 1.46, 0.46399999999999997, 0.46499999999999986, -0.04300000000000004, 0.40700000000000003, 0.4670000000000001, 0.46499999999999986, 0.44899999999999984, 0.45999999999999996, 1.4420000000000002, 0.45699999999999985, 1.4329999999999998, 1.448, 0.45599999999999996, 0.401, 0.46899999999999986, 0.45599999999999996, 0.9630000000000001, 0.45799999999999996, 0.46599999999999997, 0.45799999999999996, 0.45199999999999996, 1.4609999999999999, 0.43999999999999995, 0.46599999999999997, -0.03200000000000003, 0.4660000000000002, -0.06899999999999995, 0.30200000000000005, 0.44899999999999995, -0.05100000000000004, 0.46799999999999997, 0.45399999999999996, 0.46199999999999997, 0.45699999999999985, 0.44900000000000007, 0.46499999999999986, 0.4670000000000001, -0.22599999999999998, 1.455, 0.46899999999999986, 0.47, -0.02200000000000002, 0.45799999999999996, 0.45699999999999985, 0.44599999999999995, 1.3219999999999998, 1.4529999999999998, 1.443, 0.45699999999999985, 0.46599999999999997, 0.46899999999999986, 0.45599999999999996, 0.4590000000000001, 1.454, 0.379, 1.4369999999999998, 0.44200000000000017, 1.366, 1.455, 0.8340000000000001, 0.4630000000000001, 0.4650000000000001, 1.922, 1.459, 0.4660000000000002, 0.45799999999999996, 0.381, 0.45599999999999996, 0.43199999999999994, 1.46, 0.46599999999999997, 1.369, 0.365, 0.45999999999999996, 1.435, 1.448, 1.45, 0.43699999999999994, 0.45399999999999996, 0.46799999999999997, 0.956, -0.11300000000000009], "episode_lengths": [43, 15, 11, 17, 18, 14, 14, 22, 11, 13, 14, 11, 14, 18, 14, 14, 15, 10, 20, 14, 18, 36, 14, 13, 11, 16, 13, 16, 12, 15, 21, 15, 13, 15, 13, 15, 13, 11, 10, 10, 70, 12, 16, 11, 13, 15, 14, 162, 300, 9, 9, 53, 12, 13, 12, 11, 14, 28, 11, 11, 16, 13, 18, 14, 21, 16, 14, 30, 10, 14, 12, 13, 11, 14, 15, 13, 19, 11, 9, 11, 21, 62, 300, 300, 10, 15, 12, 14, 16, 11, 10, 72, 15, 10, 9, 7, 13, 14, 17, 204, 15, 18, 14, 11, 10, 14, 13, 15, 37, 20, 18, 42, 15, 53, 12, 10, 24, 13, 10, 13, 36, 14, 21, 13, 11, 40, 41, 13, 20, 17, 16, 300, 14, 10, 14, 300], "policy_red_0_reward": [1.371, 1.455, 1.467, 1.4489999999999998, 1.446, 1.458, 1.458, 1.4329999999999998, -0.5, 1.4609999999999999, 1.458, 1.467, 1.458, 0.946, 1.458, 1.458, 1.455, 1.47, 1.44, 1.458, 1.446, 1.392, 1.458, 1.4609999999999999, 0.967, 1.452, 1.4609999999999999, 1.452, 1.464, 1.455, 1.4369999999999998, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 1.455, 1.4609999999999999, 1.467, 1.47, 1.47, 0.786, 1.464, 1.452, 1.467, 1.4609999999999999, 1.455, 1.458, 1.012, 0.497, 1.4729999999999999, 1.4729999999999999, 0.841, 1.464, 1.4609999999999999, 1.464, 1.467, 0.958, 1.413, 1.467, 1.467, 1.452, 1.4609999999999999, 1.446, 1.458, 1.4369999999999998, 1.452, 1.458, -0.503, 1.47, 1.458, 1.464, 1.4609999999999999, 1.467, 1.458, 1.455, 1.4609999999999999, 1.443, 1.467, 0.971, 1.467, 0.9329999999999999, -0.506, -0.001, -0.002, -0.5, 1.455, -0.5, 1.458, 1.452, 1.467, 1.47, 0.784, 1.455, 1.47, 1.4729999999999999, 0.979, 1.4609999999999999, 1.458, 1.447, 0.8489999999999999, 1.455, 1.446, 1.458, 1.467, 1.47, 1.458, 1.4609999999999999, 1.455, -0.503, 1.44, 1.446, 1.373, 1.455, 1.3399999999999999, 1.464, 1.47, 1.426, 1.4609999999999999, 1.47, 1.4609999999999999, 1.3860000000000001, 1.458, -0.502, 1.4609999999999999, 1.467, 1.373, 1.376, 1.4609999999999999, 1.438, 1.4489999999999998, 1.452, 0.484, 1.458, 1.47, 1.458, -0.08100000000000006], "policy_blue_0_reward": [-0.009000000000000001, -1.002, -1.002, -1.007, -0.002, -1.001, -1.001, -1.006, 0.967, -1.002, -0.5019999999999999, -1.003, -1.004, -1.004, -1.0, 0.0, -1.002, -1.001, -1.003, -1.0, -0.003, -1.005, -1.001, -1.002, -1.0, -1.001, -1.001, -1.004, -1.0039999999999998, -0.003, -0.001, 0.498, -1.003, -1.001, 0.0, -0.003, -1.0, -1.001, -1.0, -1.001, -1.008, -1.001, -0.001, -1.002, -1.001, -1.002, -1.0, 0.48, -0.04900000000000004, -1.001, -1.001, -1.013, -1.003, -0.001, -1.0, -1.002, -1.001, -1.006, -1.0, -1.002, -1.003, -1.001, -0.004, -1.001, -0.004, -0.004, -1.002, 0.904, -1.001, -1.002, -0.501, -1.003, -1.001, -1.0, -1.003, 0.0, -1.003, -1.001, -1.003, -1.001, -1.0019999999999998, 0.808, 0.44999999999999996, -0.04900000000000004, 0.968, -1.001, 0.962, -1.001, -1.003, -1.002, -1.003, -1.01, 0.0, -1.001, -1.003, -1.001, -1.003, -1.001, -1.001, 0.473, -0.002, -0.003, -1.001, -1.001, -1.001, -1.002, -1.002, -0.001, 0.882, -0.003, -1.0039999999999998, -0.007, 0.0, -0.5059999999999999, -1.001, -1.005, 0.496, -0.002, -1.0039999999999998, -1.003, -1.005, -1.0019999999999998, 0.9339999999999999, -0.001, -1.001, -0.004, -1.011, -1.001, -0.003, -0.001, -0.002, -0.047000000000000035, -1.004, -1.002, -0.502, -0.03200000000000002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24778091357892015, "mean_inference_ms": 1.4783000557119346, "mean_action_processing_ms": 0.06326607176009162, "mean_env_wait_ms": 0.08904800795048558, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022031454478993136, "StateBufferConnector_ms": 0.0014950247371897979, "ViewRequirementAgentConnector_ms": 0.032672198379740995}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000, "num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.69555874574009, "num_env_steps_trained_throughput_per_sec": 102.69555874574009, "timesteps_total": 260000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 520000, "timers": {"training_iteration_time_ms": 38932.486, "sample_time_ms": 7578.013, "learn_time_ms": 31337.098, "learn_throughput": 127.644, "synch_weights_time_ms": 16.864}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 260000, "num_agent_steps_sampled": 520000, "num_agent_steps_trained": 520000}, "done": false, "episodes_total": 8186, "training_iteration": 65, "trial_id": "d67e4_00000", "date": "2023-09-20_22-51-32", "timestamp": 1695264692, "time_this_iter_s": 38.956056118011475, "time_total_s": 2529.430008649826, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d095fc0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2529.430008649826, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 34.512499999999996, "ram_util_percent": 50.19464285714285}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.22330097087378642, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6990291262135923, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04854368932038835, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6990291262135923, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04854368932038835, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6990291262135923, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04854368932038835, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.882940574393918, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009387251773902486, "policy_loss": -0.014976541670997297, "vf_loss": 0.005684893503591108, "vf_explained_var": 0.7473471793656548, "kl": 0.007221807570729874, "entropy": 0.5029701995352904, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 62880.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "sampler_results": {"episode_reward_max": 1.9489999999999998, "episode_reward_min": -0.40700000000000014, "episode_reward_mean": 0.6136796116504853, "episode_len_mean": 33.36893203883495, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.972}, "policy_reward_mean": {"red_0": 1.2383009708737867, "blue_0": -0.624621359223301}, "custom_metrics": {"red_0/door_open_done_mean": 0.22330097087378642, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6990291262135923, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.04854368932038835, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6990291262135923, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.04854368932038835, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6990291262135923, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.04854368932038835, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [-0.04100000000000003, 0.45100000000000007, 0.8580000000000001, 0.46499999999999986, -0.025000000000000022, 1.409, 0.46399999999999997, 0.46899999999999986, 1.456, 0.8029999999999999, -0.251, 0.365, 1.9489999999999998, 0.45799999999999996, 0.472, 0.4630000000000001, 0.4660000000000002, 1.448, 0.44300000000000006, 0.43700000000000006, 0.45199999999999996, 0.47299999999999986, 0.45999999999999996, 0.46199999999999997, 0.472, 1.424, 0.44999999999999996, 0.46199999999999997, 1.927, 1.357, 0.43599999999999994, -0.039000000000000035, 0.469, 1.46, -0.40700000000000014, 0.46899999999999986, 0.27700000000000014, 0.46199999999999997, 0.44300000000000006, 0.46199999999999997, 0.44199999999999995, 0.45699999999999985, 0.43199999999999994, -0.04800000000000004, 0.42200000000000015, 0.3809999999999999, 1.443, 1.4409999999999998, 0.45500000000000007, 1.451, 1.4609999999999999, 0.46099999999999997, -0.18799999999999994, -0.03599999999999992, -0.10799999999999998, 0.4630000000000001, 0.45500000000000007, 0.45999999999999996, 0.923, 1.436, 0.4670000000000001, 0.4630000000000001, 0.4159999999999999, -0.027999999999999914, 0.45399999999999996, 0.4590000000000001, -0.15600000000000003, 0.45799999999999996, 0.40600000000000014, 1.4489999999999998, 1.454, 0.46399999999999997, 0.45599999999999996, 0.46399999999999997, 0.45100000000000007, 0.349, 0.46199999999999997, -0.04500000000000004, 0.4630000000000001, 0.10400000000000009, -0.08899999999999997, 0.9550000000000001, 1.446, 0.389, 1.459, 1.4489999999999998, -0.06900000000000006, 0.4620000000000002, 0.47, 0.46499999999999986, 0.277, 1.4500000000000002, 0.44799999999999995, 0.43999999999999995, 0.45599999999999996, 1.4540000000000002, 0.45999999999999996, 1.4300000000000002, 0.2959999999999998, 0.45799999999999996, 1.4569999999999999, 1.448, 0.45500000000000007], "episode_lengths": [300, 15, 46, 11, 8, 29, 12, 10, 14, 62, 76, 43, 17, 13, 9, 12, 11, 16, 19, 20, 14, 9, 13, 12, 9, 24, 15, 12, 24, 43, 21, 12, 10, 13, 273, 10, 70, 12, 17, 12, 19, 14, 300, 15, 25, 300, 18, 18, 14, 15, 13, 13, 58, 11, 35, 11, 14, 13, 25, 20, 11, 12, 27, 9, 14, 13, 51, 13, 30, 16, 15, 12, 14, 12, 16, 47, 12, 14, 12, 275, 28, 14, 17, 36, 13, 17, 21, 12, 10, 11, 72, 16, 17, 19, 14, 15, 13, 23, 67, 13, 14, 17, 14], "policy_red_0_reward": [-0.001, 1.455, 1.362, 1.467, 0.976, 1.413, 1.464, 1.47, 1.458, 1.312, 0.759, 1.3679999999999999, 1.4489999999999998, 1.4609999999999999, 1.4729999999999999, 1.464, 1.467, 1.452, 1.443, 1.44, 1.4529999999999998, 1.4729999999999999, 1.4609999999999999, 1.464, 1.4729999999999999, 1.428, 1.455, 1.464, 1.428, 1.3679999999999999, 1.4369999999999998, 0.964, -0.5, 1.4609999999999999, 0.6379999999999999, 1.47, 1.286, 1.464, 1.4489999999999998, 1.464, 1.443, 1.458, 0.479, 0.955, 1.425, 0.42099999999999993, 1.446, 1.446, 1.458, 1.455, 1.4609999999999999, -0.5, 0.8200000000000001, 0.967, 0.895, 1.467, 1.458, 1.4609999999999999, 1.425, 1.44, 1.467, 1.464, 1.419, -1.0, 1.458, 1.4609999999999999, 0.846, 1.4609999999999999, 1.409, 1.452, 1.455, 1.464, 1.458, 1.464, 1.452, 1.359, 1.464, 0.956, 1.464, 0.645, 0.916, 1.458, 1.4489999999999998, 1.391, 1.4609999999999999, 1.4489999999999998, -1.0, 1.464, 1.47, 1.467, -0.5, 1.452, 1.4489999999999998, 1.443, 1.458, 1.455, 1.4609999999999999, 1.4300000000000002, 1.298, 1.4609999999999999, 1.458, 1.4489999999999998, 1.456], "policy_blue_0_reward": [-0.04000000000000003, -1.004, -0.504, -1.002, -1.001, -0.004, -1.0, -1.001, -0.002, -0.509, -1.01, -1.003, 0.5, -1.003, -1.001, -1.001, -1.001, -0.004, -1.0, -1.003, -1.001, -1.0, -1.001, -1.002, -1.001, -0.004, -1.005, -1.002, 0.499, -0.011000000000000003, -1.001, -1.003, 0.969, -0.001, -1.045, -1.001, -1.009, -1.002, -1.006, -1.002, -1.001, -1.001, -0.047000000000000035, -1.003, -1.003, -0.04000000000000003, -0.003, -0.005, -1.003, -0.004, 0.0, 0.961, -1.008, -1.003, -1.003, -1.0039999999999998, -1.003, -1.001, -0.502, -0.004, -1.0, -1.001, -1.003, 0.972, -1.004, -1.0019999999999998, -1.002, -1.003, -1.003, -0.003, -0.001, -1.0, -1.002, -1.0, -1.001, -1.01, -1.002, -1.001, -1.001, -0.541, -1.005, -0.503, -0.003, -1.002, -0.002, 0.0, 0.9309999999999999, -1.0019999999999998, -1.0, -1.002, 0.777, -0.002, -1.001, -1.003, -1.0019999999999998, -0.001, -1.001, 0.0, -1.002, -1.003, -0.001, -0.001, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24702636505389225, "mean_inference_ms": 1.4757117740289494, "mean_action_processing_ms": 0.06303796497082657, "mean_env_wait_ms": 0.08875066158847493, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022480557265790922, "StateBufferConnector_ms": 0.0014946298691832904, "ViewRequirementAgentConnector_ms": 0.03234124878077831}}, "episode_reward_max": 1.9489999999999998, "episode_reward_min": -0.40700000000000014, "episode_reward_mean": 0.6136796116504853, "episode_len_mean": 33.36893203883495, "episodes_this_iter": 103, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.045}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.972}, "policy_reward_mean": {"red_0": 1.2383009708737867, "blue_0": -0.624621359223301}, "hist_stats": {"episode_reward": [-0.04100000000000003, 0.45100000000000007, 0.8580000000000001, 0.46499999999999986, -0.025000000000000022, 1.409, 0.46399999999999997, 0.46899999999999986, 1.456, 0.8029999999999999, -0.251, 0.365, 1.9489999999999998, 0.45799999999999996, 0.472, 0.4630000000000001, 0.4660000000000002, 1.448, 0.44300000000000006, 0.43700000000000006, 0.45199999999999996, 0.47299999999999986, 0.45999999999999996, 0.46199999999999997, 0.472, 1.424, 0.44999999999999996, 0.46199999999999997, 1.927, 1.357, 0.43599999999999994, -0.039000000000000035, 0.469, 1.46, -0.40700000000000014, 0.46899999999999986, 0.27700000000000014, 0.46199999999999997, 0.44300000000000006, 0.46199999999999997, 0.44199999999999995, 0.45699999999999985, 0.43199999999999994, -0.04800000000000004, 0.42200000000000015, 0.3809999999999999, 1.443, 1.4409999999999998, 0.45500000000000007, 1.451, 1.4609999999999999, 0.46099999999999997, -0.18799999999999994, -0.03599999999999992, -0.10799999999999998, 0.4630000000000001, 0.45500000000000007, 0.45999999999999996, 0.923, 1.436, 0.4670000000000001, 0.4630000000000001, 0.4159999999999999, -0.027999999999999914, 0.45399999999999996, 0.4590000000000001, -0.15600000000000003, 0.45799999999999996, 0.40600000000000014, 1.4489999999999998, 1.454, 0.46399999999999997, 0.45599999999999996, 0.46399999999999997, 0.45100000000000007, 0.349, 0.46199999999999997, -0.04500000000000004, 0.4630000000000001, 0.10400000000000009, -0.08899999999999997, 0.9550000000000001, 1.446, 0.389, 1.459, 1.4489999999999998, -0.06900000000000006, 0.4620000000000002, 0.47, 0.46499999999999986, 0.277, 1.4500000000000002, 0.44799999999999995, 0.43999999999999995, 0.45599999999999996, 1.4540000000000002, 0.45999999999999996, 1.4300000000000002, 0.2959999999999998, 0.45799999999999996, 1.4569999999999999, 1.448, 0.45500000000000007], "episode_lengths": [300, 15, 46, 11, 8, 29, 12, 10, 14, 62, 76, 43, 17, 13, 9, 12, 11, 16, 19, 20, 14, 9, 13, 12, 9, 24, 15, 12, 24, 43, 21, 12, 10, 13, 273, 10, 70, 12, 17, 12, 19, 14, 300, 15, 25, 300, 18, 18, 14, 15, 13, 13, 58, 11, 35, 11, 14, 13, 25, 20, 11, 12, 27, 9, 14, 13, 51, 13, 30, 16, 15, 12, 14, 12, 16, 47, 12, 14, 12, 275, 28, 14, 17, 36, 13, 17, 21, 12, 10, 11, 72, 16, 17, 19, 14, 15, 13, 23, 67, 13, 14, 17, 14], "policy_red_0_reward": [-0.001, 1.455, 1.362, 1.467, 0.976, 1.413, 1.464, 1.47, 1.458, 1.312, 0.759, 1.3679999999999999, 1.4489999999999998, 1.4609999999999999, 1.4729999999999999, 1.464, 1.467, 1.452, 1.443, 1.44, 1.4529999999999998, 1.4729999999999999, 1.4609999999999999, 1.464, 1.4729999999999999, 1.428, 1.455, 1.464, 1.428, 1.3679999999999999, 1.4369999999999998, 0.964, -0.5, 1.4609999999999999, 0.6379999999999999, 1.47, 1.286, 1.464, 1.4489999999999998, 1.464, 1.443, 1.458, 0.479, 0.955, 1.425, 0.42099999999999993, 1.446, 1.446, 1.458, 1.455, 1.4609999999999999, -0.5, 0.8200000000000001, 0.967, 0.895, 1.467, 1.458, 1.4609999999999999, 1.425, 1.44, 1.467, 1.464, 1.419, -1.0, 1.458, 1.4609999999999999, 0.846, 1.4609999999999999, 1.409, 1.452, 1.455, 1.464, 1.458, 1.464, 1.452, 1.359, 1.464, 0.956, 1.464, 0.645, 0.916, 1.458, 1.4489999999999998, 1.391, 1.4609999999999999, 1.4489999999999998, -1.0, 1.464, 1.47, 1.467, -0.5, 1.452, 1.4489999999999998, 1.443, 1.458, 1.455, 1.4609999999999999, 1.4300000000000002, 1.298, 1.4609999999999999, 1.458, 1.4489999999999998, 1.456], "policy_blue_0_reward": [-0.04000000000000003, -1.004, -0.504, -1.002, -1.001, -0.004, -1.0, -1.001, -0.002, -0.509, -1.01, -1.003, 0.5, -1.003, -1.001, -1.001, -1.001, -0.004, -1.0, -1.003, -1.001, -1.0, -1.001, -1.002, -1.001, -0.004, -1.005, -1.002, 0.499, -0.011000000000000003, -1.001, -1.003, 0.969, -0.001, -1.045, -1.001, -1.009, -1.002, -1.006, -1.002, -1.001, -1.001, -0.047000000000000035, -1.003, -1.003, -0.04000000000000003, -0.003, -0.005, -1.003, -0.004, 0.0, 0.961, -1.008, -1.003, -1.003, -1.0039999999999998, -1.003, -1.001, -0.502, -0.004, -1.0, -1.001, -1.003, 0.972, -1.004, -1.0019999999999998, -1.002, -1.003, -1.003, -0.003, -0.001, -1.0, -1.002, -1.0, -1.001, -1.01, -1.002, -1.001, -1.001, -0.541, -1.005, -0.503, -0.003, -1.002, -0.002, 0.0, 0.9309999999999999, -1.0019999999999998, -1.0, -1.002, 0.777, -0.002, -1.001, -1.003, -1.0019999999999998, -0.001, -1.001, 0.0, -1.002, -1.003, -0.001, -0.001, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24702636505389225, "mean_inference_ms": 1.4757117740289494, "mean_action_processing_ms": 0.06303796497082657, "mean_env_wait_ms": 0.08875066158847493, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022480557265790922, "StateBufferConnector_ms": 0.0014946298691832904, "ViewRequirementAgentConnector_ms": 0.03234124878077831}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000, "num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.88534263944021, "num_env_steps_trained_throughput_per_sec": 102.88534263944021, "timesteps_total": 264000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 528000, "timers": {"training_iteration_time_ms": 38935.641, "sample_time_ms": 7568.628, "learn_time_ms": 31349.662, "learn_throughput": 127.593, "synch_weights_time_ms": 16.848}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 264000, "num_agent_steps_sampled": 528000, "num_agent_steps_trained": 528000}, "done": false, "episodes_total": 8289, "training_iteration": 66, "trial_id": "d67e4_00000", "date": "2023-09-20_22-52-12", "timestamp": 1695264732, "time_this_iter_s": 38.883167028427124, "time_total_s": 2568.313175678253, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a68797e0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2568.313175678253, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 33.92545454545454, "ram_util_percent": 50.198181818181794}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.23376623376623376, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6948051948051948, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05844155844155844, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6948051948051948, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.05844155844155844, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6948051948051948, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05844155844155844, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.175706950078408, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009798454538455795, "policy_loss": -0.01680836157417313, "vf_loss": 0.008387186389882118, "vf_explained_var": 0.7401762340217829, "kl": 0.00726425223509243, "entropy": 0.45259926638876397, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 63840.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "sampler_results": {"episode_reward_max": 1.958, "episode_reward_min": -0.776, "episode_reward_mean": 0.665948051948052, "episode_len_mean": 29.09090909090909, "episode_media": {}, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.0279999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.981}, "policy_reward_mean": {"red_0": 1.2706103896103897, "blue_0": -0.6046623376623377}, "custom_metrics": {"red_0/door_open_done_mean": 0.23376623376623376, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6948051948051948, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.05844155844155844, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6948051948051948, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.05844155844155844, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6948051948051948, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.05844155844155844, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.32099999999999995, 0.46099999999999985, 0.46599999999999997, 0.44399999999999995, 0.4590000000000001, 0.45599999999999996, 0.4660000000000002, 1.95, 1.455, -0.039000000000000035, 0.4710000000000001, 0.45100000000000007, 1.46, 0.45199999999999996, 0.46599999999999997, 0.46099999999999985, 0.45500000000000007, 0.3540000000000001, 0.4630000000000001, 0.45199999999999996, 0.4670000000000001, 0.44199999999999995, 0.567, 0.46599999999999997, 0.46899999999999986, 0.46399999999999997, 0.45500000000000007, 0.42299999999999993, 0.351, 1.4260000000000002, -0.03600000000000003, 1.443, 0.45599999999999996, 0.4590000000000001, 0.46899999999999986, 0.46799999999999997, 1.4500000000000002, 0.2450000000000001, 0.28, 0.45999999999999996, -0.253, 0.44300000000000006, 0.44799999999999995, 0.9569999999999999, 0.44700000000000006, 0.44599999999999995, 0.919, 1.271, 1.3319999999999999, 0.44999999999999996, 0.46399999999999997, 0.44799999999999995, 0.4630000000000001, 0.46799999999999997, 0.45699999999999985, 0.833, 0.4670000000000001, 0.45999999999999996, -0.03300000000000003, 0.46799999999999997, 1.443, 0.46399999999999997, 0.45299999999999985, 0.43199999999999994, 0.46599999999999997, 0.43500000000000005, 0.4590000000000001, 0.476, 1.399, 0.46399999999999997, 0.47, 0.4670000000000001, 1.958, 0.46599999999999997, 0.46099999999999985, 1.431, 0.4690000000000001, 0.46499999999999986, 1.279, 0.44499999999999984, 0.473, 1.4609999999999999, 1.4609999999999999, 0.391, 1.9489999999999998, 1.385, 0.4630000000000001, 0.46599999999999997, 1.4529999999999998, 0.3679999999999999, 0.45299999999999996, 0.45699999999999985, 0.45999999999999996, -0.08299999999999985, 0.45500000000000007, 0.44799999999999995, 1.4409999999999998, 0.9159999999999999, 1.444, 0.45299999999999985, 0.4670000000000001, 0.44399999999999995, 0.44599999999999995, 0.47, 1.9529999999999998, 1.45, -0.776, 1.443, 1.436, 0.42699999999999994, 0.45999999999999996, 0.45799999999999996, 0.45100000000000007, 0.46599999999999997, -0.3779999999999999, 0.958, 1.304, 0.476, 1.46, 0.44300000000000006, 0.46599999999999997, 0.47299999999999986, 0.44599999999999995, 1.454, 0.4750000000000001, 0.481, 0.4630000000000001, 0.9349999999999999, 1.458, 0.4630000000000001, 0.35599999999999987, 1.439, 1.46, -0.049000000000000044, 0.94, 0.46899999999999986, 1.459, 0.42399999999999993, 0.391, 0.43999999999999995, 1.45, 0.45699999999999985, -0.03300000000000003, 1.4369999999999998, 1.448, 0.4670000000000001, 1.46, 1.452, 0.43299999999999994, 0.43500000000000005, -0.254, -0.04700000000000004, 0.2709999999999999, 0.45999999999999996], "episode_lengths": [54, 12, 11, 18, 13, 14, 11, 16, 14, 12, 9, 16, 13, 15, 11, 13, 14, 44, 12, 16, 11, 18, 134, 11, 10, 12, 14, 24, 44, 23, 12, 18, 14, 13, 10, 10, 15, 76, 66, 13, 236, 18, 16, 14, 17, 17, 26, 73, 51, 16, 12, 17, 12, 10, 13, 54, 10, 13, 11, 10, 19, 11, 15, 20, 11, 20, 13, 8, 31, 12, 10, 11, 13, 11, 12, 22, 10, 11, 71, 17, 9, 13, 13, 34, 17, 37, 12, 11, 15, 36, 15, 14, 12, 184, 14, 17, 19, 26, 18, 15, 10, 18, 17, 10, 15, 16, 246, 18, 20, 300, 13, 13, 15, 11, 121, 14, 62, 8, 13, 18, 11, 9, 17, 15, 8, 6, 12, 300, 13, 12, 42, 19, 13, 16, 19, 10, 13, 25, 34, 19, 16, 14, 11, 21, 16, 10, 13, 15, 22, 182, 78, 15, 72, 13], "policy_red_0_reward": [-0.506, 1.464, 1.467, 1.446, 1.4609999999999999, 1.458, 1.467, 1.452, 1.458, 0.962, 1.4729999999999999, 1.452, 1.4609999999999999, 1.455, 1.467, 1.4609999999999999, 1.458, 1.363, 1.464, 0.952, 1.467, 1.446, 1.084, 1.467, 1.47, 1.464, 1.458, -0.504, 1.358, 1.431, 0.964, 1.446, 1.458, 1.4609999999999999, 1.47, 1.47, 1.455, 1.252, 1.29, 1.4609999999999999, 0.773, 1.446, 1.452, 1.458, 1.4489999999999998, 1.4489999999999998, 1.4220000000000002, 1.277, 1.343, 1.452, 1.464, 1.4489999999999998, 1.464, 1.47, 1.4609999999999999, 1.337, 1.47, 1.4609999999999999, 0.967, -0.5, 1.443, 1.467, 1.455, 1.439, 1.467, 1.44, 1.4609999999999999, 1.476, 1.401, 1.464, 1.47, 1.467, 1.4609999999999999, 1.467, 1.464, 1.434, 1.47, 1.467, 1.286, 1.4489999999999998, -0.5, 1.4609999999999999, 1.4609999999999999, 1.397, 1.4489999999999998, 1.389, 1.464, 1.467, 1.455, 1.37, -0.501, 1.458, 1.464, 0.9450000000000001, 1.458, 1.4489999999999998, 1.443, 1.4220000000000002, 1.446, 1.455, 1.47, 1.446, 1.4489999999999998, 1.47, 1.455, 1.452, -1.005, 1.446, 1.44, 0.476, 1.4609999999999999, 1.4609999999999999, 1.454, 1.467, -1.0, 1.458, 1.3130000000000002, 1.476, 1.4609999999999999, 1.446, 1.467, 1.4729999999999999, 1.448, 1.455, 1.476, -0.5, 1.464, 0.485, 1.4609999999999999, 1.464, 1.359, 1.443, 1.4609999999999999, 0.952, 1.443, 1.47, 1.4609999999999999, 1.425, 1.397, 1.443, 1.452, 1.458, 0.967, 1.4369999999999998, 1.452, 1.47, 1.4609999999999999, 1.455, -0.5, 0.949, 0.765, 0.954, 1.283, 1.4609999999999999], "policy_blue_0_reward": [0.827, -1.003, -1.001, -1.002, -1.002, -1.002, -1.001, 0.498, -0.003, -1.001, -1.002, -1.001, -0.001, -1.003, -1.001, -1.0, -1.003, -1.009, -1.001, -0.5, -1.0, -1.004, -0.517, -1.001, -1.001, -1.0, -1.003, 0.9269999999999999, -1.007, -0.005, -1.0, -0.003, -1.002, -1.002, -1.001, -1.002, -0.005, -1.007, -1.01, -1.001, -1.026, -1.003, -1.004, -0.501, -1.002, -1.003, -0.503, -0.006, -0.011000000000000003, -1.002, -1.0, -1.001, -1.001, -1.002, -1.004, -0.504, -1.003, -1.001, -1.0, 0.968, 0.0, -1.003, -1.002, -1.007, -1.001, -1.005, -1.002, -1.0, -0.002, -1.0, -1.0, -1.0, 0.497, -1.001, -1.003, -0.003, -1.001, -1.002, -0.007, -1.004, 0.973, 0.0, 0.0, -1.006, 0.5, -0.004, -1.001, -1.001, -0.002, -1.002, 0.954, -1.001, -1.004, -1.0279999999999998, -1.003, -1.001, -0.002, -0.506, -0.002, -1.002, -1.003, -1.0019999999999998, -1.003, -1.0, 0.498, -0.002, 0.22899999999999998, -0.003, -0.004, -0.04900000000000004, -1.001, -1.003, -1.003, -1.001, 0.622, -0.5, -0.009000000000000001, -1.0, -0.001, -1.003, -1.001, -1.0, -1.002, -0.001, -1.001, 0.981, -1.001, 0.44999999999999996, -0.003, -1.001, -1.003, -0.004, -0.001, -1.001, -0.503, -1.001, -0.002, -1.001, -1.006, -1.003, -0.002, -1.001, -1.0, 0.0, -0.004, -1.003, -0.001, -0.003, 0.9329999999999999, -0.5139999999999999, -1.019, -1.001, -1.012, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24787374447039515, "mean_inference_ms": 1.476896681391875, "mean_action_processing_ms": 0.0632034632628307, "mean_env_wait_ms": 0.08896546041136427, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021830317261931183, "StateBufferConnector_ms": 0.0014791240939846287, "ViewRequirementAgentConnector_ms": 0.03238908656231769}}, "episode_reward_max": 1.958, "episode_reward_min": -0.776, "episode_reward_mean": 0.665948051948052, "episode_len_mean": 29.09090909090909, "episodes_this_iter": 154, "policy_reward_min": {"red_0": -1.005, "blue_0": -1.0279999999999998}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.981}, "policy_reward_mean": {"red_0": 1.2706103896103897, "blue_0": -0.6046623376623377}, "hist_stats": {"episode_reward": [0.32099999999999995, 0.46099999999999985, 0.46599999999999997, 0.44399999999999995, 0.4590000000000001, 0.45599999999999996, 0.4660000000000002, 1.95, 1.455, -0.039000000000000035, 0.4710000000000001, 0.45100000000000007, 1.46, 0.45199999999999996, 0.46599999999999997, 0.46099999999999985, 0.45500000000000007, 0.3540000000000001, 0.4630000000000001, 0.45199999999999996, 0.4670000000000001, 0.44199999999999995, 0.567, 0.46599999999999997, 0.46899999999999986, 0.46399999999999997, 0.45500000000000007, 0.42299999999999993, 0.351, 1.4260000000000002, -0.03600000000000003, 1.443, 0.45599999999999996, 0.4590000000000001, 0.46899999999999986, 0.46799999999999997, 1.4500000000000002, 0.2450000000000001, 0.28, 0.45999999999999996, -0.253, 0.44300000000000006, 0.44799999999999995, 0.9569999999999999, 0.44700000000000006, 0.44599999999999995, 0.919, 1.271, 1.3319999999999999, 0.44999999999999996, 0.46399999999999997, 0.44799999999999995, 0.4630000000000001, 0.46799999999999997, 0.45699999999999985, 0.833, 0.4670000000000001, 0.45999999999999996, -0.03300000000000003, 0.46799999999999997, 1.443, 0.46399999999999997, 0.45299999999999985, 0.43199999999999994, 0.46599999999999997, 0.43500000000000005, 0.4590000000000001, 0.476, 1.399, 0.46399999999999997, 0.47, 0.4670000000000001, 1.958, 0.46599999999999997, 0.46099999999999985, 1.431, 0.4690000000000001, 0.46499999999999986, 1.279, 0.44499999999999984, 0.473, 1.4609999999999999, 1.4609999999999999, 0.391, 1.9489999999999998, 1.385, 0.4630000000000001, 0.46599999999999997, 1.4529999999999998, 0.3679999999999999, 0.45299999999999996, 0.45699999999999985, 0.45999999999999996, -0.08299999999999985, 0.45500000000000007, 0.44799999999999995, 1.4409999999999998, 0.9159999999999999, 1.444, 0.45299999999999985, 0.4670000000000001, 0.44399999999999995, 0.44599999999999995, 0.47, 1.9529999999999998, 1.45, -0.776, 1.443, 1.436, 0.42699999999999994, 0.45999999999999996, 0.45799999999999996, 0.45100000000000007, 0.46599999999999997, -0.3779999999999999, 0.958, 1.304, 0.476, 1.46, 0.44300000000000006, 0.46599999999999997, 0.47299999999999986, 0.44599999999999995, 1.454, 0.4750000000000001, 0.481, 0.4630000000000001, 0.9349999999999999, 1.458, 0.4630000000000001, 0.35599999999999987, 1.439, 1.46, -0.049000000000000044, 0.94, 0.46899999999999986, 1.459, 0.42399999999999993, 0.391, 0.43999999999999995, 1.45, 0.45699999999999985, -0.03300000000000003, 1.4369999999999998, 1.448, 0.4670000000000001, 1.46, 1.452, 0.43299999999999994, 0.43500000000000005, -0.254, -0.04700000000000004, 0.2709999999999999, 0.45999999999999996], "episode_lengths": [54, 12, 11, 18, 13, 14, 11, 16, 14, 12, 9, 16, 13, 15, 11, 13, 14, 44, 12, 16, 11, 18, 134, 11, 10, 12, 14, 24, 44, 23, 12, 18, 14, 13, 10, 10, 15, 76, 66, 13, 236, 18, 16, 14, 17, 17, 26, 73, 51, 16, 12, 17, 12, 10, 13, 54, 10, 13, 11, 10, 19, 11, 15, 20, 11, 20, 13, 8, 31, 12, 10, 11, 13, 11, 12, 22, 10, 11, 71, 17, 9, 13, 13, 34, 17, 37, 12, 11, 15, 36, 15, 14, 12, 184, 14, 17, 19, 26, 18, 15, 10, 18, 17, 10, 15, 16, 246, 18, 20, 300, 13, 13, 15, 11, 121, 14, 62, 8, 13, 18, 11, 9, 17, 15, 8, 6, 12, 300, 13, 12, 42, 19, 13, 16, 19, 10, 13, 25, 34, 19, 16, 14, 11, 21, 16, 10, 13, 15, 22, 182, 78, 15, 72, 13], "policy_red_0_reward": [-0.506, 1.464, 1.467, 1.446, 1.4609999999999999, 1.458, 1.467, 1.452, 1.458, 0.962, 1.4729999999999999, 1.452, 1.4609999999999999, 1.455, 1.467, 1.4609999999999999, 1.458, 1.363, 1.464, 0.952, 1.467, 1.446, 1.084, 1.467, 1.47, 1.464, 1.458, -0.504, 1.358, 1.431, 0.964, 1.446, 1.458, 1.4609999999999999, 1.47, 1.47, 1.455, 1.252, 1.29, 1.4609999999999999, 0.773, 1.446, 1.452, 1.458, 1.4489999999999998, 1.4489999999999998, 1.4220000000000002, 1.277, 1.343, 1.452, 1.464, 1.4489999999999998, 1.464, 1.47, 1.4609999999999999, 1.337, 1.47, 1.4609999999999999, 0.967, -0.5, 1.443, 1.467, 1.455, 1.439, 1.467, 1.44, 1.4609999999999999, 1.476, 1.401, 1.464, 1.47, 1.467, 1.4609999999999999, 1.467, 1.464, 1.434, 1.47, 1.467, 1.286, 1.4489999999999998, -0.5, 1.4609999999999999, 1.4609999999999999, 1.397, 1.4489999999999998, 1.389, 1.464, 1.467, 1.455, 1.37, -0.501, 1.458, 1.464, 0.9450000000000001, 1.458, 1.4489999999999998, 1.443, 1.4220000000000002, 1.446, 1.455, 1.47, 1.446, 1.4489999999999998, 1.47, 1.455, 1.452, -1.005, 1.446, 1.44, 0.476, 1.4609999999999999, 1.4609999999999999, 1.454, 1.467, -1.0, 1.458, 1.3130000000000002, 1.476, 1.4609999999999999, 1.446, 1.467, 1.4729999999999999, 1.448, 1.455, 1.476, -0.5, 1.464, 0.485, 1.4609999999999999, 1.464, 1.359, 1.443, 1.4609999999999999, 0.952, 1.443, 1.47, 1.4609999999999999, 1.425, 1.397, 1.443, 1.452, 1.458, 0.967, 1.4369999999999998, 1.452, 1.47, 1.4609999999999999, 1.455, -0.5, 0.949, 0.765, 0.954, 1.283, 1.4609999999999999], "policy_blue_0_reward": [0.827, -1.003, -1.001, -1.002, -1.002, -1.002, -1.001, 0.498, -0.003, -1.001, -1.002, -1.001, -0.001, -1.003, -1.001, -1.0, -1.003, -1.009, -1.001, -0.5, -1.0, -1.004, -0.517, -1.001, -1.001, -1.0, -1.003, 0.9269999999999999, -1.007, -0.005, -1.0, -0.003, -1.002, -1.002, -1.001, -1.002, -0.005, -1.007, -1.01, -1.001, -1.026, -1.003, -1.004, -0.501, -1.002, -1.003, -0.503, -0.006, -0.011000000000000003, -1.002, -1.0, -1.001, -1.001, -1.002, -1.004, -0.504, -1.003, -1.001, -1.0, 0.968, 0.0, -1.003, -1.002, -1.007, -1.001, -1.005, -1.002, -1.0, -0.002, -1.0, -1.0, -1.0, 0.497, -1.001, -1.003, -0.003, -1.001, -1.002, -0.007, -1.004, 0.973, 0.0, 0.0, -1.006, 0.5, -0.004, -1.001, -1.001, -0.002, -1.002, 0.954, -1.001, -1.004, -1.0279999999999998, -1.003, -1.001, -0.002, -0.506, -0.002, -1.002, -1.003, -1.0019999999999998, -1.003, -1.0, 0.498, -0.002, 0.22899999999999998, -0.003, -0.004, -0.04900000000000004, -1.001, -1.003, -1.003, -1.001, 0.622, -0.5, -0.009000000000000001, -1.0, -0.001, -1.003, -1.001, -1.0, -1.002, -0.001, -1.001, 0.981, -1.001, 0.44999999999999996, -0.003, -1.001, -1.003, -0.004, -0.001, -1.001, -0.503, -1.001, -0.002, -1.001, -1.006, -1.003, -0.002, -1.001, -1.0, 0.0, -0.004, -1.003, -0.001, -0.003, 0.9329999999999999, -0.5139999999999999, -1.019, -1.001, -1.012, -1.001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24787374447039515, "mean_inference_ms": 1.476896681391875, "mean_action_processing_ms": 0.0632034632628307, "mean_env_wait_ms": 0.08896546041136427, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021830317261931183, "StateBufferConnector_ms": 0.0014791240939846287, "ViewRequirementAgentConnector_ms": 0.03238908656231769}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000, "num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.05982315660833, "num_env_steps_trained_throughput_per_sec": 103.05982315660833, "timesteps_total": 268000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 536000, "timers": {"training_iteration_time_ms": 38930.338, "sample_time_ms": 7560.636, "learn_time_ms": 31352.37, "learn_throughput": 127.582, "synch_weights_time_ms": 16.832}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 268000, "num_agent_steps_sampled": 536000, "num_agent_steps_trained": 536000}, "done": false, "episodes_total": 8443, "training_iteration": 67, "trial_id": "d67e4_00000", "date": "2023-09-20_22-52-51", "timestamp": 1695264771, "time_this_iter_s": 38.81898093223572, "time_total_s": 2607.132156610489, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d094940>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2607.132156610489, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 34.85178571428572, "ram_util_percent": 50.21071428571428}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.2692307692307692, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6346153846153846, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.057692307692307696, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6346153846153846, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.057692307692307696, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6346153846153846, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.057692307692307696, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9276453996387621, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009617459290893748, "policy_loss": -0.014889791231083412, "vf_loss": 0.005665667053411501, "vf_explained_var": 0.7917847475657861, "kl": 0.006582011800163542, "entropy": 0.5224071175791323, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 64800.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "sampler_results": {"episode_reward_max": 1.9529999999999998, "episode_reward_min": -0.44599999999999995, "episode_reward_mean": 0.6976442307692307, "episode_len_mean": 34.25961538461539, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"red_0": -0.5079999999999999, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.968}, "policy_reward_mean": {"red_0": 1.264548076923077, "blue_0": -0.566903846153846}, "custom_metrics": {"red_0/door_open_done_mean": 0.2692307692307692, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6346153846153846, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.057692307692307696, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6346153846153846, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.057692307692307696, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6346153846153846, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.057692307692307696, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [1.6440000000000001, 0.45799999999999996, 0.4750000000000001, 0.45500000000000007, 1.9529999999999998, 0.46799999999999997, 0.4540000000000002, 0.41300000000000003, 0.45999999999999996, 1.432, 1.4569999999999999, 0.44099999999999984, 0.8339999999999999, 1.4449999999999998, 0.44999999999999996, 1.446, 1.452, 1.946, 1.447, 1.45, 0.46199999999999997, 1.4489999999999998, 0.381, 0.46099999999999985, 0.45199999999999996, 0.46399999999999997, 0.476, 0.46599999999999997, 1.434, 0.45999999999999996, 0.46099999999999985, 0.46899999999999986, 0.476, 1.447, 0.45799999999999996, 0.47, 0.4750000000000001, 1.421, 1.4580000000000002, 0.44199999999999995, 1.436, 0.4590000000000001, 0.45799999999999996, -0.44599999999999995, 0.46599999999999997, 0.34999999999999987, 0.43399999999999994, 0.8969999999999999, 1.452, 1.4100000000000001, 0.44300000000000006, 0.46899999999999986, 0.4630000000000001, 0.46399999999999997, 1.457, 0.17799999999999994, 0.47299999999999986, -0.052000000000000046, 0.46599999999999997, 0.46599999999999997, 0.43999999999999995, 0.44799999999999995, 0.21799999999999997, -0.036000000000000025, 1.447, 1.424, 1.4569999999999999, 1.447, 0.349, 1.458, 0.47, -0.137, 0.45999999999999996, 0.472, 1.452, 0.4670000000000001, -0.061000000000000054, 0.46099999999999985, 0.4670000000000001, 0.4630000000000001, 0.46799999999999997, 0.44199999999999995, 0.45199999999999996, -0.05699999999999994, 0.45399999999999996, 0.139, 0.47299999999999986, 1.4260000000000002, 1.145, 0.42700000000000005, 0.45500000000000007, 0.46599999999999997, 0.33999999999999986, 0.952, 0.2889999999999999, 0.45699999999999985, 0.45999999999999996, 1.4449999999999998, 0.45300000000000007, 0.4590000000000001, 0.45599999999999996, 0.46099999999999985, 0.46399999999999997, 0.45799999999999996], "episode_lengths": [113, 14, 8, 14, 15, 10, 14, 28, 13, 21, 14, 19, 300, 17, 16, 17, 15, 17, 16, 15, 12, 16, 37, 12, 15, 11, 8, 11, 21, 13, 13, 10, 8, 17, 14, 10, 8, 25, 13, 19, 20, 13, 14, 296, 11, 300, 20, 300, 15, 28, 17, 10, 12, 12, 13, 97, 9, 16, 11, 11, 20, 17, 87, 300, 17, 25, 14, 17, 48, 13, 10, 42, 13, 9, 15, 11, 18, 12, 11, 12, 10, 19, 15, 18, 14, 115, 9, 23, 111, 23, 14, 11, 50, 15, 67, 13, 12, 18, 15, 13, 14, 13, 12, 14], "policy_red_0_reward": [1.161, 1.458, 1.476, 1.458, 1.455, -0.5, 1.458, 1.416, 1.4609999999999999, 1.4369999999999998, 1.458, 1.443, 0.3799999999999999, 1.4489999999999998, 1.452, 1.4489999999999998, 1.455, 1.4489999999999998, 1.452, 1.455, 1.464, 1.452, -0.5, 1.464, 1.455, 1.467, 1.476, 1.467, 1.4369999999999998, 1.4609999999999999, 1.4609999999999999, 1.47, 1.476, 1.4489999999999998, 1.458, 1.47, 1.476, 1.425, 1.4609999999999999, 1.443, 1.44, 1.4609999999999999, 1.458, -0.5079999999999999, 1.467, 0.3949999999999999, 1.439, 0.44299999999999995, 1.455, 1.416, 1.4489999999999998, 1.47, 1.464, 1.464, 1.4609999999999999, 1.1880000000000002, 1.4729999999999999, 0.952, 1.467, 1.467, -0.5, 1.4489999999999998, 1.236, 0.0, 1.4489999999999998, 1.425, 1.458, 1.4489999999999998, -0.5, 1.4609999999999999, 1.47, 0.873, 1.4609999999999999, 1.4729999999999999, 1.455, 1.467, 0.942, 1.464, 1.467, 1.464, 1.47, 1.443, 1.455, 0.946, 1.458, 1.155, 1.4729999999999999, 1.431, 1.165, 1.429, 1.458, 1.467, 1.3439999999999999, 1.455, -0.502, 1.4609999999999999, 1.464, 1.446, 1.455, 1.4609999999999999, 1.458, 1.4609999999999999, 1.464, 1.458], "policy_blue_0_reward": [0.483, -1.0, -1.001, -1.003, 0.498, 0.968, -1.0039999999999998, -1.003, -1.001, -0.005, -0.001, -1.002, 0.45399999999999996, -0.004, -1.002, -0.003, -0.003, 0.497, -0.005, -0.005, -1.002, -0.003, 0.881, -1.003, -1.003, -1.003, -1.0, -1.001, -0.003, -1.001, -1.0, -1.001, -1.0, -0.002, -1.0, -1.0, -1.001, -0.004, -0.003, -1.001, -0.004, -1.002, -1.0, 0.06199999999999995, -1.001, -0.04500000000000003, -1.005, 0.45399999999999996, -0.003, -0.006, -1.0059999999999998, -1.001, -1.001, -1.0, -0.004, -1.01, -1.0, -1.004, -1.001, -1.001, 0.94, -1.001, -1.018, -0.036000000000000025, -0.002, -0.001, -0.001, -0.002, 0.849, -0.003, -1.0, -1.01, -1.001, -1.001, -0.003, -1.0, -1.003, -1.003, -1.0, -1.001, -1.002, -1.001, -1.003, -1.003, -1.004, -1.016, -1.0, -0.005, -0.02000000000000001, -1.002, -1.003, -1.001, -1.004, -0.503, 0.7909999999999999, -1.004, -1.004, -0.001, -1.0019999999999998, -1.002, -1.0019999999999998, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24736056731673647, "mean_inference_ms": 1.4762333513999562, "mean_action_processing_ms": 0.06314526523218095, "mean_env_wait_ms": 0.08877902000226637, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021733687474177435, "StateBufferConnector_ms": 0.0015132702313936674, "ViewRequirementAgentConnector_ms": 0.03225975311719454}}, "episode_reward_max": 1.9529999999999998, "episode_reward_min": -0.44599999999999995, "episode_reward_mean": 0.6976442307692307, "episode_len_mean": 34.25961538461539, "episodes_this_iter": 104, "policy_reward_min": {"red_0": -0.5079999999999999, "blue_0": -1.018}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.968}, "policy_reward_mean": {"red_0": 1.264548076923077, "blue_0": -0.566903846153846}, "hist_stats": {"episode_reward": [1.6440000000000001, 0.45799999999999996, 0.4750000000000001, 0.45500000000000007, 1.9529999999999998, 0.46799999999999997, 0.4540000000000002, 0.41300000000000003, 0.45999999999999996, 1.432, 1.4569999999999999, 0.44099999999999984, 0.8339999999999999, 1.4449999999999998, 0.44999999999999996, 1.446, 1.452, 1.946, 1.447, 1.45, 0.46199999999999997, 1.4489999999999998, 0.381, 0.46099999999999985, 0.45199999999999996, 0.46399999999999997, 0.476, 0.46599999999999997, 1.434, 0.45999999999999996, 0.46099999999999985, 0.46899999999999986, 0.476, 1.447, 0.45799999999999996, 0.47, 0.4750000000000001, 1.421, 1.4580000000000002, 0.44199999999999995, 1.436, 0.4590000000000001, 0.45799999999999996, -0.44599999999999995, 0.46599999999999997, 0.34999999999999987, 0.43399999999999994, 0.8969999999999999, 1.452, 1.4100000000000001, 0.44300000000000006, 0.46899999999999986, 0.4630000000000001, 0.46399999999999997, 1.457, 0.17799999999999994, 0.47299999999999986, -0.052000000000000046, 0.46599999999999997, 0.46599999999999997, 0.43999999999999995, 0.44799999999999995, 0.21799999999999997, -0.036000000000000025, 1.447, 1.424, 1.4569999999999999, 1.447, 0.349, 1.458, 0.47, -0.137, 0.45999999999999996, 0.472, 1.452, 0.4670000000000001, -0.061000000000000054, 0.46099999999999985, 0.4670000000000001, 0.4630000000000001, 0.46799999999999997, 0.44199999999999995, 0.45199999999999996, -0.05699999999999994, 0.45399999999999996, 0.139, 0.47299999999999986, 1.4260000000000002, 1.145, 0.42700000000000005, 0.45500000000000007, 0.46599999999999997, 0.33999999999999986, 0.952, 0.2889999999999999, 0.45699999999999985, 0.45999999999999996, 1.4449999999999998, 0.45300000000000007, 0.4590000000000001, 0.45599999999999996, 0.46099999999999985, 0.46399999999999997, 0.45799999999999996], "episode_lengths": [113, 14, 8, 14, 15, 10, 14, 28, 13, 21, 14, 19, 300, 17, 16, 17, 15, 17, 16, 15, 12, 16, 37, 12, 15, 11, 8, 11, 21, 13, 13, 10, 8, 17, 14, 10, 8, 25, 13, 19, 20, 13, 14, 296, 11, 300, 20, 300, 15, 28, 17, 10, 12, 12, 13, 97, 9, 16, 11, 11, 20, 17, 87, 300, 17, 25, 14, 17, 48, 13, 10, 42, 13, 9, 15, 11, 18, 12, 11, 12, 10, 19, 15, 18, 14, 115, 9, 23, 111, 23, 14, 11, 50, 15, 67, 13, 12, 18, 15, 13, 14, 13, 12, 14], "policy_red_0_reward": [1.161, 1.458, 1.476, 1.458, 1.455, -0.5, 1.458, 1.416, 1.4609999999999999, 1.4369999999999998, 1.458, 1.443, 0.3799999999999999, 1.4489999999999998, 1.452, 1.4489999999999998, 1.455, 1.4489999999999998, 1.452, 1.455, 1.464, 1.452, -0.5, 1.464, 1.455, 1.467, 1.476, 1.467, 1.4369999999999998, 1.4609999999999999, 1.4609999999999999, 1.47, 1.476, 1.4489999999999998, 1.458, 1.47, 1.476, 1.425, 1.4609999999999999, 1.443, 1.44, 1.4609999999999999, 1.458, -0.5079999999999999, 1.467, 0.3949999999999999, 1.439, 0.44299999999999995, 1.455, 1.416, 1.4489999999999998, 1.47, 1.464, 1.464, 1.4609999999999999, 1.1880000000000002, 1.4729999999999999, 0.952, 1.467, 1.467, -0.5, 1.4489999999999998, 1.236, 0.0, 1.4489999999999998, 1.425, 1.458, 1.4489999999999998, -0.5, 1.4609999999999999, 1.47, 0.873, 1.4609999999999999, 1.4729999999999999, 1.455, 1.467, 0.942, 1.464, 1.467, 1.464, 1.47, 1.443, 1.455, 0.946, 1.458, 1.155, 1.4729999999999999, 1.431, 1.165, 1.429, 1.458, 1.467, 1.3439999999999999, 1.455, -0.502, 1.4609999999999999, 1.464, 1.446, 1.455, 1.4609999999999999, 1.458, 1.4609999999999999, 1.464, 1.458], "policy_blue_0_reward": [0.483, -1.0, -1.001, -1.003, 0.498, 0.968, -1.0039999999999998, -1.003, -1.001, -0.005, -0.001, -1.002, 0.45399999999999996, -0.004, -1.002, -0.003, -0.003, 0.497, -0.005, -0.005, -1.002, -0.003, 0.881, -1.003, -1.003, -1.003, -1.0, -1.001, -0.003, -1.001, -1.0, -1.001, -1.0, -0.002, -1.0, -1.0, -1.001, -0.004, -0.003, -1.001, -0.004, -1.002, -1.0, 0.06199999999999995, -1.001, -0.04500000000000003, -1.005, 0.45399999999999996, -0.003, -0.006, -1.0059999999999998, -1.001, -1.001, -1.0, -0.004, -1.01, -1.0, -1.004, -1.001, -1.001, 0.94, -1.001, -1.018, -0.036000000000000025, -0.002, -0.001, -0.001, -0.002, 0.849, -0.003, -1.0, -1.01, -1.001, -1.001, -0.003, -1.0, -1.003, -1.003, -1.0, -1.001, -1.002, -1.001, -1.003, -1.003, -1.004, -1.016, -1.0, -0.005, -0.02000000000000001, -1.002, -1.003, -1.001, -1.004, -0.503, 0.7909999999999999, -1.004, -1.004, -0.001, -1.0019999999999998, -1.002, -1.0019999999999998, -1.0, -1.0, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24736056731673647, "mean_inference_ms": 1.4762333513999562, "mean_action_processing_ms": 0.06314526523218095, "mean_env_wait_ms": 0.08877902000226637, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021733687474177435, "StateBufferConnector_ms": 0.0015132702313936674, "ViewRequirementAgentConnector_ms": 0.03225975311719454}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000, "num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 103.07120403401872, "num_env_steps_trained_throughput_per_sec": 103.07120403401872, "timesteps_total": 272000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 544000, "timers": {"training_iteration_time_ms": 38920.116, "sample_time_ms": 7554.198, "learn_time_ms": 31348.533, "learn_throughput": 127.598, "synch_weights_time_ms": 16.881}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 272000, "num_agent_steps_sampled": 544000, "num_agent_steps_trained": 544000}, "done": false, "episodes_total": 8547, "training_iteration": 68, "trial_id": "d67e4_00000", "date": "2023-09-20_22-53-30", "timestamp": 1695264810, "time_this_iter_s": 38.81307315826416, "time_total_s": 2645.945229768753, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x29d0976d0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2645.945229768753, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 33.95090909090909, "ram_util_percent": 50.26181818181819}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.21875, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.703125, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0390625, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.703125, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0390625, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.703125, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0390625, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.1499730611840886, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.0069043592375237495, "policy_loss": -0.01206048501917394, "vf_loss": 0.005427853341946805, "vf_explained_var": 0.8254209312299887, "kl": 0.006471757029908732, "entropy": 0.47009161338210104, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 65760.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "sampler_results": {"episode_reward_max": 1.958, "episode_reward_min": -0.28600000000000003, "episode_reward_mean": 0.6482265625, "episode_len_mean": 33.0703125, "episode_media": {}, "episodes_this_iter": 128, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.945}, "policy_reward_mean": {"red_0": 1.2953046874999998, "blue_0": -0.647078125}, "custom_metrics": {"red_0/door_open_done_mean": 0.21875, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.703125, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0390625, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.703125, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0390625, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.703125, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0390625, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.246, 0.44099999999999984, 0.45699999999999985, 0.4650000000000001, 0.46499999999999986, 0.44700000000000006, 0.46499999999999986, 0.405, 0.47299999999999986, 0.4590000000000001, 1.426, 0.45999999999999996, 0.46899999999999986, 0.4670000000000001, 0.46399999999999997, 0.42100000000000026, -0.025000000000000022, 0.4610000000000001, 0.45500000000000007, -0.07200000000000006, 1.456, 0.4590000000000001, 0.44300000000000006, 0.474, 0.46199999999999997, 1.451, -0.131, -0.16800000000000004, 0.44999999999999996, 1.447, 1.436, 1.44, 1.428, 0.44700000000000006, 0.4630000000000001, 0.45100000000000007, 1.459, 0.45599999999999996, 0.4620000000000002, 0.42000000000000015, 1.454, 0.45999999999999996, 0.45100000000000007, 1.448, 0.46599999999999997, 1.459, 0.21499999999999997, 0.478, 0.4630000000000001, 0.45799999999999996, 1.958, 0.46799999999999997, -0.28600000000000003, 0.44399999999999995, 0.45599999999999996, 0.47, 0.45999999999999996, 0.966, 0.45699999999999985, -0.05600000000000005, 0.4670000000000001, 1.449, 0.18099999999999994, 0.33499999999999996, 0.46199999999999997, 0.46399999999999997, 0.42399999999999993, 0.45699999999999985, 0.46499999999999986, 0.46599999999999997, 0.4630000000000001, 1.454, 0.4650000000000001, 0.44700000000000006, 0.4590000000000001, 0.4630000000000001, 0.46199999999999997, 0.45199999999999996, 0.4630000000000001, 1.43, 1.446, 0.45100000000000007, 0.46799999999999997, -0.05999999999999994, 0.44899999999999995, 0.44499999999999995, 0.946, 0.472, 0.46299999999999997, 1.459, 0.46599999999999997, -0.06500000000000006, 1.4369999999999998, 0.44599999999999995, 0.45799999999999996, 1.4409999999999998, 0.46599999999999997, 1.46, 0.45500000000000007, 0.46599999999999997, 0.45799999999999996, 1.46, 0.46099999999999985, 0.44799999999999995, 0.4630000000000001, 0.31499999999999995, 0.44799999999999995, 0.46399999999999997, 0.46899999999999986, 1.446, 1.447, 0.45799999999999996, 0.2829999999999999, 0.44399999999999995, 1.952, 1.458, 1.443, 0.46899999999999986, 0.43900000000000006, 0.44799999999999995, 0.45699999999999985, 1.445, 0.44200000000000017, 0.4750000000000001, 1.454, 0.879, 0.44300000000000006, 0.46499999999999986], "episode_lengths": [237, 18, 13, 11, 11, 16, 11, 31, 9, 13, 24, 12, 10, 10, 11, 25, 8, 12, 14, 19, 14, 13, 19, 8, 12, 15, 41, 52, 16, 16, 20, 19, 22, 16, 12, 15, 13, 14, 12, 25, 15, 13, 15, 17, 11, 13, 232, 7, 11, 13, 14, 300, 90, 17, 13, 10, 13, 11, 14, 18, 10, 16, 250, 54, 12, 11, 24, 14, 11, 11, 11, 15, 11, 16, 12, 12, 12, 16, 12, 22, 17, 16, 10, 19, 300, 18, 300, 9, 300, 13, 10, 20, 20, 17, 13, 19, 11, 13, 14, 11, 13, 13, 13, 16, 12, 58, 16, 12, 10, 18, 16, 13, 56, 300, 16, 14, 17, 10, 19, 17, 13, 17, 17, 8, 14, 38, 18, 11], "policy_red_0_reward": [0.7809999999999999, 1.446, 1.4609999999999999, 1.467, 1.467, 1.452, 1.467, 1.407, 1.4729999999999999, 1.4609999999999999, 1.428, 1.464, 1.47, 1.47, 1.467, 1.425, 0.976, 1.464, 1.458, 0.9319999999999999, 1.458, 1.4609999999999999, 1.443, 1.476, 1.464, 1.455, 0.872, 0.844, 1.452, 1.452, 1.439, 1.443, 1.432, 1.452, 1.464, 1.455, 1.4609999999999999, 1.458, 1.464, 1.425, 1.455, 1.4609999999999999, 1.455, 1.4489999999999998, 1.467, 1.4609999999999999, -0.5640000000000001, 1.479, 1.467, 1.4609999999999999, 1.458, 0.5, 0.73, 1.4489999999999998, 1.4609999999999999, 1.47, 1.4609999999999999, 1.467, 1.458, 0.946, 1.47, 1.452, -0.536, -0.5, 1.464, 1.467, 1.428, 1.458, 1.467, 1.467, 1.467, 1.455, 1.467, 1.452, 1.463, 1.464, 1.464, 1.452, 1.464, 1.434, 1.4489999999999998, 1.452, 1.47, -1.0, 0.48, -0.5, 0.493, 1.4729999999999999, 0.495, 1.4609999999999999, 1.47, 0.9369999999999999, 1.44, 1.4489999999999998, 1.4609999999999999, 1.443, 1.467, 1.4609999999999999, 1.458, 1.467, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.452, 1.464, 1.326, 1.452, 1.464, 1.47, 1.446, 1.452, 1.4609999999999999, 0.7869999999999999, 0.49, 1.452, 1.458, 1.4489999999999998, 1.47, 1.443, 1.4489999999999998, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.476, 1.458, 1.383, 1.446, 1.467], "policy_blue_0_reward": [-0.535, -1.005, -1.004, -1.0019999999999998, -1.002, -1.005, -1.002, -1.002, -1.0, -1.002, -0.002, -1.004, -1.001, -1.003, -1.003, -1.0039999999999998, -1.001, -1.003, -1.003, -1.004, -0.002, -1.002, -1.0, -1.002, -1.002, -0.004, -1.003, -1.012, -1.002, -0.005, -0.003, -0.003, -0.004, -1.005, -1.001, -1.0039999999999998, -0.002, -1.002, -1.0019999999999998, -1.005, -0.001, -1.001, -1.0039999999999998, -0.001, -1.001, -0.002, 0.779, -1.001, -1.004, -1.003, 0.5, -0.03200000000000002, -1.016, -1.005, -1.005, -1.0, -1.001, -0.501, -1.001, -1.002, -1.003, -0.003, 0.717, 0.835, -1.002, -1.003, -1.004, -1.001, -1.002, -1.001, -1.004, -0.001, -1.0019999999999998, -1.005, -1.004, -1.001, -1.002, -1.0, -1.001, -0.004, -0.003, -1.001, -1.002, 0.94, -0.03100000000000002, 0.945, 0.45299999999999996, -1.001, -0.03200000000000002, -0.002, -1.004, -1.002, -0.003, -1.003, -1.003, -0.002, -1.001, -0.001, -1.003, -1.001, -1.003, -0.001, -1.0, -1.004, -1.001, -1.011, -1.004, -1.0, -1.001, 0.0, -0.005, -1.003, -0.504, -0.046000000000000034, 0.5, 0.0, -0.006, -1.001, -1.004, -1.001, -1.004, -0.004, -1.007, -1.001, -0.004, -0.5039999999999999, -1.003, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24844763676937337, "mean_inference_ms": 1.4779605721838684, "mean_action_processing_ms": 0.06330092394206407, "mean_env_wait_ms": 0.08906915685084545, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021984614431858063, "StateBufferConnector_ms": 0.0014824792742729187, "ViewRequirementAgentConnector_ms": 0.03240816295146942}}, "episode_reward_max": 1.958, "episode_reward_min": -0.28600000000000003, "episode_reward_mean": 0.6482265625, "episode_len_mean": 33.0703125, "episodes_this_iter": 128, "policy_reward_min": {"red_0": -1.0, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.479, "blue_0": 0.945}, "policy_reward_mean": {"red_0": 1.2953046874999998, "blue_0": -0.647078125}, "hist_stats": {"episode_reward": [0.246, 0.44099999999999984, 0.45699999999999985, 0.4650000000000001, 0.46499999999999986, 0.44700000000000006, 0.46499999999999986, 0.405, 0.47299999999999986, 0.4590000000000001, 1.426, 0.45999999999999996, 0.46899999999999986, 0.4670000000000001, 0.46399999999999997, 0.42100000000000026, -0.025000000000000022, 0.4610000000000001, 0.45500000000000007, -0.07200000000000006, 1.456, 0.4590000000000001, 0.44300000000000006, 0.474, 0.46199999999999997, 1.451, -0.131, -0.16800000000000004, 0.44999999999999996, 1.447, 1.436, 1.44, 1.428, 0.44700000000000006, 0.4630000000000001, 0.45100000000000007, 1.459, 0.45599999999999996, 0.4620000000000002, 0.42000000000000015, 1.454, 0.45999999999999996, 0.45100000000000007, 1.448, 0.46599999999999997, 1.459, 0.21499999999999997, 0.478, 0.4630000000000001, 0.45799999999999996, 1.958, 0.46799999999999997, -0.28600000000000003, 0.44399999999999995, 0.45599999999999996, 0.47, 0.45999999999999996, 0.966, 0.45699999999999985, -0.05600000000000005, 0.4670000000000001, 1.449, 0.18099999999999994, 0.33499999999999996, 0.46199999999999997, 0.46399999999999997, 0.42399999999999993, 0.45699999999999985, 0.46499999999999986, 0.46599999999999997, 0.4630000000000001, 1.454, 0.4650000000000001, 0.44700000000000006, 0.4590000000000001, 0.4630000000000001, 0.46199999999999997, 0.45199999999999996, 0.4630000000000001, 1.43, 1.446, 0.45100000000000007, 0.46799999999999997, -0.05999999999999994, 0.44899999999999995, 0.44499999999999995, 0.946, 0.472, 0.46299999999999997, 1.459, 0.46599999999999997, -0.06500000000000006, 1.4369999999999998, 0.44599999999999995, 0.45799999999999996, 1.4409999999999998, 0.46599999999999997, 1.46, 0.45500000000000007, 0.46599999999999997, 0.45799999999999996, 1.46, 0.46099999999999985, 0.44799999999999995, 0.4630000000000001, 0.31499999999999995, 0.44799999999999995, 0.46399999999999997, 0.46899999999999986, 1.446, 1.447, 0.45799999999999996, 0.2829999999999999, 0.44399999999999995, 1.952, 1.458, 1.443, 0.46899999999999986, 0.43900000000000006, 0.44799999999999995, 0.45699999999999985, 1.445, 0.44200000000000017, 0.4750000000000001, 1.454, 0.879, 0.44300000000000006, 0.46499999999999986], "episode_lengths": [237, 18, 13, 11, 11, 16, 11, 31, 9, 13, 24, 12, 10, 10, 11, 25, 8, 12, 14, 19, 14, 13, 19, 8, 12, 15, 41, 52, 16, 16, 20, 19, 22, 16, 12, 15, 13, 14, 12, 25, 15, 13, 15, 17, 11, 13, 232, 7, 11, 13, 14, 300, 90, 17, 13, 10, 13, 11, 14, 18, 10, 16, 250, 54, 12, 11, 24, 14, 11, 11, 11, 15, 11, 16, 12, 12, 12, 16, 12, 22, 17, 16, 10, 19, 300, 18, 300, 9, 300, 13, 10, 20, 20, 17, 13, 19, 11, 13, 14, 11, 13, 13, 13, 16, 12, 58, 16, 12, 10, 18, 16, 13, 56, 300, 16, 14, 17, 10, 19, 17, 13, 17, 17, 8, 14, 38, 18, 11], "policy_red_0_reward": [0.7809999999999999, 1.446, 1.4609999999999999, 1.467, 1.467, 1.452, 1.467, 1.407, 1.4729999999999999, 1.4609999999999999, 1.428, 1.464, 1.47, 1.47, 1.467, 1.425, 0.976, 1.464, 1.458, 0.9319999999999999, 1.458, 1.4609999999999999, 1.443, 1.476, 1.464, 1.455, 0.872, 0.844, 1.452, 1.452, 1.439, 1.443, 1.432, 1.452, 1.464, 1.455, 1.4609999999999999, 1.458, 1.464, 1.425, 1.455, 1.4609999999999999, 1.455, 1.4489999999999998, 1.467, 1.4609999999999999, -0.5640000000000001, 1.479, 1.467, 1.4609999999999999, 1.458, 0.5, 0.73, 1.4489999999999998, 1.4609999999999999, 1.47, 1.4609999999999999, 1.467, 1.458, 0.946, 1.47, 1.452, -0.536, -0.5, 1.464, 1.467, 1.428, 1.458, 1.467, 1.467, 1.467, 1.455, 1.467, 1.452, 1.463, 1.464, 1.464, 1.452, 1.464, 1.434, 1.4489999999999998, 1.452, 1.47, -1.0, 0.48, -0.5, 0.493, 1.4729999999999999, 0.495, 1.4609999999999999, 1.47, 0.9369999999999999, 1.44, 1.4489999999999998, 1.4609999999999999, 1.443, 1.467, 1.4609999999999999, 1.458, 1.467, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.452, 1.464, 1.326, 1.452, 1.464, 1.47, 1.446, 1.452, 1.4609999999999999, 0.7869999999999999, 0.49, 1.452, 1.458, 1.4489999999999998, 1.47, 1.443, 1.4489999999999998, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.476, 1.458, 1.383, 1.446, 1.467], "policy_blue_0_reward": [-0.535, -1.005, -1.004, -1.0019999999999998, -1.002, -1.005, -1.002, -1.002, -1.0, -1.002, -0.002, -1.004, -1.001, -1.003, -1.003, -1.0039999999999998, -1.001, -1.003, -1.003, -1.004, -0.002, -1.002, -1.0, -1.002, -1.002, -0.004, -1.003, -1.012, -1.002, -0.005, -0.003, -0.003, -0.004, -1.005, -1.001, -1.0039999999999998, -0.002, -1.002, -1.0019999999999998, -1.005, -0.001, -1.001, -1.0039999999999998, -0.001, -1.001, -0.002, 0.779, -1.001, -1.004, -1.003, 0.5, -0.03200000000000002, -1.016, -1.005, -1.005, -1.0, -1.001, -0.501, -1.001, -1.002, -1.003, -0.003, 0.717, 0.835, -1.002, -1.003, -1.004, -1.001, -1.002, -1.001, -1.004, -0.001, -1.0019999999999998, -1.005, -1.004, -1.001, -1.002, -1.0, -1.001, -0.004, -0.003, -1.001, -1.002, 0.94, -0.03100000000000002, 0.945, 0.45299999999999996, -1.001, -0.03200000000000002, -0.002, -1.004, -1.002, -0.003, -1.003, -1.003, -0.002, -1.001, -0.001, -1.003, -1.001, -1.003, -0.001, -1.0, -1.004, -1.001, -1.011, -1.004, -1.0, -1.001, 0.0, -0.005, -1.003, -0.504, -0.046000000000000034, 0.5, 0.0, -0.006, -1.001, -1.004, -1.001, -1.004, -0.004, -1.007, -1.001, -0.004, -0.5039999999999999, -1.003, -1.002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24844763676937337, "mean_inference_ms": 1.4779605721838684, "mean_action_processing_ms": 0.06330092394206407, "mean_env_wait_ms": 0.08906915685084545, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.021984614431858063, "StateBufferConnector_ms": 0.0014824792742729187, "ViewRequirementAgentConnector_ms": 0.03240816295146942}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000, "num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.72104967524048, "num_env_steps_trained_throughput_per_sec": 102.72104967524048, "timesteps_total": 276000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 552000, "timers": {"training_iteration_time_ms": 38922.989, "sample_time_ms": 7548.408, "learn_time_ms": 31357.106, "learn_throughput": 127.563, "synch_weights_time_ms": 16.971}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 276000, "num_agent_steps_sampled": 552000, "num_agent_steps_trained": 552000}, "done": false, "episodes_total": 8675, "training_iteration": 69, "trial_id": "d67e4_00000", "date": "2023-09-20_22-54-09", "timestamp": 1695264849, "time_this_iter_s": 38.946218967437744, "time_total_s": 2684.891448736191, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687acb0>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2684.891448736191, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 33.36607142857143, "ram_util_percent": 50.333928571428565}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.33544303797468356, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6075949367088608, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0379746835443038, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6075949367088608, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0379746835443038, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6075949367088608, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0379746835443038, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.8560254436917603, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.009703088955575367, "policy_loss": -0.01603118656639708, "vf_loss": 0.006160824435937684, "vf_explained_var": 0.8318828556686639, "kl": 0.008181640400850499, "entropy": 0.43405228899791837, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 66720.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "sampler_results": {"episode_reward_max": 1.9489999999999998, "episode_reward_min": -0.44100000000000006, "episode_reward_mean": 0.7764810126582279, "episode_len_mean": 26.670886075949365, "episode_media": {}, "episodes_this_iter": 158, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.976}, "policy_reward_mean": {"red_0": 1.3231645569620254, "blue_0": -0.5466835443037974}, "custom_metrics": {"red_0/door_open_done_mean": 0.33544303797468356, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6075949367088608, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.0379746835443038, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6075949367088608, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.0379746835443038, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6075949367088608, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.0379746835443038, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.46799999999999997, 0.9220000000000002, 1.4449999999999998, 1.4580000000000002, 0.46799999999999997, 1.454, 1.4449999999999998, 0.45999999999999996, 1.459, 0.45299999999999985, 0.45399999999999996, 0.45599999999999996, 0.4650000000000001, 0.45099999999999996, 0.46599999999999997, 1.45, 0.4590000000000001, 0.45599999999999996, 1.459, 0.369, 1.4180000000000001, 0.3620000000000001, 1.45, 1.9489999999999998, 1.447, 0.44999999999999996, 0.46599999999999997, 0.46199999999999997, 1.459, 0.46799999999999997, 0.44099999999999984, 0.46499999999999986, 0.3460000000000001, 0.45999999999999996, 1.928, 0.46099999999999985, 0.4159999999999999, 0.45299999999999985, 1.4609999999999999, 0.263, 1.436, 1.452, 1.46, 1.431, 0.474, 0.46399999999999997, 0.45599999999999996, 0.4630000000000001, 0.46499999999999986, 0.46599999999999997, 1.4609999999999999, -0.122, 0.47, 0.4670000000000001, 0.4500000000000002, 1.454, 1.46, 0.32499999999999996, 0.46599999999999997, 0.46899999999999986, 0.9729999999999999, 0.964, 0.46099999999999985, 0.46799999999999997, 1.448, 1.4529999999999998, 1.393, 0.46399999999999997, 0.4580000000000002, 1.454, 0.4590000000000001, 1.4449999999999998, 1.4500000000000002, 0.976, 0.46199999999999997, -0.09899999999999998, 0.472, 1.429, 0.44999999999999996, 0.46799999999999997, 0.4590000000000001, 0.46599999999999997, -0.06900000000000006, 0.46399999999999997, 1.4329999999999998, 0.45999999999999996, 0.45999999999999996, 0.96, 0.46599999999999997, 0.45199999999999996, 0.4670000000000001, -0.05900000000000005, 1.612, 0.46399999999999997, 0.4630000000000001, 0.4630000000000001, 0.45299999999999985, 0.4079999999999999, 0.4630000000000001, 0.46499999999999986, 1.46, 1.4529999999999998, 0.44300000000000006, 1.447, 0.476, -0.05600000000000005, 1.4020000000000001, 1.454, 1.0019999999999998, 0.46099999999999985, 0.46499999999999986, 0.46899999999999986, 0.47, 0.46399999999999997, 1.447, 0.4590000000000001, 1.452, 1.429, 1.44, 0.41900000000000004, 0.45999999999999996, 1.451, 0.4630000000000001, 0.4630000000000001, 0.1359999999999999, 0.46199999999999997, 0.46399999999999997, 1.452, 1.447, 0.45799999999999996, 0.4630000000000001, 0.45500000000000007, 1.451, 0.46399999999999997, 1.016, 1.452, 1.459, -0.08099999999999996, 0.44700000000000006, 1.455, 0.43599999999999994, 0.45399999999999996, 0.45299999999999985, 0.46199999999999997, 0.46499999999999986, 1.443, 1.439, 0.46399999999999997, 1.424, 0.43799999999999994, 1.459, -0.44100000000000006, 1.439, 0.43199999999999994, 0.46199999999999997, 0.476, 0.9609999999999999, 0.11799999999999988], "episode_lengths": [10, 25, 18, 13, 10, 14, 18, 12, 13, 15, 14, 14, 11, 16, 11, 15, 13, 14, 13, 42, 27, 44, 16, 16, 17, 16, 11, 12, 13, 10, 18, 11, 46, 13, 23, 12, 300, 15, 13, 75, 20, 15, 13, 21, 8, 11, 14, 11, 11, 11, 13, 38, 10, 11, 15, 15, 13, 49, 11, 10, 9, 12, 12, 10, 17, 15, 34, 12, 13, 15, 13, 18, 15, 8, 12, 31, 9, 23, 16, 10, 13, 11, 22, 11, 22, 13, 13, 13, 11, 14, 11, 19, 122, 11, 12, 11, 15, 300, 12, 11, 13, 15, 18, 17, 8, 16, 31, 15, 294, 13, 11, 10, 10, 12, 17, 13, 15, 23, 18, 26, 13, 16, 11, 11, 104, 12, 11, 15, 16, 14, 11, 14, 16, 12, 154, 15, 13, 26, 17, 15, 300, 15, 15, 12, 11, 18, 20, 12, 24, 19, 13, 139, 19, 22, 11, 8, 13, 122], "policy_red_0_reward": [1.47, 1.425, 1.446, 1.4609999999999999, 1.47, 1.458, 1.446, 1.464, 1.4609999999999999, 1.455, 1.458, 1.458, 1.467, -0.5, 1.467, 1.455, 1.4609999999999999, 1.458, 1.4609999999999999, 1.3719999999999999, 1.419, 1.366, 1.452, 1.452, 1.4489999999999998, 1.452, 1.467, 1.464, 1.4609999999999999, 1.47, 1.446, 1.467, 1.355, 1.4609999999999999, 1.431, 1.464, 0.45499999999999996, 1.455, 1.4609999999999999, -0.502, 1.44, 1.455, 1.4609999999999999, 1.4369999999999998, 1.476, 1.467, 1.458, 1.467, 1.467, 1.467, 1.4609999999999999, 0.885, -0.5, 1.467, 1.455, 1.455, 1.4609999999999999, 1.3319999999999999, 1.467, 1.47, 1.4729999999999999, 1.464, 1.464, 1.47, 1.4489999999999998, 1.455, 1.3980000000000001, 1.464, 1.4609999999999999, 1.455, 1.4609999999999999, 1.446, 1.455, 1.476, 1.464, 0.906, 1.4729999999999999, 1.431, 1.452, 1.47, 1.4609999999999999, 1.467, 0.9319999999999999, 1.467, 1.4329999999999998, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.467, 1.458, 1.467, 0.943, 1.131, 1.467, 1.464, 1.467, 1.454, 0.43399999999999994, 1.464, 1.467, 1.4609999999999999, 1.455, 1.446, 1.4489999999999998, -0.5, 0.95, 1.407, 1.455, 0.5449999999999999, 1.4609999999999999, 1.467, 1.47, 1.47, 1.464, 1.4489999999999998, 1.4609999999999999, 1.455, 1.431, 1.446, 1.4220000000000002, 1.4609999999999999, 1.452, 1.467, 1.467, 1.1509999999999998, 1.464, 1.467, 1.455, 1.452, 1.458, 1.467, 1.458, 1.452, 1.464, 1.033, 1.455, 1.4609999999999999, 0.921, 1.4489999999999998, 1.455, 0.477, 1.455, 1.455, 1.464, 1.467, 1.446, 1.44, 1.464, 1.426, -0.5, 1.4609999999999999, -1.002, 1.443, 1.434, 1.467, 1.476, 1.4609999999999999, 1.134], "policy_blue_0_reward": [-1.002, -0.503, -0.001, -0.003, -1.002, -0.004, -0.001, -1.004, -0.002, -1.002, -1.004, -1.0019999999999998, -1.0019999999999998, 0.951, -1.001, -0.005, -1.002, -1.002, -0.002, -1.003, -0.001, -1.004, -0.002, 0.497, -0.002, -1.002, -1.001, -1.002, -0.002, -1.002, -1.005, -1.002, -1.009, -1.001, 0.497, -1.003, -0.03900000000000003, -1.002, 0.0, 0.765, -0.004, -0.003, -0.001, -0.006, -1.002, -1.003, -1.0019999999999998, -1.004, -1.002, -1.001, 0.0, -1.007, 0.97, -1.0, -1.005, -0.001, -0.001, -1.007, -1.001, -1.001, -0.5, -0.5, -1.003, -1.0019999999999998, -0.001, -0.002, -0.005, -1.0, -1.003, -0.001, -1.002, -0.001, -0.005, -0.5, -1.002, -1.005, -1.001, -0.002, -1.002, -1.002, -1.002, -1.001, -1.001, -1.003, 0.0, -1.001, -1.001, -0.501, -1.001, -1.006, -1.0, -1.002, 0.481, -1.003, -1.001, -1.0039999999999998, -1.001, -0.026000000000000016, -1.001, -1.002, -0.001, -0.002, -1.003, -0.002, 0.976, -1.006, -0.005, -0.001, 0.45699999999999996, -1.0, -1.002, -1.001, -1.0, -1.0, -0.002, -1.0019999999999998, -0.003, -0.002, -0.006, -1.003, -1.001, -0.001, -1.0039999999999998, -1.0039999999999998, -1.015, -1.002, -1.003, -0.003, -0.005, -1.0, -1.0039999999999998, -1.003, -0.001, -1.0, -0.017000000000000008, -0.003, -0.002, -1.002, -1.002, 0.0, -0.04100000000000003, -1.001, -1.002, -1.002, -1.002, -0.003, -0.001, -1.0, -0.002, 0.938, -0.002, 0.5609999999999999, -0.004, -1.002, -1.005, -1.0, -0.5, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24793673738197014, "mean_inference_ms": 1.4764986949667362, "mean_action_processing_ms": 0.0632117437289921, "mean_env_wait_ms": 0.08891492101636314, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022043910207627696, "StateBufferConnector_ms": 0.0014650670787956141, "ViewRequirementAgentConnector_ms": 0.032436093197593205}}, "episode_reward_max": 1.9489999999999998, "episode_reward_min": -0.44100000000000006, "episode_reward_mean": 0.7764810126582279, "episode_len_mean": 26.670886075949365, "episodes_this_iter": 158, "policy_reward_min": {"red_0": -1.002, "blue_0": -1.016}, "policy_reward_max": {"red_0": 1.476, "blue_0": 0.976}, "policy_reward_mean": {"red_0": 1.3231645569620254, "blue_0": -0.5466835443037974}, "hist_stats": {"episode_reward": [0.46799999999999997, 0.9220000000000002, 1.4449999999999998, 1.4580000000000002, 0.46799999999999997, 1.454, 1.4449999999999998, 0.45999999999999996, 1.459, 0.45299999999999985, 0.45399999999999996, 0.45599999999999996, 0.4650000000000001, 0.45099999999999996, 0.46599999999999997, 1.45, 0.4590000000000001, 0.45599999999999996, 1.459, 0.369, 1.4180000000000001, 0.3620000000000001, 1.45, 1.9489999999999998, 1.447, 0.44999999999999996, 0.46599999999999997, 0.46199999999999997, 1.459, 0.46799999999999997, 0.44099999999999984, 0.46499999999999986, 0.3460000000000001, 0.45999999999999996, 1.928, 0.46099999999999985, 0.4159999999999999, 0.45299999999999985, 1.4609999999999999, 0.263, 1.436, 1.452, 1.46, 1.431, 0.474, 0.46399999999999997, 0.45599999999999996, 0.4630000000000001, 0.46499999999999986, 0.46599999999999997, 1.4609999999999999, -0.122, 0.47, 0.4670000000000001, 0.4500000000000002, 1.454, 1.46, 0.32499999999999996, 0.46599999999999997, 0.46899999999999986, 0.9729999999999999, 0.964, 0.46099999999999985, 0.46799999999999997, 1.448, 1.4529999999999998, 1.393, 0.46399999999999997, 0.4580000000000002, 1.454, 0.4590000000000001, 1.4449999999999998, 1.4500000000000002, 0.976, 0.46199999999999997, -0.09899999999999998, 0.472, 1.429, 0.44999999999999996, 0.46799999999999997, 0.4590000000000001, 0.46599999999999997, -0.06900000000000006, 0.46399999999999997, 1.4329999999999998, 0.45999999999999996, 0.45999999999999996, 0.96, 0.46599999999999997, 0.45199999999999996, 0.4670000000000001, -0.05900000000000005, 1.612, 0.46399999999999997, 0.4630000000000001, 0.4630000000000001, 0.45299999999999985, 0.4079999999999999, 0.4630000000000001, 0.46499999999999986, 1.46, 1.4529999999999998, 0.44300000000000006, 1.447, 0.476, -0.05600000000000005, 1.4020000000000001, 1.454, 1.0019999999999998, 0.46099999999999985, 0.46499999999999986, 0.46899999999999986, 0.47, 0.46399999999999997, 1.447, 0.4590000000000001, 1.452, 1.429, 1.44, 0.41900000000000004, 0.45999999999999996, 1.451, 0.4630000000000001, 0.4630000000000001, 0.1359999999999999, 0.46199999999999997, 0.46399999999999997, 1.452, 1.447, 0.45799999999999996, 0.4630000000000001, 0.45500000000000007, 1.451, 0.46399999999999997, 1.016, 1.452, 1.459, -0.08099999999999996, 0.44700000000000006, 1.455, 0.43599999999999994, 0.45399999999999996, 0.45299999999999985, 0.46199999999999997, 0.46499999999999986, 1.443, 1.439, 0.46399999999999997, 1.424, 0.43799999999999994, 1.459, -0.44100000000000006, 1.439, 0.43199999999999994, 0.46199999999999997, 0.476, 0.9609999999999999, 0.11799999999999988], "episode_lengths": [10, 25, 18, 13, 10, 14, 18, 12, 13, 15, 14, 14, 11, 16, 11, 15, 13, 14, 13, 42, 27, 44, 16, 16, 17, 16, 11, 12, 13, 10, 18, 11, 46, 13, 23, 12, 300, 15, 13, 75, 20, 15, 13, 21, 8, 11, 14, 11, 11, 11, 13, 38, 10, 11, 15, 15, 13, 49, 11, 10, 9, 12, 12, 10, 17, 15, 34, 12, 13, 15, 13, 18, 15, 8, 12, 31, 9, 23, 16, 10, 13, 11, 22, 11, 22, 13, 13, 13, 11, 14, 11, 19, 122, 11, 12, 11, 15, 300, 12, 11, 13, 15, 18, 17, 8, 16, 31, 15, 294, 13, 11, 10, 10, 12, 17, 13, 15, 23, 18, 26, 13, 16, 11, 11, 104, 12, 11, 15, 16, 14, 11, 14, 16, 12, 154, 15, 13, 26, 17, 15, 300, 15, 15, 12, 11, 18, 20, 12, 24, 19, 13, 139, 19, 22, 11, 8, 13, 122], "policy_red_0_reward": [1.47, 1.425, 1.446, 1.4609999999999999, 1.47, 1.458, 1.446, 1.464, 1.4609999999999999, 1.455, 1.458, 1.458, 1.467, -0.5, 1.467, 1.455, 1.4609999999999999, 1.458, 1.4609999999999999, 1.3719999999999999, 1.419, 1.366, 1.452, 1.452, 1.4489999999999998, 1.452, 1.467, 1.464, 1.4609999999999999, 1.47, 1.446, 1.467, 1.355, 1.4609999999999999, 1.431, 1.464, 0.45499999999999996, 1.455, 1.4609999999999999, -0.502, 1.44, 1.455, 1.4609999999999999, 1.4369999999999998, 1.476, 1.467, 1.458, 1.467, 1.467, 1.467, 1.4609999999999999, 0.885, -0.5, 1.467, 1.455, 1.455, 1.4609999999999999, 1.3319999999999999, 1.467, 1.47, 1.4729999999999999, 1.464, 1.464, 1.47, 1.4489999999999998, 1.455, 1.3980000000000001, 1.464, 1.4609999999999999, 1.455, 1.4609999999999999, 1.446, 1.455, 1.476, 1.464, 0.906, 1.4729999999999999, 1.431, 1.452, 1.47, 1.4609999999999999, 1.467, 0.9319999999999999, 1.467, 1.4329999999999998, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.467, 1.458, 1.467, 0.943, 1.131, 1.467, 1.464, 1.467, 1.454, 0.43399999999999994, 1.464, 1.467, 1.4609999999999999, 1.455, 1.446, 1.4489999999999998, -0.5, 0.95, 1.407, 1.455, 0.5449999999999999, 1.4609999999999999, 1.467, 1.47, 1.47, 1.464, 1.4489999999999998, 1.4609999999999999, 1.455, 1.431, 1.446, 1.4220000000000002, 1.4609999999999999, 1.452, 1.467, 1.467, 1.1509999999999998, 1.464, 1.467, 1.455, 1.452, 1.458, 1.467, 1.458, 1.452, 1.464, 1.033, 1.455, 1.4609999999999999, 0.921, 1.4489999999999998, 1.455, 0.477, 1.455, 1.455, 1.464, 1.467, 1.446, 1.44, 1.464, 1.426, -0.5, 1.4609999999999999, -1.002, 1.443, 1.434, 1.467, 1.476, 1.4609999999999999, 1.134], "policy_blue_0_reward": [-1.002, -0.503, -0.001, -0.003, -1.002, -0.004, -0.001, -1.004, -0.002, -1.002, -1.004, -1.0019999999999998, -1.0019999999999998, 0.951, -1.001, -0.005, -1.002, -1.002, -0.002, -1.003, -0.001, -1.004, -0.002, 0.497, -0.002, -1.002, -1.001, -1.002, -0.002, -1.002, -1.005, -1.002, -1.009, -1.001, 0.497, -1.003, -0.03900000000000003, -1.002, 0.0, 0.765, -0.004, -0.003, -0.001, -0.006, -1.002, -1.003, -1.0019999999999998, -1.004, -1.002, -1.001, 0.0, -1.007, 0.97, -1.0, -1.005, -0.001, -0.001, -1.007, -1.001, -1.001, -0.5, -0.5, -1.003, -1.0019999999999998, -0.001, -0.002, -0.005, -1.0, -1.003, -0.001, -1.002, -0.001, -0.005, -0.5, -1.002, -1.005, -1.001, -0.002, -1.002, -1.002, -1.002, -1.001, -1.001, -1.003, 0.0, -1.001, -1.001, -0.501, -1.001, -1.006, -1.0, -1.002, 0.481, -1.003, -1.001, -1.0039999999999998, -1.001, -0.026000000000000016, -1.001, -1.002, -0.001, -0.002, -1.003, -0.002, 0.976, -1.006, -0.005, -0.001, 0.45699999999999996, -1.0, -1.002, -1.001, -1.0, -1.0, -0.002, -1.0019999999999998, -0.003, -0.002, -0.006, -1.003, -1.001, -0.001, -1.0039999999999998, -1.0039999999999998, -1.015, -1.002, -1.003, -0.003, -0.005, -1.0, -1.0039999999999998, -1.003, -0.001, -1.0, -0.017000000000000008, -0.003, -0.002, -1.002, -1.002, 0.0, -0.04100000000000003, -1.001, -1.002, -1.002, -1.002, -0.003, -0.001, -1.0, -0.002, 0.938, -0.002, 0.5609999999999999, -0.004, -1.002, -1.005, -1.0, -0.5, -1.016]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.24793673738197014, "mean_inference_ms": 1.4764986949667362, "mean_action_processing_ms": 0.0632117437289921, "mean_env_wait_ms": 0.08891492101636314, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.022043910207627696, "StateBufferConnector_ms": 0.0014650670787956141, "ViewRequirementAgentConnector_ms": 0.032436093197593205}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000, "num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.76801789219795, "num_env_steps_trained_throughput_per_sec": 102.76801789219795, "timesteps_total": 280000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 560000, "timers": {"training_iteration_time_ms": 38918.531, "sample_time_ms": 7554.738, "learn_time_ms": 31346.359, "learn_throughput": 127.607, "synch_weights_time_ms": 16.932}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 280000, "num_agent_steps_sampled": 560000, "num_agent_steps_trained": 560000}, "done": false, "episodes_total": 8833, "training_iteration": 70, "trial_id": "d67e4_00000", "date": "2023-09-20_22-54-48", "timestamp": 1695264888, "time_this_iter_s": 38.9292311668396, "time_total_s": 2723.8206799030304, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a687bd00>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2723.8206799030304, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 34.95454545454545, "ram_util_percent": 50.38727272727272}}
{"custom_metrics": {"red_0/door_open_done_mean": 0.32673267326732675, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6435643564356436, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.024752475247524754, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6435643564356436, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.024752475247524754, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6435643564356436, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.024752475247524754, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "episode_media": {}, "info": {"learner": {"red_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9687513647290567, "cur_kl_coeff": 0.4500000000000001, "cur_lr": 5.0000000000000016e-05, "total_loss": -0.00687922118207401, "policy_loss": -0.012761102784861578, "vf_loss": 0.007154629635260789, "vf_explained_var": 0.8040518862505753, "kl": 0.00579224151941611, "entropy": 0.30194155109735826, "entropy_coeff": 0.0010000000000000005}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 125.0, "num_grad_updates_lifetime": 67680.5, "diff_num_grad_updates_vs_sampler_policy": 479.5}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "sampler_results": {"episode_reward_max": 1.956, "episode_reward_min": -0.3750000000000001, "episode_reward_mean": 0.7553762376237625, "episode_len_mean": 20.623762376237625, "episode_media": {}, "episodes_this_iter": 202, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.043}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.982}, "policy_reward_mean": {"red_0": 1.3568267326732673, "blue_0": -0.6014504950495049}, "custom_metrics": {"red_0/door_open_done_mean": 0.32673267326732675, "red_0/door_open_done_min": 0, "red_0/door_open_done_max": 1, "red_0/eliminated_opponents_done_mean": 0.6435643564356436, "red_0/eliminated_opponents_done_min": 0, "red_0/eliminated_opponents_done_max": 1, "red_0/got_eliminated_done_mean": 0.024752475247524754, "red_0/got_eliminated_done_min": 0, "red_0/got_eliminated_done_max": 1, "red_0/eliminated_opponent_num_mean": 0.6435643564356436, "red_0/eliminated_opponent_num_min": 0, "red_0/eliminated_opponent_num_max": 1, "blue_0/door_open_done_mean": 0.0, "blue_0/door_open_done_min": 0, "blue_0/door_open_done_max": 0, "blue_0/eliminated_opponents_done_mean": 0.024752475247524754, "blue_0/eliminated_opponents_done_min": 0, "blue_0/eliminated_opponents_done_max": 1, "blue_0/got_eliminated_done_mean": 0.6435643564356436, "blue_0/got_eliminated_done_min": 0, "blue_0/got_eliminated_done_max": 1, "blue_0/eliminated_opponent_num_mean": 0.024752475247524754, "blue_0/eliminated_opponent_num_min": 0, "blue_0/eliminated_opponent_num_max": 1}, "hist_stats": {"episode_reward": [0.45199999999999996, 0.45999999999999996, 0.45699999999999985, 1.439, 1.447, 1.452, 1.433, 0.4500000000000002, 0.44700000000000006, 0.45199999999999996, 1.4449999999999998, 0.4630000000000001, 0.45599999999999996, 1.4489999999999998, 0.4630000000000001, -0.121, 1.439, 1.443, 0.45999999999999996, 1.4460000000000002, 1.447, 1.4529999999999998, 0.45299999999999985, 0.45599999999999996, 0.028000000000000025, -0.04300000000000004, 0.46099999999999985, -0.04300000000000004, 0.45699999999999985, 1.454, 0.4630000000000001, 0.46599999999999997, 1.454, 1.4489999999999998, 0.47299999999999986, 0.46799999999999997, 0.46799999999999997, 0.45799999999999996, 0.45500000000000007, 1.442, 0.44300000000000006, 1.458, 0.45999999999999996, 0.46499999999999986, 0.46099999999999985, 0.3700000000000001, 1.4569999999999999, 1.44, 0.46399999999999997, 0.45399999999999996, -0.038999999999999924, 0.4630000000000001, 0.45300000000000007, 0.45799999999999996, 0.46099999999999985, 0.45399999999999996, 0.45699999999999985, 1.46, -0.018000000000000016, 1.454, 0.46499999999999986, 1.453, 0.46399999999999997, 1.444, 0.46099999999999985, 1.956, 0.46599999999999997, 0.44999999999999996, 0.46899999999999986, 0.356, 1.4569999999999999, 0.45799999999999996, 0.44099999999999984, 0.47, 0.46199999999999997, 0.46199999999999997, 0.46399999999999997, 0.45500000000000007, 0.44700000000000006, 1.443, 1.438, 0.45999999999999996, 1.454, 1.4540000000000002, 1.455, 0.45500000000000007, -0.05400000000000005, 0.46099999999999985, 0.46499999999999986, 0.45799999999999996, 1.393, 0.4670000000000001, 0.45199999999999996, 0.46899999999999986, 0.966, 0.4710000000000001, 0.43100000000000005, 0.4610000000000001, 0.4710000000000001, 0.4590000000000001, 0.44700000000000006, 1.46, 0.46499999999999986, 1.451, 1.948, 0.46199999999999997, 0.46899999999999986, 1.444, 1.426, 0.47, 1.458, 0.45199999999999996, 0.46599999999999997, 0.46199999999999997, 1.448, 0.46599999999999997, 0.45999999999999996, 0.45399999999999996, 1.459, 1.943, 0.45799999999999996, 1.456, 0.45299999999999985, -0.3750000000000001, -0.05300000000000005, 1.46, -0.052000000000000046, 0.45100000000000007, 0.43000000000000016, 0.46399999999999997, 0.2290000000000001, 0.45599999999999996, 1.391, 1.4489999999999998, 0.46499999999999986, 0.44300000000000006, 1.459, 0.46499999999999986, 0.45599999999999996, 1.459, 1.442, 0.46399999999999997, 1.453, 0.43900000000000006, 0.46399999999999997, 0.46599999999999997, 0.46499999999999986, 0.45399999999999996, -0.038000000000000034, 0.45999999999999996, 1.454, 0.45999999999999996, 1.459, 0.45599999999999996, 0.4610000000000001, 0.4670000000000001, 1.431, 0.4590000000000001, 1.46, 0.45999999999999996, 1.455, 0.9670000000000001, 1.454, 0.45599999999999996, 1.379, 0.45999999999999996, 0.367, 1.46, 0.45999999999999996, 0.44599999999999995, 0.4660000000000002, 0.9359999999999999, 0.45999999999999996, 1.458, -0.26, 0.44300000000000006, 0.391, 0.46199999999999997, 1.452, 1.459, 0.45699999999999985, 1.456, -0.051000000000000045, -0.04399999999999993, 0.46399999999999997, 0.4630000000000001, 1.446, 0.44499999999999984, 1.46, 1.452, 0.4590000000000001, 0.3540000000000001, -0.025000000000000022, 0.46199999999999997, 1.4569999999999999, 0.46099999999999985, 0.43699999999999983, 1.431, 1.452, 1.393, 0.9510000000000001, 0.47], "episode_lengths": [15, 12, 14, 19, 17, 15, 21, 16, 16, 15, 18, 11, 14, 16, 12, 38, 20, 18, 13, 17, 17, 15, 15, 13, 294, 14, 13, 13, 13, 15, 12, 11, 15, 15, 9, 10, 10, 13, 14, 18, 19, 13, 13, 11, 13, 36, 14, 19, 12, 14, 12, 12, 15, 13, 12, 15, 14, 13, 6, 15, 11, 15, 11, 17, 13, 14, 11, 16, 10, 46, 14, 13, 18, 10, 12, 12, 11, 14, 17, 18, 18, 13, 14, 15, 14, 14, 175, 12, 11, 13, 34, 11, 15, 10, 11, 9, 22, 12, 9, 13, 17, 13, 11, 16, 17, 12, 10, 17, 24, 10, 13, 15, 11, 12, 16, 11, 13, 15, 13, 19, 13, 13, 15, 99, 17, 13, 16, 16, 22, 12, 86, 14, 35, 17, 11, 18, 13, 11, 14, 13, 18, 11, 15, 18, 12, 11, 11, 15, 12, 12, 15, 13, 13, 14, 12, 11, 22, 13, 13, 13, 14, 11, 15, 14, 38, 13, 41, 13, 12, 18, 11, 300, 13, 13, 239, 17, 35, 11, 15, 13, 13, 14, 15, 13, 11, 11, 17, 17, 13, 15, 13, 45, 8, 12, 13, 12, 19, 22, 16, 33, 16, 10], "policy_red_0_reward": [1.455, 1.464, 1.458, 1.4409999999999998, 1.4489999999999998, 1.455, 1.4369999999999998, 1.452, 1.452, 1.455, 1.4449999999999998, 1.467, 1.458, 1.452, 1.464, 0.883, 1.439, 1.446, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.455, 1.455, 1.4609999999999999, 0.572, 0.958, 1.4609999999999999, 0.96, 1.4609999999999999, 1.455, 1.464, 1.467, 1.455, 1.455, 1.4729999999999999, 1.47, 1.47, 1.4609999999999999, 1.458, 1.446, 1.443, 1.4609999999999999, 1.4609999999999999, 1.467, 1.4609999999999999, 1.376, 1.458, 1.443, 1.464, 1.458, -1.0, 1.464, 1.455, 1.4609999999999999, 1.464, 1.455, 1.458, 1.4609999999999999, -1.0, 1.455, 1.467, 1.455, 1.467, 1.4489999999999998, 1.4609999999999999, 1.458, 1.467, 1.452, 1.47, -0.5, 1.458, 1.4609999999999999, 1.4449999999999998, 1.47, 1.464, 1.464, 1.467, 1.458, 1.4489999999999998, 1.446, 1.446, 1.4609999999999999, 1.458, 1.455, 1.458, 1.458, 0.974, 1.464, 1.467, 1.4609999999999999, 1.397, 1.467, 1.455, 1.47, 1.467, 1.4729999999999999, 1.432, 1.464, 1.4729999999999999, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.467, 1.452, 1.4489999999999998, 1.464, 1.47, 1.448, 1.428, 1.47, 1.4609999999999999, 1.455, 1.467, 1.464, 1.452, 1.467, 1.4609999999999999, 1.455, 1.4609999999999999, 1.443, 1.4609999999999999, 1.4609999999999999, 1.455, 0.6359999999999999, 0.948, 1.4609999999999999, 0.952, 1.452, 1.434, 1.464, 0.742, 1.458, 1.395, 1.4489999999999998, 1.467, 1.446, 1.4609999999999999, 1.467, 1.458, 1.4609999999999999, 1.446, 1.467, 1.455, 1.446, 1.464, 1.467, 1.467, 1.454, 0.964, 1.464, 1.455, 1.4609999999999999, 1.4609999999999999, 1.458, 1.464, 1.467, 1.434, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.458, 1.467, 1.455, 1.4569999999999999, 1.385, 1.4609999999999999, -0.504, 1.4609999999999999, 1.464, 1.446, 1.467, 0.482, 1.4609999999999999, 1.4609999999999999, 0.783, 1.446, 1.393, 1.467, 1.455, 1.4609999999999999, 1.4609999999999999, 1.458, -1.001, 0.96, 1.467, 1.467, 1.4489999999999998, 1.4489999999999998, 1.4609999999999999, 1.455, 1.4609999999999999, 1.3599999999999999, 0.976, 1.464, 1.4609999999999999, 1.464, 1.4409999999999998, 1.434, 1.452, 1.401, 1.452, 1.47], "policy_blue_0_reward": [-1.003, -1.004, -1.001, -0.002, -0.002, -0.003, -0.004, -1.0019999999999998, -1.005, -1.003, 0.0, -1.004, -1.002, -0.003, -1.001, -1.004, 0.0, -0.003, -1.001, -0.003, -0.002, -0.002, -1.002, -1.005, -0.544, -1.001, -1.0, -1.003, -1.004, -0.001, -1.001, -1.001, -0.001, -0.006, -1.0, -1.002, -1.002, -1.003, -1.003, -0.004, -1.0, -0.003, -1.001, -1.002, -1.0, -1.006, -0.001, -0.003, -1.0, -1.004, 0.961, -1.001, -1.0019999999999998, -1.003, -1.003, -1.001, -1.001, -0.001, 0.982, -0.001, -1.002, -0.002, -1.003, -0.005, -1.0, 0.498, -1.001, -1.002, -1.001, 0.856, -0.001, -1.003, -1.004, -1.0, -1.002, -1.002, -1.003, -1.003, -1.002, -0.003, -0.008, -1.001, -0.004, -0.001, -0.003, -1.003, -1.028, -1.003, -1.002, -1.003, -0.004, -1.0, -1.003, -1.001, -0.501, -1.002, -1.001, -1.003, -1.002, -1.002, -1.002, -0.001, -1.002, -0.001, 0.499, -1.002, -1.001, -0.004, -0.002, -1.0, -0.003, -1.003, -1.001, -1.002, -0.004, -1.001, -1.001, -1.001, -0.002, 0.5, -1.003, -0.005, -1.002, -1.011, -1.001, -0.001, -1.004, -1.001, -1.0039999999999998, -1.0, -0.513, -1.002, -0.004, 0.0, -1.002, -1.003, -0.002, -1.002, -1.002, -0.002, -0.004, -1.003, -0.002, -1.007, -1.0, -1.001, -1.002, -1.0, -1.002, -1.0039999999999998, -0.001, -1.001, -0.002, -1.002, -1.003, -1.0, -0.003, -1.0019999999999998, -0.001, -1.001, -0.003, -0.5, -0.001, -1.001, -0.006, -1.001, 0.871, -0.001, -1.0039999999999998, -1.0, -1.001, 0.45399999999999996, -1.001, -0.003, -1.043, -1.003, -1.002, -1.005, -0.003, -0.002, -1.004, -0.002, 0.95, -1.0039999999999998, -1.003, -1.004, -0.003, -1.004, -0.001, -0.003, -1.002, -1.006, -1.001, -1.002, -0.004, -1.003, -1.004, -0.003, 0.0, -0.008, -0.501, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2480201286268195, "mean_inference_ms": 1.476422420871703, "mean_action_processing_ms": 0.06316500394683622, "mean_env_wait_ms": 0.08887562513464561, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019388505727937905, "StateBufferConnector_ms": 0.0014322228951029257, "ViewRequirementAgentConnector_ms": 0.031225161977333597}}, "episode_reward_max": 1.956, "episode_reward_min": -0.3750000000000001, "episode_reward_mean": 0.7553762376237625, "episode_len_mean": 20.623762376237625, "episodes_this_iter": 202, "policy_reward_min": {"red_0": -1.001, "blue_0": -1.043}, "policy_reward_max": {"red_0": 1.4729999999999999, "blue_0": 0.982}, "policy_reward_mean": {"red_0": 1.3568267326732673, "blue_0": -0.6014504950495049}, "hist_stats": {"episode_reward": [0.45199999999999996, 0.45999999999999996, 0.45699999999999985, 1.439, 1.447, 1.452, 1.433, 0.4500000000000002, 0.44700000000000006, 0.45199999999999996, 1.4449999999999998, 0.4630000000000001, 0.45599999999999996, 1.4489999999999998, 0.4630000000000001, -0.121, 1.439, 1.443, 0.45999999999999996, 1.4460000000000002, 1.447, 1.4529999999999998, 0.45299999999999985, 0.45599999999999996, 0.028000000000000025, -0.04300000000000004, 0.46099999999999985, -0.04300000000000004, 0.45699999999999985, 1.454, 0.4630000000000001, 0.46599999999999997, 1.454, 1.4489999999999998, 0.47299999999999986, 0.46799999999999997, 0.46799999999999997, 0.45799999999999996, 0.45500000000000007, 1.442, 0.44300000000000006, 1.458, 0.45999999999999996, 0.46499999999999986, 0.46099999999999985, 0.3700000000000001, 1.4569999999999999, 1.44, 0.46399999999999997, 0.45399999999999996, -0.038999999999999924, 0.4630000000000001, 0.45300000000000007, 0.45799999999999996, 0.46099999999999985, 0.45399999999999996, 0.45699999999999985, 1.46, -0.018000000000000016, 1.454, 0.46499999999999986, 1.453, 0.46399999999999997, 1.444, 0.46099999999999985, 1.956, 0.46599999999999997, 0.44999999999999996, 0.46899999999999986, 0.356, 1.4569999999999999, 0.45799999999999996, 0.44099999999999984, 0.47, 0.46199999999999997, 0.46199999999999997, 0.46399999999999997, 0.45500000000000007, 0.44700000000000006, 1.443, 1.438, 0.45999999999999996, 1.454, 1.4540000000000002, 1.455, 0.45500000000000007, -0.05400000000000005, 0.46099999999999985, 0.46499999999999986, 0.45799999999999996, 1.393, 0.4670000000000001, 0.45199999999999996, 0.46899999999999986, 0.966, 0.4710000000000001, 0.43100000000000005, 0.4610000000000001, 0.4710000000000001, 0.4590000000000001, 0.44700000000000006, 1.46, 0.46499999999999986, 1.451, 1.948, 0.46199999999999997, 0.46899999999999986, 1.444, 1.426, 0.47, 1.458, 0.45199999999999996, 0.46599999999999997, 0.46199999999999997, 1.448, 0.46599999999999997, 0.45999999999999996, 0.45399999999999996, 1.459, 1.943, 0.45799999999999996, 1.456, 0.45299999999999985, -0.3750000000000001, -0.05300000000000005, 1.46, -0.052000000000000046, 0.45100000000000007, 0.43000000000000016, 0.46399999999999997, 0.2290000000000001, 0.45599999999999996, 1.391, 1.4489999999999998, 0.46499999999999986, 0.44300000000000006, 1.459, 0.46499999999999986, 0.45599999999999996, 1.459, 1.442, 0.46399999999999997, 1.453, 0.43900000000000006, 0.46399999999999997, 0.46599999999999997, 0.46499999999999986, 0.45399999999999996, -0.038000000000000034, 0.45999999999999996, 1.454, 0.45999999999999996, 1.459, 0.45599999999999996, 0.4610000000000001, 0.4670000000000001, 1.431, 0.4590000000000001, 1.46, 0.45999999999999996, 1.455, 0.9670000000000001, 1.454, 0.45599999999999996, 1.379, 0.45999999999999996, 0.367, 1.46, 0.45999999999999996, 0.44599999999999995, 0.4660000000000002, 0.9359999999999999, 0.45999999999999996, 1.458, -0.26, 0.44300000000000006, 0.391, 0.46199999999999997, 1.452, 1.459, 0.45699999999999985, 1.456, -0.051000000000000045, -0.04399999999999993, 0.46399999999999997, 0.4630000000000001, 1.446, 0.44499999999999984, 1.46, 1.452, 0.4590000000000001, 0.3540000000000001, -0.025000000000000022, 0.46199999999999997, 1.4569999999999999, 0.46099999999999985, 0.43699999999999983, 1.431, 1.452, 1.393, 0.9510000000000001, 0.47], "episode_lengths": [15, 12, 14, 19, 17, 15, 21, 16, 16, 15, 18, 11, 14, 16, 12, 38, 20, 18, 13, 17, 17, 15, 15, 13, 294, 14, 13, 13, 13, 15, 12, 11, 15, 15, 9, 10, 10, 13, 14, 18, 19, 13, 13, 11, 13, 36, 14, 19, 12, 14, 12, 12, 15, 13, 12, 15, 14, 13, 6, 15, 11, 15, 11, 17, 13, 14, 11, 16, 10, 46, 14, 13, 18, 10, 12, 12, 11, 14, 17, 18, 18, 13, 14, 15, 14, 14, 175, 12, 11, 13, 34, 11, 15, 10, 11, 9, 22, 12, 9, 13, 17, 13, 11, 16, 17, 12, 10, 17, 24, 10, 13, 15, 11, 12, 16, 11, 13, 15, 13, 19, 13, 13, 15, 99, 17, 13, 16, 16, 22, 12, 86, 14, 35, 17, 11, 18, 13, 11, 14, 13, 18, 11, 15, 18, 12, 11, 11, 15, 12, 12, 15, 13, 13, 14, 12, 11, 22, 13, 13, 13, 14, 11, 15, 14, 38, 13, 41, 13, 12, 18, 11, 300, 13, 13, 239, 17, 35, 11, 15, 13, 13, 14, 15, 13, 11, 11, 17, 17, 13, 15, 13, 45, 8, 12, 13, 12, 19, 22, 16, 33, 16, 10], "policy_red_0_reward": [1.455, 1.464, 1.458, 1.4409999999999998, 1.4489999999999998, 1.455, 1.4369999999999998, 1.452, 1.452, 1.455, 1.4449999999999998, 1.467, 1.458, 1.452, 1.464, 0.883, 1.439, 1.446, 1.4609999999999999, 1.4489999999999998, 1.4489999999999998, 1.455, 1.455, 1.4609999999999999, 0.572, 0.958, 1.4609999999999999, 0.96, 1.4609999999999999, 1.455, 1.464, 1.467, 1.455, 1.455, 1.4729999999999999, 1.47, 1.47, 1.4609999999999999, 1.458, 1.446, 1.443, 1.4609999999999999, 1.4609999999999999, 1.467, 1.4609999999999999, 1.376, 1.458, 1.443, 1.464, 1.458, -1.0, 1.464, 1.455, 1.4609999999999999, 1.464, 1.455, 1.458, 1.4609999999999999, -1.0, 1.455, 1.467, 1.455, 1.467, 1.4489999999999998, 1.4609999999999999, 1.458, 1.467, 1.452, 1.47, -0.5, 1.458, 1.4609999999999999, 1.4449999999999998, 1.47, 1.464, 1.464, 1.467, 1.458, 1.4489999999999998, 1.446, 1.446, 1.4609999999999999, 1.458, 1.455, 1.458, 1.458, 0.974, 1.464, 1.467, 1.4609999999999999, 1.397, 1.467, 1.455, 1.47, 1.467, 1.4729999999999999, 1.432, 1.464, 1.4729999999999999, 1.4609999999999999, 1.4489999999999998, 1.4609999999999999, 1.467, 1.452, 1.4489999999999998, 1.464, 1.47, 1.448, 1.428, 1.47, 1.4609999999999999, 1.455, 1.467, 1.464, 1.452, 1.467, 1.4609999999999999, 1.455, 1.4609999999999999, 1.443, 1.4609999999999999, 1.4609999999999999, 1.455, 0.6359999999999999, 0.948, 1.4609999999999999, 0.952, 1.452, 1.434, 1.464, 0.742, 1.458, 1.395, 1.4489999999999998, 1.467, 1.446, 1.4609999999999999, 1.467, 1.458, 1.4609999999999999, 1.446, 1.467, 1.455, 1.446, 1.464, 1.467, 1.467, 1.454, 0.964, 1.464, 1.455, 1.4609999999999999, 1.4609999999999999, 1.458, 1.464, 1.467, 1.434, 1.4609999999999999, 1.4609999999999999, 1.4609999999999999, 1.458, 1.467, 1.455, 1.4569999999999999, 1.385, 1.4609999999999999, -0.504, 1.4609999999999999, 1.464, 1.446, 1.467, 0.482, 1.4609999999999999, 1.4609999999999999, 0.783, 1.446, 1.393, 1.467, 1.455, 1.4609999999999999, 1.4609999999999999, 1.458, -1.001, 0.96, 1.467, 1.467, 1.4489999999999998, 1.4489999999999998, 1.4609999999999999, 1.455, 1.4609999999999999, 1.3599999999999999, 0.976, 1.464, 1.4609999999999999, 1.464, 1.4409999999999998, 1.434, 1.452, 1.401, 1.452, 1.47], "policy_blue_0_reward": [-1.003, -1.004, -1.001, -0.002, -0.002, -0.003, -0.004, -1.0019999999999998, -1.005, -1.003, 0.0, -1.004, -1.002, -0.003, -1.001, -1.004, 0.0, -0.003, -1.001, -0.003, -0.002, -0.002, -1.002, -1.005, -0.544, -1.001, -1.0, -1.003, -1.004, -0.001, -1.001, -1.001, -0.001, -0.006, -1.0, -1.002, -1.002, -1.003, -1.003, -0.004, -1.0, -0.003, -1.001, -1.002, -1.0, -1.006, -0.001, -0.003, -1.0, -1.004, 0.961, -1.001, -1.0019999999999998, -1.003, -1.003, -1.001, -1.001, -0.001, 0.982, -0.001, -1.002, -0.002, -1.003, -0.005, -1.0, 0.498, -1.001, -1.002, -1.001, 0.856, -0.001, -1.003, -1.004, -1.0, -1.002, -1.002, -1.003, -1.003, -1.002, -0.003, -0.008, -1.001, -0.004, -0.001, -0.003, -1.003, -1.028, -1.003, -1.002, -1.003, -0.004, -1.0, -1.003, -1.001, -0.501, -1.002, -1.001, -1.003, -1.002, -1.002, -1.002, -0.001, -1.002, -0.001, 0.499, -1.002, -1.001, -0.004, -0.002, -1.0, -0.003, -1.003, -1.001, -1.002, -0.004, -1.001, -1.001, -1.001, -0.002, 0.5, -1.003, -0.005, -1.002, -1.011, -1.001, -0.001, -1.004, -1.001, -1.0039999999999998, -1.0, -0.513, -1.002, -0.004, 0.0, -1.002, -1.003, -0.002, -1.002, -1.002, -0.002, -0.004, -1.003, -0.002, -1.007, -1.0, -1.001, -1.002, -1.0, -1.002, -1.0039999999999998, -0.001, -1.001, -0.002, -1.002, -1.003, -1.0, -0.003, -1.0019999999999998, -0.001, -1.001, -0.003, -0.5, -0.001, -1.001, -0.006, -1.001, 0.871, -0.001, -1.0039999999999998, -1.0, -1.001, 0.45399999999999996, -1.001, -0.003, -1.043, -1.003, -1.002, -1.005, -0.003, -0.002, -1.004, -0.002, 0.95, -1.0039999999999998, -1.003, -1.004, -0.003, -1.004, -0.001, -0.003, -1.002, -1.006, -1.001, -1.002, -0.004, -1.003, -1.004, -0.003, 0.0, -0.008, -0.501, -1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.2480201286268195, "mean_inference_ms": 1.476422420871703, "mean_action_processing_ms": 0.06316500394683622, "mean_env_wait_ms": 0.08887562513464561, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.019388505727937905, "StateBufferConnector_ms": 0.0014322228951029257, "ViewRequirementAgentConnector_ms": 0.031225161977333597}, "num_healthy_workers": 10, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000, "num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 4000, "num_env_steps_sampled_throughput_per_sec": 102.65764160746984, "num_env_steps_trained_throughput_per_sec": 102.65764160746984, "timesteps_total": 284000, "num_steps_trained_this_iter": 4000, "agent_timesteps_total": 568000, "timers": {"training_iteration_time_ms": 38915.781, "sample_time_ms": 7564.412, "learn_time_ms": 31333.917, "learn_throughput": 127.657, "synch_weights_time_ms": 16.949}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 284000, "num_agent_steps_sampled": 568000, "num_agent_steps_trained": 568000}, "done": false, "episodes_total": 9035, "training_iteration": 71, "trial_id": "d67e4_00000", "date": "2023-09-20_22-55-28", "timestamp": 1695264928, "time_this_iter_s": 38.97235321998596, "time_total_s": 2762.7930331230164, "pid": 90908, "hostname": "str-mac-5031", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "MultiGrid-CompetativeRedBlueDoor-v3-DTDE-1v1", "env_config": {"size": 8, "allow_agent_overlap": false, "has_obsticle": false, "death_match": true, "teams": {"red": 1, "blue": 1}, "agents": 2, "training_scheme": "DTDE", "reward_schemes": {"red_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}, "blue_0": {"eliminated_opponent_sparse_reward": 0.5, "key_pickup_sparse_reward": 0.5, "ball_pickup_dense_reward": 0.5, "dense_reward_discount_factor": {"ball_carrying_discount_factor": 0.9}, "invalid_pickup_dense_penalty": 0.001}}, "randomization": true, "max_steps": 300}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "is_atari": false, "auto_wrap_old_gym_envs": true, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "lr_schedule": null, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [64, 64], "fcnet_activation": "tanh", "conv_filters": [[16, [3, 3], 1], [32, [3, 3], 1], [64, [3, 3], 1]], "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "<class 'multigrid.rllib.models.TorchModel'>", "custom_model_config": {"teams": {"red": 1, "blue": 1}, "training_scheme": "DTDE"}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "policy_states_are_swappable": false, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": 0, "worker_cls": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "replay_sequence_length": null, "horizon": -1, "soft_horizon": -1, "no_done_at_end": -1, "use_critic": true, "use_gae": true, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 0.5, "entropy_coeff": 0.001, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 1.0, "kl_target": 0.01, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 0.5, "input": "sampler", "multiagent": {"policies": "{'red_0', 'blue_0'}", "policy_mapping_fn": "<function algorithm_config.<locals>.<lambda> at 0x2a6878e50>", "policies_to_train": ["red_0"], "policy_map_capacity": 100, "policy_map_cache": -1, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'multigrid.utils.training_utilis.EvaluationCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 10}, "time_since_restore": 2762.7930331230164, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 34.455357142857146, "ram_util_percent": 50.43392857142857}}
